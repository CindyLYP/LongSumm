[{"blog_id": "diplomat-using-delegations-to-protect-community-repositories", "summary": ["Diplomat: Using Delegations to Protect Community Repositories \u2013 Kuppusamy et al. 2016  Community repositories, such as Docker Hub, Python Package Index (PyPI), RubyGems, and SourceForge provide an easy way for a developer to disseminate software\u2026 [they] are immensely popular and collectively serve more than a billion packages per year.", "Unfortunately, the popularity of these repositories also makes them an attractive target to hackers\u2026 Major repositories run by Adobe, Apache, Debian, Fedora, FreeBSD, Gentoo, GitHub, GNU Savannah, Linux, Microsoft, npm, Opera, PHP, RedHat, RubyGems, SourceForge, and WordPress have all been compromised at least once.", "This is a topic of immediate importance.", "Diplomat is a practical security system for community repositories that combines immediate project registration (adding new projects happens all the time with popular repositories) and compromise-resilience.", "Diplomat source code and standards documents are freely available at  [url]"], "author_id": "ACOLYER", "pdf_url": "https://isis.poly.edu/%7Ejcappos/papers/kuppusamy_nsdi_16.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 34524227}, {"blog_id": "the-network-is-reliable", "summary": ["The Network is Reliable \u2013 Bailis and Kingsbury 2014  This must be the easiest paper summary to write of the series so far.", "The network is reliable?", "Oh no it isn\u2019t\u2026  OK, here\u2019s a little more detail :)  Network reliability matters because it prevents us from having reliable communication, and that in turn makes building distributed systems really hard.", "(Fallacy #1 in Peter Deutsch\u2019s \u2018 Eight fallacies of distributed computing \u2018 is \u2018The network is reliable\u2019).", "In fact, if we look at this list for a moment we can see that the top three fallacies all correspond to interesting failure modes in networks as well as being something you have to take into account in the happy paths.", "Sudden large latency spikes for example can be very disruptive to fault detectors, and noisy network neighbours might consume lots of your bandwidth.", "The network is reliable.", "Latency is zero.", "Bandwidth is infinite.", "The network is secure.", "Topology doesn\u2019t change.", "There is one administrator.", "Transport cost is zero.", "The network is homogeneous.", "No.", "5 is also something we\u2019ve had to learn to accommodate to a whole new degree with cloud deployments.", "Topology changing all the time is the norm.", "If we can assume that \u2018the network is reliable enough,\u2019 then it might make sense as an engineering trade-off to become unavailable in the event of a partition.", "I\u2019ve heard the argument made that \u2018partitions only happen in the cloud,\u2019 we never really see them in practice in our own data centers.", "Conscious trade-off or not, the work of one of the authors of this paper, Kyle Kingsbury, on the wonderful Jepsen Reports shows that many real-world systems struggle with partitions.", "The degree of reliability in deployment environments is critical in robust systems design and directly determines the kinds of operations that systems can reliably perform without waiting.", "Unfortunately, the degree to which networks are actually reliable in the real world is the subject of considerable and evolving debate.", "Some people have claimed that networks are reliable (or that partitions are rare enough in practice) and that we are too concerned with designing for theoretical failure modes.", "Conversely, others attest that partitions do occur in their deployments\u2026  We have some pretty good statistics on disk, host, and rack failure rates, but not so much on network failures.", "Yet network failures can be much more disruptive than a disk failure for example.", "As a result, much of what we believe about the failure modes of real-world distributed systems is founded on guesswork and rumor.", "Sysadmins and developers will swap stories over beer, but detailed, public postmortems and comprehensive surveys of network availability are few and far between.", "In this article, we\u2019d like to informally bring a few of these stories (which, in most cases, are unabashedly anecdotal) together\u2026  There follows a long collection of stories of every kind of network failure you can imagine.", "It\u2019s the cumulative effect that gets you as you read through \u2013 start off on page 2 thinking \u2018yeah ok, isolated scenario(s)\u2019, but the stories keep coming and coming and coming.", "By the time you get to page 12, you\u2019ve probably come to the conclusion that Murphy must have been working as a network engineer at the time he formulated his famous law!", "Split-brains, partitions, device failures, link failures, high rates of packet loss, maintenance and admin issues, and more are all in here \u2013 resulting in comedies of errors in the systems built on top of them that would be fit for a christmas pantomine if the consequences weren\u2019t so severe!", "This reads like a skit from a comedy show:  This 90-second network partition caused file servers using Pacemaker and DRBD (Distributed Replicated Block Device) for HA (high availability) failover to declare each other dead, and to issue STONITH (shoot the other node in the head) messages to one another.", "The network partition delayed delivery of those messages, causing some file-server pairs to believe they were both active.", "When the network recovered, both nodes shot each other at the same time.", "With both nodes dead, files belonging to the pair were unavailable.", "You really do need to read through the paper to get the overall impression, a summary cannot do it justice.", "As a consequence of all this:  Split-brain is not an academic concern: it happens to all kinds of systems\u2014sometimes for days on end.", "Partitions deserve serious consideration\u2026 It\u2019s important to consider this risk before a partition occurs, because it\u2019s much easier to make decisions about partition behavior on a whiteboard than to redesign, reengineer, and upgrade a complex system in a production environment\u2014especially when it\u2019s throwing errors at your users.", "For some applications, failure is an option\u2014but you should characterize and explicitly account for it as a part of your design.", "Finally, given the additional latency and coordination benefits of partition-aware designs, you might just find that accounting for these partitions delivers benefits in the average case as well.", "The authors also acknowledge that there might be reliable networks out there:  On the other hand, some networks really are reliable.", "Engineers at major financial firms have anecdotally reported that despite putting serious effort into designing systems that gracefully tolerate partitions, their networks rarely, if ever, exhibit partition behavior.", "Cautious engineering and aggressive network advances (along with lots of money) can prevent outages.", "Moreover, in this article, we have presented failure scenarios; we acknowledge it\u2019s much harder to demonstrate that network failures have not occurred.", "But if I was thinking about future architectures and cloud deployments, I wouldn\u2019t want to rely on it ;)."], "author_id": "ACOLYER", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2639988.2655736?download=true", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 12642073}, {"blog_id": "combining-static-model-checking-with-dynamic-enforcement-using-the-statecall-policy-language", "summary": ["Combining static model checking with dynamic enforcement using the Statecall Policy Language \u2013 Madhavapeddy 2009  We know that getting distributed systems right is hard, and subtle, \u2018deep\u2019 bugs can lurk in both algorithms and implementations.", "Can we do better than informal reasoning coupled with some unit and integration tests?", "Evidence suggests we have to do better!", "We\u2019ve previously looked at Amazon\u2019s use of TLA+ , and today\u2019s selection is the first of three papers I\u2019ve selected to probe deeper into this issue.", "Today\u2019s choice looks at the Statecall Policy Language (SPL) that was used by Howard et al. in Raft refloated to validate their Raft implementation.", "In the next two days we\u2019ll also be looking at distributed model checking made practical with SAMC, and pitting our wits against Molly with Peter Alvaro\u2019s \u2018Lineage Driven Fault Injection.\u2019  The Statecall Policy Language (SPL) was designed to make model checking more accessible to regular programmers.", "Models are specified in terms of allowable sequences of program events, and the SPL model can then be translated by a compiler into a variety of forms.", "These include:  A translation into PROMELA ,  which can then be used with SPIN to check static properties of the model.", "A graphical visualization using GraphViz.", "Generated code in your target implementation language (OCaml backend is currently implemented, but the design allows for others) that enables run-time validation (i.e. ensures that the real-world behaviour is not deviating from the model).", "Also known as a safety monitor.", "Debugging stubs to support an HTML and Javascript debugging view giving a real-time window into all the automata embedded in the program.", "Writing as of 2009, Madhavapeddy states:  None of the major implementations of protocols such as HTTP (Apache), SMTP (Sendmail/Postfix), or DNS (BIND) are regularly model-checked by their development teams.", "All of them regularly suffer from serious security flaws ranging from low-level buffer overflows to subtle high-level protocol errors, some of which could have been caught by using model checking.", "(We\u2019ll see more examples of verification techniques finding meaningful real-world bugs over the next two days).", "Here\u2019s an SPL model for ping that supports the -c n (only send n packets in total) and -w (wait instead of timing out) flags/behaviours.", "01 automaton ping (int max_count, int count, bool can_timeout) { 02   Initialize; 03   during { 04     count = 0; 05     do { 06       Transmit_Ping; 07       either { 08         Receive_Ping; 09       } or (can_timeout) { 10         Timeout_Ping; 11       }; 12       count = count + 1; 13     } until (count &gt;= max_count); 14   } handle { 15     SIGINFO; 16     Print_Summary; 17   }; 18 }  The Statecalls begin with an initial capital letter: Initialize, Transmit_Ping, Receive_Ping, Timeout_Ping, and Print_Summary.", "The automaton defines the allowable sequences of statecalls.", "Signal handlers are often a source of bugs due to their extremely asynchronous nature \u2014 SPL provides a during/handle construct (used in the example above, see the lines 03 and 14) which models them by permitting a state transition into alternative statement blocks during normal execution of an SPL specification.", "Once you are satisfied with the SPL model you can run the SPL compiler.", "The generated code for the executable model can be linked with the real ping implementation.", "You can \u2018even do this manually\u2019 if you really want to!", "This code is linked in with the main ping application, and appropriate calls to initialize the automaton and invoke statecalls are inserted in the code.", "Crucially, we do not mandate a single style of invoking statecalls; instead the programmer can choose between automatic mechanisms (e.g. MPL packet parsing code can automatically invoke statecalls when transmitting or receiving packets), language-assisted means (e.g.", "functional combinators, object inheritance, or pre-processors such as cpp), or even careful manual insertion in places where other methods are inconvenient.", "Underneath the covers, SPL translates models into an intermediate form based on a Control Flow Automata (CFA) graph.", "For more complex protocols, it is possible to \u2018divide-and-conquer\u2019 :  It is often more convenient and readable to break down a complex protocol into smaller blocks which express the same protocol but with certain aspects factored out into simpler state machines.", "Accordingly, SPL specifications can define multiple automata, but the external interface hides this abstraction and only exposes a single, flat set of statecalls.", "Each automaton then executes in parallel, received statecalls are only dispatched to automata which include the statecall in their alphabet.", "The debugging support is a nice touch (see screenshot below):  This page contains a real-time graphical view of all the automata embedded in the program, along with the set of valid states they can transition to next.", "Since the granularity of the SPL automata are chosen by the programmer, this is much more useful than the \u201craw\u201d models obtained through static code analysis which often include a lot of superfluous information.", "Figure 5 shows a screen capture of the SPL AJAX debugger single-stepping through the global SPL automaton for theMelange SSH server.", "The mlssh server is blocked waiting for password authentication, having previously attempted to authenticate via null and public-key authentication.", "In our experience, the debugger was a valuable tool to debug complex protocol bugs in our implementation, as the single-stepping view via this debugger is significantly higher level than the alternative provided by either the native OCaml debugger or gdb."], "author_id": "ACOLYER", "pdf_url": "http://anil.recoil.org/papers/2009-icfem-spl.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 29796623}, {"blog_id": "what-bugs-cause-cloud-production-incidents", "summary": ["What bugs cause production cloud incidents?", "Liu et al., HotOS\u201919  Last time out we looked at SLOs for cloud platforms , today we\u2019re looking at what causes them to be broken!", "This is a study of every high severity production incident at Microsoft Azure services over a span of six months, where the root cause of that incident was a software bug.", "In total, there were 112 such incidents over the period March \u2013 September 2018 (not all of them affecting external customers).", "Software bugs are the most common cause of incidents during this period, accounting for around 40% of all incidents (so we can infer there were around 280 incidents total in the pool).", "The 112 incidents caused by software bugs are further broken down into categories, with data-format bugs, fault-related bugs, timing bugs, and constant_value bugs being the largest categories.", "Interestingly, outages caused by configuration errors represented only a small number of incidents in this study.", "This could be an artefact of that data set in some way, or it might be due to the tool chain that Microsoft uses:  The types of bugs we observed in production are biased by the fact that Microsoft uses effective tools to mostly eliminate many types oft bugs before they can manifest in production, and hence our study includes zero or few of such bugs.", "For example, we observed only a small number of configuration bugs caused by mis-specification of configuration entries in configuration files, even though such bugs were reported to be common in other settings.", "Most Azure code is written in .Net managed languages such as C#, reducing memory leak bugs.", "Tools like CHESS and PCT are used to expose shared-memory concurrency bugs.", "TLA+ is used to model concurrent and distributed system protocols helping to eliminate high level design and semantic bugs.", "In addition, Azure\u2019s Fault Analysis Service supports various types of fault injections during testing, such as node restart, data migration,  and random faults.", "Microsoft is also using fuzz testing, cloud contract checking, and network configuration verification tools.", "Data formats  Of the software bugs that survive all of this and end up causing high severity incidents, one of.", "the most common causes are data format change (21%).", "Different components of cloud services interact with each other through various types of \u201cdata\u201d, including inter-process/node messages, persistent files, and so on.", "At the same time, cloud software goes through frequent updates.", "As a result, different software components in the cloud could hold conflicting assumptions about the format of certain data, leading to service incidents.", "It looks like data validation isn\u2019t only useful in a machine learning context !", "All but one of the data format bugs involved multiple processes or nodes.", "In 40% of cases different parties assume different formats for shared files or database tables.", "For example, an upgrade has been deployed to a component \u2018owning\u2019 the table which changes the schema.", "The other 60% of cases are caused by a service changing the interface of its external message APIs.", "For example, a service that used to return 200 together with an empty list when no results were found changes to returning a 404, and breaks existing clients.", "The large scale, frequent updates, and long running nature of cloud services likely have facilitated the occurrence of these bugs.", "I\u2019d expect this class of bugs to also surface in microservices systems.", "Does that match your experience?", "Fault related  Next up is an old chestnut: error and exception handling faults (31%).", "Components that fail and report an error that can\u2019t be handled (e.g., missing exception handlers) (43% of this category)  Unresponsive components that hang and are not picked up by fault-detection mechanisms, leading to user-visible timeouts (29% of this category)  Silent corruption of data with no error detection code in place, leading to incorrect results returned to users (17% of this category)  Exception / error handlers contribute to the incidents by either ignoring error reports (35%), over-reacting (35%), or containing bugs within the handlers themselves leading to infinite loops, timing issues, and so on (30%).", "Timing incidents  13% of the incidents are related to timing, with only 14% of the timing incidents actually recorded as deadlocks.", "Compared to classic timing bugs racing between threads in the same process, here many of these bugs are about race conditions between multiple nodes and many of them are racing on persistent data like cached firewall rules, configuration, database tables, and so on.", "Constant-value setting incidents  7% of all software bug incidents are caused by mistakes in constants: hard-code configuration, special purpose strings such as URLs, and enum-typed values.", "Bug resolution  Facing tight time pressure, more often than not, software bug incidents were resolved through a variety of mitigation techniques (56%) without patching the buggy code (44%), providing quick solutions to users and maximizing service availability.", "(Mitigated incidents may well have been followed up later with code changes, but these aren\u2019t recorded in the respective incident reports).", "When mitigating there are three main types of mitigation uncovered:  Code mitigation involves rolling back to an earlier version of the software  Data mitigation involves manually restoring, cleaning up, or deleting data in a file, table, etc.", "Environment mitigation involves killing and restarting processes, migrating workloads, adding fail-over resources, etc..", "When mitigating, environment mitigations are the most common.", "Although the kind of mitigate employed does vary based on root cause:  Much recent work looked at how to automatically generate new patches.", "In comparison, automatically generating mitigation steps has not been well studied and is worth more attention in the future."], "author_id": "ACOLYER", "pdf_url": "https://people.cs.uchicago.edu/~shanlu/paper/hotos19_azure.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 48091191}, {"blog_id": "the-semantic-elegance-of-applicative-languages", "summary": ["The Semantic Elegance of Applicative Languages \u2013 Turner \u201981.", "Here\u2019s a paper you can enjoy simply for its prose!", "In what does the alleged superiority of applicative languages consist?", "In what indeed!", "And while we\u2019re at it, what\u2019s an applicative language?", "I looked up a few definitions; if we call it a functional language I don\u2019t think we\u2019ll go too far wrong.", "Let us resume\u2026  In what does the alleged superiority of applicative languages consist?", "In the last analysis the answer must be in terms of the reduction in the time required to produce a correct program to solve a given problem.", "On reflection I decided that the best way to demonstrate this would be to take some reasonably non-trivial problem and show how, by proceeding within a certain kind of applicative language framework it was possible to develop a  working solution with a fraction of the effort that would have been necessary in a conventional imperative language.", "The cynical among you might be thinking: he\u2019s picked a problem that\u2019s well suited to be solved with a functional programming approach, and then shown that the functional approach is a good way of solving it!", "Even if that is true, it\u2019s still a joy to get an insight into the mind of an advanced functional programmer.", "It reminds me of one of those chess books where a great player explains what they were thinking move by move in an annotated game.", "The problem is to enumerate all of the possible paraffin molecules.", "These are made of carbon C and hydrogen H atoms.", "Each C makes 4 bonds, and paraffins don\u2019t allow double bonds or cycles.", "H                H   H     |                |   | H - C - H   ,    H - C - C - H    , ...     |                |   |     H                H   H  See the problem statement and example in the paper \u2013 it is succintly explained, and for maximum value you should pause and spend some time thinking how you would solve it before reading on.", "The tricky parts come when the \u2018C\u2019s themselves start to make complex shapes (T\u2019s etc.", "), and you need to weed out duplicates through symmetries.", "from the point of view  of a programmer who had not tried it before, the problem seemed difficult enough to be interesting.", "At least several competent programmers I know reported to me that they had found it so.", "Central to the solution is figuring out when two molecules are equivalent.", "Turner defines operations \u2018invert\u2019, \u2018rotate\u2019 and \u2018swap\u2019 which make structure-preserving changes to the shape of a molecule.", "There then follows a very elegant solution based on determining a \u2018closure under laws.\u2019  -- a and b are equivalent if b is a member of the set of  -- all equivalent representations of a...   equiv a b = member (equivclass a) b  equivclass a = closure_under_laws [rotate, invert, swap] [a]  The key idea is embodied in the function \u201cclosure under laws\u201d which takes a set of functions and a set of objects and finds the closure of the latter under repeated applications of the members of the former.", "With another neat (and commonly used) functional technique of generating an infinite list of molecules from which we can display as many as we like, the initial version of the program is complete.", "This solution, however, runs with appalling slowness (I tried it) mainly because of easily removable inefficiencies in our definition of \u201cpara\u201d.", "There is a minor problem and a major problem\u2026  The major problem is due to repeated calculation of the same sub-molecules many times over.", "Failure to memoise leads to an exponential deterioration in performance!", "For a recursive function, like \u201cpara\u201d, memoisation leads to an exponential improvement in performance.", "(or to put it another way, failure to memoise leads an exponential deterioration in performance!)", "There follows some discussion of the author\u2019s lessons learned during this exercise:  the effort needed to derive a solution can be reduced to a small fraction of that required in a traditional programming language  an applicative language (even if it\u2019s not the language used for the ultimate implementation) can be an extremely valuable tool for the development and testing of algorithms  the language supports very nicely a separation of concerns in which you first make things correct without worrying about efficiency, and then repair efficiency by applying transformations known to preserve correctness:  In a surprising large number of cases it turns out that a small number of standard optimisations are sufficient to bring about the necessary improvement in performance.", "Two in particular seem to be of such general applicability as to deserve special mention in a next (and final) section of this paper\u2026  And what are these two methods?", "Memoisation (discussed earlier), and filter promotion.", "Filter promotion is the idea that instead of generating a list containing terms we don\u2019t want, and then filtering them out (e.g. filter pred xs), push the filter predicate down into the list generator so that we don\u2019t generate the unwanted terms in the first place.", "We can get a considerable improvement in performance, however, by pushing the filter inside the generator \u201cpartitions\u201d so that the unwanted lists are not created in the first place  It\u2019s a short read, and hard to communicate the value in a summary.", "I hope I have whetted your appetite to go and read the whole paper.", "If you want to play around with the code, I ported the solution to Haskell here .", "Though I bet you can improve on my code given I\u2019m not especially fluent in Haskell\u2026"], "author_id": "ACOLYER", "pdf_url": "http://nsl.com/misc/sasl/paraffins-turner.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 88700162}, {"blog_id": "isomap", "summary": ["Tenenbaum, et al. 2000  Isomap, seemingly named for \u201cIsometric mapping\u201d, seeks to provide a solution to the problem of non-linear dimensionality reduction.", "The method is especially suitable for high-dimensional manifolds that exhibit non-Euclidean geometry, such that the Euclidean distance between data points returns distances that are not actually realistic for the underlying low-dimensional manifold.", "The intuition for this approach lies in the use of the all-pairs shortest path algorithm to improve upon Multi-dimensional scaling.", "Under general conditions on the density and curvature of the points, a geodesic distance can be estimated between far away points on the high-dimensional manifold via the all-pairs shortest path that converges to the true distance in the limit.", "Then, similar to MDS, Isomap attempts to find coordinate vectors for a low-dimensional space within which the distances between points are preserved as much as possible.", "This essentially results in the selection of the largest p eigenvectors of the matrix of estimated distances on the high-dimensional manifold (transformed to inner products).", "To make the algorithm work, the first step consists of clustering the data points either using k-NN or $\\epsilon$-balls.", "Edges are placed between all points clustered together, to form the graph upon which all-pairs shortest path is run.", "In this paper, the authors present examples of applying Isomap to a dataset of faces, MNIST, and the \u201cswiss roll\u201d dataset.", "Interestingly, they are able to map the faces dataset to a 3-D space, capturing left-right poses, up-down poses, and variations in ambient lighting.", "They show that PCA and MDS converge (the residual loss goes to 0) but they are unable to recover the true dimensionality of the low-dimensional manifold.", "This seems to be troublesome, because if one naively applies PCA to a dataset and the residual loss goes to 0, it appears then that the user of this algorithm will mistakenly believe they have recovered the true low-dimensional manifold.", "It would be interesting to then run a classifier on this low-dimensional representation produced by PCA, and then check the performance against the same classifier using the low-dimensional representation learned by Isomap.", "I imagine that the Isomap classifier will have slightly better performance."], "author_id": "pemami", "pdf_url": "https://web.mit.edu/cocosci/Papers/sci_reprint.pdf", "author_full_name": "Patrick Emami", "source_website": "https://pemami4911.github.io/index.html", "id": 18027931}, {"blog_id": "the-rise-of-the-citizen-developer-assessing-the-security-impact-of-online-app-generators", "summary": ["The rise of the citizen developer: assessing the security impact of online app generators Oltrogge et al., IEEE Security & Privacy 2018  \u201cLow code\u201d, \u201cno code\u201d, \u201ccitizen developers\u201d, call it what you will, there\u2019s been a big rise in platforms that seek to make it easy to develop applications for non-export developers.", "Today\u2019s paper choice studies the online application generator (OAG) market for Android applications.", "When what used to be a web site (with many successful web site  templating and building options around) is often in many cases now also or instead a mobile app, so it makes sense that the same kind of templating and building approach should exist there too.", "For a brief period at the end of last year, Apple flirted with banning such apps from their app store , before back-tracking just a couple of weeks after the initial announcement.", "After reading today\u2019s paper I can\u2019t help but feel that perhaps they were on to something.", "Not that templated apps are bad per se, but when the generated apps contain widespread vulnerabilities and privacy issues, then that is bad.", "With the increasing use of OAGs the duty of generating secure code shifts away from the app developer to the generator service.", "This leaves the question of whether OAGs can provide save and privacy-preserving default implementations of common tasks to generate more secure apps at an unprecedented scale.", "Being an optimist by nature, my hope was that such app generation services would improve the state of security, because spending time and effort getting it right once would pay back across all of the generated apps.", "In theory that could still happen, but in practice it seems the opposite is occurring.", "It doesn\u2019t seem to make a lot of difference whether you use a free online app generator (what are their incentives, and where does their revenue come from?", "Always good questions to ask), or a paid service, the situation is not good.", "The re-configuration attacks that the authors discover are particularly devastating.", "Online app generation services and penetration  Online application generators enable app development using wizard-like, point-and-click web interfaces in which developers only need to add and suitably interconnect UI elements that represent application components\u2026 There is no need and typically no option to write custom code.", "The authors started by searching the web for advertised online app generation platform, resulting in the set of services shown in the table below (the Como the authors refer to is I believe now called \u2018swiftic\u2019 \u2013  [url]"], "author_id": "ACOLYER", "pdf_url": "https://saschafahl.de/papers/appgens2018.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 58874274}, {"blog_id": "fran", "summary": ["Functional Reactive Animation \u2013 Elliott & Hudak 1997  This is the paper widely acknowledged to have given birth to (Functional) Reactive Programming or FRP.", "The challenge that Elliott and Hudak faced was to provide an elegant and expressive way to specify animations without resorting to tedious frame-by-frame constructions.", "A key insight is that animations are all about how something changes over time, and time is conceptually continuous.", "Fran makes the notion of continuous behaviours first class in the programming model.", "The construction of richly interactive multimedia animations (involving audio, pictures, video, 2D and 3D graphics) has long been a complex and tedious job.", "Much of the difficulty, we believe, stems from the lack of sufficiently high-level abstractions, and in particular from the failure to clearly distinguish between modeling and presentation, or in other words, between what an animation is and how it should be presented\u2026 The benefits of a modeling approach to animation are similarto those in favor of a functional (or other declarative) programming paradigm, and include clarity, ease of construction, composability, and clean semantics.", "The modeling approach also makes animations easier to author, and easier to optimize.", "Fran is a collection of recursive data types, functions, and primitive graphics routines brought together around four central concepts: behaviors, events, declarative reactivity, and polymorphic media.", "The most novel aspect of Fran is its implicit treatment of time.", "Behaviours (temporal modeling)  A behaviour is a value that can vary over time.", "Behaviors are first-class values, and are built up compositionally; concurrency (parallel composition) is expressed naturally and implicitly.", "The simplest primitive behaviour is time itself.", "And cos time, for example,  is a behaviour  that varies as the cosine of time, created by lifting the cosine function to apply to behaviours.", "We can create a simple animation that changes the shape of a square over time as follows:  bigger (cos time) square  bigger scales its second argument by the amount specified in the first argument.", "Since the first argument is a behaviour, the result is also a behaviour.", "Using the over function as an infix operator we can place a circle on top whose size changes as the sine of time:  bigger (sin time) circle `over` bigger (cos time) square  Event Modeling  Events are also first class values in Fran.", "They can represent actual events in the external world (for example, a button press), and they can also be expressed as predicates (for example, based on proximity).", "Events are \u2018what\u2019, \u2018when\u2019 pairs.", "The when component is a lower bound on the time of the event \u2013 for examplelbp t0 represents the first left button press (\u2018what\u2019), occurring after time t0.", "Declarative reactivity  Here we see the first use of the \u2018reactive\u2019 term\u2026  Many behaviors are naturally expressed in terms of reactions to events.", "But even these \u201creactive behaviors\u201d have declarative semantics in terms of temporal composition, rather than an imperative semantics in terms of the state changes often employed in event-based formalisms.", "b `untilB` e  Exhibits behaviour b until event e occurs, after which it behaves according to the behaviour associated with e. Using this we can describe a colour cycle as follows:  colorCycle t0 =        red `untilB` lbp t0 *=> \\t1 -> green `untilB` lbp t1 *=> \\t2 -> colorCycle t2  update: fixed &gt; vs > in the above, thanks David for pointing out the issue.", "Fran is implemented in Haskell, where \\x -> \u2026 defines a lambda function with bound variable x.", "This reactive behaviour can thus be interpreted as:  show red until the first left-button press after time t0, and then  show green until the first left-button press after time t1 (the time of the previous lbp), and then  repeat the color cycle starting at time t2 (the time of the second lbp)  Polymorphic Media  The variety of time-varying media (images, video, sound, 3D geometry) and parameters of those types (spatial transformations, colors, points, vectors, numbers) have their own type-specific operations (e.g. image rotation, sound mixing, and numerical addition), but fit into a common framework of behaviors and reactivity.", "For instance, the \u201cuntilB\u201d operation used above is polymorphic, applying to all types of time-varying values.", "Examples  The paper includes a formal semantics of behaviours and events, as well as some implementation notes that describe an \u2018interval analysis\u2019 technique for detecting predicate events.", "We\u2019ll look in more detail at design and implementation considerations for reactive frameworks later this week.", "For now, let\u2019s just look at a few more code examples to get a feel for the expressivity of modeling that behaviours and events support.", "A behaviour that varies smoothly and cyclically between -1 and 1:  wiggle  = sin (pi * time)  And a behaviour that builds on this to smoothly vary between a high and low value:  wiggleRange lo hi =    lo + (hi - lo) * (wiggle + 1)/2  A red pulsating ball:  pBall = withColor red           (bigger (wiggleRange 0.5 1) circle)  Behaviours are composable, as we\u2019ve been seeing already.", "Let\u2019s use pBall as a building block\u2026  rBall = move (vectorPolar 2.0 time)               (bigger 0.1 pBall)  \u201cwhich yields a ball moving in a circular motion with radius 2.0 at a rate proportional to time.", "The ball itself is the same as pBall (red and pulsating), but 1/10 the original size.\u201d  An image that tracks the position of the mouse:  followMouse im t0 = move (mouse t0) im  As a final example, let\u2019s develop a modular program to describe \u201cbouncing balls.\u201d First note that the physical equations describing the position y and velocity v at time t of an object being accelerated by gravity g are:  where y0 and v0 are the initial position and velocity, respectively of the object at time t0.", "In Fran these equations are simply:  y = lift0 y0 + integral v t0 x = lift0 v0 + integral g t0  update: corrected typo in the x expression, thanks to zteve for pointing it out.", "Next we define a function bounce that, in addition to computing the position of an object based on the above equations, also determines when the ball has hit either the floor or the ceiling, and if so reverses the direction of the ball while reducing its velocity by a certain reciprocity, to account for loss of energy during the collision\u2026  (See figure 1 in the paper for the bounce code).", "Using bounce we can also simulate horizontal movement if we simply use 0 for acceleration.", "Here\u2019s a bouncing ball in a box:  moveXY x y   (withColor green circle) where   x = bounce xMin xMax x0 vx0 0 t0   y = bounce yMin yMax y0 vy0 g t0  See the full paper for further examples."], "author_id": "ACOLYER", "pdf_url": "http://conal.net/papers/icfp97/icfp97.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 40561438}, {"blog_id": "using-word-embedding-to-enable-semantic-queries-on-relational-databases", "summary": ["Using word embedding to enable semantic queries in relational databases Bordawekar and Shmeuli, DEEM\u201917  As I\u2019m sure some of you have figured out, I\u2019ve started to work through a collection of papers from SIGMOD\u201917.", "Strictly speaking, this paper comes from the DEEM workshop held in conjunction with SIGMOD, but it sparked my imagination and I hope you\u2019ll enjoy it too.", "Plus, as a bonus it\u2019s only four pages long!", "What do you get if you cross word embedding vectors with a relational database?", "The ability to ask a new class of queries, which the authors term cognitive intelligence (CI) queries, that ask about the semantic relationship between tokens in the database, rather than just syntactic matching as is supported by current queries.", "It\u2019s a really interesting example of AI infusing everyday systems.", "We begin with a simple observation: there is a large amount of untapped latent information within a database relation.", "This is intuitively clear for columns that contain unstructured text.", "But even columns that contain different types of data, e.g., strings, numerical values, images, dates, etc., possess significant latent information in the form of inter- and intra-column relationships.", "If we understood the meaning of these tokens in the database (at least in some abstract way that was comparable), we could ask queries such as \u201cshow me all the rows similar to this.\u201d That\u2019s something you can\u2019t easily do with relational databases today \u2013 excepting perhaps for range queries on specific types such as dates.", "Where can we get comparable abstract representations of meaning though?", "The answer is already given away in the paper title of course \u2013 this is exactly what word embedding vectors do for us!", "If you\u2019re not familiar with word embedding vectors, we covered word2vec and GloVe in The Morning Paper a while back.", "In fact, \u201c The Amazing Power of Word Vectors \u201d continues to be one of the most read pieces on this blog.", "In short:  The idea of word embedding is to fix a d-dimensional vector space and for each word in a text corpus associate a dimension d vector of reals numbers that encodes the meaning of that word\u2026 If two words have similar meaning, their word vectors point in very similar directions.", "The authors use word2vec in their work, though as they point out they could equally have used GloVe.", "How do we get word embedding vectors for database content?", "One approach is to use word vectors that have been pre-trained from external sources.", "You can also learn directly from the database itself.", "Think of each row as corresponding to a sentence, and a relation as a document.", "Word embedding then can extract latent semantic information in terms of word (and in general, token) associations and co-occurrences and encode it in word vectors.", "Thus, these vectors capture first inter- and intra-attribute relationships within a row (sentence) and then aggregate these relationships across the relation (document) to compute the collective semantic relationships.", "In their prototype implementation, the authors first textify (!)", "the data in a database table (e.g., using a view), and then use a modified version of word2vec to learn vectors for the words (database tokens) in the extracted text.", "This phase can also use an external source (e.g. Wikipedia articles) for model training.", "We use word as a synonym to token although some tokens may not be valid words in any natural language.", "Following vector training, the resultant vectors are stored in a relational system table.", "At runtime, the system (built on Spark using Spark SQL and the DataFrames API) uses UDFs to fetch trained vectors from the system and answer CI queries.", "CI Queries  Broadly, there are two classes of cognitive intelligence queries: similarity and prediction queries\u2026 The key characteristic of the CI queries is that these queries are executed, in part, using the vectors in the word embedding model.", "If the word embedding model is generated using the database being queried, it captures meaning in the context of the associated relational table, as specified by the relational view.", "If a model is rebuilt using a different relational view, a CI query may return different results for the new model.", "It\u2019s time to look at some concrete examples to make all this a bit clearer.", "Given a similarityUDF that can tell us how similar two sets of word vectors are, we can ask a query such as:  In this case, the vector sets correspond to the items purchased by the corresponding customers.", "What this query will return is pairs of customers that have similar purchasing histories!", "The pattern observed in this query can be applied to other domains as well, e.g., identifying patients that are taking similar drugs, but with different brand names or identifying food items with similar ingredients, or finding mutual funds with similar investment strategies.", "The key difference to a traditional query is that we\u2019re matching by semantic similarity, not by values.", "Recall that word embeddings also support inductive reasoning (e.g., the classic King is to Man as Queen is to ?", "style queries).", "You can exploit this capability in CI queries too.", "In the following toy example, we\u2019re looking for food product pairs that relate to each other as \u2018peanut-butter\u2019 relates to \u2018jelly\u2019.", "(For example, the query may return the pair \u2018chips\u2019, \u2018salsa\u2019).", "The analogyUDF computes the differences (peanut butter \u2013 jelly) and (p1 \u2013 p2) and looks at the cosine similarity of those differences.", "The analogy capabilities of CI queries have several applications in the enterprise space, e.g., associating customers with either most-common or least-common purchases in a given domain (e.g., books, electronics, etc.).", "I understand the analogy query mechanism, but I\u2019m not sure I quite get the example the authors are trying to give above.", "Neither finding product popularity, nor seeing whether a customer has purchased a low-popularity (high popularity) item seems to need an analogy?", "Here\u2019s an example of my own \u2013 recommendation by analogy: razor is to blade as [product the customer just put in their basket] is to ?.", "(Probably not about to replace frequent itemset mining anytime soon!)", "Our final example shows how embeddings trained using external data can be used in queries.", "Suppose we trained word embeddings with a data set that reveals information about fruits and their allergenic properties.", "We would have a relationship between the vector for \u2018allergenic\u2019 and the vectors for allergenic fruit names.", "Now we can ask:  This example demonstrates a very powerful ability of CI queries that enables users to query a database using a token (e.g., allergenic) not present in the database.", "The last word  Will all relational databases one day come with CI querying capabilities built-in?", "In summary, we believe this work is a step towards empowering database systems with built-in AI capabilities\u2026 We believe CI queries are applicable to a broad class of application domains including healthcare, bio-informatics, document searching, retail analysis, and data integration.", "We are currently working on applying the CI capabilities to some of these domains."], "author_id": "ACOLYER", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3076246.3076251?download=true", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 9563928}, {"blog_id": "skyway-connecting-managed-heaps-in-distributed-big-data-systems", "summary": ["Skyway: connecting managed heaps in distributed big data systems Nguyen et al., ASPLOS\u201918  Yesterday we saw how to make Java objects persistent using NVM-backed heaps with Espresso.", "One of the drawbacks of using that as a persistence mechanism is that they\u2019re only stored in the memory of a single node.", "If only there was some way to create a cluster of JVMs, and efficiently copy objects across remote heaps in the cluster\u2026 Meet Skyway!", "Skyway is aimed at JVM-based big data systems (think Spark, Flink) that end up spending a lot of their time serializing and deserializing objects to move them around the cluster (e.g., to and from workers \u2013 see \u2018 Making sense of performance in data analytics frameworks \u2019).", "Java comes with a default serialization mechanism, and there are also many third party libraries.", "Kryo is the recommended library for use with Spark.", "Consider a small Spark cluster (3 worker nodes each with a 20 GB heap) running a triangle counting algorithm over the LiveJournal graph (about 1.2GB).", "With both the standard Java serializers and Kryo, serialization and deserialization combined account for a significant portion of the overall execution time (more than 30%).", "Where does all the time go?", "To transfer an object o from one JVM to another takes three steps:  A serialization procedure turns the whole object graph reachable from o into a binary sequence.", "During this process the serializer extracts the object data, strips the header, removes all references stored in an object, and changes the representation of certain metadata.", "The byte sequence is sent across the wire  A deserialization procedure reads the byte sequence, creates objects accordingly, and rebuilds the object graph in the managed heap of the receiver machine.", "In a big data system, a transfer can involve millions of objects, which means invoking, e.g., reflection APIs millions of times or more.", "Moreover, the Java serializer represents every type by a string containing the name of a class and all its superclasses.", "These type strings can consume a huge portion of the byte sequence transferred across the network, and reflection has to be used on the receiver end to resolve types from the string.", "Reflection is also heavily used when repairing object references in the graph on the receiving end.", "The key problem with existing S/D (serialization/deserialization) libraries is that, with an existing JVM, there are no alternative routes to transfer objects other than first disassembling and pushing them down to a (different) binary format, and the reassembling and pulling them back up into a remote heap.", "In this paper, we advocate to build a \u201cskyway\u201d between managed heaps so that data objects no longer need to pushed down to a lower level for transfer.", "At a high level, Skyway is fairly easy to understand.", "It extends the JVM (OpenJDK) to enable object graphs to be moved as is from one heap to another, and immediately used on a remote node right after the move.", "Given a root object o, Skyway performs a GC-like traversal copying every reachable object into an output buffer while performing only a very lightweight adjustment to machine-dependent metadata.", "Crucially, the object format is not changed and every object is transferred as a whole.", "This includes the hashcode, so that hash-based data structures can be used on the receiver node without rehashing.", "Types are represented by a global type-numbering procedure which assumes a master-workers pattern and keeps a registry of all types and their ids at the master.", "Workers communicate with the master to obtain ids for classes upon class loading.", "Absolute addresses in objects are turned into relative addresses when copied into the output buffer.", "The output buffer is streamed to an input buffer at the remote node, where the relative addresses are turned back into absolute addresses in the target heap.", "\u2026data processing applications frequently shuffle many millions of objects and do so in strongly delimited phases.", "Hence, sending objects in batch without changing their formats provides significant execution efficiency.", "Second, the use of modern network technology enables extra bytes to be quickly transferred without incurring much overhead.", "Skyway under the covers  Skyway uses a GC-like mechanism to discover the object graph reachable from a set of root objects.", "Objects encountered during the traversal are copied into an output buffer (located in off-heap native memory so it doesn\u2019t interfere with GC), which is streamed to the corresponding buffer(s) on the receiving node.", "Input buffers are allocated in the old generation (tenured) of the managed heap, and  can span multiple memory chunks \u2013 handy since you don\u2019t always know the ultimate size of the buffer when streaming starts.", "Root objects in a stream are demarcated by special top marks which helps the receiver to efficiently read entire graphs without needing to parse all of their content.", "Once a data transfer is complete, Skyway updates the card table of the Parallel Scavenge GC making the new objects reachable via garbage collection.", "Skyway can support heterogeneous clusters, where JVMs may have different object formats, by adjusting the format of objects as they are copied into the output buffer.", "The implementation on top of OpenJDK 1.8.0 touches the classloader subsystem, the object/heap layout, and the Parallel Scavenge garbage collector.", "Skyway develops a distributed type-registration system that automatically allows different representations of the same class on different JVM instances to share the same integer ID.", "This system completely eliminates the need to represent types during data transfer\u2026  The driver / master JVM maintains a complete type registry covering all classes that have been loaded in the cluster, initially populated by scanning its own loaded classes after JVM startup.", "When a worker JVM starts up it requests a copy of the registry from the driver, giving it a view of all classes loaded in the cluster to that point.", "If a worker JVM loads a class that does not yet exist in its local registry view it checks with the driver to obtain an ID for it.", "Whereas the standard Java serializer sends a type string over the network with every object, Skyway sends a type string at most once for every class on each machine during the entire computation.", "Performance evaluation  The first evaluation compares Skyway against 90 existing serialization libraries using the Java serializer benchmark set (JSBS).", "Results for the fastest 28 are shown below.", "Skyway is the fastest of the lot: 2.2x faster than Kryo-manual (intrusive), and 67x faster than the Java serializer.", "The next experiment modifies Spark (v1.2.0) to replace the use of Kryo-manual with the Skyway library.", "Four programs (Word Count, Page Rank, Connected Components, and Triangle Counting) are each run over four different graph inputs:  The following charts summarise the performance of Java serialisation, Kryo, and Skyway for each of the programs across each of the input graphs:  Skyway makes Spark run 36% faster than the Java serializer, and 16% faster than Kryo.", "Skyway is also evaluated against Flink 1.3.2 (released Aug 2017) in a batch processing mode.", "The TPC-H data generator is used to generate a 100GB input dataset, and 5 representative TPC-H queries are transformed into Flink applications.", "The performance of Skyway vs Flink\u2019s built-in serializer is show below:  Skyway improves Flink\u2019s performance by 19% on average.", "Our evaluation shows that Skyway outperforms all existing S/D libraries and improves widely-deployed systems such as Spark and Flink."], "author_id": "ACOLYER", "pdf_url": "https://people.cs.uchicago.edu/~shanlu/paper/asplos18_skyway.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 84655302}, {"blog_id": "three-years-of-the-right-to-be-forgotten", "summary": ["Three years of the Right To Be Forgotten Bertram et al., 2018  With thanks to Elie Bursztein for bringing this paper to my attention.", "See also Elie\u2019s blog post \u2018 Insights about the first three years of the Right To Be Forgotten requests at Google .\u2019  Following on from the GDPR we looked at yesterday, and which comes into force in May of this year, I thought it would be interesting to take a look at another right to be forgotten (RTBF) that has been in force since May 2014.", "Today\u2019s paper choice is a retrospective study from Google of the 2.4M URLs that were requested for delisting from the Google search engine over the last 3 and a half years.", "This particular right to be forgotten enables individuals to request that search engines delist URLs containing \u201cinaccurate, inadequate, irrelevant or excessive\u201d information surfaced by queries containing the name of the requestor.", "Critically, the ruling requires that search engine operators make the determination for whether an individual\u2019s right to privacy outweighs the public\u2019s right to access lawful information when delisting URLs.", "That\u2019s a lot of responsibility to place with private groups within search engine companies!", "Google formed an advisory council drawn from academic scholars, media producers, data protection authorities, civil society, and technologists to establish decision criteria for \u201cparticularly challenging delisting requests.\u201d  Google make a RTBF submission form available online.", "Requestors must verify their identity and provide a list of URLs they would like to delist along with the search queries leading to those URLs and a short comment about how the URLs relate to the requestor.", "Every submission is manually reviewed \u2013 there is no automation in the decision process.", "The reviewers consider four criteria, designed to weigh public interest against the requestor\u2019s personal privacy:  The validity of the request: is it actionable (e.g., specifies exact URLs) and is the requestor connected with an EU/EEA country.", "The identity of the requestor: for example, if the requestor is a public figure there may be heightened public interest.", "Other categories of interest include minors, politicians, and professionals.", "The content referenced by the URL.", "\u201cFor example, information related to a requestor\u2019s business may be of public interest for potential customers.", "Similarly, content related to a violent crime may be of interest to the general public\u2026 \u201c  The source of the information: e.g., government site, news site, blog, or forum.", "For the period between May 30th 2014, and December 31st 2017, Google received requests to delist almost 2.4M URLs, from 399,779 unique requestors.", "Only 43% of these URLs were ultimately delisted.", "From January 22nd 2016, requested URLs were additionally annotated with categorical data for purposes of improving transparency around RTBF requests.", "Applying judgement  The paper contains a sprinkling of anonymous requests and the decisions reached, which provide good insight into the challenges the reviewers face.", "Here are some examples:  \u201c\u2026 an individual, who was convicted for two separate instances of domestic violence within the previous five years, sent Google a delisting request focusing on the fact that their first conviction was \u2018spent\u2019 under local law.", "The requestor did not disclose that the second conviction was not similarly spent, and falsely attributed all the pages sought for delisting to the first conviction.", "Reviewers discovered this as part of the review process and the request was ultimately rejected.\u201d  \u201cIn another case, reviewers first delisted 150 URLs submitted by a businessman who was convicted for benefit fraud, after they provided documentation confirming their acquittal.", "When the same person later requested the delisting of URLs related to a conviction for manufacturing court documents about their acquittal, reviewers evaluated the acquittal documentation sent to Google, found it to be a forgery, and reinstated all previously delisted URLs\u201d.", "\u201c\u2026a requestor who held a significant position at a major company sought to delist an article about receiving a long prison sentence for attempted fraud.", "Google rejected this request due to the seriousness of the crime and the professional relevance of the content.\u201d  \u201c\u2026an individual sought to delist an interview they conducted after surviving a terrorist attack.", "Despite the article\u2019s self-authored nature given the requestor was interviewed [note the assumption here that the journalist gave a fair impression of what the interviewee actually said!", "], Google delisted the URL as the requestor was a minor and because of the sensitive nature of the content.\u201d  \u201c\u2026 a requestor sought to delist a news article about their acquittal for domestic violence on the grounds that no medical report was presented to the judge confirming the victim\u2019s injuries.", "Given that the requestor was acquitted, Google delisted the article.", "**\u201d  Welcome to the court of social reputation!", "How often are requests made and who makes them?", "Overall, the number of RTBF requests per month has been slowly declining after an initial peak when the facility was first launched.", "The number of previously unseen requestors per month is also declining.", "The most requests originate in France, Germany, and the United Kingdom, though if we look at per capita rates Estonia tops the table.", "Most interestingly, reputation management is clearly a growing business (see also Black Mirror: \u2018nosedive\u2019):  The top thousand requesters (0.25% of all requesters) generated 14.6% of requests and 20.8% of delistings.", "These mostly included law firms and reputation management agencies, as well as some requestors with a sizable online presence\u2026 while hundreds of thousands of Europeans rely on the RTBF to delist a handful of URLs, there are thousands of entities using the RTBF to alter hundreds of URLs about them or their clients that appear in search results.", "Most requested for delisting, by an order of magnitude,  are URLs concerning private individuals:  Requests predominantly come from private individuals (88%).", "Politicians and government officials requested delisting of 33,937 URLs, and non-governmental public figures another 41,213 URLs.", "Over 77% of requests to delist URLs rooted in a country code top-level domain come from requestors in the same country.", "Requests now take a median of 4 days to process.", "What content do people request delisting for?", "The major categories of sites that contains URLs targeted for delisting are social media sides, directory sites aggregating contact details and personal content, and news sites.", "It seems that people don\u2019t want you to read bad things about them on Facebook!", "Here are the most requested sites by category:  Different countries show different characteristics, which can be explained by, for example, the character of the news organisations in those countries, and the role of the government in publishing information.", "In Italy and the UK, requestors target news media much more than in Germany and France for example.", "Journalists in the former countries are prone to reveal the identity of individuals, whereas those in the latter tend to anonymise parties in their coverage of crimes.", "Requestors in France and Germany target social media and directory services more than average.", "In Spain there is a higher proportion of requests targeting government records.", "Spanish law requires the government to publish \u2018edictos\u2019 and \u2018indultos.\u2019 \u201c_The former are public notifications to inform missing individuals about a government decision that directly affects them; the latter are government decisions to absolve an individual from a criminal sentence or to commute to a lesser one.\u201d  Looking at the content at the URLs requested for delisting, we find that most pages contain professional information, though it\u2019s interesting to see self-authored content in the number two spot!", "The most commonly requested content related to professional information, which rarely met the criteria for delisting (16.7%).", "Many of these requests pertain to information which is directly relevant or connected to the requestor\u2019s current profession and is therefore in the public interest to have indexed in Google Search."], "author_id": "ACOLYER", "pdf_url": "https://www.elie.net/static/files/three-years-of-the-right-to-be-forgotten/three-years-of-the-right-to-be-forgotten-paper.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 13793499}, {"blog_id": "formal-requirements-for-virtualizable-third-generation-architectures", "summary": ["Formal Requirements for Virtualizable Third Generation Architectures \u2013 Popek & Goldberg 1974.", "With thanks to Alfred Bratterud for pointing me at this paper.", "What exactly is a virtual machine?", "What does a virtual machine monitor do?", "And how do we now whether a given piece of hardware can support virtualization or not?", "In today\u2019s paper choice, Popek and Goldberg set out the answers for us \u2013 and by the way, they had all this figured out way back in 1974!", "What is a Virtual Machine?", "There are currently (1974) a number of viewpoints suggesting what a virtual machine is, how it ought to be constructed, and what hardware and operating system implications result\u2026  Here\u2019s a very simple definition of a virtual machine:  A virtual machine is taken to be an efficient, isolated duplicate of the real machine.", "Though of course we need to dig further and understand what is implied by the three words efficient, isolated, and duplicate.", "To explain these, the authors introduce the notion of a virtual machine monitor\u2026  What is a Virtual Machine Monitor?", "A virtual machine monitor (VMM) does three things:  It provides a duplicate, or essentially identical to the original machine, environment for programs.", "\u201cAny program run under the VMM should exhibit an effect  identical with that demonstrated if the program had been run  on the original machine directly, with the possible exception of differences caused by the availability of system resources and differences caused by timing dependencies.\u201d  It does so efficiently, requiring \u201ca statistically dominant subset of the virtual processor\u2019s instructions be executed directly by the real processor, with no software intervention by the VMM.", "This statement rules out traditional emulators and complete software interpreters (simulators) from the virtual machine umbrella.\u201d Thus programs that run in this environment show only minor decreases in speed.", "It is in complete control of system resources (memory, peripherals, and the like).", "This requires two conditions: (i) it must not be possible for a program running in the created environment to access any resource not allocated to it (isolation), and (ii) it is possible under certain circumstances to regain control of resources already allocated.", "A virtual machine is the environment created by the virtual machine monitor.", "Does my Hardware Support Virtualization?", "This is the question the vast majority of the paper is dedicated to.", "Before we can get to the answer (which is actually a very simple and easy test), we need to understand what the authors mean by a \u2018third generation architecture\u2019 (per the paper title).", "Examples of a third generation architecture machine are the IBM 360, Honeywell 6000, or DEC PDP-10.", "Such machines have a processor, and linear uniformly addressable memory.", "The processor can operate in supervisor mode, or in user mode.", "Some instructions are only available in supervisor mode.", "Memory addressing is done relative to a relocation register R=(l,b) which is always active.", "The location parameter l gives the absolute address that corresponds to the apparent address zero, and the bounds parameter b gives the absolute size of the virtual memory.", "Suppose an instruction produces some address a, we check and then find the true address as follows:  if  a + l >= total-real-memory-size then       // out of real memory bounds     memorytrap  else if a >= b then     // out of virtual memory bounds    memorytrap else     use address a+l  The program status word PSW is a triplet (mode \u2013 user/supervisor, program counter, relocation register), and the overall state S of the machine can be modeled as (E,PSW) where E is the executable storage.", "E[0] and E[1] are used to store an old-PSW and fetch a new PSW respectively.", "Instructions  are simply modeled as a function from State -> State.", "In this model, for simplicity, we have departed slightly from most common relocation systems by assuming it to be active in the supervisor as well as user mode.", "This difference will not be important to the proof of our result.", "Note also that all references made by the processor to memory are assumed to be relocated.", "A trap, such as the memorytrap above, automatically saves the current state of the machine and passes control to a pre-specified control routine by changing the PSW to the values specified in E[1].", "Key to understand whether or not it is possible to virtualize a given piece of hardware is to divide the instructions into groups.", "In particular, privileged instructions are those that do not trap when the processor is in supervisor mode, but do trap (a privileged instruction trap) when in user mode.", "Privileged instructions are independent of the virtualization process.", "They are merely characteristics of the machine which may be determined from reading the principles of operation.", "Note, however, that the way we have defined privileged instructions requires them to trap.", "Merely NOPing the instruction without trapping is insufficient.", "The latter case should not be called a privileged instruction; maybe \u201cuser mode NOP\u201d would be more accurate.", "Sensitive instructions may be either control sensitive, or behaviour sensitive.", "Control sensitive instructions are those that affect or can affect control over system resources \u2013 in our simplified model the only such resource is memory.", "A control sensitive instruction attempts to change the amount of resource (memory) available, or change processor mode, without going through a memory trap.", "A behaviour sensitive instruction is one whereby the effect of its execution is dependent on the value of the relocation bounds register (location in real memory) or processor mode.", "An instruction that is not sensitive is innocuous.", "A virtual machine monitor is a control program comprising a dispatcher, an allocator, and a set of interpreters, one per privileged instruction.", "The location of the control program (dispatcher) is placed in the program counter at E[1], it directs execution to the allocator or interpreters as needed.", "The allocator decides what system resources are to be provided (e.g. keeping the VMM and VM memory separate).", "The allocator will be invoked by the dispatcher whenever an attempted execution of a privileged instruction in a virtual machine environment occurs which would have the effect of changing the machine resources associated with that environment.", "Attempting to reset the R (relocation-bounds) register is the primary example in our skeletal model.", "If the processor were to be treated as a resource, a halt would be another.", "The job of the interpreters is to simulate the instruction that trapped.", "A virtual machine monitor [that satisfies the three properties of efficiency, resource control, and equivalence] may be constructed if the set of sensitive instructions for that computer is a subset of the privileged instructions.", "The proof of this statement is given in the paper and the appendices \u2013 it rests on showing a one-one homomorphism f between real machine states and virtual machine states, and that if the real machine halts in state S, then the virtual machine halts in state f(S).", "The final step is an existence argument (i.e. there is at least one way) to build the privileged instruction interpreters \u2013 using a lookup table.", "Furthermore, recursive virtualization (a VM that runs a copy of itself under the VMM) is possible if (a) a VMM can be constructed for the hardware as above, and (b) the VMM does not have any timing dependencies.", "The theorem provides a fairly simple condition sufficient to guarantee virtualizability, assuming, of course, that the requisite features of \u201cconventional third generation machines\u201d are present.", "However, those features which have been assumed are fairly standard ones, so the relationship between the sets of sensitive and privileged instructions is the only constraint.", "It is a very modest one, easy to check.", "Further, it is also a simple matter for hardware designers to use as a design requirement."], "author_id": "ACOLYER", "pdf_url": "https://www.princeton.edu/~rblee/ELE572Papers/Fall04Readings/secureOS/popek_virtualizable.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 17349212}, {"blog_id": "the-paradigms-of-programming", "summary": ["The paradigms of programming Floyd, CACM 1979  (Also available in  )  A couple of weeks ago we looked at Dan Bernstein\u2019s very topical \u201c thoughts on security after ten years of qmail 1.0 .\u201d From the general reaction I can tell that lots of you enjoyed reading that paper, but in the discussions that I saw, no-one was picking up on what I see as the real underlying secret to Bernstein\u2019s success and progression as a software engineer.", "(Perhaps because it is one level of indirection away from the main topic of security in that paper).", "Here is my favourite extract again:  For many years I have been systematically identifying error-prone programming habits \u2014 by reviewing the literature, analyzing other people\u2019s mistakes, and analyzing my own mistakes \u2014 and redesigning my programming environment to eliminate those habits.", "In today\u2019s paper choice we\u2019ll be looking at some other ways of systematically improving your skills over time (along with quite a few other gems).", "In 1978 Professor Robert Floyd was presented with the ACM Turing Award for \u201chelping to found the following important subfields of computer science: the theory of parsing, the semantics of programming languages, automatic program verification, automatic program synthesis, and analysis of algorithms.\u201d Not a bad list!", "\u201cThe paradigms of programming\u201d is his acceptance speech.", "Today I want to talk about the paradigms of programming, how they affect our success as designers of computer programs, how they should be taught, and how they should be embodied in our programming languages.", "Dominant at the time was the idea of structured programming (whose ideas are still very much with us today of course).", "The notion of starting with a top-down, stepwise refinement of the problem, and then building upwards from the primitives of the underlying machine to \u2018meet in the middle\u2019 with a set of more abstract modules and functions to be used by the top-down design.", "See e.g. \u2018 Program development by stepwise refinement \u2019, and \u2018 On the criteria to be used in decomposing systems into modules \u2019.", "The structured programming paradigm is useful, says Floyd, but it\u2019s not the only one.", "Programming paradigms are at the heart of this paper \u2013 and a reasonable interpretation of what Floyd means by paradigm here is, I think, \u2018a strategy or tactic for solving a class of problems.\u2019 That sounds a bit like a design pattern when I say it that way, but the examples Floyd gives us are at a slightly more fundamental level than those the phrase \u2018design patterns\u2019 conjures in my mind.", "Far more powerful than how many languages you know (in terms of syntax), is how many paradigms you are fluent with.", "I believe that the current state of the art of computer programming reflects inadequacies in our stock of paradigms, and in the way our programming languages support, or fail to support, the paradigms of their user communities.", "Computer science quickly breaks down into communities each with its own languages and dominant paradigms.", "The problem of falling into one of these and not escaping is that it becomes hard to see the fundamentals afresh and discover new approaches.", "Quoting from Kuhn in \u2018The Structure of Scientific Revolutions\u2019 :  The study of paradigms, including many that are far more specialized than those named illustratively above, is what mainly prepares the student for membership in the particular scientific community with which he will later practice.", "Because he there joins men who learned the bases of their field from the same concrete models, his subsequent practice will seldom evoke overt disagreement over fundamentals.", "John Cocke invented the dynamic programming paradigm to solve a problem with the efficient parsing of context-free languages.", "Floyd discovered recursive coroutines as a structure while building hierarchical top-down parsers.", "John Cocke\u2019s experience and mine illustrate the likelihood that continued advance in programming will require the continuing invention, elaboration, and communication of new paradigms.", "On developing as a programmer  So much for the advancement of the field, what about developing your own skills?", "If the advancement of the general art of programming requires the continuing invention and elaboration of paradigms, advancement of the art of the individual programming requires that he expand his repertory of paradigms.", "Here\u2019s the technique that Floyd used to expand his own capabilities.", "After solving a challenging problem, I solve it again from scratch, retracing only the insight of the earlier solution.", "I repeat this until the solution is as clean and direct as I can hope for.", "Then I look for a general rule for attacking similar problems, that would have led me to approach the given problem in the most efficient way the first time.", "Often, such a rule is of permanent value.", "It can be hard to gain exposure to new paradigms from within your own immediate environment, because it\u2019s likely your colleagues are all working within the same local paradigm set \u2014 witness job advertisements that specify the desired programming language (\u201cThe rules of Fortran can be learned within a few hours; the associated paradigms take much longer,  both to learn and unlearn.\u201d).", "Floyd writes of an eye-opening experience of visiting MIT and seeing the power of Lisp first-hand (as someone grown up more in the tradition of Algol-like languages).", "\u2026 my message to the serious programmer is to spend a part of your working day examining and refining your own methods.", "Even though programmers are always struggling to meet some future or past deadline, methodological abstraction is a wise long term investment.", "On designing (and evaluating) programming languages  Everyone wants to design a new programming language.", "Bah!", "Floyd doesn\u2019t find much satisfaction in the incremental extensions to existing languages (example: adding variant records to Pascal).", "Instead, it\u2019s far more important to look at the paradigms a language supports.", "I believe that the continued advance of programming as a craft requires the development and dissemination of languages which support the major paradigms of their user\u2019s communities.", "The design of a language should be preceded by enumeration of those paradigms, including a study of the deficiencies in programming caused by discouragement of unsupported paradigms\u2026 If there is ever a science of programming language design, it will probably consist largely of matching languages to the design methods they support.", "It\u2019s not just the programming language itself of course, \u201cthe entire environment in which we program, diagnostic systems, files systems, editors, and all, can be analyzed as supporting or failing to support the spectrum of methods for design of programs.\u201d  To persuade me of the merit of your language, you must show me how to construct programs in it.", "I don\u2019t want to discourage the design of new languages; I want to encourage the language designer to become a serious student of the details of the design process.", "On teaching programming  We have an unfortunate obsession with form over content (Floyd is speaking in 1978 remember, not a lot has changed in the intervening 40 years!).", "You can feel Floyd\u2019s heart sink in the following exchange:  If I ask another professor what he teaches in the introductory programming course, whether he answers proudly \u201cPascal\u201d or diffidently \u201cFORTRAN,\u201d I know that he is teaching a grammar, a set of semantic rules, and some finished algorithms, leaving the students to discover, on their own, some process of design.", "We would do better to explicitly teach a set of systematic methods for all levels of program design.", "Students trained this way \u201chave a large head start over those conventionally taught.\u201d  To the teacher of programming\u2026 I say: identify the paradigms you use, as fully as you can, then teach them explicitly.", "They will serve your students when Fortran has replaced Latin and Sanskrit as the archetypal dead language.", "How many paradigms do you have in your toolbox?"], "author_id": "ACOLYER", "pdf_url": "https://pdfs.semanticscholar.org/a57d/cde5113855aec888b2a4e1fdd6e3956ce2e6.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 75962230}, {"blog_id": "information-flow-analysis-of-android-applications-in-droidsafe", "summary": ["Information-Flow Analysis of Android Applications in DroidSafe \u2013 Gordon et al. 2015  This is the first of three papers we\u2019ll be looking at this week from the NDSS\u201915 conference that took place earlier this month.", "DroidSafe is a tool that looks for potential leaks of sensitive information in Android applications.", "And it works incredibly well!", "DroidSafe detects all malicious information flow leaks inserted into 24 real-world Android applications by three independent, hostile Red-Team organizations.", "The previous state-of-the art analysis, in contrast, detects less than 10% of these malicious flows.", "The definition of sensitive data includes the unique device ID, sensor data (location, acceleration etc.", "), file data, image data and meta-data, email and SMS messages, passwords, network traffic and screen-shots.", "DroidSafe is a static analysis framework that analyzes the application before it executes.", "Given the size, richness, and complexity of the Android API and runtime (about 1.3 million lines of code) this is a significant challenge.", "It\u2019s important to detect leaks, and to be practical it\u2019s also important not to generate too many false positives.", "The Android API version 4.4.3 includes over 3,500 classes visible to an application developer.", "Analyzing the complete source code for the API is exceedingly difficult because it is implemented over multiple languages and some of the implementation is device-specific.", "Thus, static analysis frameworks rely on modelling the Android API semantics.", "Beyond the sheer scale of the challenge, event dispatching, callbacks, and inter-component communication all add to the difficulty.", "Event dispatching can lead to many different orderings of events, and event handlers are not called directly in application code.", "Callback handlers can include arguments passed by the runtime to the application for processing \u2013 which could include data from the application (tainted data), depending on the execution sequence prior to the event.", "Inter-component communication (ICC) is via Intent objects \u2013 and the resolution of an Intent destination is complex and may be dynamically determined.", "Starting with the Android Open Source Project (AOSP) source code, \u201cit quickly became apparent that the size and complexity of the Android environment made it necessary to develop the model and the analysis together as an integrated whole, with the design decisions in the model and the analysis working together synergistically to enable an effective solution to the Android static information-flow analysis problem.\u201d Stubs were developed to cover code outside of the AOSP Java codebase:  Examples of semantics missing in the AOSP and added via accurate analysis stubs include native methods; event callback initiation with accurate context; component life-cycle events; and hidden state maintained by the Android runtime and accessible to the application only via the Android API.", "For the information flow analysis, 4051 sensitive source methods and 2116 sensitive sink methods were manually identified and classified.", "In addition the implementation of 117 classes in the Java standard library and Android library were carefully simplified to increase precision and decrease analysis time (on the order of 5 to 10 minutes).", "At the core of the model are 550 Android classes that account for over 98.1% of the total calls made by over 95K applications downloaded from the Google Play Store.", "These were manually reviewed to confirm that the implementation fully covered semantics for data flow, object instantiation and aliasing, and that the event callbacks defined are called explicitly by the model with the proper context.", "At the core of the approach is an analysis method called \u2018Points-to\u2019 analysis:  Points-to analysis (PTA) is a foundational static program analysis that computes a static abstraction of all the heap locations that a pointer (reference) variable may point to during program execution.", "In addition to the points-to relation, points-to analysis also constructs a call graph as modern languages re-quire points-to results to calculate targets for dynamic dispatch and functional lambda calculations.", "The PTA implementation implements object sensitivity (identifying flows that originate in different object instances).", "\u201cObject sensitivity is notoriously difficult to understand and implement.\u201d It also requires large amounts of memory.", "Prior to optimising, several applications could not be analysed even with 64GB of heap memory.", "With optimisations, all tested applications now fit in under 34GB.", "The optimisation involved analysing a suite of Android applications to determine an appropriate context-depth (from 0 to 4) for each API class.", "(Traditional approaches use a fixed context depth).", "For inter-component communication, string analysis is performed to work out possible runtime targets using the JSA String Analyzer.", "This creates a regular expression representing the possible values of the string value.", "After JSA is run, we replace resolved string values in the application code with constants representing their computed regular expression, and perform a pass of our points-to analysis such that these values can be propagated globally.", "Additional transformations are made for ICC initiation calls and Android Service components to improve model precision.", "The resulting information flow analysis is built on top of the Soot Java Analysis framework and comprises approximately 70Kloc of Java code.", "Our information-flow analysis computes an over-approximation of all the memory states that occur during the execution of a program.", "The analysis is designed as a forward data-flow analysis.", "For each type of statement, we define a transfer function in terms of how it changes the state of memory.", "We divide memory into four separate areas that store local variables, instance fields, static fields, and arrays, reflecting the semantics of the Java programming language.", "Each of the memory areas is modelled as a function whose codomain consists of a set of information values.", "An information value is a tuple of the type of information and the source code location where the information was first injected.", "Our analysis can identify not only the kind of information being exfiltrated but the code location of the source.", "Results  We evaluate DroidSafe on 24 complete real-world Android applications that, as part of the DARPA Automated Program Analysis for Cybersecurity (APAC) program, have been augmented with malicious information flow leaks by three hostile Red Team organizations.", "The goal of these organizations was to develop information leaks that would either evade detection by static analysis tools or overwhelm static analysis tools into producing unacceptable results (by, for example, manipulating the tool into reporting an overwhelming number of false positive flows).", "DroidSafe accurately detects all of the 69 malicious flows in these applications (while reporting a manageable total number of flows).", "A current state-of-the-art Android information-flow analysis system, Flow-Droid + IccTA, in contrast, detects only 6 of the 69 malicious flows, and has a larger ratio of total flows reported to true malicious flows reported.", "DroidSafe was also evaluated against the DroidBench suite and gave the highest reported accuracy and highest precision for the suite to date at 94.3% and 87.6% respectively.", "Unsurprisingly, DroidSafe gets 100% accuracy and precision on its own test suite \u2013 but the next best tool could only achieve 34.9% accuracy and 79.9% precision.", "As these results illustrate, DroidSafe implements an analysis of unprecedented accuracy and precision.", "To the best of our knowledge, DroidSafe provides the first usable information-flow analysis for Android applications.", "The Secret Sauce  Our experience developing DroidSafe shows that 1) there is no substitute for an accurate and precise model of the application environment, and 2) using the model to drive the design decisions behind the analysis and supporting techniques (such as accurate analysis stubs) is one effective but (inevitably) labor-intensive way to obtain an acceptably precise and accurate analysis.", "As long as there are complex application frameworks, we anticipate that making an appropriate set of design decisions (such as the use of a scalable flow insensitive analysis) to successfully navigate the trade-off space that the application framework implicitly presents will be a necessary prerequisite for obtaining acceptable accuracy and precision."], "author_id": "ACOLYER", "pdf_url": "http://www.internetsociety.org/sites/default/files/02_1_2.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 50524744}, {"blog_id": "helping-developers-help-themselves-automatic-decomposition-of-code-review-changes", "summary": ["Helping Developers Help Themselves: Automatic Decomposition of Code Review Changes \u2013 Barnett et al. 2015  Earlier this week we saw that pull requests with well organised commits are strongly preferred by integrators .", "Unfortunately, developers often make changes that incorporate multiple bug fixes, feature additions, refactorings, etc..", "These result in changes that are both large and only loosely related, if at all, leading to difficulty in understanding.", "Rounding out this week of papers from ICSE \u201915, Barnett et al. from Microsoft developed a tool called ClusterChanges which decomposes changesets into independent parts.", "In a study, developers found the partioning to be a helpful aid during code reviews.", "\u2026 we built a prototype graphical tool and used it to investigate changesets submitted for review in Bing and Office at Microsoft.", "Our quantitative evaluation shows that over 40% of changes submitted for review at Microsoft can be potentially decomposed into multiple partitions, indicating a high potential for use.", "The basic approach to identifying related changes is to take the diff-regions produced by a standard diff tool comparing before and after versions of files, and then group those diff-regions together based on definition-and-use relationships.", "We use the def-use relationship as the primary organizing principle for clustering diff-regions.", "Programmers often introduce interesting functional changes to code by introducing or modifying definitions along with their uses.", "ClusterChanges finds definitions (of types, fields, and methods) that have been changed within a diff-region, and the uses of that definition changed within diff-regions.", "Diff-regions f1 and f2 are then grouped into the same partition (RelatedDiffs) if any one of the following conditions is true:  f1 and f2 are both within the same enclosing method, or  there are changes to the definition of some element in f1 and corresponding changes in the use of that element in f2  f1 and f2 both contain a change to the use of some element, and that element is defined within the changeset, but not itself changed  We group diff-regions in the same method together because a) in practice, we observe that changes to the same method are often related, and b) in prior research, we observed that reviewers usually review methods atomically (i.e., they rarely review different diffregions in a method separately).", "Given these relations we create a partitioning over the set of diff-regions by computing the reflexive, symmetric and transitive closure of RelatedDiffs.", "The result of this process is a set of trivial partitions that are fully enclosed within a single method, or where there is only one diff-region and it is outside of a method, and a set of non-trivial partitions (everything else).", "The ClusterChanges tool then displays these partitions graphically:  ClusterChanges was applied to a randomly selected set of 1000 changesets submitted for review in the development of Microsoft Office 2013.", "While the most common case are changesets containing just one non-trivial partition, this still makes up only 45%.", "Nearly 42% of all changes contain more than one non-trivial partition.", "In addition, the proportion of changed methods that end up in non-trivial partitions is 66% on average per review.", "To the degree that CLUSTERCHANGES correctly identifies non-trivial partitions, this indicates that i) a large proportion of changesets can be decomposed into multiple independent changes, and ii) our decomposition covers a large fraction of changed methods in a review.", "Looking at changesets with lots of partitions, the authors found that many of these could be further consolidated by an enhancement to the tool that also considered:  (a) annotating several methods with common C# attributes such as Serializable or Obsolete, (b) a common refactoring (e.g. addition of a log message or variable renaming) across a large number of methods, and (c) relationships between overridden methods and their implementations.", "A user study was conducted in which the developers responsible for the changesets were asked if they agreed with the automated decomposition.", "Of the 20 participants, 16 said that our non-trivial partitions were both correct and complete, i.e., the non-trivial partitions were indeed independent, the diff-regions within each partition were related and there were no missing conceptual groups\u2026 most developers agree with our automatic partitioning and believe the decomposition is useful for reviewers to understand their changes better (some even asked for the prototype to use on their own reviews going forward).", "With these promising early results, the authors will now be moving on to do further studies with code reviewers."], "author_id": "ACOLYER", "pdf_url": "http://research.microsoft.com/pubs/238937/barnett2015hdh.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 187460}, {"blog_id": "a-few-useful-things-to-know-about-machine-learning", "summary": ["A few useful things to know about machine learning \u2013 Domingos 2012  Developing successful machine learning applications requires a substantial amount of \u2018black art\u2019 that is hard to find in textbooks  This paper looks at twelve key lessons including pitfalls to avoid, important issues to focus on, and answers to common questions.", "The paper was published in 2012, and since then the excellent \u2018 Data Science for Business \u2018 book by Provost and Fawcett has been released by O\u2019Reilly.", "Now much of the wisdom from this paper can indeed be found in a textbook!", "If you enjoy this paper, I highly recommend the book as well.", "According to the paper, the key to not getting lost in the huge space of learning algorithms is to understand that they are composed of three elements: a representation model (e.g. k-nearest neighbour, naive bayes, decision trees); an evaluation function (scoring function) to tell good from bad; and an optimization technique to search for the highest scoring classifier.", "Most textbooks are organized by representation, and it\u2019s easy to overlook the fact that the other components are equally important.", "You want your machine learning to work well (generalize) outside of the examples in the training set you gave it.", "The most common mistake among machine learning beginners is to test on the training data and have the illusion of success\u2026 in the early days of machine learning, the need to keep training and test data separate was not widely appreciated.", "(Of course, if you started your journey as a \u2018machine learning beginner\u2019 by taking Andrew Ng\u2019s online course you won\u2019t be falling into this trap!).", "Data alone is not enough, you also need to supply some domain knowledge to help guide the process.", "Machine learning is not magic; it can\u2019t get something from nothing.", "What it does is get more from less.", "Programming, like all engineering, is a lot of work: we have to build everything from scratch.", "Learning is more like farming, which lets nature do most of the work.", "Farmers combine seeds with nutrients to grow crops.", "Learners combine knowledge with data to grow programs.", "Overfitting is a well-known problem in machine learning, and cross-validation can help to combat this.", "Nevertheless, you should be skeptical of claims that a particular technique \u2018solves\u2019 the overfitting problem.", "It\u2019s easy to avoid overfitting (variance), by falling into the opposite problem of underfitting (bias).", "Simultaneously avoiding both requires learning a perfect classifier, and short of knowing it in advance there is no single technique that will always do best.", "The \u2018curse of dimensionality\u2019 refers to the fact that many algorithms that work in low dimensions become intractable when the input is high-dimensional.", "\u2026the similarity-based reasoning that machine learning algorithms depend on (explicitly or implicitly) breaks down in high dimensions  Fortunately many problem domains are non-uniform giving an effectively lower dimension, or algorithms for explicitly reducing the dimensionality can be used.", "The most important factor in the success of a machine learning project is the features used.", "If the raw data is not in a form that is amenable to learning, you may be able to construct features from it that are:  First-timers are often surprised by how little time in a machine learning project is spent actually doing machine learning.", "But it makes sense if you consider how time consuming it is to gather data, integrate it, clean it and pre-process it, and how much trial and error can go into feature design.", "What\u2019s better?", "Smart algorithms or lots of data:  As a rule of thumb, a dumb algorithm with lots and lots of data beats a clever one with modest amounts of it.", "This brings up the problem of scalability:  In most of computer science, the two main limited resources are time and memory.", "In machine learning there is a third one: training data.", "Which one is the bottleneck has changed from decade to decade.", "Why have just one learner though, when you can have many, ensembles of learners do best.", "\u2026researchers noticed that if instead of selecting the best variation found, we combine many variations, the results are better \u2013 often much better \u2013 and at little extra effort for the user  The winner of the \u2018 Netflix prize \u2018 was a stacked ensemble of over 100 learners.", "There\u2019s plenty more folk wisdom in the paper, so do check it out if this has piqued your interest."], "author_id": "ACOLYER", "pdf_url": "http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 11006232}, {"blog_id": "multiple-model-based-reinforcement-learning", "summary": ["The paper presents some general ideas and mechanisms for multiple model-based RL.", "Even though the task and model architecture may not be very relevant now, I find the general idea and the mechanisms to be quite useful.", "As such, I am focusing only on high-level ideas and not the implementation details themselves.", "The main idea behind Multiple Model-based RL (MMRL) is to decompose complex tasks into multiple domains in space and time so that the environment dynamics within each domain is predictable.", "MMRL proposes an RL architecture composes of multiple modules, each with its own state prediction model and RL controller.", "The prediction error from each of the state prediction model defines the \u201cresponsibility signal\u201d for each module.", "This responsibility signal is used to:  Weigh the state prediction output ie the predicted state is the weighted sum of individual state predictions (weighted by the responsibility signal).", "Weigh the parameter update of the environment models as well as the RL controllers.", "Weighing the action output - ie predicted action is a weighted sum of individual actions.", "The framework is amenable for incorporating prior knowledge about which module should be selected.", "In the modular decomposition of a task, the modules should not change too frequently and some kind of spatial and temporal continuity is also desired.", "Temporal continuity can be accounted for by using the previous responsibility signal as input during the current timestep.", "Spatial continuity can b ensured by considering a spatial prior like the Gaussian spatial prior.", "Though model-free methods could be used for learning the RL controllers, model-based methods could be more relevant given that the modules are learning state-prediction models as well.", "Exploration can be ensured by using a stochastic version of greedy action selection.", "One failure mode for such modular architectures is when a single module tries to perform well across all the tasks.", "The modules themselves should be relatively simplistic (eg linear models) which can learn quickly and generalize well.", "Non-stationary hunting task in a grid world and non-linear, non-stationary control task of swinging up a pendulum provides the proof of concept for the proposed methods."], "author_id": "shugan", "pdf_url": "https://www.mitpressjournals.org/doi/pdf/10.1162/089976602753712972", "author_full_name": "Shagun Sodhani", "source_website": "https://github.com/shagunsodhani/papers-I-read", "id": 88969640}, {"blog_id": "towards-a-natural-benchmark-for-continual-learning", "summary": ["Continual Learning paradigm focuses on learning from a non-stationary stream of data with additional desiderata - transferring knowledge from previously seen task to unseen tasks and being resilient to catastrophic forgetting - all with a fixed memory and computational budget.", "This is in contrast to the IID (independent and identically distributed) assumption in statistical learning.", "One common example of the non-iid data is setups involving sequential decision making - eg Reinforcement learning.", "Paper  Benchmark  Many existing benchmarks use MNIST as the underlying dataset (eg Permuted MNIST, Split MNIST, etc).", "These benchmarks lack complexity and make it hard to observe positive and negative backward transfer.", "Most works focus only on the catastrophic forgetting challenge and ignore the other issues (like computation and memory footprint, the capacity of the network, etc).", "The paper proposes a new benchmark based on Starcraft II video game to understand the different approaches for lifelong learning.", "The sequence of tasks is designed to be a curriculum - the learning agent stats with learning simple skills and later move to more complex tasks.", "These complex tasks require remembering and composing skills learned in the earlier levels.", "To evaluate for catastrophic forgetting, the tasks are designed such that not all the skills are needed for solving each task.", "Hence the learning agent needs to remember skills even though they are not needed at the current level.", "Each level comes with a fixed computational budget of episodes and each episode has a fixed time limit.", "Once the budget is consumed the agent has to proceed to the next level.", "Hence agents with better sample efficiency would benefit.", "The benchmark supports both RL and supervised learning version.", "In the supervised version, expert agents (pretrained on each level) are also provided.", "Baselines are provided for distillation (using experts): sequential training (fine tuning), Dropout and SER.", "None of the baseline methods achieve positive or negative backward transfer.", "When modeled as a pure RL task, the benchmark is extremely difficult to solve.", "The paper suggests using a metric to record the amount of learning/data required to recover performance on the previous task."], "author_id": "shugan", "pdf_url": "https://www.mitpressjournals.org/doi/pdf/10.1162/089976602753712972", "author_full_name": "Shagun Sodhani", "source_website": "https://github.com/shagunsodhani/papers-I-read", "id": 24000799}, {"blog_id": "end-of-term-5", "summary": ["We\u2019ve reached the end of term again on The Morning Paper, and I\u2019ll be taking a two week break.", "The Morning Paper will resume on Tuesday 7th May (since Monday 6th is a public holiday in the UK).", "My end of term tradition is to highlight a few of the papers from the term that I especially enjoyed, but this time around I want to let one work stand alone:  Making reliable distributed systems in the presence of software errors , Joe Armstrong, December 2003.", "You might also enjoy \u201c The Mess We\u2019re In ,\u201d and Joe\u2019s seven deadly sins of programming:  Code even you cannot understand a week after you wrote it \u2013 no comments  Code with no specifications  Code that is shipped as soon as it runs and before it is beautiful  Code with added features  Code that is very very fast very very very obscure and incorrect  Code that is not beautiful  Code that you wrote without understanding the problem  We\u2019re in an even bigger mess without you Joe.", "Thank you for everything.", "RIP."], "author_id": "ACOLYER", "pdf_url": "http://erlang.org/download/armstrong_thesis_2003.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 73424952}, {"blog_id": "network-motifs-simple-building-blocks-of-complex-networks", "summary": ["The paper presents the concept of \u201cnetwork motifs\u201d to understand the structural design of a network or a graph.", "Idea  A network motif is defined as \u201ca pattern of inter-connections occurring in complex networks in numbers that are significantly higher than those in randomized networks\u201d.", "In the practical setting, given an input network, we first create randomized networks which have same single node characteristics (like a number of incoming and outgoing edges) as the input network.", "The patterns that occur at a much higher frequency in the input graph (than the randomized graphs) are reported as motifs.", "More specifically, the patterns for which the probability of appearing in a randomized network an equal or more number of times than in the real network is lower than a cutoff value (say 0.01).", "Motivation  Real-life networks exhibit properties like \u201csmall world\u201d property ( the majority of nodes are within a distance of fewer than 7 hops from each other) and \u201cscale-free\u201d property (fraction of nodes having k edges decays as a power-law).", "Motifs are one such structural property that is exhibited by networks in biochemistry, neurobiology, ecology, and engineering.", "Further, motifs shared by graphs of different domains are different which hints at the usefulness of motifs as a fundamental structural property of the graph and relates to the process of evolution of the graph."], "author_id": "shugan", "pdf_url": "https://science.sciencemag.org/content/298/5594/824/tab-pdf", "author_full_name": "Shagun Sodhani", "source_website": "https://github.com/shagunsodhani/papers-I-read", "id": 99440206}, {"blog_id": "lle", "summary": ["Roweis, Saul, 2000  ISOMAP and MDS require estimates of pairwise distances between data points.", "LLE gets around this by \u201cthinking\u201d globally but fitting locally.", "Essentially, each data point should hypothetically be representable by a locally linear patch.", "Therefore, LLE seeks $W$ such that  is minimized.", "Hence, a data point should be reconstructed by its neighbors; the problem is solved via least squares.", "Note that the weights are invariant to affine transformations and translations.", "Assuming that $W$ should be preserved in a lower dimensional representation of the data, LLE seeks to solve  The optimal coordinates $Y$ can be found by solving a sparse $n \\times n$ eigenvalue problem.", "Because of the simple construction and use of simple linear algebra, LLE has better theoretical properties than other algorithms like autoencoders  It also has less hyperparameters  Doesn\u2019t need to be rerun when new dimensions are added to the embedding space (old ones do not change)  Does LLE work on spheres?", "It seems like it would run into the same problem if the sphere didn\u2019t have a hole taken out of it"], "author_id": "pemami", "pdf_url": "http://www.robots.ox.ac.uk/~az/lectures/ml/lle.pdf", "author_full_name": "Patrick Emami", "source_website": "https://pemami4911.github.io/index.html", "id": 12175403}, {"blog_id": "a-design-methodology-for-reliable-software-systems", "summary": ["A design methodology for reliable software systems Liskov 1972  We\u2019ve come to the end of Liskov\u2019s list .", "The final paper is by Barbara Liskov herself, on the question of how best to go about designing software systems so that we can have some confidence they will work.", "The unfortunate fact is that the standard approach to building systems, involving extensive debugging, has not proved successful in producing reliable software, and there is no reason to suppose it ever will.", "So we\u2019re going to need some testing, and for high levels of confidence we\u2019ll need good coverage via:  a complete but minimal set of test cases, and  a system in which the set of relevant test cases is small, such that it is possible to generate every case  It is the system design which determines how many test cases there are and how easily they can be identified, the problems can be solved most effectively during the design process.\u201d  And with that short introduction, the rest of the paper focuses on the questions of \u2018What is a good system design?\u2019 and \u2018What process will help to ensure we produce one?\u2019  A good system design is one where complexity is tamed by dividing it into modules (called \u2018partitions\u2019 in the paper, because the term module had already become very overloaded).", "As we\u2019ve looked at previously , just dividing a system into modules isn\u2019t enough though \u2013 it matters very much how you make those divisions.", "In fact,  \u2026the division of a system into modules may introduce additional complexity\u2026 if modularity is viewed only as an aid to management, then any ad hoc modularization of the system is acceptable.", "However, the success of modularity depends directly on how well the modules are chosen.", "A good modularity is based on levels of abstraction, and uses structural programming within modules.", "Level of abstraction were first defined by Dijktsra.", "They provide a conceptual framework for achieving a clear and logical design for the system.", "The entire system is conceived as a hierarchy of levels, the lowest levels being those closest to the machine.", "There are two important rules given for levels of abstraction:  Each level has resources which it owns exclusively and which other levels are not permitted to access.", "Lower levels are not aware of the existence of higher levels and therefore may not refer to them in any way.", "With good modularity, the system is broken into a hierarchy of partitions (modules), with each partition representing one level of abstraction and consisting of one or more functions which share common resources.", "The connections between partitions are limited as follows:  Control connections are limited by the rules about the hierarchy of levels of abstraction  Connections in data passed between partitions are limited to the explicit arguments passed from the functions of one partition to the (external) functions of another partition.", "Implicit interaction on common data may only occur among functions within a partition.", "The combined activity of the functions in a partition support its abstraction and nothing more.", "The definition of connections in the above follows Parnas : \u201cThe connections between modules are the assumptions which the modules make about each other.\u201d  We know what good modularity looks like when we see it now.", "But how do you arrive at good modularity in the first place?", "The traditional technique for modularization is to analyze the execution-time flow of the system and organize the system structure around each major sequential task.", "This technique leads to a structure which has very simple connections in control, but the connections in data tend to be complex.", "(See Parnas again).", "Select modules to support abstractions or concepts which you find helpful in thinking about the system\u2026.", "Abstraction is a very valuable aid to ordering complexity.", "Abstractions are introduced in order to make what the system is doing clearer and more understandable; an abstraction is a conceptual simplification because it expresses what is being done without specifying how it is done.", "What kinds of abstractions should we be on the lookout for?", "Abstractions of resources \u2013 modules that map the characteristics of an abstract resource into the real underlying resource or resources  Abstractions that hide data storage representations  Abstractions that limit information:  According to the third requirement for good modularizatio, the functions comprising a partition support only one abstraction and nothing more.", "Sometimes it is difficult to see that this restriction is being violated, or to recognize that the possibility for identification of another abstraction exists.", "One technique for simplification is to limit the amount of information which the functions in the partition need to know (or even have access to).", "One way to limit information is to introduce modules at a lower level, on which the higher-level module depends, which hide that knowledge.", "Abstractions that generalize a function or group of functions.", "\u201cSeparating such groups is a common technique in system implementation and is also useful for error avoidance, minimization of work, and standardization.\u201d  Abstractions that encapsulate areas likely to change  The design process proceeds iteratively as follows.", "First determine an initial set of abstractions which represent the eventual system behaviour in a very general way.", "Then establish the data and flow of control connections among the partitions.", "The second phase occurs concurrently with the first; as abstractions are proposed, their utility and practicality are immediately investigated\u2026 A partition has been adequately investigated when its connections with the rest of the system are known and when the designers are confident that they understand exactly what its effect on the system will be.", "Varying depths of analysis will be necessary to achieve this confidence.", "When do you start programming modules?", "There is a tendency to think of this as the era of the strict waterfall, but that\u2019s not what Liskov proposes:  It is not clear exactly how early structured programming of the system should begin\u2026 The best rule is probably to keep trying to write structured programs; failure will indicate that the system abstractions are not yet sufficiently understood and perhaps this exercise will shed some light on where more effort is needed or where other abstractions are required.", "Finally, a design can be considered \u2018finished\u2019 when the following criteria are met:  All major abstractions have been identified and partitions defined for them; the system resources have been distributed among the partitions and their positions in the hierararchy established.", "The system exists as a structured program\u2026 this consists of several components, but no component is likely to be completely defined.", "Rather each component is likely to use the names of lower-level components which are not yet defined.", "Sufficient information is available so that a skeleton of a user\u2019s guide to the system could be written.", "(This was an era of much simpler user interfaces remember)."], "author_id": "ACOLYER", "pdf_url": "https://valbonne-consulting.com/papers/classic/Liskov_72-Design_Methodology_for_Reliable_Software_Systems.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 74642936}, {"blog_id": "a-case-for-managed-and-model-less-inference-serving", "summary": ["A case for managed and model-less inference serving Yadwadkar et al., HotOS\u201919  HotOS\u201919 is presenting me with something of a problem as there are so many interesting looking papers in the proceedings this year it\u2019s going to be hard to cover them all!", "As a transition from the SysML papers we\u2019ve been looking at recently, I\u2019ve chosen a HotOS position paper from the Stanford Platform Lab to kick things off.", "As we saw with the SOAP paper last time out, even with a fixed model variant and hardware there are a lot of different ways to map a training workload over the available hardware.", "In \u201cA case for managed and model-less inference serving\u201d Yadwadkar et al. look at a similar universe of possibilities for model serving at inference time, and conclude that it\u2019s too much to expect users to navigate this by themselves.", "Making queries to an inference engine has many of the same throughput, latency, and cost considerations as making queries to a datastore, and more and more applications are coming to depend on such queries .", "\u201cFor instance, Facebook applications issue tens-of-trillions of inference queries per day with varying performance, accuracy, and cost constraints.\u201d  If we want an increasing number of applications to use machine learning, we must automate issues that affect ease-of-use, performance, and cost efficiency for users and providers\u2026 Despite significant research, this is missing right now.", "Perhaps inspired by serverless in spirit and in terminology, the path forward proposed in this paper is towards a managed and model-less inference serving system.", "Managed here means that the system automates resource provisioning for models to match a set of SLO constraints (cf.", "autoscaling).", "Model-less is more confusing.", "First off there still is a model of course (but then there are servers hiding behind a serverless abstraction too!).", "Most of the discussion in the paper focuses on model families, i.e. selecting among variants of a given model transparently to the end user.", "But the vision clearly seems to include selection of the model itself.", "I get the former, but the latter feels to me much more like something you\u2019d be doing during model development and training rather than dynamically at inference time.", "Perhaps we are intended to develop and train multiple models with differing characteristics, and make all of these available to the inference serving system to dynamically select from at runtime??", "The paper is silent on this issue.", "\u2026 we argue for an interface to the managed inference serving system where users are able to focus on querying an inference for their tasks without needing to think of models, and the trade-offs offered by model-variants.", "We term this interface model-less.", "Usability expectations  Creating a managed and model-less inferencing platform faces many challenges: applications have diverse SLOs (e.g. throughput sensitive vs latency sensitive); query patterns change dynamically over time; the underlying available hardware resources are diverse and also change over time; and their are many possible variants of a given model to choose from.", "Model variants can be created by methods such as model compression, knowledge distillation, tuning of hyperparameter values, varying precision, optimising for different batch sizes, and so on.", "The following figure highlights how just one of these variables, batch size, impacts throughput and latency on ResNet50.", "Expectation 1: Model-variant selection should be hidden behind a high-level API that allows users to simply specify their performance and cost objectives.", "Different hardware architectures (CPUs, GPUs, TPUs, FPGAs, ASICs, \u2026) offer different performance and cost trade-offs.", "Performance may vary by up to a couple of orders of magnitude for example.", "Expectation 2: The choice of hardware should be hidden behind the same high level API for users.", "The system should select the right hardware type(s) to use at any point in time for meeting performance and cost SLOs.", "We\u2019d like to pack models as efficiently as possible on the underlying infrastructure.", "Different applications will have different needs (and resource requirements) in terms of throughput and latency.", "Today it is most common to provision separate resources for each model, but model multi-tenancy would allow us to make better use of the underlying resources.", "An evaluation conducted by the authors showed that most models experience minimal performance loss with up to 5-6 concurrent instances running on a shared GPU.", "A quick back-of-the-envelope calculation suggests cost savings around an order of magnitude or more from sharing of hardware resources.", "Expectation 3: Resource management to meet query cost and performance goals for different models under varying load should be abstracted away from users.", "To improve provider resource utilization and TCO, the system must transparently (i) share resources across different model instances, (ii) share models across users, and (iii) manage memory by replicating and evicting models based on observed load and popularity.", "Similar to the start-up latency of a cold function in the serverless world, there\u2019s start-up latency to be considered when first loading a model onto a given hardware platform.", "We pay this price when scaling up and when adding a new model to the system.", "Ideally we\u2019d hide this from the user as best as possible:  Expectation 4: Start-up latency arising due to (i) loading a model-variant into the target hardware\u2019s memory or storage and (ii) building an optimized model-variant, should be handled transparently.", "Keeping all model-variants warm all the time though is going to be very expensive, so there\u2019s a constraint:  Expectation 5: To prevent poor resource utilization, providers should not need to constantly keep model-variants running.", "How can we get there?", "The wonderful thing about position papers is that you don\u2019t have to show working implementations ;).", "Section 3 of the paper instead provides a sketch of approaches and research directions that can take us towards the vision.", "A user sends one or more queries for a prediction task, such as object recognition, with optional SLO constraints, for instance, 90 th percentile inference latency.", "The serving system takes care of the rest \u2013 automatic model-variant and target hardware selection, automatic model-variant generation, load-aware adaptive scaling, fault tolerance, monitoring, logging, maintaining security and privacy of models and queries.", "Based on the SLO of a query, and the dynamic state of the system, it will be mapped to a pairing of a model variant and target hardware for running that variant.", "Model variants can be generated on demand if needed.", "Ideally there would already be an instance of the variant running on the target hardware, if not we\u2019ll need to start one (presumably the start-up latency cost will be a factor in determining placement).", "\u201cHow to design mechanisms and policies to avoid or reduce this latency remains an open question.\u201d It\u2019s probably a combination of heuristics and learned behaviour to proactively launch variants, together with an eviction model to clean-up under-utilised model instances.", "Further opportunities come from considering model placement at the edge and middle tiers, not just in cloud datacenters.", "Different layers offer trade-offs in terms of resource capacity, cost and network latency, management overheads, and energy-efficiency.", "Utilizing the resources across this continuum of core-middle-edge computing opens new opportunities and research directions.", "The final discussion in the paper concerns security and privacy.", "Authentication and authorization should be in place to prevent unauthorized access to queries, their submission patterns, and inference outcomes, to other users and providers.", "When building personalized models by adding a user-specific layer on top of a number of generic layers, can we share  the generic layers across users?", "Are there privacy concerns in doing so?", "The last word  The growing importance of ML inference forces us to finally solve several problems together: management of heterogeneity for both hardware and models, designing user interfaces, and building SLO-driven systems.", "These challenges are non-trivial and create new avenues for research.", "The good news, however, is that it is a bounded problem (i.e., models and model-variants are immutable once created), thus giving us hope to get it right soon.", "Replace \u2018model\u2019 with \u2018datastore\u2019 and you\u2019ll see a very similar set of problems that we\u2019ve been chipping away at for a very long time.", "Hope that we can make meaningful progress soon, yes.", "But hope that we can \u2018get it right\u2019 soon and put this challenge behind us?", "My personal bet is that this is a longer road\u2026"], "author_id": "ACOLYER", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3317550.3321443?download=true", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 17601393}, {"blog_id": "polaris-faster-page-loads-using-fine-grained-dependency-tracking", "summary": ["Polaris: Faster Page Loads Using Fine-Grained Dependency Tracking \u2013 Netravali et al. 2016  Yesterday we looked at Shandian which promised faster web page load times, but required a modified client-side browser.", "Today we\u2019re sticking with the theme of reducing page load times with Polaris.", "Unlike Shandian, Polaris works with unmodified browsers, and in tests with content from 200 sites out of the top Alexa 500 it is able to reduce load times by 34% at the median, and 59% at the 95th percentile.", "To load a page, a browser must resolve the page\u2019s dependency graph.", "The dependency graph captures \u201cload-before\u201d relationships between a page\u2019s HTML, CSS, JavaScript, and image objects.", "Consider a browser parsing an HTML file that encounters a script tag.", "It has to halt the parsing and rendering of the page to download the linked .js file and evaluate it as this may alter the downstream HTML, or define JavaScript state required by later script files.", "Synchronously loading JavaScript files guarantees correctness, but this approach is often too cautious.", "For example, if first.js and second.js do not modify mutually observable state, the browser should be free to download and evaluate the files in whatever order maximizes the utilization of the network and the CPU.", "However, pages do not expose such fine-grained dependency information to browsers\u2026  (Yes, \u201c tags can be marked with async or defer attributes, but by default they have neither.", "In the test corpus of 200 popular sites, this accounts for 98.3% of all scripts\u2026).", "The Scout tool is used to load a page offline and produce a fine-grained dependency graph that is much more detailed than those produced by prior frameworks.", "\u201cFor 81% of the 200 real-world pages that we examined, our new graphs have different critical paths than those of graphs from prior work.\u201d  Polaris is a dynamic client-side scheduler that uses the dependency graphs created by Scout to reduce page load times:  When a user makes a request for a Polaris-enabled page, the server returns a scheduler stub instead of the page\u2019s original HTML.", "The scheduler stub includes the Polaris JavaScript library, the page\u2019s fine-grained dependency graph (as generated by Scout), and the original HTML.", "The Polaris library uses the Scout graph, as well as dynamic observations about network conditions, to load objects in an order that reduces page load time.", "Scout  Given simply lexical dependency information, then:  A script tag might read CSS style properties from the DOM tree, so CSS evaluation must block JavaScript execution  A script tag might change downstream HTML, so when a browser encounters such a tag it must block or transfer HTML parsing to a speculative thread  Two script tags that are lexically adjacent might exhibit a read/write dependency on JavaScript state.", "Thus browsers must execute the script tags serially\u2026  Scout finds out the true dependencies, not just the potential ones.", "It captures three types of data flows involving the JavaScript heap and the DOM state belonging to HTML and CSS:  Write/read dependencies: one object produces state that another object consumes.", "E.g. a global variable created by a.js and later read by b.js.", "Read/write dependencies: one object must read a piece of state before the value is updated by another object.", "For example, JavaScript code reading a DOM value before the value is changed by the HTML parser.", "\u201cAny reordering of object evaluations must ensure value equivalence for DOM queries \u2013 regardless of when a JavaScript file is executed, its DOM queries must return the same results.\u201d  Write/write dependencies: two objects update the same piece of state, and we must preserve the happens-before relationship.", "For example, CSS files update DOM state, changing the rules which govern a page\u2019s visual presentation.", "The CSS specification states that if two files update the same rule, the last writer wins.", "\u2026once we know the DOM dependencies and JavaScript heap dependencies for a script tag, the time at which the script can be evaluated is completely decoupled from the position of the script tag in the HTML \u2013 we merely have to ensure that we evaluate the script after its fine-grained dependencies are satisfied.", "Similarly, we can parse and render a piece of HTML at any time, as long as we ensure that we have blocked the evaluation of downstream objects in the dependency graph.", "The content of web pages is recorded using Mahimahi .", "Scout then rewrites each JavaScript and HTML file in the page adding instrumentation to log the fine-grained data flows across the JavaScript heap and the DOM.", "The page is then loaded in a regular browser and the log is used to generated the dependency graph.", "For a given page, a web server may generate a different dependency graph for different clients\u2026 The server-side logic must run Scout on each version of the dependency graph.", "We believe that this burden will be small in practice, since even customized versions of a page often share the same underlying graph structure (with different content in some of the nodes).", "An analysis of 200 sites from the Alexa top 500 showed that Scout finds 30% more edges at the median, and 118% more edges at the 95% percentile than existing dependency analysis tools (Klotski, WProf).", "Those additional edges have a dramatic impact on the characteristics of dependency graphs.", "For example, adding fine-grained dependencies alters the critical path length for 80.8% of the pages in our corpus.", "Polaris  Polaris is written completely in JavaScript and can be run on unmodified commodity browsers.", "It combines the dependency graph produced by Scout with observations about current network conditions to determine the dynamic critical path for a page.", "The dynamic critical path, i.e. the path which currently has the most unresolved objects, is influenced by the order and latency with which network fetches complete; importantly, the dynamic critical path may be different than the critical path in the static dependency graph.", "To load a page using Polaris, a web server is configured to respond to page requests with the Polaris scheduler stub HTML.", "This contains four components:  The scheduler itself, as inline JavaScript code  The Scout dependency graph, as a JavaScript variable inside the scheduler  DNS prefetch hints to indicate that the scheduler will be contacting certain hostnames in the near future.", "\u201cDNS hints allow Polaris to pre-warm the DNS cache in the same way that the browser does during speculative HTML parsing.\u201d  The page\u2019s original HTML, broken into chunks by Scout as determined by Scout\u2019s fine-grained dependency resolution.", "Across the 200 sites in test corpus, the schedule stub increased page size by 36.5KB (3%) at the median.", "Since modern browsers limit a page to at most six outstanding requests to a give origin, Polaris maintains per-origin priority queues.", "With the exception of the top-level HTML (which is included in the scheduler stub), each object in the dependency graph belongs to exactly one queue.", "Inside a queue, objects that are higher in the dependency tree receive a higher priority, since those objects prevent the evaluation of more downstream objects.", "At any given moment, the scheduler tries to fetch objects that reside in a dynamic critical path for the page load.", "However, if fetching the next object along a critical path would violate a per-origin network constraint, Polaris examines its queues, and fetches the highest priority object from an origin that has available request slots.", "How well does it work?", "\u2026 we demonstrate that Polaris can decrease page load times across a variety of web pages and network configurations: performance improves by 34% and 59% for the median and 95th percentile sites, respectively.", "Polaris\u2019 benefits grow as network latencies increase, because higher RTTs increase the penalty for bad fetch schedules.", "Thus, Polaris is particularly valuable for clients with cellular or low-quality wired networks.", "However, even for networks with moderate RTTs, Polaris can often reduce load times by over 20%.", "A closer look at three sites, Apple, ESPN, and Weather.com shows the impact the dependency graph has on the benefits that Polaris can bring:  Apple\u2019s home page has a flat dependency graph such that once the top-level HTML is loaded, all other objects can be fetched and evaluated in an arbitrary order.", "For low RTTs, this makes Polaris slower than the baseline.", "Weather.com has a much more complex dependency graph, which enables Polaris to beat the baseline handsomely.", "Polaris was also tested in conjunction with SPDY and found to be complementary: load times using Polaris over SPDY are 2.05%-4.03% faster than those with Polaris over HTTP/1.1."], "author_id": "ACOLYER", "pdf_url": "http://web.mit.edu/ravinet/www/polaris_nsdi16.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 8455503}, {"blog_id": "time-adaptive-sketches-ada-sketches-for-summarizing-data-streams", "summary": ["Time-adaptive sketches (Ada Sketches) for Summarizing Data Streams Shrivastava et al. SIGMOD 2016  More algorithm fun today, and again in the context of data streams.", "It\u2019s the 3 V\u2019s of big data, but not as you know it: Volume, Velocity, and Var\u2026 Volatility.", "Volatility here refers to changing patterns in the data over time, and that can make life awkward if you\u2019re trying to extract information from a stream.", "In particular, the authors study the heavy hitters problem, but with a twist: we want to give more weight to recent trends.", "In most applications that involve temporal data, most recent trends tend to be most informative for predictive purposes\u2026.", "For instance, most recent variations in credit history are much stronger indicators of a person\u2019s ability to make loan payments compared to variations in credit history from the distant past.", "Time-adaptive sketches generalize sketching algorithms and have the property that they retain counts of heavy hitters with good accuracy, while also providing provable time-adaptive guarantees.", "Coming in at 16 pages, the essence of the paper, especially if you\u2019re familiar with count-min sketches is this: instead of increasing counters by 1 every time you see an item, increase them by f(t), where f(t) is a monotone function in time.", "When you want to extract count estimates for time t, divide by f(t).", "The authors experiment with a linear function f(t) = at, for fixed a (0.5), and also an exponential function f(t) = at for fixed a (1.0015).", "Both gave good results.", "Finishing the write-up here though would be to short-change you.", "We\u2019re interested in why this works, and what guarantees it gives.", "Plus the paper also gives an excellent tour through some of the prior approaches to solving the heavy hitters problem.", "Let\u2019s start there, with a very quick recap on the basic Count-Min Sketch (CMS) algorithm.", "Count-Min Sketch  Create an integer array initialised to zeros that is w wide and d deep.", "Take d pairwise independent hash functions, h1,\u2026,hd and associate one with each row of the table, these functions should produce a value in the range 1..w. When a new value is seen, for each row of the table, hash the value with the corresponding hash function, and increment the counter in the indicated array slot.", "If you want to know the estimate of how many instances of a given value have been seen, hash the value as previously and look up the counter values that gives you in each row.", "Take the smallest of these as your estimate.", "Hokusai \u2013 nearly but not quite  Hokusai-sketching (Matusevych et al. 2012) introduced an item aggregation algorithm for constructing time-adaptive sketches.", "Hokusai uses a set of Count-Min sketches for different time intervals, to estimate the counts of any item for a given time or interval.", "To adapt the error rate temporally in limited space, the algorithm uses larger sketches for recent intervals and sketches of smaller size for older intervals.", "At the end of a time interval (e.g T), a sketch needs to be moved into the next-sized-down sketch, (the one for T\u20131).", "Hokusai has a very elegant way of doing this: at each rung on the ladder, sketch widths are halved.", "You can therefore compress a larger sketch into a smaller one by simply adding one half of the sketch to the other, and also halving the hash function ranges using modulo 2 operations.", "Although this idea of having different-size sketches for different time intervals is reasonable and yields accuracies that are time-adaptive, it comes with several inherent shortingcomings.", "Inspiration \u2013 Dolby noise reduction!", "This might date some of The Morning Paper readers \u2013 do you remember Dolby B noise reduction?", "And then the exciting introduction of Dolby C?", "Some of us grew up with music on cassette tapes, and Dolby Noise Reduction was ever present.", "When recording, Dolby systems employ pre-emphasis \u2013 artificially boosting certain parts of the input signal.", "On playback, the reverse de-emphasis translation restores the original signal levels.", "This process helps to improve the signal-to-noise ratio and combat tape hiss.", "We exploit the fact that Count-Min Sketch (CMS)\u2026 has better accuracy for heavy-hitters as compared to the rest of the items.", "While updating the sketch we apply pre-emphasis and artificially inflate the counts of more recent items compared to older ones, i.e., we make them heavier with respect to the older items.", "This is done by multiplying updates cit with f(t), which is any monotonically increasing function of time t. Thus, instead of updating the sketch with cit we update the sketch with _f(t) x cit.", "The tendency of the sketch is to preserve large values.", "This inflation thus preserves the accuracy of recent items, after artificial inflation, compared to the older ones.", "On querying of course, the de-emphasis process must be applied, which means dividing the results by f(t) to obtain the estimate of item i at time t. In the absence of collisions, as with the base CMS, counts are estimated exactly.", "Consider a CMS with only one row, and the case when two independent items i and j collide.", "We see cit instances of i, and cjt\u2019 instances of j.", "With plain CMS, we would over-estimate the count for i by cjt\u2019, whereas with the pre-emphasis process we overestimate by (f(t) x cjt)/f(t\u2019)).", "Therefore it is easy to see that more recent items suffer less compared to older items.", "Adaptive CMS  The Adaptive Count-Min Sketch algorithm (Ada-CMS), is just CMS but with the update and query mechanisms adapted to use the pre-emphasis and de-emphasis mechanism just described.", "Note that when f(t) = 1 we obtain the original CMS algorithm.", "By choosing appropriate f(t) functions, we can tailor the behaviour for different situations.", "One major question we are interested in is \"Given a fixed space and current state of time T, what are the values of time t \u2264 T where Ada-CMS is more accurate than vanilla CMS?", "For a given w and d, we can see as a start that the expected error of Ada-CMS will be less than CMS if:  For t=T this will always be true (due to the monotonicity requirement on f(t)).", "The upper bound on the error with vanilla CMS is &sqrt;T, so Ada-CMS wins when its error is less than this.", "To illustrate a reasonable scenario, suppose we want the errors with Ada-CMS to be never off by a factor \u03b3 away from that of vanilla CMS \u2200 t. This ensures that we guarantee accuracy within a factor \u03b3 of what the original CMS would achieve to even very old heavy hitters.", "In addition, we want to be more accurate than CMS on all recent time t > K, for some desirable choice of K.  With a couple of simple manoeuvres (see section 5.2), this turns into solving the following pair of simultaneous equations:  Other applications  The pre-emphasis and de-emphasis technique can be used in a number of other scenarios.", "The authors show an example with the Lossy Counting algorithm, and also how it can be applied to range queries (see \u00a76).", "Evaluation  Experimental evaluation is undertaken with two real-world streaming datasets from AOL (36M search queries with 3.8M unique terms) and Criteo (150K unique categorical terms).", "Comparison is undertaken between vanilla CMS, the Hokusai algorithm, Ada-CMS with a linear function (f(t) = 0.5t), and Ada-CMS with an exponential function (f(t)=1.0015t).", "In all cases d = 4, and w was varied from 210 to 223 to see the impact of varying range sizes.", "Here are the results for the AOL dataset:  Here\u2019s the standard deviation of those errors with w=218:  The Last Word  The proposed integration of sketches with pre-emphasis and de-emphasis, as we demonstrate, posseses strong theoretical guarantees on errors over time.", "Experiments on real datasets support our theoretical findings and show significantly superior accuracy and runtime overhead compared to the recently proposed Hokusai algorithm.", "We hope that our proposal will be adopted in practice, and it will lead to further exploration of the pre-emphasis and de-emphasis idea for solving massive data stream problems."], "author_id": "ACOLYER", "pdf_url": "http://research.microsoft.com/en-us/um/people/mbilenko/papers/16-ada-sketches.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 37479343}, {"blog_id": "why-does-the-neocortex-have-columns-a-theory-of-learning-the-structure-of-the-world", "summary": ["Why does the neocortex have columns, a theory of learning the structure of the world Hawkins et al., bioRxiv preprint, 2017  Yesterday we looked at the ability of the HTM sequence memory model to learn sequences over time, with a model that resembles what happens in a single layer of the neocortex.", "But the neocortex has six layers.", "Today\u2019s paper builds on the previous work to show how pairs of layers can learn predictive models of static objects, when the sensory input changes due to our own movement.", "For example, when our fingers touch an object.", "Our research has focused on how the brain makes predictions of sensory inputs.", "Starting with the premise that all sensory regions make predictions of their constantly changing input, we deduced that each small area in a sensory region must have access to a location signal that represents where on an object the column is sensing.", "Building on this idea, we deduced the probable function of several cellular layers and are beginning to understand what cortical columns in their entirety might be doing.", "Anatomical evidence  A few general rules have been observed for cellular layers in the neocortex:  Cells in layers that receive direct feedforward input don\u2019t send their axons outside the local region, and don\u2019t form long distance horizontal connections within their own layer.", "Cells in layers driven by input layers do form long range connections within their layer, and also send an axonal branch outside of the region, representing an output.", "The two layer input-output circuit thus formed appears between layer 4 and layer 2/3 of the six layers in the neocortex.", "Layers 6 and 5 may be a second instance of the pattern.", "The prevalence of this two-layer connection motif suggests it plays an essential role in cortical processing.", "A key component of our theory is the presence in each column of a signal representing location.", "The location signal represents an \u201callocentric\u201d location, meaning it is a location relative to the object being sensed.", "The neurons effectively have to compute a predicted new location from the combination of current location, object orientation, and movement.", "That sounds a tall order, but we already know that grid cells in the entorhinal cortex perform these types of transformations, encoding the location of an animal\u2019s body relative to an external environment.", "These analogs, plus the fact that grid cells are phylogenetically older than the neocortex, lead us to hypothesize that the cellular mechanism used by grid cells were preserved and replicated in the sub-granular layers of each cortical column.", "Enough of the biology, let\u2019s now turn to the model it inspired.", "Multi-layer model  The current model consists of two layers of pyramidal neurons arranged in a column.", "The model has one or more of these columns.", "Each cortical column processes a subset of the sensory input space and is exposed to different parts of the world as the sensors move.", "The neurons used in the model are HTM model neurons as we looked at yesterday.", "Input layer  The input layer of each column consists of HTM neurons arranged in mini-columns.", "It receives a sensory input as a feedforward input, and a location input as a basal modulatory input.", "The sensory input is a sparse binary array representing the current feature in input space.", "During inference, cells that recognize both the modulatory location input and the feedforward driving input will inhibit other cells in the mini-column.", "In this way, the input layer forms a sparse representation that is unique for a specific sensory feature at a specific location on the object.", "Neurons in the input layer also receive feedback connections from the output layer.", "These carry information about the object detected, which combined with modularity input representing the anticipated new location, allow the input layer to more precisely predict the next sensory input.", "Output layer  The output layer is also made up of HTM neurons.", "The set of cells that are active in the output layer represent objects.", "Output layer cells receive feedforward input from the input layer, and modulatory input from other output cells representing the same object, both within the column and also from neighbouring columns.", "During learning, the set of cells representing an object remains active over multiple movements and learns to recognize successive patterns in the input layer.", "Thus, an object comprises a representation in the output layer, plus an associated set of feature/location representations in the input layer.", "Cells representing the same object positively bias each other.", "Say at time t, a column has feedforward support for objects A and B.", "And at time t+1 it has feedforward support for objects B and C. Due to the modulatory input from time t, the output layer will converge on the representation for B.", "Example: cubes and wedges  The following figure shows two layers of a single cortical column collaborating to disambiguate between a cube and a wedge shape that have shared features.", "The first sensed feature f1 is ambiguous so the output layer supports both object patterns, but with repeated sensations the output layer quickly narrows down on the correct choice (the cube in this case).", "( Enlarge )  Learning  Learning is based on Hebbian-style adaptation as we saw yesterday.", "The input layer learns specific feature/location combinations, and if the current combination has not yet been learned, then one cell from each mini-column (the one with the best modulatory input match) is chosen as the winner and becomes active.", "Winner cells learn by forming and strengthening modulatory connections with the current input location.", "The output layer learns representations that correspond to objects:  When the network first encounters a new object, a sparse set of cells in the output layer is chosen to represent the new object.", "These cells remain active while the system senses the object at different locations.", "Feed forward connections between the changing active cells in the input layer and unchanging active cells in the output layer are continuously reinforced.", "Simulation results  Networks are constructed with one or more two-layer cortical columns.", "In each column the input layer comprises 150 mini-columns, 16 cells tall each.", "The output layer consists of 4096 cells, which are not arranged in mini-columns.", "One-column and three-column variations of the network are trained on a library of 500 objects.", "As can be seen below, both variations converge on a single object representation over time, but the three-column version gets there faster.", "The capacity of the network is defined as the number of objects it can learn and recognise without confusion.", "It is influenced by the representational space of the network, the number of mini-columns in the input layer, the number of neurons  in the output layer, and the number of cortical columns.", "150 mini-columns with 16 cells per mini-column, and 10 simultaneously active mini-columns, turns out to be enough to uniquely represent about 10^15 sensory features, each represented at 16^10 unique locations.", "As the number of learned objects increases, neurons in the output layer form increasing numbers of connections to neurons in the input layer.", "If an output neuron connects to too many input neurons, it may be falsely activated by a pattern it was not trained on.", "Therefore, the capacity of the network is limited by the pooling capacity of the output layer.", "Mathematical analysis suggests that a single cortical column can store hundreds of objects before reaching this limit.", "Figure 5 below explores the various dimensions of network capacity.", "The network shows no drop in recognition accuracy with up to 20% noise in the sensory input, and 40% noise in the location input, though it does take longer to converge.", "Mountcastle\u2019s conjecture  In 1978 Mountcastle postulated that since the complex anatomy of cortical columns is similar in all of the neocortex, then all areas of the neocortex must be performing a similar function\u2026  The model of a cortical column presented in this paper is described in terms of sensory regions and sensory processing, but the circuitry underlying our model exists in all cortical regions.", "Thus if Mountcastle\u2019s conjecture is correct, even high-level cognitive functions, such as mathematics, language, and science would be implemented in this framework.", "It suggests that event abstract knowledge is stored in relation to some form of \u201clocation\u201d and that much of what we consider to be \u201cthought\u201d is implemented by inference and behavior generating mechanisms originally evolved to move and infer with fingers and eyes."], "author_id": "ACOLYER", "pdf_url": "https://www.frontiersin.org/articles/10.3389/fncir.2017.00081/full", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 35377831}, {"blog_id": "bbr-congestion-based-congestion-control", "summary": ["BBR: Congestion-based congestion control Cardwell et al., ACM Queue Sep-Oct 2016  With thanks to Hossein Ghodse (@hossg) for recommending today\u2019s paper selection.", "This is the story of how members of Google\u2019s make-tcp-fast project developed and deployed a new congestion control algorithm for TCP called BBR (for Bandwidth Bottleneck and Round-trip propagation time), leading to 2-25x throughput improvement over the previous loss-based congestion control CUBIC algorithm.", "In fact, the improvements would have been even more significant but for the fact that throughput became limited by the deployed TCP receive buffer size.", "Increasing this buffer size led to a huge 133x relative improvement with BBR (2Gbps), while CUBIC remained at 15Mbps.", "BBR is also being deployed on YouTube servers, with a small percentage of users being assigned BBR playback.", "Playbacks using BBBR show significant improvement in all of YouTube\u2019s quality-of-experience metrics, possibly because BBR\u2019s behavior is more consistent and predictable\u2026 BBR reduces median RTT by 53 percent on average globally, and by more than 80 percent in the developing world.", "TCP congestion and bottlenecks  The Internet isn\u2019t working as well as it should, and many of the problems relate to TCP\u2019s loss-based congestion control, even with the current best-of-breed CUBIC algorithm.", "This ties back to design decisions taken in the 1980\u2019s when packet loss and congestion were synonymous due to technology limitations.", "That correspondence no longer holds so directly.", "When bottleneck buffers are large, loss-based congestion control keeps them full, causing bufferbloat.", "When bottleneck buffers are small, loss-based congestion control misinterprets loss as a signal of congestion, leading to low throughput.", "Fixing these problems requires finding an alternative to loss-based congestion control.", "From the perspective of TCP, the performance of an arbitrarily complex path is bound by two constraints: round-trip propagation time (RTprop), and bottleneck bandwidth, BtlBw (the bandwidth at the slowest link in each direction).", "Here\u2019s a picture to help make this clearer:  The RTprop time is the minimum time for round-trip propagation if there are no queuing delays and no processing delays at the receiver.", "The more familiar RTT (round-trip time) is formed of RTprop + these additional sources of noise and delay.", "Bandwidth Delay Product (BDP) is the maximum possible amount of data in transit in a network, and is obtained by multiplying the bottleneck bandwidth and round-trip propagation time.", "BDP is central to understanding network performance.", "Consider what happens to delivery rate as we gradually increase the amount of data inflight.", "When the amount of inflight data is less than BDP, then delivery rate increases as we send more data \u2013 delivery rate is limited by the application.", "Once the bandwidth at the bottleneck is saturated though, the delivery rate cannot go up anymore \u2013 we\u2019re pushing data through that pipe just as fast as it can go.", "The buffer will fill up, eventually we\u2019ll start dropping packets, but we still won\u2019t increase delivery rate.", "The optimum operating point is right on the BDP threshold (blue dot above), but loss-based congestion control operates at the BDP + Bottleneck Buffer Size point (green dot above).", "Now let\u2019s look at what happens to RTT as we increase the amount of data inflight.", "It can never be better than RTprop, so until we reach BDP, RTT ~= RTprop.", "Beyond BDP, as buffers start to fill, RTT goes up until buffers are completely full and we start dropping packets.", "Once more, the optimum operating point would be right on the BDP threshold.", "This was proved by Leonard Kleinrock in 1979, unfortunately about the same time Jeffrey M. Jaffe proved that it was impossible to create a distributed algorithm that converged to this operation point.", "Jaffe\u2019s result rests on fundamental measurement ambiguities.", "Although it is impossible to disambiguate any single measurement, a connection\u2019s behavior over time tells a clearer story, suggesting the possibility of measurement strategies designed to resolve ambiguity.", "Introducing BBR  BBR is a congestion control algorithm based on these two parameters that fundamentally characterise a path: bottleneck bandwidth and round-trip propagation time.", "It makes continuous estimates of these values, resulting in a distributed congestion control algorithm that reacts to actual congestion, not packet loss or transient queue delay, and converges with high probability to Kleinrock\u2019s optimal operating point.", "(BBR is a simple instance of a Max-plus control system , a new approach to control based on nonstandard algebra.", "This approach allows the adaptation rate [controlled by the max gain] to be independent of the queue growth [controlled by the average gain].", "Applied to this problem, it results in a simple, implicit control loop where the adaptation to physical constraint changes is automatically handled by the filters representing those constraints.", "A conventional control system would require multiple loops connected by a complex state machine to accomplish the same result.)", "Since RTT can never be less than RTprop, tracking the minimum RTT provides an unbiased and efficient estimator of the round-trip propagation time.", "The existing TCP acks provide enough information for us to calculate RTT.", "Unlike RTT, nothing in the TCP spec requires implementations to track bottleneck bandwidth, but a good estimate results from tracking delivery rate.", "The average delivery rate between a send and an ack is simply the amount of data delivered divided by the time taken.", "We know that this must be less than the true bottleneck delivery rate, so we can use the highest recorded delivery rate as our running estimate of bandwidth bottleneck.", "Putting this altogether leads to a core BBR algorithm with two parts: a protocol to follow on receiving an ack, and a protocol to following when sending.", "You\u2019ll find the pseudocode for these on pages 28 and 29-30.", "From my reading, there are a couple of small mistakes in the pseudocode (but I could be mistaken!", "), so I\u2019ve recreated clean versions below.", "Please do check against those in the original article if you\u2019re digging deeper\u2026  Here\u2019s the ack protocol:  (app_limited_until is set on the sending side, when the app is not sending enough data to reach BDP).", "This is what the sending protocol looks like:  The pacing_gain controls how fast packets are sent relative to BtlBw and is key to BBR\u2019s ability to learn.", "A pacing_gain greater than 1 increases inflight and decreases packet inter-arrival time, moving the connection to the right on the performance charts.", "A pacing_gain less than 1 has the opposite effect, moving the connection to the left.", "BBR uses this pacing_gain to implement a simple sequential probing state machine that alternates between testing for higher bandwidths and then testing for lower round-trip times.", "The frequency, magnitude, duration and structure of these experiments differ depending on what\u2019s already known (start-up or steady state) and the sending app\u2019s behaviour (intermittent or continuous).", "Most time is spent in the ProbeBW state probing bandwidth.", "BBR cycles through a sequence of gains for pacing_gain, using an eight-phase cycle with values 5/4, 3/4, 1, 1, 1, 1, 1, 1.", "Each phase lasts for the estimated round-trip propagation time.", "This design allows the gain cycle first to probe for more bandwidth with a pacing_gain above 1.0, then drain any resulting queue with a pacing_gain an equal distance below 1.0, and then cruise with a short queue using a pacing_gain of 1.0.", "The result is a control loop that looks like this plot below showing the RTT (blue), inflight (green) and delivery rate (red) from 700ms of a 10Mbps, 40-ms flow.", "Here\u2019s how BBR compares to CUBIC during the first second of a 10 Mbps, 40-ms flow.", "(BBR in green, CUBIC in red).", "We talked about the BBR benefits in Google\u2019s high-speed WAN network (B4) and in YouTube in the introduction.", "It also has massive benefits for low bandwidth mobile subscriptions.", "More than half of the world\u2019s 7 billion mobile Internet subscriptions connect via 8-to 114-kbps 2.5 G systems, which suffer well-documented problems because of loss-based congestion control\u2019s buffer-filling propensities.", "The bottleneck link for these systems is usually between the SGSN (serving GPRS support node)18 and mobile device.", "SGSN software runs on a standard PC platform with ample memory, so there are frequently megabytes of buffer between the Internet and mobile device.", "Figure 10 [ below] compares (emulated) SGSN Internet-to-mobile delay for BBR and CUBIC."], "author_id": "ACOLYER", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3012426.3022184?download=true", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 89628084}, {"blog_id": "why-do-recordreplay-tests-of-web-applications-break", "summary": ["Why do Record/Replay Tests of Web Applications Break?", "\u2013 Hammoudi et al. ICST \u201916  Your web application regression tests created using record/replay tools are fragile and keep breaking.", "Hammoudi et al. set out to find out why.", "If we knew that, perhaps we could design mechanisms to automatically repair broken tests, or to build more robust tests.", "The authors look at 300 different versions of five open source web applications, creating test suites for their initial versions using Selenium IDE and then following the evolution of the projects.", "When a test broke in a given version, it was repaired so that the process could continue.", "At the end of this process, data had been gathered on 722 individual test breakages.", "Using the data we gathered, we developed a taxonomy of the causes of test breakages that categorizes all of the breakages observed on the applications we studied.", "We then gathered 153 versions of three additional web applications and applied the foregoing process to them as well; this yielded data on 343 additional test breakages.", "We analyzed these in light of our taxonomy and were able to accommodate all of them without further changing the taxonomy; this provides evidence that our taxonomy may be more generally applicable.", "Hammoudi et al. had to create their own tests since, \u201cIn searching for web applications, we discovered that few open-source applications are provided with capture-replay test suites; in fact, few are provided with any test suites at all\u2026.\u201d  This will be a shorter paper write-up than usual.", "What you really need to know is your tests are breaking because the information used to locate page elements keeps breaking.", "After collating and clustering all of the breakages across the web tests, the authors create a taxonomy with 5 high level causes of test breakages:  Causes related to locators used in tests  Causes related to values and actions used in tests  Causes related to page reloading  Causes related to changes in user sessions times  Causes related to popup boxes.", "Locators are used by JavaScript and other languages, and by record/replay tools, to identify and manipulate elements.", "We identify two classes of locators, the second of which is composed of two sub-classes\u2026  Attribute-based locators use element attributes such as element ids and names.", "Structure-based locators rely on the structure of a web page and may locate elements via a hierarchy (e.g. xpaths or CSS selectors) or via an index in the case of multiple otherwise identical elements.", "Over 70% of all breakages are due to locator fragility in the face of change, and over 50% of all breakages are further due to attribute-based locators.", "Note that we cannot conclude from this that element attribute based location is inferior to other forms of location \u2013 even though it is responsible for most breakages \u2013 since we don\u2019t know the base rate of usage of the different location strategies.", "My personal suspicion is that attribute-based location is one of the more robust strategies.", "In terms of giving guidance to practitioners seeking to write more robust tests, it would be really nice to see this additional level of analysis.", "Our data suggests which categories of test breakages merit the greatest attention.", "Locators caused over 73% of the test breakages we observed, and attribute-based locators caused the majority of these.", "Clearly, addressing just this class of errors by finding ways to repair them if they break would have the largest overall impact on the reusability of tests across releases.", "The data also suggest where subsequent priorities should be placed in terms of finding methods for repairing test breakages."], "author_id": "ACOLYER", "pdf_url": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7515470", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 27300559}, {"blog_id": "distributed-consensus-and-the-implications-of-nvm-on-database-management-systems", "summary": ["Distributed consensus and the implications of NVM on database management systems Fournier, Arulraj, & Pavlo ACM Queue Vol 14, issue 3  As you may recall, Peter Bailis and ACM Queue have started a \u201cResearch for Practice\u201d series introducing \u201cexpert curated guides to the best of CS research.\u201d Aka, reading lists for The Morning Paper!", "I previously covered the papers from the first edition (blog entries dated June 14th-21st, 2016).", "Today we\u2019re turning our attention to the the second edition:  I am thrilled to introduce our second instalment of Research for Practice, which provides highlights from two critical areas in storage and large-scale services: distributed consensus and non-volatile memory.", "Distributed consensus  The first topic area is Distributed Consensus, with papers selected by Camille Fournier.", "\u201cThe three papers included in this selection address the real world of consensus system: Why are they needed?", "Why are they difficult to understand?", "What happens when you try to implement.", "Them?", "Is there an easier way, something that more developers can understand and therefore implement?\u201d  Fournier\u2019s three choices are:  Paxos made live \u2013 an engineering perspective  The Chubby lock service for loosely coupled distributed systems  In search of an understandable consensus algorithm  All of which will be familiar to regular readers of The Morning Paper ;) (Links above are to my write-ups).", "If you want more of this kind of thing, I did a two-week mini-series on consensus back in March of last year.", "Here are three additional picks of my own:  Viewstamped Replication Revisited  Raft Refloated  And yesterday\u2019s paper, Flexible Paxos  Implications of NVM on database management systems  Joy Arulrja and Andrew Pavlo introduce a selection of three papers looking at the implications of NVM for database management systems:  The advent of non-volatile memory (NVM) will fundamentally change the dichotomy between memory and durable storage in a database management systems (DBMS).", "This is a topic area that really caught my attention earlier this year, and I wrote a short post entitled \u201c All change please \u201d summarizing some of the hardware advances hitting our data centers, including NVM.", "On the subject of NVM itself and its implications, the papers I\u2019ve covered so far can be found by searching on the blog for the keyword \u2018NVM\u2019 .", "The first of Arulja and Pavlo\u2019s picks is  From ARIES to MARS  Which looks at the classic ARIES recovery protocol and how it can be optimized for NVM.", "Their second and third paper choices are ones that I haven\u2019t covered before.", "So we\u2019ll be looking at those papers in the next two days.", "The links below will go live as each days\u2019 post goes up.", "Let\u2019s talk about storage and recovery methods for non-volatile memory database systems \u2013 a wonderful tour of common DBMS storage engine designs, and how they can be adapted to NVM.", "How did I miss this paper first time around???", "It\u2019s a real gem.", "Write-limited sorts and joins for persistent memory , which looks at the implications of read/write cost imbalance and limited write endurance in NVM.", "As Arulja and Pavlo say,  The common theme for these papers is that you cannot just run an existing DBMS on NVM and expect it to leverage its unique set of properties.", "The only way to achieve that is to come up with novel architectures, protocols, and algorithms that are tailor-made for NVM.", "The third edition of Reseach for Practice must be due out soon \u2013 I\u2019m very much looking forward to seeing where it goes next!"], "author_id": "ACOLYER", "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/2956641.2967618?download=true", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 27051635}, {"blog_id": "recursive-programming", "summary": ["Recursive Programming \u2013 Dijkstra 1960  * Updated link to one that is not behind a paywall \u2013 thanks to Graham Markall for the catch *  This paper deals with something we take so much for granted that it\u2019s hard to imagine a time when it had yet to be introduced to the world.", "That time was 1960, the concept is the language runtime stack, and the author of the paper is none other than Dijkstra.", "In fact, we\u2019re so familiar with the stack, that it takes a while to get your head around what went before: each subroutine in a program had its own private fixed working space.", "That is, suppose you write a program that contains 30 subroutines \u2013 then there will be 30 reserved areas in memory, one for each subroutine to use.", "Dijkstra points out a couple of difficulties with this arrangement:  In the first place, the storage allocations for all the subroutines together will, in general, occupy much more memory space than they ever need simultaneously, and the available memory space is therefore used rather uneconomically.", "Furthermore \u2013 and this is a more serious objection \u2013 it is then impossible to call a subroutine while one or more of the previous activations of the same subroutine have not yet come to an end, without losing the possibility of finishing them off properly later on.", "In other words, if each subroutine has its own fixed storage area, then recursive programming is not possible (you\u2019ll overwrite the state in the one fixed storage area for the subroutine).", "Since this rather limits the design space of programs, Dijkstra was interested in finding a technique that could eliminate the restriction:  The basic concept of the method is the so-called stack.", "Dijkstra describes how to build a stack with a block of memory and a stack pointer \u2013 I\u2019m going to assume you\u2019re all familiar with the idea!", "The following insight is key to the use of the stack in this context:  If we mark off, on a time axis, the moments when a unit is added to or removed from the stack, by using an opening bracket for the addition of a unit, and a closing bracket for its removal, then we obtain a correctly nested bracket structure, in which the opening and closing brackets form pairs in the same way as they do in a normal algebraic expression involving brackets.", "This is closely related to the circumstance that we can use a stack for storing the intermediate results formed in the evaluation of an arbitrary algebraic expression by means of elementary algebraic operations.", "In this case, the interest is always restricted to the most recent element in the stack.", "As the intermediate results are used only once, use of an element implies its removal from the stack.", "Take an expression  A + (B - C) * (D|E + F)  We know that we can record this in reverse polish notation as :  A, B, C, -, D, E, |, F, +, *, +  The above is well-known, and so elegant that we could not refrain from trying to extend this technique by consistent application of its principles.", "The example above assumes that A, B, C etc are numerical values that can be found in memory.", "But Dijkstra points out that C could equally have been an expression (for example C = (P/(Q-R + S*T )), and by the time we have done evaluating C, the net result would be the same as if we had the value of C accessible directly.", "In other words, it is immaterial to the \u201csurroundings\u201d in which the value C is used, whether the value C can be found ready-made in memory, or whether it is necessary to make temporary use of a number of the next stack locations for its evaluation.", "Now suppose it wasn\u2019t an expression that appears for the value of C, but a function (to be evaluated by a subroutine): \u201cthis provides a strong argument for arranging the subroutine in such a way that it operates in the first free places of the stack, in just the same way as a compound term written out in full.\u201d  The stack can be used by a subroutine for its parameters, its local variables, and even anonymous intermediate results created during execution of the subroutine.", "Inside the subroutine we store the most anonymous intermediate results in the \u201ctop\u201d of the stack in just the same way.", "Every reference to a local quantiity, however, implies one is interested in a place that is situated deeper within the stack, and here one is interested in random access to the stack places, in other words we must be able to give the places deeper in the stack some kind of address.", "The value of that reference point is, \u2018to be derived from the value of the stack pointer at the moment of the call.\u2019 With a final flourish, Dijkstra goes on to show that \u2018link\u2019 information must be preserved  in the stack when calling subroutines, so that regardless of complexity we can pick up exactly where we left off (in the ALU)- this is to include a return address.", "We can now follow what happens when subroutine A calls subroutine B, and observe that:  In this process, nothings forbids A from being identical with B.", "The subroutine only has to appear in the memory once, but it may have more than one simultaneous \u201cincarnation\u201d from a dynamic point of view: the \u201cinnermost\u201d activation causes the same piece of text to work in a higher part of the stack.", "Thus the subroutine has developed into a defining element that can be used completely recursively.", "Tada!", "Note: 1960 is also the year of \u201cRecursive Functions of Symbolic Expressions and their Computation by Machine,\u201d McCarthy\u2019s famous paper which \u201cdescribes a formalism for defining functions recursively,\u201d and then shows how it can be implemented in the LISP programming system for the IBM 704.", "\"Recursive Functions of Symbolic Expressions\u2026\" McCarthy, 1960 (LISP)  [url]"], "author_id": "ACOLYER", "pdf_url": "http://oai.cwi.nl/oai/asset/9253/9253A.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 74547298}, {"blog_id": "includeos", "summary": ["IncludeOS: A minimal, resource efficient unikernel for cloud systems \u2013 Bratterud et al. 2015  There has been lots of excitement around unikernels over the last year, and especially with the recent acquisition of the Unikernel Systems team by Docker ( MirageOS , Mergeable Persistent Data Structures , Jitsu: Just-in time summoning of Unikernels ).", "Whereas MirageOS is built around an OCaml stack, in today\u2019s paper choice we get a look at IncludeOS, which is built on a C++ stack.", "In true unikernel style, you just include the parts of the operating system you need, directly linked with your application.", "What makes me smile every time is that in IncludeOS this is literally achieved via \u2018#include <os>\u2019 !", "In this paper we present IncludeOS, a single-tasking operating system designed for virtualizedenvironments.", "IncludeOS provides a novel way for developers to build their C++-based code directlyinto a virtual machine at compile-time\u2026  A fully virtualized \u201cHello World\u201d service in IncludeOS (which of course includes the necessary components of the OS) uses only 8.45MB of memory.", "A Ubuntu 14.04 OS image (the default guest OS for OpenStack) is around 300MB by comparison.", "Even running a regular Java Hello World program (ignoring the OS), just the Java process itself takes about 28MB.", "If you\u2019re spinning up lots of instances in your cluster, this reduction in memory overhead can result in significant savings \u2013 memory being one of the most expensive resources.", "A minimal IncludeOS VM can also boot in about 0.3s.", "A DNS service built with IncludeOS results in a 158K disk image (for comparison, the MirageOS DNS server image came in at 200K).", "Finally, IncludeOS is designed to be very efficient at runtime, when idle it uses no CPU at all.", "The designers of IncludeOS were guided by the \u2018Zero Overhead Principle\u2018 :  IncludeOS aims for true minimality in the sense that nothing should be included by default that the service does not explicitly need.", "This corresponds to the zero overhead principle of e.g. C++; \u201dwhat you don\u2019t use you don\u2019t pay for.\u201d \u2026 While many other projects are related, IncludeOS is different: where systems such as Mirage and OSv aims to provide a platform for a high-level language-runtimes, which impose significant resource penalties in themselves, IncludeOS aims to represent absolute minimality.", "Including only what is needed in an OS image is a job that can be delegated to the GCC tool chain:  The mechanism used for extracting only what is needed from the operating system, is the one provided by default by modern linkers.", "Each part of the OS is compiled into an object-file, such as ip4.o, udp.o, pci_device.o etc., which are then combined using ar to form a static library os.a.", "When a program links with this library, only what\u2019s necessary will automatically be extracted by the linker and end up in the final binary.", "To facilitate this build process a custom GCC-toolchain has been created.", "For the C standard library, IncludeOS uses RedHat\u2019s standard library implementation due to its small size, reliance on only a handful of system calls, and ability to be compiled into a statically linked library.", "\u201cThe C++ standard library is larger and trickier\u2026\u201d Currently IncludeOS uses Electronic Art\u2019s EASTL exception-free implementation, future work will include a port of a full-featured implementation.", "IncludeOS currently has only one device driver, namely a VirtioNet Device driver.", "The key benefit of virtio is that the hypervisor does not need to emulate a certain physical device, but instead can insert data directly into a queue in memory shared by the guest.", "While Virtio 1.0 has recently emerged as an OASIS standard, none of the hypervisors used during development supported any of the new features.", "Therefore the driver currently only implements Virtio Legacy functionality, but development has been done with future support for Virtio 1.0 in mind.", "The network stack was a more complex challenge, since existing network stacks are often entangled with the operating system and not designed with the zero overhead principle in mind.", "The IncludeOS project is working on a completely modularized networking stack \u2013 the current implementation is sufficiently advanced to support e.g. the DNS server implementation previously mentioned, and work is underway to complete a full TCP and IPv6 stack that will also be running standalone in Linux user space.", "Currently, all IRQ handlers in IncludeOS will simply (atomically) update a counter, and defer further handling to the main event-loop, whenever there is time.", "This eliminates the need for a context switch, while also eliminating concurrency-related issues such as race conditions.", "The CPU is kept busy by having all I/O be asynchronous, so that no blocking occurs.", "This encourages a callback-based programming model, such as is common in modern Javascript applications.", "This is one of a number of factors that contribute to IncludeOS\u2019s excellent runtime performance:  There is no system call overhead as the OS and the service are one binary, eliminating the need for memory protection barriers.", "There is no unnecessary overhead from timer interrupts.", "There is no I/O waiting, since IncludeOS uses an asynchronous event-based I/O model.", "There is no overhead from emulating the Programmable Interrupt Timer (i.e. no periodic timer interrupts, and no pre-emptive scheduling).", "The number of protected instructions has been kept very low reduce VM exits.", "That being so, IncludeOS in its current form is not fit for every task.", "In particular, deferring all IRQ\u2019s will cause the VM to seem unresponsive (i.e. not answer ping) under workloads requiring a lot of CPU activity per request (this is not the case for DNS)\u2026 For services requiring several seconds of CPU-processing for each request, ICMP-packets would simply be queued until the virtio-queue was full, at which point they would be dropped, giving the impression of an unresponsive service.", "A really interesting future development for IncludeOS is the design of a Node.js style framework for supporting high performance web-applications:  A near-future use case for IncludeOS will be running high-performance web-applications, written in an asynchronous programming style similar to Node.js, but in a maximally efficient and minimal-overhead C++ language framework.", "These services will have no host kernel dependencies, running directly on top of virtual hardware, in any IaaS cloud."], "author_id": "ACOLYER", "pdf_url": "https://github.com/hioa-cs/IncludeOS/blob/master/doc/papers/IncludeOS_IEEE_CloudCom2015_PREPRINT.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 76635514}, {"blog_id": "predicate-logic-as-programming-language", "summary": ["Predicate Logic as Programming Language \u2013 Kowalski 1974  The purpose of programming languages is to enable the communication from man to machine of problems and their general means of solution.", "Kowalski shows us that predicate logic can be used as the basis of a \u201cuseful and practical, high-level, non-deterministic programming language with sound theoretical foundations.\u201d This is the foundation for Prolog and Datalog.", "As a programming language, predicate logic is the only language which is entirely user-oriented.", "It differs from existing high-level languages in that it possesses no features which are meaningful only in machine terms.", "Sentences are expressed in clausal form with a very simple syntax.", "B1,...,Bm <- A1,...,An  which can be interpreted as meaning B1 or \u2026 or Bm is implied by A1 and \u2026 and An.", "It is our thesis, that clausal form defines a natural and useful language in its own right, that thoughts can be conveniently expressed directly in clausal form, and that literal translation from another language, such as full predicate logic, often distorts the original thought.", "The Horn clause subset of predicated logic is that where clauses contain at most one disjunction (B) term.", "This is the form used for computation in the paper.", "A simple factorial example is given.", "Let Fact(x,y) denote the fact that the factorial of x is y, and let s(x) be the successor of x in the natural numbers.", "Finally, let Times(x,y,z) denote that x * y is z.", "Then:  -- the factorial of 0 is s(0), i.e. 1  Fact(0,s(0)) <-    -- if v is the factorial of x, and s(x) * v is u, then -- the factorial of s(x) is u Fact(s(x),u) <- Fact(x,v), Times(s(x),v,u)  To read these programs, I mentally insert an \u2018if\u2019 ; we can deduce the terms on the left if the terms on the right are true.", "Contrast this to a functional declaration where we mentally insert an \u2018is\u2019:  factorial 0     = 1 factorial (n+1) = (n+1) * factorial n  Non-determinism and the potential for parallelism  Predicate logic is an essentially non-deterministic programming language.", "Non-determinism is due to the fact that a given program and activating goal statement may admit more than a single legitimate computation.", "This is nicely illustrated with a program for sorting lists.", "Let Sort(x,y) denote that y is a sorted version of x; Perm(x,y) that y is a permutation of x; Ord(y) that y is ordered; Del(x,y,z) that deleting x from y results in z; and LE(x,y) that x is less than or equal to y; then:  Sort(x,y) <- Perm(x,y), Ord(y)      Perm(nil,nil) <- Perm(z,cons(x,y)) <- Perm(z',y), Del(x,z,z')      Del(x,cons(x,y),y) <- Del(x,cons(y,z),cons(y,z')) <- Del(x,z,z')      Ord(nil) <- Ord(cons(x,nil)) <- Ord(cons(x,cons(y,z))) <- LE(x,y), Ord(cons(y,z))  Consider three difference approaches to computing the sorted version of a list based on these declarations:  Generate a permutation y of x, and then test to see if y is ordered, or  Generate an ordered list y, and then test to see if it is a permutation of x, or  Grow increasingly longer ordered subsets of x, adding one element from x at each stage.", "Clearly the difference in efficiency can be enormous, but the meaning, as determined by the input-output relation Sort(x,y), computed by the program, is the same.", "It is in this sense that the sequencing of procedure calls can be said to have no semantics.", "This is fundamentally what enables highly-parallel executions in languages such as Dedalus , a Datalog derivative:  The use of parallel processes and co-routines is a particular way of sequencing procedure calls.", "The possibility of independent parallel processing arises when, for example, different procedure calls in the same body share no variables.", "In such a case, the independent procedure calls can be activated simultaneously and, given a single processor, their execution sequences can be interleaved arbitrarily.", "40 years later, and we\u2019re seeing a mini-revival in interest in Datalog and its derivatives."], "author_id": "ACOLYER", "pdf_url": "http://www-public.it-sudparis.eu/~gibson/Teaching/CSC4504/ReadingMaterial/Kowalski74.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 39155988}, {"blog_id": "brownout-building-more-robust-cloud-applications", "summary": ["Brownout: building more robust cloud applications \u2013 Klein et al. 2014  How can we design cloud applications to be resilient in the face of varying resources and user load, and always deliver the best possible user experience?", "That\u2019s a pretty important question these days, and Klein et al. report on a very interesting new development combining control theory and adaptive application behaviour with impressive results.", "Our work borrows from the concept of brownout in electrical grids.", "Brownouts are an intentional voltage drop often used to prevent blackouts through load reduction in case of emergency.", "In such a situation, incandescent light bulbs dim, hence originating the term.", "Applications can saturate \u2013 i.e. become unable to serve users in a timely manner.", "Some users may experience high latencies, while others may not receive any service at all.", "The authors argue that it is better to downgrade the user experience and continue serving a larger number of clients with reasonable latency.", "We define a cloud application as brownout compliant if it can gradually downgrade user experience to avoid saturation.", "This is actually very reminiscent of circuit breakers, as described in Nygard\u2019s \u2018Release It!\u2019 and popularized by Netflix.", "If you\u2019re already designing with circuit breakers, you\u2019ve probably got all the pieces you need to add brownout support to your application relatively easily.", "To lower the maintenance effort, brownouts should be automatically triggered.", "This enables cloud applications to rapidly and robustly avoid saturation due to unexpected environmental changes, lowering the burden on human operators.", "Of course, the other thing we might do is provide the application with more resources.", "Studies later on in the paper look at what happens when brownout controls are applied as resources are added and removed.", "The results indicate that brownout control should be able to smooth out the application response and maximise user experience during such transitions.", "How does the brownout model work?", "Application designers need to identify the parts of the response that may be considered optional (for example, return product information but not recommendations, or showing a post but not comments), and make it possible to activate the optional computations on a per-request basis.", "The application needs to export a dynamically changeable runtime parameter called the \u2018dimmer\u2019.", "The setting of the dimmer controls the probability that the optional computations will be performed when generating a given response.", "A new application component called the controller is added, its goal is to adjust the dimmer as a function of the current performance.", "So whereas a circuit breaker is triggered on failure & timeouts, the dimmer switch acts more like a flow control valve determining how many requests get to execute the optional components.", "we synthesize a control-theoretical solution to automatically decide when to activate those optional features  I\u2019ve long said that adapting an application to changing demands is a control-theory problem (and implementing a RabbitMQ-based autoscaler for a SpringOne keynote a couple of years ago made that abundantly clear) so it\u2019s great to see this approach being used here.", "It\u2019s also why I have a copy of \u2018 Feedback Control \u2018 on my Kindle waiting to be read.", "\u2026control theory allows us to provide some formal guarantees on the system.", "Our main aim is to close a loop around a cloud application, constraining the application to have a behaviour that is as predictable as possible.", "If your knowledge of control theory is better than mine, you might be able to follow along with the derivation of the controller algorithm!", "The end result (after a bit of time spent decoding on my part) actually seems pretty straightforward.", "It\u2019s a little bit like the wikipedia page on PID Controllers that I had to refer to: scroll past lots of theory and math, till you get to the \u2018pseudocode\u2019 section at the bottom and you\u2019ll see what I mean!", "The question everyone wants answered of course is \u2018does it work?\u2019 Experiments suggest a very strong yes.", "Tests were performed first with a constant load, and varying resources (e.g. to simulate failure or loss of nodes and subsequent recovery); then with constant resources and varying load (e.g.", "to simulate usage spikes); and finally varying both load and resources.", "The time-series results show that the self-adaptive application behaves as intended.", "The controller adapts the dimmer both to the available capacity and number of users as expected, and keeps the perceived latencies close to the setpoint.", "Moreover, the advantages that the brownout paradigm brings to previously non-adaptive applications can clearly be observed from the results.", "The paper includes a number of charts that show very significant improvements in the ability to continue serving user requests within the desired latency targets when the system is under stress.", "A word of caution though, they\u2019re not the easiest to interpret.", "\u2026self-adaptation through brownout can allow applications to support more users or run on fewer resources than their non-adaptive counterparts.", "Hence our proposition enables cloud applications to more robustly deal with unexpected peaks or unexpected failures, without requiring spare capacity.", "The work in this paper only considers a single server!", "There\u2019s an important extension for multiple servers, some much easier to follow charts, and a discussion on the implications for load balancing that we\u2019ll look at next time\u2026"], "author_id": "ACOLYER", "pdf_url": "http://www.martinamaggio.com/preprints/icse2014-preprint.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 41161677}, {"blog_id": "cohenl14", "summary": ["Academic Torrents is a BitTorrent service that aims to make it easy for academics to share data via BitTorrent.", "Specific use cases are during competitions where everyone needs access to data quickly.", "Also, when a dataset is not available anymore the data can be shared from simple desktop computers and become available globally."], "author_id": "joecohen", "pdf_url": "https://dl.acm.org/doi/pdf/abs/10.1145/2616498.2616528.pdf", "author_full_name": "Joseph Cohen", "source_website": "https://www.shortscience.org/user?name=joecohen", "id": 1077676}]