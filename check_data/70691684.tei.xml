<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-02-25">25 Feb 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">MPI for Intelligent Systems</orgName>
								<address>
									<settlement>TÃ¼bingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
							<email>slevine@google.com</email>
							<affiliation key="aff2">
								<orgName type="department">Google Brain 4 Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
							<email>ilyasu@google.com</email>
							<affiliation key="aff2">
								<orgName type="department">Google Brain 4 Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
							<email>amnih@google.com</email>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-02-25">25 Feb 2016</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1511.05176v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Deep neural networks are powerful parametric models that can be trained efficiently using the backpropagation algorithm. Stochastic neural networks combine the power of large parametric functions with that of graphical models, which makes it possible to learn very complex distributions. However, as backpropagation is not directly applicable to stochastic networks that include discrete sampling operations within their computational graph, training such networks remains difficult. We present MuProp, an unbiased gradient estimator for stochastic networks, designed to make this task easier. MuProp improves on the likelihood-ratio estimator by reducing its variance using a control variate based on the first-order Taylor expansion of a mean-field network. Crucially, unlike prior attempts at using backpropagation for training stochastic networks, the resulting estimator is unbiased and well behaved. Our experiments on structured output prediction and discrete latent variable modeling demonstrate that MuProp yields consistently good performance across a range of difficult tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep neural networks <ref type="bibr" target="#b9">(Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b6">Hinton et al., 2012;</ref><ref type="bibr" target="#b22">Sutskever et al., 2014)</ref> are responsible for numerous state-of-the-art results in a variety of domains, including computer vision, speech recognition, and natural language processing. The cornerstone of their success has been the simple and scalable backpropagation algorithm <ref type="bibr" target="#b19">(Rumelhart et al., 1986)</ref>. Backpropagation provides an efficient way of computing the derivatives of the error with respect to the model parameters. The key to the applicability of backpropagation is to utilize deterministic, differentiable activation functions, such as sigmoidal and softmax units, to make the model differentiable. However, in certain real-world scenarios, it is more suitable to learn a model that can carry out a sequence of stochastic operations internally, in order to represent a complex stochastic process. Such stochastic networks are studied in policy gradient reinforcement learning methods <ref type="bibr" target="#b26">(Williams, 1992;</ref><ref type="bibr" target="#b25">Weaver &amp; Tao, 2001;</ref><ref type="bibr" target="#b15">Peters &amp; Schaal, 2006)</ref>, probabilistic latent variable models for structured prediction, unsupervised learning of generative models <ref type="bibr" target="#b23">(Tang &amp; Salakhutdinov, 2013;</ref><ref type="bibr" target="#b8">Kingma &amp; Welling, 2014)</ref>, and most recently, attention and memory networks <ref type="bibr" target="#b27">Zaremba &amp; Sutskever, 2015)</ref>.</p><p>The versatility of stochastic neural networks motivates research into more effective algorithms for training them. Models with continuous latent variables and simple approximate posteriors can already be trained efficiently using the variational lower bound along with the reparameterization trick, which makes it possible to train both the model and the inference network using backpropagation <ref type="bibr" target="#b8">(Kingma &amp; Welling, 2014;</ref><ref type="bibr" target="#b18">Rezende et al., 2014)</ref>. Training models with discrete latent variable distributions, such as Bernoulli or multinomial, is considerably more difficult. Unbiased estimators based on the likelihood-ratio method tend to be significantly less effective than biased estimators, such as the straight-through method <ref type="bibr" target="#b0">(Bengio et al., 2013;</ref><ref type="bibr" target="#b16">Raiko et al., 2015)</ref> and the estimator proposed by <ref type="bibr" target="#b4">Gregor et al. (2014)</ref>. We hypothesize that this is due to the fact that, unlike the biased estimators, the unbiased ones do not take advantage of the gradient information provided by the backpropagation algorithm. However, the biased estimators are heuristic and not well understood, which means that it is difficult to enumerate the situations in which these estimators will work well.</p><p>Published as a conference paper at <ref type="bibr">ICLR 2016</ref> We posit that an effective method for training stochastic neural networks should take advantage of the highly efficient backpropagation algorithm, while still providing the convergence guarantees of an unbiased estimator.</p><p>To that end, we derive MuProp, an unbiased gradient estimator for deep stochastic neural networks that is based on backpropagation. To the best of our knowledge, it is the first unbiased estimator that can handle both continuous and discrete stochastic variables while taking advantage of analytic gradient information. MuProp's simple and general formulation allows a straightforward derivation of unbiased gradient estimators for arbitrary stochastic computational graphs -directed acyclic graph (DAG) with a mix of stochastic and deterministic computational nodes (see, e.g., <ref type="bibr" target="#b21">Schulman et al. (2015)</ref>). While the algorithm is applicable to both continuous and discrete distributions, we used only discrete models in our experiments, since the reparameterization trick <ref type="bibr" target="#b8">(Kingma &amp; Welling, 2014)</ref> already provides an effective method for handling continuous variables. We present experimental results for training neural networks with discrete Bernoulli and multinomial variables for both supervised and unsupervised learning tasks. With these models, which are notoriously difficult to train, biased methods often significantly outperform the unbiased ones <ref type="bibr" target="#b3">(Dayan et al., 1995;</ref><ref type="bibr" target="#b4">Gregor et al., 2014;</ref><ref type="bibr" target="#b16">Raiko et al., 2015)</ref>, except in certain cases . Our results indicate that MuProp's performance is more consistent and often superior to that of the competing estimators. It is the first time that a well-grounded, unbiased estimator consistently performs as well or better than the biased gradient estimators across a range of difficult tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>Probabilistic latent variable models described by neural networks date back to pioneering early work on sigmoidal belief networks and Helmholtz machines <ref type="bibr" target="#b13">(Neal, 1992;</ref><ref type="bibr" target="#b3">Dayan et al., 1995)</ref>. However, their adoption has been hindered by the lack of training methods that are both efficient and theoretically sound. Algorithms based on Markov chain Monte Carlo <ref type="bibr" target="#b13">(Neal, 1992)</ref> and mean-field inference <ref type="bibr" target="#b20">(Saul et al., 1996)</ref> are theoretically well-grounded, but do not scale well to large models. The wakesleep algorithm <ref type="bibr" target="#b7">(Hinton et al., 1995)</ref> scales to large models, but does not optimize a well definedobjective function, and therefore does not provide convergence guarantees. Recently, several new scalable methods have been proposed for training such models. A number of these algorithms use likelihood ratio estimators with variance reduction techniques <ref type="bibr" target="#b17">(Ranganath et al., 2014;</ref><ref type="bibr" target="#b4">Gregor et al., 2014)</ref>, inspired by methods from reinforcement learning <ref type="bibr" target="#b26">(Williams, 1992;</ref><ref type="bibr" target="#b25">Weaver &amp; Tao, 2001;</ref><ref type="bibr" target="#b15">Peters &amp; Schaal, 2006)</ref>. Another group of algorithms specifically addresses structured predictions tasks involving binary latent variables. Instead of performing inference using an inference network, these algorithms either use importance sampling to reweight samples from the prior <ref type="bibr" target="#b23">(Tang &amp; Salakhutdinov, 2013;</ref><ref type="bibr" target="#b16">Raiko et al., 2015)</ref>, or rely on heuristics for approximate backpropagation through the stochastic units <ref type="bibr" target="#b0">(Bengio et al., 2013;</ref><ref type="bibr" target="#b16">Raiko et al., 2015;</ref><ref type="bibr" target="#b4">Gregor et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LIKELIHOOD-RATIO GRADIENT ESTIMATION</head><p>Consider a simple stochastic system with discrete random variable x whose probability is given by p Î¸ (x), and a loss function f (x). This formulation subsumes the training objectives of popular generative models such as sigmoid belief networks, with or without inference networks. The objective of training is to minimize the expected cost</p><formula xml:id="formula_0">L(Î¸) = E p Î¸ (x) [f (x)]</formula><p>. The gradient g = âL/âÎ¸ is usually intractable to compute exactly, and must therefore be estimated using an estimatorÄ</p><formula xml:id="formula_1">(x), i.e. g â m i=1Ä (x i )/m, where x i â¼ p Î¸ (x)</formula><p>and m is the number of Monte Carlo samples. The likelihood-ratio (LR) estimator, of which the popular REINFORCE algorithm is a special case <ref type="bibr" target="#b26">(Williams, 1992;</ref><ref type="bibr" target="#b15">Peters &amp; Schaal, 2006)</ref>, provides a convenient method for estimating this gradient, and serves as the basis for all of the unbiased estimators discussed in this paper, including MuProp. The LR method only requires that p Î¸ (x) is differentiable with respect to Î¸:</p><formula xml:id="formula_2">g (LR) = â Î¸ E p Î¸ (x) [f (x)] = x â Î¸ p Î¸ (x)f (x) = x p Î¸ (x)â Î¸ log p Î¸ (x) â¢ f (x) = E p Î¸ (x) [â Î¸ log p Î¸ â¢ f (x)] g (LR) = â Î¸ log p Î¸ (x) â¢ f (x) where x â¼ p Î¸ (1)</formula><p>In its basic form, this estimator is unbiased, but tends to have high variance, and variance reduction techniques are typically required to make it practical <ref type="bibr" target="#b26">(Williams, 1992;</ref><ref type="bibr" target="#b15">Peters &amp; Schaal, 2006)</ref>. A major deficiency of the LR estimator is that it fails to utilize information about the derivative of the cost function, unlike the most successful biased estimators. We will show that MuProp, which combines the derivative information with the LR estimator, can outperform these biased estimators, as well as the standard LR method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">VARIANCE REDUCTION WITH THE LIKELIHOOD-RATIO ESTIMATOR</head><p>High variance of LR estimators can make convergence very slow or impossible. This is further exacerbated by the fact that LR estimators for minibatch training of neural networks typically use m = 1, in order to maximize the variety of examples seen by the network <ref type="bibr" target="#b8">(Kingma &amp; Welling, 2014;</ref><ref type="bibr" target="#b4">Gregor et al., 2014;</ref><ref type="bibr" target="#b18">Rezende et al., 2014;</ref>. The simplest way to reduce variance is to increase m, but this is computationally expensive. Efficient and effective variance reduction techniques are therefore crucial for the LR estimator to be practical.</p><p>The derivation of MuProp in Section 3 uses a variance reduction technique known as control variates <ref type="bibr" target="#b14">(Paisley et al., 2012)</ref>. The main idea is to subtract an analytically tractable term from the LR estimate in order to reduce the variance of the Monte Carlo estimate, and then add back the analytical expectation of this term to recover an unbiased estimator:</p><formula xml:id="formula_3">E p Î¸ (x) [â Î¸ log p Î¸ (x) â¢ f (x)] = E p Î¸ (x) [â Î¸ log p Î¸ (x) â¢ (f (x) â b â h(x))] + Âµ<label>(2)</label></formula><p>In this example, b + h(x) is a control variate, which is also known as a sample-dependent baseline. The expectation of the baseline needs to be added to the expression to make the resulting estimator unbiased. If the baseline is constant (i.e. h(x) = 0), its contribution to the gradient estimate is always zero in expectation, since</p><formula xml:id="formula_4">x p Î¸ (x)â Î¸ log p Î¸ (x) = x â Î¸ p Î¸ (x) = â Î¸ x p Î¸ (x) = â Î¸ 1 = 0.</formula><p>Otherwise, we must compute the expectation of the baseline</p><formula xml:id="formula_5">(b + h(x))â log p Î¸ (x) analytically, as Âµ = E p Î¸ (x) [â Î¸ log p Î¸ (x) â¢ h(x)].</formula><p>In our experiments, we utilize three types of variance reduction techniques for the estimators that include the same term as Eq. 2. While these techniques, proposed in a similar context in , do not result in the optimal variance reduction, they work well enough to make LR estimators useful in practice. 1 For the precise details of these variance reduction techniques, please refer to . For reference, the techniques are:</p><p>â¢ Centering the learning signal (C), which involves subtracting from the learning signal its moving average (corresponding to b in Eq. 2).</p><p>â¢ Input-dependent baseline (IDB), which allows baseline b to depend on the input or the sample from the previous layer (x 0 ). This baseline is a neural network parameterized by Ï, and is trained jointly with the model to minimize the expected square of the centered</p><formula xml:id="formula_6">learning signal E p Î¸ (x|x0) [(l(x) â b â B Ï (x 0 )) 2 ].</formula><p>â¢ Variance normalization (VN), which keeps track of the moving average of the signal variance v, and divides the learning signal by max(1, â v). Unlike the other two techniques, this does not correspond to a baseline, and is a type of adaptive gradient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MUPROP</head><p>The MuProp estimator has two components: a deterministic termÄ M F , which is computed by backpropagation through a mean-field network that we describe in Section 3.1, and a LR termÄ R , which accounts for the residuals to produce an unbiased gradient estimate. In the following, let</p><formula xml:id="formula_7">Âµ x (Î¸) be E p Î¸ (x) [x]</formula><p>andx be any value that does not depend on x. The key idea of MuProp is summarized in the following equation: where x â¼ p Î¸ , andÄ (Âµ) is an unbiased estimate of the gradient. The derivation follows directly from the baseline technique described in Section 2.2: MuProp uses a control variate that corresponds to the first-order Taylor expansion of f around some fixed valuex, i.e., h(</p><formula xml:id="formula_8">g (Âµ) = â Î¸ log p Î¸ (x) â¢ [f (x) â f (x) â f (x)(x âx)] Ä R + f (x)â Î¸ Âµ x (Î¸) Ä M F (3) s x h f (s) Î¸s x h f Î¸ âf âx âf âh âf âs s x h f (s) Î¸s (x) f (x)s x(h) f (h)s x h f âf âx âf âs âf âh</formula><formula xml:id="formula_9">x) = f (x) + f (x)(x âx).</formula><p>The idea of using Taylor expansion as a baseline is also explored by <ref type="bibr" target="#b14">(Paisley et al., 2012)</ref> and <ref type="bibr" target="#b4">(Gregor et al., 2014)</ref>; however, <ref type="bibr" target="#b14">(Paisley et al., 2012)</ref> does not explore the estimator in the context of arbitrary stochastic computational graphs, and <ref type="bibr" target="#b4">(Gregor et al., 2014)</ref> chooses a different form of Taylor expansion that makes the estimator biased. The latter approach also does not generalize to multi-layer graphs.</p><p>Our contribution with MuProp is to extend the idea of Taylor expansions as baselines and make them applicable to arbitrary stochastic computational graphs. We will describe our derivation and design choices, as well as possible extensions to the standard form of MuProp that can enhance the statistical efficiency of the method. In the appendix, we also present a simple algorithm to compute the MuProp estimator using automatic differentiation, which makes it easy to integrate into any existing automatic differentiation library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">GENERALIZED BACKPROPAGATION WITH MEAN-FIELD NETWORKS</head><p>It is not always possible to directly apply Eq. 3 to an arbitrary computation graph because of the f (x) terms. If the computation graph includes a discrete sampling operation as in <ref type="figure" target="#fig_0">Figure 1</ref>, then one cannot directly define continuous gradient through such an operation. As a solution, we use a deterministic mean-field network, which ignores the sampling operations in the original graph and propagates the mean values instead of the samples. <ref type="figure" target="#fig_0">Figure 1</ref> shows how the backward pass computes the gradient with respect to Î¸. MuProp computes the Taylor expansion using the mean-field network, which is fully differentiable, and uses these terms to reduce the variance. While the choice to use the mean-field network seems arbitrary, we show that a proper recursive derivation of Eq. 3 for deep networks naturally leads to recursive Taylor expansions around the mean functions. Furthermore, ifx coincides with the mean-field forward pass, the gradient estimator simplifies to Eq. 3. The full derivation is given in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COMPARISON WITH OTHER GRADIENT ESTIMATORS</head><p>While MuProp is derived from the LR estimator, which is also unbiased, it is closely related to two biased estimators commonly used to train stochastic binary networks. In this section we will describe these two estimators, the Straight-Through estimator and the 1/2 estimator. To simplify notation, we describe the estimators assuming one stochastic variable x. The provided estimator expressions however generalize easily to arbitrary stochastic computational graphs. The estimators mentioned above are summarized in <ref type="table" target="#tab_1">Table 1</ref> for completeness.</p><p>We do not consider the importance-sampling based approaches <ref type="bibr" target="#b16">(Raiko et al., 2015;</ref><ref type="bibr" target="#b23">Tang &amp; Salakhutdinov, 2013;</ref><ref type="bibr" target="#b1">Bornschein &amp; Bengio, 2015;</ref><ref type="bibr" target="#b2">Burda et al., 2015)</ref> as these can be interpreted as optimizing a different objective <ref type="bibr" target="#b2">(Burda et al., 2015</ref>) that requires sampling the latent variables multiple times. The resulting estimators are more specialized than the ones considered in this paper, which are agnostic to the objective being optimized. As a result, MuProp and the other general estimators can be applied to the objective optimized by the importance-sampling based methods. We leave exploring this direction as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">THE STRAIGHT-THROUGH ESTIMATOR</head><p>The straight-through estimator (ST) <ref type="bibr" target="#b0">(Bengio et al., 2013;</ref><ref type="bibr" target="#b16">Raiko et al., 2015</ref>) is a biased but lowvariance estimator, devised primarily for binary stochastic neurons 3 . The idea is to backpropagate through the thresholding function as if it were the identity function. The estimator is given below:</p><formula xml:id="formula_10">g (ST ) = f (x)â Î¸ Âµ x (Î¸)<label>(4)</label></formula><p>The estimator resembles theÄ M F term in our estimator in Eq. 3, since for a stochastic binary network the activation function is the mean function. The difference is that this estimator depends on sampled x i during backpropagation, while our formulation backpropagates the gradient through the mean-field activations. Despite the heuristic derivation, this simple biased estimator works well in practice, most likely due to its overall similarity to the backpropagation algorithm. However, we show that MuProp significantly outperforms ST estimators on certain tasks, which suggests that unbiased estimators are more reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">THE 1/2 ESTIMATOR</head><p>Gregor et al. <ref type="formula">2014</ref>proposed a biased estimator for the Deep AutoRegressive Network (DARN), which we refer to as the "1/2" estimator due to its particular choice of the baseline. Like the Straight-Through estimator, the 1/2 estimator is also specialized for stochastic binary networks. For models with only one stochastic unit, the 1/2 estimator corresponds to using the Taylor expansion around the sample x, evaluated at a fixed pointx, as the baseline, such that</p><formula xml:id="formula_11">h(x) = f (x) + f (x)(x â x).</formula><p>Since the expectation over h(x) cannot be computed analytically andx cannot be chosen to make the baseline mean 0 for any arbitrary function f , this estimator is biased. Critically, the 1/2 estimator is derived for models with only one unit but is applied to large models by treating each unit as the sole unit of the model. Furthermore, the 1/2 estimator is not well-justified in the multi-layer case. However, backpropagating the gradient estimator derived in the single-layer case is shown to work well for stochastic binary neurons. The basic form of the estimator is given bÅ·</p><formula xml:id="formula_12">g (1/2) = â Î¸ log p Î¸ (x) â¢ (f (x) T â¢ (x âx))<label>(5)</label></formula><p>If x consists of binary random variables, the expression can be further simplified by usingx = 1/2 (see <ref type="bibr" target="#b4">(Gregor et al., 2014)</ref> for justification); however, for non-quadratic f , the estimator is biased:</p><formula xml:id="formula_13">g (1/2) = f (x)â Î¸ Âµ x (Î¸) 2p Î¸ (x)<label>(6)</label></formula><p>If x consists of multinomial random variables with k categories, no sensiblex has been proposed. Since 1/2 estimator is only tested on binary variables, we experimented with three choices ofx: 1/2, 1/k, and Âµ x (Î¸). Let Âµ x (Î¸) = softmax(Î¸) be the mean of the multinomial units (Î¸ â R k ), and</p><p>x â R k is one-hot encoding of the categorical values. Then the 1/2 estimator for the multinomial case becomesÄ</p><formula xml:id="formula_14">(1/2) = (f (x) T â¢ (x âx))(x T â¢ â Î¸ Âµ x (Î¸)) Âµ x (Î¸)<label>(7)</label></formula><p>The ST estimator was proposed by <ref type="bibr" target="#b5">Hinton (2012)</ref> and named in <ref type="bibr" target="#b0">Bengio et al. (2013)</ref>. The ST estimator can include the derivative of the sigmoid or not. <ref type="bibr" target="#b16">Raiko et al. (2015)</ref> derive the version with the derivative of the sigmoid using another interpretation and differentiate it from the original ST estimator in their work. For simplicity, here we always assume that the ST estimator includes the derivative of the sigmoid, which is often essential for achieving the best performance <ref type="bibr" target="#b16">(Raiko et al., 2015</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We compare the LR, ST, and 1/2 estimators with the MuProp estimator on tasks that use a diverse set of network architectures. For the LR and the MuProp estimators, '-C', '-VN', and '-IDB' indicate constant mean baseline, variance normalization, and input-dependent baseline respectively. The first task does not make use of an inference network and involves direct optimization of an approximation to the expected objective. The second task involves training a sigmoid belief network jointly with an inference network by maximizing the variational lower bound on the intractable log-likelihood. MuProp performs consistently well at both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">STRUCTURED OUTPUT PREDICTION</head><p>In this experiment, we follow the setup proposed by <ref type="bibr" target="#b16">Raiko et al. (2015)</ref>. The two tasks are to predict the lower half of an MNIST digit given the top half, and to predict multiple facial expressions from an average face using Toronto Face dataset (TFD); the output distribution in both tasks exhibits complex multi-modality. For MNIST, the output pixels are binarized using the same protocol as in <ref type="bibr" target="#b16">(Raiko et al., 2015)</ref>. Given an input x, an output y, and stochastic hidden variables h, the objective is to maximize</p><formula xml:id="formula_15">E hiâ¼p Î¸ (h|x) log 1 m m i=1 p Î¸ (y|h i )</formula><p>, an importance-sampled estimate of the likelihood objective <ref type="bibr" target="#b16">(Raiko et al., 2015;</ref><ref type="bibr" target="#b2">Burda et al., 2015)</ref>. We use m = 1 for training, and m = 100 for validation and testing. For MNIST, a fixed learning rate is chosen from {0.003, 0.001, .., 0.00003}, and the best test result is reported for each method. For the TFD dataset, the learning rate is chosen from the same list, but each learning rate is 10 times smaller. We used a momentum of 0.9 and minibatches of size 100. The input-dependent baseline (IDB) of  uses both the input and output as its input and has a single hidden-layer of 100 Tanh units.    <ref type="figure" target="#fig_1">Figure 2a</ref> shows the test cost versus the number of parameter update steps of a typical run, while <ref type="table" target="#tab_3">Table 2</ref> summarizes the test performance for the different estimators. Convergence of the LR estimators is significantly slower than that of MuProp, ST, and 1/2. In fact, MuProp with simple mean subtraction is consistently better than LR with all of the variance reduction techniques. For MuProp, adding input-dependent baselines does not lead to any improvement over a simple constant mean baseline and variance normalization, and it is interesting to observe that MuProp's sampledependent-baseline reduces the variance significantly more than the input-dependent baseline that also utilizes the output y. MuProp is slightly worse than ST and 1/2, and this performance gap can be explained by the fact that standard MuProp only uses a single-trunk mean-field pass of the network, making the "mean" values at higher layers less correlated with the true conditional distribution. Section 6 discusses extensions to address this problem, at the cost of more computation or training an auxiliary network.</p><p>Our results show that MuProp significantly outperforms LR and closely matches the performance of ST and 1/2 in terms of both convergence speed and final accuracy, and is the only unbiased estimator that can compete with the biased ST and 1/2 estimators on this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">VARIATIONAL TRAINING OF GENERATIVE MODELS</head><p>In the second set of experiments, we apply MuProp to variational training of generative models. The auto-encoding variational Bayes framework <ref type="bibr" target="#b8">(Kingma &amp; Welling, 2014)</ref>, along with similar methods, allows powerful generative models to be trained efficiently by replacing slow iterative inference algorithms with fast feedforward approximate inference networks. The inference networks, which map observations to samples from the variational posterior, are trained jointly with the model by maximizing a common objective. This objective is a variational lower bound on the marginal loglikelihood, and it is straight-forward to show that it is a stochastic computation graph with particular choice of cost.</p><p>When the variational distributions over the latent variables have a specific form, such as conditional Gaussian, such models can be trained easily by using the reparameterization trick to backpropagate the gradient through the inference network <ref type="bibr" target="#b8">(Kingma &amp; Welling, 2014)</ref>. However, Gaussian distributions are not appropriate for all types of data or all models. If we opt to use discrete latent variables, we would have to choose between gradient estimators that are biased but have low variance <ref type="bibr" target="#b4">(Gregor et al., 2014)</ref> or are unbiased but higher variance . As MuProp is unbiased and has relatively low variance due to its use of backpropagation for gradient estimation, we expect it to be particularly well-suited for training such models.</p><p>We will concentrate on training layered belief networks with either Bernoulli or multinomial latent variables. The model in question is equivalent to a sigmoid belief network if it does not have autoregressive connections, or to fDARN if it has autoregressive connections <ref type="bibr" target="#b4">Gregor et al. (2014)</ref>. The multinomial model uses 200 latent variables with 10 categories each (k = 10), and thus is referred to as the 200Ã10 model. We applied the models to the binarized MNIST dataset, which consists of 28Ã28 images of hand-written digits, and is commonly used for evaluating generative models. We trained the models using stochastic gradient descent using momentum of 0.9. The learning rate was selected from {0.003, 0.001, .., 0.000003}, and the best test score is reported. For the 1/2 estimator in the categorical model, we found thatx=1/2 or 1/k worked best, and used the latter value for the results reported. As we used the same experimental setup and SBN/fDARN models, our results are directly comparable to those obtained using neural variational inference and learning (NVIL) in . Note that LR-C-VN-IDB is our implementation of NVIL.   <ref type="figure" target="#fig_2">Figure 3</ref> shows sample training curves for typical runs, and <ref type="table" target="#tab_5">Table 3</ref> summarizes the results. These results convincingly show that MuProp outperforms all the competing estimators. While the variancereduced LR estimator (NVIL) performs very well on this task and is on par with MuProp on the final variational lower-bound, MuProp converges significantly faster (e.g. for the categorical model, about 3-4 times faster). This suggests that MuProp (with only mean subtraction) still has significantly less variance than LR on this task, just as in Section 5.1. For the ST and 1/2 estimators, the story is more interesting. First, their final variational lower-bounds are significantly worse than MuProp or LR. More importantly, they exhibit little consistency in performance. On the SBN models, 1/2 typically outperforms ST, while on the categorical model, the reverse is true. This result, along with the fluctuations observed in the categorical model training curve for 1/2, suggests that such biased estimators can be unreliable for more complex models, and that their performance can vary drastically based on the cost function and model architecture. MuProp, on the other hand, is guaranteed to improve the desired objective because it is unbiased, while having much less variance than LR due to the use of the gradient information from backpropagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>In this paper, we presented MuProp, which is an unbiased estimator of derivatives in stochastic computational graphs that combines the statistical efficiency of backpropagation with the correctness of a likelihood ratio method.</p><p>MuProp has a number of natural extensions. First, we might consider using other functions for the baseline rather than just the Taylor expansion, which could be learned in a manner that resembles Q-learning <ref type="bibr" target="#b24">(Watkins &amp; Dayan, 1992)</ref> and target propagation <ref type="bibr" target="#b10">(Lee et al., 2015)</ref>. In reinforcement learning, fitted Q-functions obtained by estimating the expected return of a given policy Ï Î¸ summarize all future costs, and a good Q-function can greatly simplify the temporal credit assignment problem. Combining MuProp with such fitted Q-functions could greatly reduce the variance of the estimator and make it better suited for very deep computational graphs, such as long recurrent neural networks and applications in reinforcement learning.</p><p>The second extension is to makex depend on samples of its parent nodes, as illustrated by rollout procedure in <ref type="figure" target="#fig_0">Figure 1</ref>. This could substantially improve performance on deeper networks, where the value from a single-trunk mean-field pass may diverge significantly from any samples drawn with a fully stochastic pass. By drawingx using mean-field passes originating at sampled values from preceding layers would prevent such divergence, though at additional computational cost, since the number of mean-field passes would depend on the depth n of the network, for a total of O(n 2 ) partial passes through the network. Intuitively, the single mean-field "chain" would turn into a "tree," with a sampled trunk and a different mean-field branch at each layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX 7 RECURSIVE DERIVATION OF MUPROP</head><p>Given a model with multiple layers of discrete random variables x 1 ...x n and input x 0 , the general loss function can be written as</p><formula xml:id="formula_16">L(x 0 , Î¸) = E p(x1,...,xn|x0,Î¸) [f Î¸ (x 0:n )]. For simplicity, we show derivation assuming that p(x 1 , ..., x n |x 0 , Î¸) = n i=1 p(x i |x iâ1 , Î¸ iâ1 ) = n i=1 p i and f (x 1:n , Î¸) = f (x n , Î¸ n )</formula><p>, where Î¸ = {Î¸ 0 , ..., Î¸ n }; however, the derivation is easy to extend to any directed acyclic graph. We assume that there is a continuous and differentiable mean function for each p(</p><formula xml:id="formula_17">x i |x iâ1 , Î¸ iâ1 ), denoted by Âµ i (x iâ1 , Î¸ iâ1 ) = E p(xi|xiâ1,Î¸iâ1) [x i ].</formula><p>The derivation is based on the recursive first-order Taylor expansion around some arbitrary fixed pointsx 1:n , which we detail later. We use Âµ i and f to denote âÂµi âxiâ1 and âf âxn .</p><p>We first derive the gradient for âL âÎ¸n and âL âÎ¸nâ1 and then for { âL âÎ¸i } i=0:n . The final expression for the estimator resembles the classical backpropagation formulation, and allows efficient computation through forward and backward passes. We intentionally avoid the standard matrix algebra notation to provide clean derivations, as the extension is straight-forward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>âL âÎ¸</head><formula xml:id="formula_18">n = E p1:n [â Î¸n f (x n , Î¸ n )] (8) âL âÎ¸ nâ1 = E p1:nâ1 [â Î¸nâ1 E pn [f (x n , Î¸ n )]] = E p1:nâ1 [E pn [â Î¸nâ1 log p n â¢ f (x n , Î¸ n )]] = E p1:nâ1 [E pn [â Î¸nâ1 log p n â¢ [f (x n , Î¸ n ) â f (x n , Î¸ n ) â f (x n , Î¸ n ) â¢ (x n âx n )]] + E pn [â Î¸nâ1 log p n â¢ [f (x n , Î¸ n ) + f (x n , Î¸ n ) â¢ (x n âx n )]]] = E p1:nâ1 [E pn [â Î¸nâ1 log p n â¢ R n ] + f (x n , Î¸ n )â Î¸nâ1 E pn [x N ]] = E p1:nâ1 [E pn [â Î¸nâ1 log p n â¢ R n ] + f (x n , Î¸ n )â Î¸nâ1 Âµ n (x nâ1 , Î¸ nâ1 )]<label>(9)</label></formula><p>where we define the residuals</p><formula xml:id="formula_19">R i = Âµ i+1 (x i , Î¸ i ) â Âµ i+1 (x i , Î¸ i ) â Âµ i+1 (x i , Î¸ i ) â¢ (x i âx i ) and let Âµ n+1 (x n , Î¸ n ) = f (x n , Î¸ n ).</formula><p>Applying the same derivation recursively, we get:</p><formula xml:id="formula_20">âL âÎ¸ i = E p1:n [â Î¸i log p i+1 â¢ R n ] + f (x n , Î¸ n ) â¢ E p1:nâ1 [â Î¸i log p i+1 â¢ Âµ n (x nâ1 , Î¸ nâ1 )] = E p1:n [â Î¸i log p i+1 â¢ R n ] + f (x n , Î¸ n )[E p1:nâ1 [â Î¸i log p i+1 â¢ R nâ1 ] + Âµ n (x nâ1 , Î¸ nâ1 )[E p1:nâ2 [â Î¸i log p i+1 â¢ R nâ2 ] + ... + Âµ i+2 (x i+1 , Î¸ i+1 ) â¢ â Î¸i Âµ i+1 (x i , Î¸ i )]]...] = E p1:n [â Î¸i log p i+1 â¢ ( n k=i+1 R k n+1 j=k+2 Âµ j (x jâ1 , Î¸ jâ1 ))] + E p1:i [( n+1 j=i+2 Âµ j (x jâ1 , Î¸ jâ1 )) â¢ â Î¸i Âµ i+1 (x i , Î¸ i )]<label>(10)</label></formula><p>where we slightly abuse the notation and assume n+1 j=n+2 (Âµ j ) = 1. The estimator expression is:</p><formula xml:id="formula_21">âL âÎ¸ i (Âµ) = â Î¸i log p i+1 â¢ ( n k=i+1 R k n+1 j=k+2 Âµ j (x jâ1 , Î¸ jâ1 )) + ( n+1 j=i+2 Âµ j (x jâ1 , Î¸ jâ1 )) â¢ â Î¸i Âµ i+1 (x i , Î¸ i )<label>(11)</label></formula><p>The formulation assumes a set of fixed pointsx 1:n , whose only requirements are thatx i cannot depend on x i . If we choosex 1:n as given by deterministic mean-field forward pass, the gradient estimator simplifies and recovers Eq. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">MUPROP WITH AUTOMATIC DIFFERENTIATION</head><p>We present a simple algorithm to compute MuProp gradient, taking advantage of the automatic differentiation functionalities. Algorithm 1 assumes that the automatic differentiation library provides two functionalities: Gradients(cost, inputs) which computes derivatives of cost with respect to inputs, and StopGradient(x) which returns a node with equal value with x but stops gradient when Gradients is called. It assumes that the graph consists of n stochastic nodes {x i } i=1:n and loss function f which can be the sum of multiple loss functions at different parts of the graph. PARENTS xi denotes the stochastic parental nodes of x i . ForwardPass builds the symbolic graph whose outputs can be differentiated using Gradients. When stochastic=true, each stochastic node samples the value and wraps the value using StopGradient such that no gradient is propagated through the stochastic operation. stochastic=false builds the mean-field network that is fully differentiable. The algorithm also assumes it uses m = 1 sample, and in general the run time of the algorithm is 1 deterministic pass + m stochastic passes through the network. In practice, we augment the algorithm with the variance reduction techniques described in Section 2.2. Extensions discussed in Section 6 are also easy to include.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Compute MuProp Gradient Estimator</head><p>Require: Input: x 0 , Parameters: Î¸ x 1:n , f (x 1:n ) â ForwardPass(x 0 , stochastic=false) {f (x i )} i=1:n â Gradients(f (x 1:n ),x 1:n )</p><formula xml:id="formula_22">x 1:n , Âµ 1:n , f (x 1:n ), {log p Î¸ (x i |PARENTS xi )} i=1:n â ForwardPass(x 0 , stochastic=true) c i â log p Î¸ (x i |PARENTS xi )StopGradient(f (x 1:n ) â f (x 1:n ) â f (x i ) T â¢ (x i âx i )) + Âµ T â¢ StopGradient(f (x i )) c â f (x 1:n ) + n i=1 c Ã® g (Âµ) â Gradients(c, Î¸)</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Standard MuProp (left) and MuProp with rollout (right). Circles indicate stochastic nodes. Blue, black, and red arrows indicate stochastic forward pass, deterministic mean-field forward pass, and gradient flow in backward pass respectively.f indicates mean-field evaluation of f .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Results for MNIST imputation dataset. MuProp is the only unbiased estimator that can compete with the biased estimators such as ST and 1/2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Test negative variational lower-bound on 200-200-784 SBN model (left) and 200Ã10-784 categorical model (right). MuProp outperforms ST and 1/2 and converges faster than LR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Summary of Gradient Estimators for Stochastic Discrete Variables</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Test Negative Log-likelihood</cell><cell></cell></row><row><cell></cell><cell>90</cell><cell></cell><cell></cell><cell>LR-C-VN LR-C-VN-IDB</cell></row><row><cell></cell><cell>85</cell><cell></cell><cell></cell><cell>ST</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1/2</cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell><cell>MuProp-C</cell></row><row><cell>NLL</cell><cell>75</cell><cell></cell><cell></cell><cell>MuProp-C-VN</cell></row><row><cell></cell><cell>70</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>65</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>60</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>55</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>50</cell><cell>100</cell><cell>150</cell><cell>200</cell><cell>250</cell></row><row><cell></cell><cell></cell><cell>step (x10 4 )</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">(a) Test negative log-likelihood (NLL)</cell><cell>(b) Test samples</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Test negative log-likelihood on MNIST 392-200-200-392 model.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Negative variational lower-bound on MNIST test data</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Optimal baselines are somewhat involved, as they take into account the magnitude of â Î¸ log p Î¸ (x) and are different for each parameter<ref type="bibr" target="#b25">(Weaver &amp; Tao, 2001</ref>).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Only the LR and MuProp estimators have a principled extension to deep networks. The other methods can be extended to deep networks heuristically.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We sincerely thank Jascha Solh-dickstein, Laurent Dinh, Ben Poole, and Quoc Le for helpful discussions and the Google Brain team for the support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Estimating or propagating gradients through stochastic neurons for conditional computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>LÃ©onard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.3432</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">JÃ¶rg</forename><surname>Bornschein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Reweighted wake-sleep. ICLR</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00519</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Importance weighted autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The helmholtz machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zemel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep autoregressive networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ivo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andriy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Neural networks for machine learning. Coursera, video lectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Navdeep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The &quot;wake-sleep&quot; algorithm for unsupervised neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neal</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">268</biblScope>
			<biblScope unit="issue">5214</biblScope>
			<biblScope unit="page" from="1158" to="1161" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Difference target propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saizheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="498" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recurrent models of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Volodymyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nicolas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Connectionist learning of belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="113" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Variational bayesian inference with stochastic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Policy gradient methods for robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="2219" to="2225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Techniques for learning binary stochastic feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alain</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Black box variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">ICML</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning representations by backpropagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Williams</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mean field theory for sigmoid belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="76" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gradient estimation using stochastic computation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nicolas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theophane</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning stochastic feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichuan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The optimal reward baseline for gradient-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lex</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="538" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00521</idno>
		<title level="m">Reinforcement learning neural turing machines</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
