<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-06-01">1 Jun 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Technology</orgName>
								<orgName type="laboratory" key="lab1">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="laboratory" key="lab2">National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
							<email>aihuang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Technology</orgName>
								<orgName type="laboratory" key="lab1">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="laboratory" key="lab2">National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Technology</orgName>
								<orgName type="laboratory" key="lab1">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="laboratory" key="lab2">National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Technology</orgName>
								<orgName type="laboratory" key="lab1">State Key Laboratory of Intelligent Technology and Systems</orgName>
								<orgName type="laboratory" key="lab2">National Laboratory for Information Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
							<email>liub@cs.uic.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>Illinois</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Encoder Emotion Embedding Internal Memory</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Post Training Inference</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-06-01">1 Jun 2018</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1704.01074v4[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Perception and expression of emotion are key factors to the success of dialogue systems or conversational agents. However, this problem has not been studied in large-scale conversation generation so far. In this paper, we propose Emotional Chatting Machine (ECM) that can generate appropriate responses not only in content (relevant and grammatical) but also in emotion (emotionally consistent). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor using three new mechanisms that respectively (1) models the high-level abstraction of emotion expressions by embedding emotion categories, (2) captures the change of implicit internal emotion states, and (3) uses explicit emotion expressions with an external emotion vocabulary. Experiments show that the proposed model can generate responses appropriate not only in content but also in emotion.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>As a vital part of human intelligence, emotional intelligence is defined as the ability to perceive, integrate, understand, and regulate emotions <ref type="bibr" target="#b10">(Mayer and Salovey 1997)</ref>. It has been a long-term goal of artificial intelligence to enable a machine to understand affect and emotion <ref type="bibr" target="#b13">(Picard and Picard 1997)</ref>. To create a chatbot capable of communicating with a user at the human level, it is necessary to equip the machine with the ability of perceiving and expressing emotions.</p><p>Existing studies show that addressing affect and emotion in dialogue systems or conversational agents can enhance user satisfaction <ref type="bibr" target="#b14">(Prendinger, Mori, and Ishizuka 2005)</ref>, and lead to fewer breakdowns in dialogues <ref type="bibr" target="#b9">(Martinovski and Traum 2003)</ref>. Some initial work has also been done on adjusting dialogue behaviors to suit users' emotional states <ref type="bibr" target="#b13">(Polzin and Waibel 2000)</ref>, and on generating responses to users' utterances at both the content-and affect-related levels <ref type="bibr" target="#b18">(Skowron 2010)</ref>.</p><p>However, these studies, mostly inspired by psychology findings, are either rule-based or limited to small-scale data. Recently, neural models trained on large-scale data have advanced open-domain conversation generation significantly <ref type="bibr" target="#b15">(Ritter, Cherry, and Dolan 2011;</ref><ref type="bibr" target="#b20">Vinyals and Le 2015;</ref><ref type="bibr" target="#b17">Shang, Lu, and Li 2015;</ref>. Most of these models aim to improve the content quality of conversation generation <ref type="bibr" target="#b1">(Gu et al. 2016;</ref><ref type="bibr" target="#b6">Li et al. 2016a;</ref><ref type="bibr" target="#b12">Mou et al. 2016;</ref><ref type="bibr" target="#b7">Li et al. 2016b)</ref>. To the best of our knowledge, the emotion factor has not been addressed in existing neural models for conversation generation. <ref type="table">Table 1</ref> shows some examples with/without considering emotions. We can see that our ECM model is emotionally involved and more empathetic.</p><p>User: Worst day ever. I arrived late because of the traffic. Basic Seq2Seq: You were late. ECM (Like): I am always here to support you. ECM (Happy): Keep smiling! Things will get better. ECM (Sad): It's depressing. ECM (Disgust): Sometimes life just sucks. ECM (Angry): The traffic is too bad! <ref type="table">Table 1</ref>: Conversations with/without considering emotion.</p><p>There are several challenges in addressing the emotion factor in large-scale conversation generation. First, highquality emotion-labeled data are difficult to obtain in a largescale corpus, as emotion annotation is a fairly subjective task and emotion classification is also challenging. Second, it is difficult to consider emotions in a natural and coherent way because we need to balance grammaticality and expressions of emotions, as argued in <ref type="bibr" target="#b0">(Ghosh et al. 2017)</ref>. Last, simply embedding emotion information in existing neural models, as shown in our experiments, cannot produce desirable emotional responses but just hard-to-perceive general expressions (which contain only common words that are quite implicit or ambiguous about emotions, and amount to 73.7% of all emotional responses in our dataset).</p><p>In this paper, we address the problem of generating emotional responses in open-domain conversational systems and propose an emotional chatting machine (ECM for short). To obtain large-scale emotion-labeled data for ECM, we train a neural classifier on a manually annotated corpus. The classifier is used to annotate large-scale conversation data automatically for the training of ECM. To express emotion naturally and coherently in a sentence, we design a sequence-to-sequence generation model equipped with new mechanisms for emotion expression generation, namely, emotion category embedding for capturing high-level abstraction of emotion expressions, an internal emotion state for balancing grammaticality and emotion dynamically, and an external emotion memory to help generate more explicit and unambiguous emotional expressions.</p><p>In summary, this paper makes the following contributions:</p><p>• It proposes to address the emotion factor in large-scale conversation generation. To the best of our knowledge, this is the first work on the topic.</p><p>• It proposes an end-to-end framework (called ECM) to incorporate the emotion influence in large-scale conversation generation. It has three novel mechanisms: emotion category embedding, an internal emotion memory, and an external memory.</p><p>• It shows that ECM can generate responses with higher content and emotion scores than the traditional seq2seq model. We believe that future work such as the empathetic computer agent and the emotion interaction model can be carried out based on ECM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>In human-machine interactions, the ability to detect signs of human emotions and to properly react to them can enrich communication. For example, display of empathetic emotional expressions enhanced users' performance <ref type="bibr" target="#b12">(Partala and Surakka 2004)</ref>, and led to an increase in user satisfaction <ref type="bibr" target="#b14">(Prendinger, Mori, and Ishizuka 2005)</ref>. Experiments in <ref type="bibr" target="#b14">(Prendinger and Ishizuka 2005)</ref> showed that an empathetic computer agent can contribute to a more positive perception of the interaction. In <ref type="bibr" target="#b9">(Martinovski and Traum 2003)</ref>, the authors showed that many breakdowns could be avoided if the machine was able to recognize the emotional state of the user and responded to it sensitively. The work in (Polzin and Waibel 2000) presented how dialogue behaviors can be adjusted to users' emotional states. <ref type="bibr" target="#b18">Skowron (2010)</ref> proposed conversational systems, called affect listeners, that can respond to users' utterances both at the content-and affectrelated level. These works, mainly inspired by psychological findings, are either rule-based, or limited to small data, making them difficult to apply to large-scale conversation generation. Recently, sequence-to-sequence generation models <ref type="bibr" target="#b19">(Sutskever, Vinyals, and Le 2014;</ref><ref type="bibr" target="#b0">Bahdanau, Cho, and Bengio 2014)</ref> have been successfully applied to large-scale conversation generation (Vinyals and Le 2015), including neural responding machine <ref type="bibr" target="#b17">(Shang, Lu, and Li 2015)</ref>, hierarchical recurrent models <ref type="bibr" target="#b16">(Serban et al. 2015)</ref>, and many others. These models focus on improving the content quality of the generated responses, including diversity promotion <ref type="bibr" target="#b6">(Li et al. 2016a)</ref>, considering additional information <ref type="bibr" target="#b12">Mou et al. 2016;</ref><ref type="bibr" target="#b7">Li et al. 2016b;</ref><ref type="bibr" target="#b2">Herzig et al. 2017)</ref>, and handing unknown words <ref type="bibr" target="#b1">(Gu et al. 2016)</ref>.</p><p>However, no work has addressed the emotion factor in large-scale conversation generation. There are several studies that generate text from controllable variables. <ref type="bibr" target="#b5">(Hu et al. 2017</ref>) proposed a generative model which can generate sentences conditioned on certain attributes of the language such as sentiment and tenses. Affect Language Model was proposed in <ref type="bibr" target="#b0">(Ghosh et al. 2017)</ref> to generate text conditioned on context words and affect categories. (Cagan, Frank, and Tsarfaty 2017) incorporated the grammar information to generate comments for a document using sentiment and topics. Our work is different in two main aspects: 1) prior studies are heavily dependent on linguistic tools or customized parameters in text generation, while our model is fully datadriven without any manual adjustment; 2) prior studies are unable to model multiple emotion interactions between the input post and the response, instead, the generated text simply continues the emotion of the leading context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotional Chatting Machine</head><p>Background: Encoder-decoder Framework Our model is based on the encoder-decoder framework of the general sequence-to-sequence (seq2seq for short) model <ref type="bibr" target="#b19">(Sutskever, Vinyals, and Le 2014)</ref>. It is implemented with gated recurrent units (GRU) <ref type="bibr" target="#b0">(Cho et al. 2014;</ref><ref type="bibr" target="#b0">Chung et al. 2014)</ref>. The encoder converts the post sequence</p><formula xml:id="formula_0">X = (x 1 , x 2 , • • • , x n ) to hidden representations h = (h 1 , h 2 , • • • , h n )</formula><p>, which is defined as:</p><formula xml:id="formula_1">h t = GRU(h t−1 , x t ).</formula><p>(1)</p><p>The decoder takes as input a context vector c t and the embedding of a previously decoded word e(y t−1 ) to update its state s t using another GRU:</p><formula xml:id="formula_2">s t = GRU(s t−1 , [c t ; e(y t−1 )]),<label>(2)</label></formula><p>where [c t ; e(y t−1 )] is the concatenation of the two vectors, serving as the input to the GRU cell. The context vector c t is designed to dynamically attend on key information of the input post during decoding (Bahdanau, Cho, and Bengio 2014). Once the state vector s t is obtained, the decoder generates a token by sampling from the output probability distribution o t computed from the decoder's state s t as follows:</p><formula xml:id="formula_3">y t ∼ o t = P (y t | y 1 , y 2 , • • • , y t−1 , c t ), (3) = softmax(W o s t ).</formula><p>(4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Definition and Overview</head><p>Our problem is formulated as follows: Given a post</p><formula xml:id="formula_4">X = (x 1 , x 2 , • • • , x n )</formula><p>and an emotion category e of the response to be generated (explained below), the goal is to generate a response Y = (y 1 , y 2 , • • • , y m ) that is coherent with the emotion category e. Essentially, the model estimates the probability: P (Y |X, e) = m t=1 P (y t |y &lt;t , X, e). The emotion categories are {Angry, Disgust, Happy, Like, Sad, Other}, adopted from a Chinese emotion classification challenge task. <ref type="bibr">1</ref> The taxonomy comes from http://tcci.ccf.org.cn/confere -nce/2014/dldoc/evatask1.pdf In our problem statement, we assume that the emotion category of the to-be-generated response is given, because emotions are highly subjective. Given a post, there may be multiple emotion categories that are suitable for its response, depending on the attitude of the respondent. For example, for a sad story, someone may respond with sympathy (as a friend), someone may feel angry (as an irritable stranger), yet someone else may be happy (as an enemy). Flexible emotion interactions between a post and a response are an important difference from the previous studies <ref type="bibr" target="#b5">(Hu et al. 2017;</ref><ref type="bibr" target="#b0">Ghosh et al. 2017;</ref><ref type="bibr" target="#b0">Cagan, Frank, and Tsarfaty 2017)</ref>, which use the same emotion or sentiment for response as that in the input post.</p><p>Thus, due to this subjectivity of emotional responses, we choose to focus on solving the core problem: generating an emotional response given a post and an emotion category of the response. Our model thus works regardless the response emotion category. Note that there can be multiple ways to enable a chatbot to choose an emotion category for response. One way is to give the chatbot a personality and some background knowledge. Another way is to use the training data to find the most frequent response emotion category for the emotion in the given post and use that as the response emotion. This method is reasonable as it reflects the general emotion of the people. We leave this study to our future work.</p><p>Building upon the generation framework discussed in the previous section, we propose the Emotional Chatting Machine (ECM) to generate emotion expressions using three mechanisms: First, since the emotion category is a highlevel abstraction of an emotion expression, ECM embeds the emotion category and feeds the emotion category embedding to the decoder. Second, we assume that during decoding, there is an internal emotion state, and in order to capture the implicit change of the state and to balance the weights between the grammar state and the emotion state dynamically, ECM adopts an internal memory module. Third, an explicit expression of an emotion is modeled through an explicit selection of a generic (non-emotion) or emotion word by an external memory module.</p><p>An overview of ECM is given in <ref type="figure" target="#fig_0">Figure 1</ref>. In the training process, the corpus of post-response pairs is fed to an emotion classifier to generate the emotion label of each response, and then ECM is trained on the data of triples: posts, responses and emotion labels of responses. In the inference process, a post is fed to ECM to generate emotional responses conditioned on different emotion categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotion Category Embedding</head><p>Since an emotion category (for instance, Angry, Disgust, Happy) provides a high-level abstraction of an emotion expression, the most intuitive approach to modeling emotion in response generation is to take as additional input the emotion category of a response to be generated. Each emotion category is represented by a real-valued, low dimensional vector. For each emotion category e, we randomly initialize the vector of an emotion category v e , and then learn the vectors of the emotion category through training. The emotion category embedding v e , along with word embedding e(y t−1 ), and the context vector c t , are fed into the decoder to update the decoder's state s t :</p><formula xml:id="formula_5">s t = GRU(s t−1 , [c t ; e(y t−1 ); v e ]).<label>(5)</label></formula><p>Based on s t , the decoding probability distribution can be computed accordingly by Eq. 4 to generate the next token y t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Internal Memory</head><p>The method presented in the preceding section is rather static: the emotion category embedding will not change during the generation process which may sacrifice grammatical correctness of sentences as argued in (Ghosh et al. 2017).</p><p>Inspired by the psychological findings that emotional responses are relatively short lived and involve changes <ref type="bibr" target="#b1">(Gross 1998;</ref><ref type="bibr" target="#b4">Hochschild 1979)</ref>, and the dynamic emotion situation in emotional responses (Alam, Danieli, and Riccardi 2017), we design an internal memory module to capture the emotion dynamics during decoding. We simulate the process of expressing emotions as follows: there is an internal emotion state for each category before the decoding process starts; at each step the emotion state decays by a certain amount; once the decoding process is completed, the emotion state should decay to zero indicating the emotion is completely expressed.</p><p>The detailed process of the internal memory module is illustrated in <ref type="figure">Figure 2</ref>. At each step t, ECM computes a read  <ref type="figure">Figure 2</ref>: Data flow of the decoder with an internal memory. The internal memory M I e,t is read with the read gate g r t by an amount M I r,t to update the decoder's state, and the memory is updated to M I e,t+1 with the write gate g w t .</p><p>gate g r t with the input of the word embedding of the previously decoded word e(y t−1 ), the previous state of the decoder s t−1 , and the current context vector c t . A write gate g w t is computed on the decoder's state vector s t . The read gate and write gate are defined as follows:</p><formula xml:id="formula_6">g r t = sigmoid(W r g [e(y t−1 ); s t−1 ; c t ]), (6) g w t = sigmoid(W w g s t ).<label>(7)</label></formula><p>The read and write gates are then used to read from and write into the internal memory, respectively. Hence, the emotion state is erased by a certain amount (by g w t ) at each step. At the last step, the internal emotion state will decay to zero. This process is formally described as below:</p><formula xml:id="formula_7">M I r,t = g r t ⊗ M I e,t ,<label>(8)</label></formula><formula xml:id="formula_8">M I e,t+1 = g w t ⊗ M I e,t ,<label>(9)</label></formula><p>where ⊗ is element-wise multiplication, r/w denotes read/write respectively, and I means Internal. GRU updates its state s t conditioned on the previous target word e(y t−1 ), the previous state of the decoder s t−1 , the context vector c t , and the emotion state update M I r,t , as follows:</p><formula xml:id="formula_9">s t = GRU(s t−1 , [c t ; e(y t−1 ); M I r,t ]).<label>(10)</label></formula><p>Based on the state, the word generation distribution o t can be obtained with Eq. 4, and the next word y t can be sampled. After generating the next word, M I e,t+1 is written back to the internal memory. Note that if Eq. 9 is executed many times, it is equivalent to continuously multiplying the matrix, resulting in a decay effect since ≤ sigmoid(•) ≤ 1. This is similar to a DELETE operation in memory networks <ref type="bibr" target="#b11">(Miller et al. 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>External Memory</head><p>In the internal memory module, the correlation between the change of the internal emotion state and selection of a word is implicit and not directly observable. As the emotion expressions are quite distinct with emotion words <ref type="bibr" target="#b20">(Xu et al. 2008)</ref> contained in a sentence, such as lovely and awesome, which carry strong emotions compared to generic (non-emotion) words, such as person and day, we propose an external memory module to model emotion expressions explicitly by assigning different generation probabilities to emotion words and generic words. Thus, the model can choose to generate words from an emotion vocabulary or a generic vocabulary.</p><formula xml:id="formula_10">GRU what a GRU a lovely … … Type Selector Generic Softmax Emotion Softmax person α 1-α s t M e E y t</formula><p>External Memory <ref type="figure">Figure 3</ref>: Data flow of the decoder with an external memory. The final decoding probability is weighted between the emotion softmax and the generic softmax, where the weight is computed by the type selector.</p><p>The decoder with an external memory is illustrated in <ref type="figure">Figure</ref> 3. Given the current state of the decoder s t , the emotion softmax P e (y t = w e ) and the generic softmax P g (y t = w g ) are computed over the emotion vocabulary which is read from the external memory and generic vocabulary, respectively. The type selector α t controls the weight of generating an emotion or a generic word. Finally, the next word y t is sampled from the next word probability, the concatenation of the two weighted probabilities. The process can be formulated as follows:</p><formula xml:id="formula_11">α t = sigmoid(v u s t ),<label>(11)</label></formula><formula xml:id="formula_12">P g (y t = w g ) = softmax(W o g s t ),<label>(12)</label></formula><p>P e (y t = w e ) = softmax(W o e s t ),</p><p>y t ∼ o t = P (y t ) =</p><p>(1 − αt)Pg(yt = wg) αtPe(yt = we)</p><p>,</p><p>where α t ∈ [0, 1] is a scalar to balance the choice between an emotion word w e and a generic word w g , P g /P e is the distribution over generic/emotion words respectively, and P (y t ) is the final word decoding distribution. Note that the two vocabularies have no intersection, and the final distribution P (y t ) is a concatenation of two distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss Function</head><p>The loss function is the cross entropy error between the predicted token distribution o t and the gold distribution p t in the training corpus. Additionally, we apply two regularization terms: one on the internal memory, enforcing that the internal emotion state should decay to zero at the end of decoding, and the other on the external memory, constraining the selection of an emotional or generic word.</p><p>The loss on one sample &lt; X, Y &gt; (X = x 1 , x 2 , ..., x n , Y = y 1 , y 2 , ..., y m ) is defined as:</p><formula xml:id="formula_15">L(θ) = − m t=1 p t log(o t ) − m t=1 q t log(α t )+ M I e,m ,<label>(15)</label></formula><p>where M I e,m is the internal emotion state at the last step m, α t is the probability of choosing an emotion word or a generic word, and q t ∈ {0, 1} is the true choice of an emotion word or a generic word in Y . The second term is used to supervise the probability of selecting an emotion or generic word. And the third term is used to ensure that the internal emotion state has been expressed completely once the generation is completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Preparation</head><p>Since there is no off-the-shelf data to train ECM, we firstly trained an emotion classifier using the NLPCC emotion classification dataset and then used the classifier to annotate the STC conversation dataset <ref type="bibr" target="#b17">(Shang, Lu, and Li 2015)</ref> to construct our own experiment dataset. There are two steps in the data preparation process:</p><p>1. Building an Emotion Classifier. We trained several classifiers on the NLPCC dataset and then chose the best classifier for automatic annotation. This dataset was used in challenging tasks of emotion classification in NLPCC2013 2 and NLPCC2014 3 , consisting of 23,105 sentences collected from Weibo. It was manually annotated with 8 emotion categories: Angry, Disgust, Fear, Happy, Like, Sad, Surprise, and Other. After removing the infrequent classes (Fear (1.5%) and Surprise (4.4%)), we have six emotion categories, i.e., Angry, Disgust, Happy, Like, Sad and Other.</p><p>We then partitioned the NLPCC dataset into training, validation, and test sets with the ratio of 8:1:1. Several emotion classifiers were trained on the filtered dataset, including a lexicon-based classifier (Liu 2012) (we used the emotion lexicon in <ref type="bibr" target="#b20">(Xu et al. 2008)</ref>), RNN <ref type="bibr" target="#b11">(Mikolov et al. 2010)</ref>, LSTM <ref type="bibr" target="#b3">(Hochreiter and Schmidhuber 1997)</ref>, and Bidirectional LSTM (Bi-LSTM) <ref type="bibr" target="#b1">(Graves, Fernández, and Schmidhuber 2005)</ref>. Results in <ref type="table">Table 2</ref> show that all neural classifiers outperform the lexicon-based classifier, and the Bi-LSTM classifier obtains the best accuracy of 0.623.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Accuracy Lexicon-based 0.432 RNN 0.564 LSTM 0.594 Bi-LSTM 0.623 <ref type="table">Table 2</ref>: Classification accuracy on the NLPCC dataset.</p><p>2. Annotating STC with Emotion. We applied the best classifier, Bi-LSTM, to annotate the STC Dataset with the six emotion categories. After annotation, we obtained an http://tcci.ccf.org.cn/conference/2013/ 3 http://tcci.ccf.org.cn/conference/2014/ emotion-labeled dataset, which we call the Emotional STC (ESTC) Dataset. The statistics of the ESTC Dataset are shown in <ref type="table" target="#tab_2">Table 3</ref>. Although the emotion labels for ESTC Dataset are noisy due to automatic annotation, this dataset is good enough to train the models in practice. As future work, we will study how the classification errors influence response generation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Implementation Details</head><p>We used Tensorflow 4 to implement the proposed model 5 . The encoder and decoder have 2-layer GRU structures with 256 hidden cells for each layer and use different sets of parameters respectively. The word embedding size is set to 100. The vocabulary size is limited to 40,000. The embedding size of emotion category is set to 100. The internal memory is a trainable matrix of size 6×256 and the external memory is a list of 40,000 words containing generic words and emotion words (but emotion words have different markers). To generate diverse responses, we adopted beam search in the decoding process of which the beam size is set to 20, and then reranked responses by the generation probability after removing those containing UNKs, unknown words. We used the stochastic gradient descent (SGD) algorithm with mini-batch. Batch size and learning rate are set to 128 and 0.5, respectively. To accelerate the training process, we trained a seq2seq model on the STC dataset with pre-trained word embeddings. And we then trained our model on the ESTC Dataset with parameters initialized by the parameters of the pre-trained seq2seq model. We ran 20 epoches, and the training stage of each model took about a week on a Titan X GPU machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines</head><p>As aforementioned, this paper is the first work to address the emotion factor in large-scale conversation generation. We did not find closely-related baselines in the literature. Affect-LM (Ghosh et al. 2017) cannot be our baseline because it is unable to generate responses of different emotions for the same post. Instead, it simply copies and uses the emotion of the input post. Moreover, it depends heavily on linguistic resources and needs manual parameter adjustments.</p><p>Nevertheless, we chose two suitable baselines: a general seq2seq model <ref type="bibr" target="#b19">(Sutskever, Vinyals, and Le 2014)</ref>, and an emotion category embedding model (Emb) created by us where the emotion category is embedded into a vector, and the vector serves as an input to every decoding position, similar to the idea of user embedding in <ref type="bibr" target="#b7">(Li et al. 2016b)</ref>. As emotion category is a high-level abstraction of emotion expressions, this is a proper baseline for our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automatic Evaluation</head><p>Metrics: As argued in <ref type="bibr" target="#b8">(Liu et al. 2016)</ref>, BLEU is not suitable for measuring conversation generation due to its low correlation with human judgment. We adopted perplexity to evaluate the model at the content level (whether the content is relevant and grammatical). To evaluate the model at the emotion level, we adopted emotion accuracy as the agreement between the expected emotion category (as input to the model) and the predicted emotion category of a generated response by the emotion classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Perplexity  <ref type="table">Table 4</ref>: Objective evaluation with perplexity and accuracy.</p><p>Results: The results are shown in <ref type="table">Table 4</ref>. As can be seen, ECM obtains the best performance in emotion accuracy, and the performance in perplexity is better than Seq2Seq but worse than Emb. This may be because the loss function of ECM is supervised not only on perplexity, but also on the selection of generic or emotion words (see Eq.15). In practice, emotion accuracy is more important than perplexity considering that the generated sentences are already fluent and grammatical with the perplexity of 68.0. In order to investigate the influence of different modules, we conducted ablation tests where one of the three modules was removed from ECM each time. As we can see, ECM without the external memory achieves the best performance in perplexity. Our model can generate responses without sacrificing grammaticality by introducing the internal memory, where the module can balance the weights between grammar and emotion dynamically. After removing the external memory, the emotion accuracy decreases the most, indicating the external memory leads to a higher emotion accuracy since it explicitly chooses the emotion words. Note that the emotion accuracy of Seq2Seq is extremely low because it generates the same response for different emotion categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Manual Evaluation</head><p>In order to better understand the quality of the generated responses from the content and emotion perspectives, we performed manual evaluation. Given a post and an emotion cat-egory, responses generated from all the models were randomized and presented to three human annotators.</p><p>Metrics: Annotators were asked to score a response in terms of Content (rating scale is 0,1,2) and Emotion (rating scale is 0,1), and also to state a preference between any two systems. Content is defined as whether the response is appropriate and natural to a post and could plausibly have been produced by a human, which is a widely accepted metric adopted by researchers and conversation challenging tasks, as proposed in <ref type="bibr" target="#b17">(Shang, Lu, and Li 2015)</ref>. Emotion is defined as whether the emotion expression of a response agrees with the given emotion category.</p><p>Annotation Statistics: We randomly sampled 200 posts from the test set. For each model we generated 1,200 responses in total: for Seq2Seq, we generated the top 6 responses for each post, and for Emb and ECM, we generated the top responses corresponding to the 6 emotion categories.</p><p>We calculated the Fleiss' kappa <ref type="bibr" target="#b0">(Fleiss 1971)</ref> to measure inter-rater consistency. Fleiss' kappa for Content and Emotion is 0.441 and 0.757, indicating "Moderate agreement" and "Substantial agreement" respectively. Method (%) 2-1 1-1 0-1 2-0 1-0 0-0 Seq2Seq 9.0 5.1 1.1 37.6 28.0 19.2 Emb 22.8 9.3 4.3 27.1 19.1 17.4 ECM 27.2 10.8 4.4 24.2 15.5 17.9 <ref type="table">Table 5</ref>: The percentage of responses in manual evaluation with the score of Content-Emotion. For instance, 2-1 means content score is 2 and emotion score is 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results:</head><p>The results are shown in <ref type="table" target="#tab_6">Table 6</ref>. ECM with all options outperforms the other methods in both metrics significantly (2-tailed t-test, p &lt; 0.05 for Content, and p &lt; 0.005 for Emotion). After incorporating the internal memory and the external memory modules, the performance of ECM in Emotion is improved comparing to Emb, indicating our model can generate more explicit expressions of emotion. Besides, the performance in Content is improved from 1.256 of Emb to 1.299 of ECM, which shows the ability of ECM to control the weight of emotion and generate responses appropriate in content. For all emotion categories, the performance of ECM in Emotion outperforms the other methods. However, the performances of ECM in Content is worse than baselines in Disgust and Angry categories, due to the fact that there are not sufficient training data for the two categories. For instance, the Angry category has 234,635 responses in our ESTC Dataset, much less than the other categories.</p><p>To evaluate whether ECM can generate responses that are appropriate not only in content but also in emotion, we present results in <ref type="table">Table 5</ref> by considering content and emotion scores simultaneously 6 . As we can see, 27.2% of the responses generated by ECM have a Content score of 2 and an Emotion score of 1, while only 22.8% for Emb and 9.0%</p><p>Note that Content and Emotion are two independent metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response(Original) Response(Translated)</head><p>A promise is what a cheater says to a fool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Seq2Seq</head><p>A promise is what a cheater says to a fool.     <ref type="table">Table 7</ref>: Pairwise preference of the three systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ECM Like</head><p>Preference Test: In addition, emotion models (Emb and ECM) are much more preferred than Seq2Seq, and ECM is also significantly (2-tailed t-test, p &lt; 0.001) preferred by annotators against other methods as shown in <ref type="table">Table 7</ref>. The diverse emotional responses are more attractive to users than the generic responses generated by the Seq2Seq model. And with the explicitly expressions of emotions as well as the appropriateness in content, ECM is much more preferred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of Emotion Interaction and Case Study</head><p>Figure 5 visualizes the emotion interaction patterns of the posts and responses in the ESTC Dataset. An emotion interaction pattern (EIP) is defined as &lt; e p , e r &gt;, the pair of emotion categories of the post and its response. The value of an EIP is the conditional probability P (e r |e p ) = P (e r , e p )/P (e p ). An EIP marked with a darker color occurs more frequently than a lighter color. From the figure, we can make a few observations. First, frequent EIPs show that there are some major responding emotions given a post emo- tion category. For instance, when a post expresses Happy, the responding emotion is typically Like or Happy. Second, the diagonal patterns indicate emotional empathy, a common type of emotion interaction. Third, there are also other EIPs for a post, indicating that emotion interactions in conversation are quite diverse, as mentioned earlier. Note that class Other has much more data than other classes (see <ref type="table" target="#tab_2">Table 3</ref>), indicating that EIPs are biased toward this class (the first column of <ref type="figure" target="#fig_2">Figure 5</ref>), due to the data bias and the emotion classification errors. We present some examples in <ref type="figure" target="#fig_1">Figure 4</ref>. As can be seen, for a given post, there are multiple emotion categories that are suitable for its response in conversation. Seq2Seq generates a response with a random emotion. ECM can generate emotional responses conditioned on every emotion category. All these responses are appropriate to the post, indicating the existence of multiple EIPs and the reason why an emotion category should be specified as an input to our system.</p><p>We can see that ECM can generate appropriate responses if the pre-specified emotion category and the emotion of the post belong to one of the frequent EIPs. Colored words show that ECM can explicitly express emotion by applying the external memory which can choose a generic (non-emotion) or emotion word during decoding. For low-frequency EIPs such as &lt; Happy, Disgust &gt; and &lt; Happy, Angry &gt; as shown in the last two lines of <ref type="figure" target="#fig_1">Figure 4</ref>, responses are not appropriate to the emotion category due to the lack of training data and/or the errors caused by the emotion classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and Future Work</head><p>In this paper, we proposed the Emotional Chatting Machine (ECM) to model the emotion influence in large-scale conversation generation. Three mechanisms were proposed to model the emotion factor, including emotion category embedding, internal emotion memory, and external memory. Objective and manual evaluation show that ECM can generate responses appropriate not only in content but also in emotion.</p><p>In our future work, we will explore emotion interactions with ECM: instead of specifying an emotion class, the model should decide the most appropriate emotion category for the response. However, this may be challenging since such a task depends on the topics, contexts, or the mood of the user.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Overview of ECM (the grey unit). The pink units are used to model emotion factors in the framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Sample responses generated by Seq2Seq and ECM (original Chinese and English translation, the colored words are the emotion words corresponding to the given emotion category). The corresponding posts did not appear in the training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Visualization of emotion interaction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Statistics of the ESTC Dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Manual evaluation of the generated responses in terms of Content (Cont.) and Emotion (Emot.) .for Seq2Seq. These indicate that ECM is better in generating high-quality responses in both content and emotion.</figDesc><table><row><cell cols="4">Pref. (%) Seq2Seq Emb ECM</cell></row><row><cell>Seq2Seq</cell><cell>-</cell><cell cols="2">38.8 38.6</cell></row><row><cell>Emb</cell><cell>60.2</cell><cell>-</cell><cell>43.1</cell></row><row><cell>ECM</cell><cell>61.4</cell><cell>56.9</cell><cell>-</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/tensorflow/tensorflow 5 https://github.com/tuxchow/ecm</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partly supported by the National Science Foundation of China under grant No.61272227/61332007, and a joint project with Sogou. We would like to thank our collaborators, Jingfang Xu and Haizhou Zhao.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate. CoRR abs/1409.0473. [Cagan, Frank, and Tsarfaty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danieli</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Riccardi ; Alam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Fleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Laksana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Scherer</surname></persName>
		</author>
		<idno>abs/1412.3555</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1971" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="634" to="642" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bidirectional lstm networks for improved phoneme classification and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernández</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">O</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICANN</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural response generation for customer service based on personality traits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shmueli-Scheuer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sandbank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Konopnicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Natural Language Generation</title>
		<meeting>the 10th International Conference on Natural Language Generation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="252" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Emotion work, feeling rules, and social structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Hochschild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of sociology</title>
		<imprint>
			<biblScope unit="page" from="551" to="575" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Toward controlled generation of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1587" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A personabased neural conversation model</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="994" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Breakdown in human-machine interaction: the error is the clue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Martinovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ISCA tutorial and research workshop</title>
		<meeting>the ISCA tutorial and research workshop</meeting>
		<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
	<note>Sentiment analysis and opinion mining</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Salovey</surname></persName>
		</author>
		<title level="m">What is emotional intelligence? Emotional Development and Emotional Intelligence</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="3" to="31" />
		</imprint>
	</monogr>
	<note>Mayer and Salovey</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Keyvalue memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1400" to="1409" />
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="295" to="309" />
		</imprint>
	</monogr>
	<note>The effects of affective interventions in human-computer interaction</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Emotion-sensitive human-computer interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Polzin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA Tutorial and Research Workshop (ITRW) on Speech and Emotion</title>
		<imprint>
			<publisher>MIT press Cambridge</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">252</biblScope>
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
	<note>Affective computing</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using human physiology to evaluate subtle expressivity of a virtual quizmaster in a mathematical game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ishizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of human-computer studies</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="231" to="245" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Applied Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cherry</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Building end-toend dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Serban</surname></persName>
		</author>
		<idno>abs/1507.04808</idno>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
	<note>Hierarchical neural network generative models for movie dialogues</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li ;</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Affect listeners: Acquisition of affective states by means of conversational systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Skowron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Development of Multimodal Interfaces: Active Listening and Synchrony</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="169" to="181" />
		</imprint>
	</monogr>
	<note>Skowron</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinyals</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><forename type="middle">;</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Topic aware neural response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="180" to="185" />
		</imprint>
	</monogr>
	<note>Affective lexicon ontology</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
