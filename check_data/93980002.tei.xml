<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multipolicy Decision-Making for Autonomous Driving via Changepoint-based Behavior Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enric</forename><surname>Galceran</surname></persName>
							<email>egalcera@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Cunningham</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">M</forename><surname>Eustice</surname></persName>
							<email>eustice@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><surname>Olson</surname></persName>
							<email>ebolson@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Michigan</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multipolicy Decision-Making for Autonomous Driving via Changepoint-based Behavior Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>To operate reliably in real-world traffic, an autonomous car must evaluate the consequences of its potential actions by anticipating the uncertain intentions of other traffic participants. This paper presents an integrated behavioral inference and decision-making approach that models vehicle behavior for both our vehicle and nearby vehicles as a discrete set of closedloop policies that react to the actions of other agents. Each policy captures a distinct high-level behavior and intention, such as driving along a lane or turning at an intersection. We first employ Bayesian changepoint detection on the observed history of states of nearby cars to estimate the distribution over potential policies that each nearby car might be executing. We then sample policies from these distributions to obtain high-likelihood actions for each participating vehicle. Through closed-loop forward simulation of these samples, we can evaluate the outcomes of the interaction of our vehicle with other participants (e.g., a merging vehicle accelerates and we slow down to make room for it, or the vehicle in front of ours suddenly slows down and we decide to pass it). Based on those samples, our vehicle then executes the policy with the maximum expected reward value. Thus, our system is able to make decisions based on coupled interactions between cars in a tractable manner. This work extends our previous multipolicy system [11] by incorporating behavioral anticipation into decision-making to evaluate sampled potential vehicle interactions. We evaluate our approach using real-world traffic-tracking data from our autonomous vehicle platform, and present decision-making results in simulation involving highway traffic scenarios.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Decision-making for autonomous driving is hard due to uncertainty on the continuous state of nearby vehicles and, in particular, due to uncertainty over their discrete potential intentions (such as turning at an intersection or changing lanes).</p><p>Previous approaches have employed hand-tuned heuristics <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41]</ref> and numerical optimization <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b41">42]</ref>, but these methods fail to capture the coupled dynamic effects of interacting traffic agents. Partially observable Markov decision process (POMDP) solvers <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35]</ref> offer a theoreticallygrounded framework to capture these interactions, but have difficulty scaling up to real-world scenarios. In addition, current approaches for anticipating future intentions of other traffic agents <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref> either consider only the current state of the target vehicle, ignoring the history of its past actions, or rather require expensive collection of training data.</p><p>In this paper, we present an integrated behavioral anticipation and decision-making system that models behavior for both our vehicle and nearby vehicles as the result of closed-loop <ref type="figure">Fig. 1</ref>. Our multipolicy approach allows us to sample from the likely coupled interactions between traffic agents. In this simulation at a four-way stopsign-regulated intersection ( §VI-D), we evaluate the outcomes of the possible intentions of other cars to make a decision for our car. The bottom and right cars proceed through the intersection, while the other two cars yield. This experiment shows that our multipolicy sampling strategy generates highlikelihood samples over the coupled interactions of vehicles, and that is orders of magnitude faster than uninformed sampling strategies commonly used in the literature ( §VI-D). Legend: human-driven trajectories (red); rollouts from our multipolicy sampling strategy (purple); high-likelihood trajectories obtained by an uninformed sampling strategy (dark blue); trajectories sampled by the uninformed strategy before finding a high-likelihood sample (light blue).</p><p>policies. This approach is made tractable by considering only a finite set of a priori known policies. Each policy is designed to capture a different high-level behavior, such as following a lane, changing lanes, or turning at an intersection. Our system proceeds in a sequence of two interleaved stages of behavioral prediction and decision-making. In the first stage, we estimate the probability distribution over the potential policies other traffic agents may be executing. To this aim, we leverage Bayesian changepoint detection to estimate which policy a given vehicle was executing at each point in its history of actions, and then infer the likelihood of each potential intention of the vehicle. Furthermore, we propose a statistical test based on changepoint detection to identify anomalous behavior of other vehicles, such as driving in the wrong direction or swerving out of lanes. Individual policies can therefore adjust their behavior to react to anomalous cars.</p><p>In the second stage, we use this distribution to sample over permutations of other vehicle policies and the policies available for our car, with forward-simulation of these sampled intentions to evaluate their outcomes via a user-defined reward function. Our vehicle finally executes the policy that maximizes the expected reward given the sampled outcomes. Thus, our system is able to make decisions based on closedloop interactions between cars in a tractable manner.</p><p>We evaluate our behavioral prediction system using a realworld autonomous vehicle, and present decision-making results in simulation involving highway traffic scenarios.</p><p>The central contributions of this paper are:</p><p>• A changepoint-based behavioral prediction approach that leverages the history of actions of a target vehicle to infer the likelihood of its possible future actions and detect anomalous behavior online. • A decision-making algorithm that evaluates the outcomes of modeled interactions between vehicles, being able to account for the effect of its actions on the future reactions of other participants. • An evaluation of the proposed system using both traffic data obtained from a real-world autonomous vehicle and simulated traffic scenarios. This work extends our earlier work <ref type="bibr" target="#b10">[11]</ref>, where we proposed the strategy of selecting between multiple policies for our car by evaluating them via forward simulation, and demonstrated passing maneuvers using a real-world autonomous vehicle. However, that work did not address anticipation of policies for other cars. In contrast, this paper presents a fully integrated behavioral anticipation and decision-making approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Related Work on Behavioral Prediction</head><p>Despite the probabilistic nature of the anticipation problem, some approaches in the literature assume no uncertainty on the future states of other participants <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33]</ref>. Such an approach could be justified in a scenario where vehicles broadcast their intentions over some communications channel, but it is an unrealistic assumption otherwise.</p><p>Some approaches assume a dynamic model of the obstacle and propagate its state using standard filtering techniques such as the extended Kalman filter <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b17">18]</ref>. Despite providing rigorous probabilistic estimates over an obstacle's future states, these methods often perform poorly when dealing with nonlinearities in the assumed dynamics model and the multimodalities induced by discrete decisions (e.g. continuing straight, merging, or passing). Some researchers have explored using Gaussian mixture models (GMMs) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22]</ref> and contextsensitive models <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref> to account for nonlinearities and multiple discrete decisions. However, this approach does not consider the history of previous states of the target object, assigning an equal likelihood to each discrete hypothesis and leading to a conservative estimate.</p><p>A common anticipation strategy in autonomous driving <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21]</ref> consists in computing the possible goals of a target vehicle by planning from its standpoint, accounting for its current state. This strategy is similar to our factorization of potential driving behavior into a set of policies, but lacks our closed-loop simulation of vehicle interactions.</p><p>Recent work uses Gaussian process (GP) regression to learn typical motion patterns for classification and prediction of agent trajectories <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b39">40]</ref>, particularly in autonomous driving <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref>. Nonetheless, these methods require collecting training data to reflect all possible motion patterns the system may encounter, which can be time consuming. For instance, a lane change motion pattern learned in urban roads will not be representative of the same maneuver performed at higher speeds on the highway.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Related Work on Decision Making</head><p>The first instances of decision making systems for autonomous vehicles capable of handling urban traffic situations stem from the 2007 DARPA Urban Challenge <ref type="bibr" target="#b11">[12]</ref>. In that event, participants tackled decision making using a variety of solutions ranging from finite state machines (FSMs) <ref type="bibr" target="#b28">[29]</ref> and decision trees <ref type="bibr" target="#b27">[28]</ref> to several heuristics <ref type="bibr" target="#b40">[41]</ref>. However, these approaches were tailored for very specific and simplified situations and were, even according to their authors, "not robust to a varied world" <ref type="bibr" target="#b40">[41]</ref>.</p><p>More recent approaches have addressed the decision making problem for autonomous driving through the lens of trajectory optimization <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b41">42]</ref>. However, these methods do not model the closed-loop interactions between vehicles, failing to reason about their potential outcomes.</p><p>The POMDP model provides a mathematically rigorous formulation of the decision making problem in dynamic, uncertain scenarios such as autonomous driving. Unfortunately, finding an optimal solution to most POMDPs is intractable <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b31">32]</ref>. A variety of general <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref> and domainspecific <ref type="bibr" target="#b7">[8]</ref> POMDP solvers exist in the literature that seek to approximate the solution. Nonetheless, online application of POMDP solvers <ref type="bibr" target="#b5">[6]</ref> remains challenging because they often explore unlikely regions of the belief space.</p><p>The idea of assuming finite sets of policies to speed up planning has appeared before in the POMDP literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b35">36]</ref>. However, these approaches dedicate significant resources to compute their sets of policies, and as a result they are limited to short planning horizons and relatively small state, observation, and action spaces. In contrast, we propose to exploit domain knowledge to design a set of policies that are readily available at planning time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROBLEM FORMULATION</head><p>We first formulate the problem of decision making in dynamic, uncertain environments with tightly coupled interactions between multiple agents as a multiagent POMDP. We then show how we exploit autonomous driving domain knowledge to make approximations to the POMDP formulation, thus enabling principled decisions in a tractable manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. General Decision Process</head><p>Let V denote the set of vehicles interacting in a local neighborhood of our vehicle, including our controlled vehicle. At time t, a vehicle v ∈ V can take an action</p><formula xml:id="formula_0">a v t ∈ A v to transition from state x v t ∈ X v to x v t+1 .</formula><p>In our system, a state</p><formula xml:id="formula_1">x v</formula><p>t is a tuple of the pose, velocity, and acceleration and an action a v t is a tuple of controls for steering, throttle, brake, shifter, and directionals. As a notational convenience, let x t include all state variables x v t for all vehicles at time t, and similarly let a t ∈ A be the actions of all vehicles.</p><p>We model the vehicle dynamics with a conditional probability function</p><formula xml:id="formula_2">T (x t , a t , x t+1 ) = p(x t+1 |x t , a t ). Similarly, we model observation uncertainty as Z(x t , z v t ) = p(z v t |x t ), where z v t ∈ Z v</formula><p>is the observation made by vehicle v at time t, and z t ∈ Z is the vector of all sensor observations made by all vehicles. In our system, an observation z v t is a tuple including the estimated poses and velocities of nearby vehicles and an occupancy grid of static obstacles. Further, we model uncertainty on the behavior of other agents with the following driver model:</p><formula xml:id="formula_3">D(x t , z v t , a v t ) = p(a v t |x t , z v t )</formula><p>, where a v t ∈ A is a latent variable that must be inferred from sensor observations.</p><p>Our vehicle's goal is to find an optimal policy π * that maximizes the expected reward over a given decision horizon H, where a policy is a mapping π : X × Z v → A v that yields an action from the current maximum a posteriori (MAP) estimate of the state and an observation:</p><formula xml:id="formula_4">π * = argmax π E H t=t0 X R(x t )p(x t ) dx t ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_5">R(x t ) is a real-valued reward function R : X → R. The evolution of p(x t ) over time is governed by p(x t+1 ) = X Z A p(x t+1 |x t , a t )p(z t |x t ) p(a t |x t , z t )p(x t ) da t dz t dx t .<label>(2)</label></formula><p>The driver model</p><formula xml:id="formula_6">D(x t , z v t , a v t )</formula><p>implicitly assumes that the instantaneous actions of each vehicle are independent of each other, since a v t is conditioned only on x t and z v t . However, modeled agents can still react to the observed states of nearby vehicles via z v t . That is to say that vehicles do not collaborate with each other, as would be implied by an action a v t dependent on a t . Thus, the joint density for a single vehicle v can be written as</p><formula xml:id="formula_7">p v (x v t , x v t+1 , z v t , a v t ) = p(x v t+1 |x v t , a v t )p(z v t |x v t ) p(a v t |x v t , z v t )p(x v t ),<label>(3)</label></formula><p>and the independence assumption finally leads to</p><formula xml:id="formula_8">p(x t+1 ) = v∈V X v Z v A v p v (x v t , x v t+1 , z v t , a v t ) da v t dz v t dx v t .</formula><p>(4) Despite assuming independent vehicle actions, marginalizing over the large state, observation and action spaces in Eq. 4 is too expensive to find an optimal policy online in a timely manner. A possible approximation to speed up the process, commonly used by general POMDP solvers <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b36">37]</ref> is to solve Eq. 1 by drawing samples from p(x t ). However, sampling over the full probability space with random walks will yield a large number of low probability samples (see <ref type="figure">Fig. 1</ref>). This paper presents an approach designed to sample from high likelihood scenarios such that the decision-making process is tractable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multipolicy Approach</head><p>We make the following approximations to sample from the likely interactions of traffic agents: 1) At any given time, both our vehicle and other vehicles are executing a policy from a discrete set of policies. 2) We approximate the vehicle dynamics and observation models through deterministic, closed-loop forward simulation of all vehicles with assigned policies.</p><p>These approximations allow us to evaluate the consequences of our decisions over a limited set of high-level behaviors determined by the available policies (for both our vehicle and other agents), rather than performing the evaluation for every possible control input of every vehicle. Let Π be a discrete set of policies, where each policy captures a specific high-level driving behavior. Let each policy π ∈ Π be parameterized by a parameter vector θ capturing variations of the given policy. For example, for a lanefollowing policy, θ can capture the "driving style" of the policy by regulating its acceleration profile to be more or less aggressive. We thus reduce the search in Eq. 1 to a limited set of policies. By assuming each vehicle v ∈ V is executing a policy π v t ∈ Π at time t, the driver model for other agents can be now expressed as:</p><formula xml:id="formula_9">D(x t , z v</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. BEHAVIORAL ANALYSIS AND PREDICTION VIA CHANGEPOINT DETECTION</head><p>In this section, we describe how we infer the probability of the policies executed by other cars and their parameters. Our behavioral anticipation method is based on a segmentation of the history of observed states of each vehicle, where each segment is associated with the policy most likely to have generated the observations in the segment. We obtain this segmentation using Bayesian changepoint detection, which infers the points in the history of observations where the underlying policy generating the observations changes. Thereby, we can compute the likelihood of all available policies for the target car given the observations in the most recent segment, capturing the distribution p(π v t |x t , z 0:t ) over the car's potential policies at the current timestep. Further, full history segmentation allows us to detect anomalous behavior that is not explained by the set of policies in our system. The changepoint-detection procedure is illustrated by the simulation in <ref type="figure">Fig. 2</ref>. We next describe the anticipation method for a single vehicle, which we then apply successively to all nearby vehicles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Changepoint Detection</head><p>To segment a target car's history of observed states, we adopt the recently proposed CHAMP algorithm by Niekum et al. <ref type="bibr" target="#b29">[30]</ref>, which builds upon the work of Fearnhead and Liu <ref type="bibr" target="#b14">[15]</ref>. Given the set of available policies Π and a time series of the observed states of a given vehicle z 1:n = (z 1 , z 2 , . . . , z n ), CHAMP infers the MAP set of times τ 1 , τ 2 , . . . , τ m , at which changepoints between policies have occurred, yielding m + 1 segments. Thus, the i th segment consists of observations z τ i +1:τ i+1 and has an associated policy π i ∈ Π with parameters θ i .</p><p>The changepoint positions are modeled as a Markov chain where the transition probabilites are a function of the time since the last changepoint:</p><formula xml:id="formula_10">p(τ i+1 = t|τ i = s) = g(t − s),<label>(8)</label></formula><p>where g(•) is a pdf over time, and G(•) denotes its cdf. Given a segment from time s to t and a policy π, CHAMP approximates the logarithm of the policy evidence for that segment via the Bayesian information criterion (BIC) <ref type="bibr" target="#b3">[4]</ref> as:</p><formula xml:id="formula_11">log L(s, t, π) ≈ log p(z s+1:t |π,θ) − 1 k π log(t − s),<label>(9)</label></formula><p>where k π is the number of parameters of policy π and θ are estimated parameters for policy π. The BIC is a well-known approximation that avoids marginalizing over the policy parameters and provides a principled penalty against complex policies by assuming a Gaussian posterior around the estimated parametersθ. Thus, only the ability to fit policies to the observed data is required, which can be achieved via a maximum likelihood estimation (MLE) method of choice (we elaborate on this in §IV-B).</p><p>As shown by Fearnhead and Liu <ref type="bibr" target="#b14">[15]</ref>, the distribution C t over the position of the first changepoint before time t can be estimated efficiently using standard Bayesian filtering and an online Viterbi algorithm. Defining</p><formula xml:id="formula_12">P t (j, q) = p(C t = j, q, E j , z 1:t )<label>(10)</label></formula><formula xml:id="formula_13">P MAP t = p(Changepoint at t, E t , z 1:t ),<label>(11)</label></formula><p>where E j is the event that the MAP choice of changepoints has occurred prior to a given changepoint at time j, results in:</p><formula xml:id="formula_14">P t (j, q) = (1 − G(t − j − 1))L(j, t, q)p(q)P MAP j<label>(12)</label></formula><formula xml:id="formula_15">P MAP t = max j,q g(t − j) 1 − G(t − j − 1) P t (j, q) .<label>(13)</label></formula><p>At any time, the most likely sequence of latent policies (called the Viterbi path) that results in the sequence of observations can be recovered by finding (j, q) that maximize P MAP t , and then repeating the maximization for P MAP j , successively until time zero is reached. Further details on this changepoint detection method are provided by Niekum et al. <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Behavioral Prediction</head><p>In contrast with other anticipation approaches in the literature which consider only the current state of the target vehicle and assign equal likelihood to all its potential intentions <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>, here we compute the likelihood of each latent policy by leveraging changepoint detection on the history of observed vehicle states.</p><p>Consider the (m + 1) th segment (the most recent), obtained via changepoint detection and consisting of observations z τm+1:n . The likelihood and parameters of each latent policy π ∈ Π for the target vehicle given the present segment can be computed by solving the following MLE problem:</p><formula xml:id="formula_16">∀π ∈ Π, L(π) = argmax θ log p(z τm+1:n |π, θ).<label>(14)</label></formula><p>Specifically, we assume p(z τm+1:n |π, θ) to be a multivariate Gaussian with mean at the trajectory ψ π,θ obtained by simulating forward in time the execution of policy π under parameters θ from timestep τ m + 1:</p><formula xml:id="formula_17">p(z τm+1:n |π, θ) = N (z τm+1:n ; ψ π,θ , σI),<label>(15)</label></formula><p>where σ is a nuisance parameter capturing modeling error and I is a suitable identity matrix (we discuss our forward simulation of policies further in §V-B). That is, Eq. 15 essentially measures the deviation of the observed states from those prescribed by the given policy. The policy likelihoods obtained via Eq. 14 capture the probability distribution over the possible policies that the observed vehicle might be executing at the current timestep, which can be represented, using delta functions, as a mixture distribution:</p><formula xml:id="formula_18">p(π v t |x t , z 0:t ) = η |Π| i=1 δ(α i ) • L(π i ),<label>(16)</label></formula><p>where α i is the hypothesis over policy π i and η is a normalizing constant. We can therefore compute the approximated posterior of Eq. 7 by sampling from this distribution for each vehicle, obtaining high-likelihood samples from the coupled interactions of traffic agents. <ref type="figure">Fig. 2</ref>. Policy changepoint detection on a simulated passing maneuver on a highway. Our vehicle (far right) tracks the behavior of another traffic agent (far left) as it navigates through the highway segment from right to left. Using the tracked vehicle's history of past observations (green curve), we are able to infer which policies are most likely to have generated the maneuvers of the tracked vehicle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Anomaly Detection</head><p>The time-series segmentation obtained via changepoint detection allows us to perform online detection of anomalous behavior not modeled by our policies. Inspired by prior work on anomaly detection <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34]</ref>, we first define the properties of anomalous behavior in terms of policy likelihoods, and then compare the observed data against labeled normal patterns in previously-recorded vehicle trajectories. Thus, we define the following two criteria for anomalous behavior: 1) Unlikelihood against available policies. Anomalous behavior is not likely to be explained by any of the available policies, since they are designed to abide by traffic rules and provide a smooth riding experience. Therefore, behaviors like driving in the wrong direction or crossing a solid line on the highway will not be captured by the available policies. We thus measure the average likelihood among all segments in the vehicle's history as the global similarity of the observed history to all available policies:</p><formula xml:id="formula_19">S = 1 m + 1 m+1 i=1 L(π i ),<label>(17)</label></formula><p>where π i is the policy associated with the i th segment. 2) Ambiguity among policies. A history segmentation that fluctuates frequently among different policies might be a sign of ambiguity on the segmentation. To express this criterion formally, we first construct a histogram capturing the occurrences of each policy in the vehicle's segmented history. A histogram with a broad spread indicates frequent fluctuation, whereas one with a single mode is more likely to correspond to normal behavior. We measure this characteristic as the excess kurtosis of the histogram, κ = µ4 σ 4 − 3, where µ 4 is the fourth moment of the mean and σ is the standard deviation. The excess kurtosis satisfies −2 &lt; κ &lt; ∞. If κ = 0, the histogram resembles a normal distribution, whereas if κ &lt; 0, the histogram presents a broader spread. That is, we seek to identify changepoint sequences where there is no dominant policy. Using these criteria, we define the following normality measure given a vehicle's MAP choice of changepoints:</p><formula xml:id="formula_20">N = 1 [(κ + 2)S] .<label>(18)</label></formula><p>This normality measure on the target car's history can then be compared to that of a set of previously recorded trajectories of other vehicles. We thus define the normality test for the current vehicle's history as N &lt; 0.5γ, where γ is the minimum normality measure evaluated on the prior time-series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. MULTIPOLICY DECISION-MAKING</head><p>We now present the policy selection procedure for our car (Algorithm 1), which implements the formulation and approximations given in §III by leveraging the anticipation scheme from §IV. The algorithm begins by drawing a set of samples s ∈ S from the distribution over policies of other cars via Eq. 16, where each sample assigns a policy π v ∈ Π to each nearby vehicle v, excluding our car. For each policy π available to our car and for each sample s, we roll out forward in time until the decision horizon H all vehicles under the policy assignments (π, s) with closed loop simulation to yield a set Ψ of simulated trajectories ψ. We then evaluate the reward r π,s for each rollout Ψ, and finally select the policy π * maximizing the expected reward. The process continuously repeats in a receding horizon manner. Note that policies that are not applicable given the current state x 0 , such as an intersection handling policy when driving on the highway, are not considered for selection (line 5). We next discuss three key points of our decision-making procedure: the design of the set of available policies, using forward simulation to roll out potential interactions, and the reward function.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Sample Rollout via Forward Simulation</head><p>While it is possible to perform high-fidelity simulation for rolling out sampled policy assignments, a lower-fidelity simulation can capture the necessary interactions between vehicles to make reasonable choices for our vehicle behavior, while providing faster performance. In practice, we use a simplified simulation model for each vehicle that assumes an idealized steering controller. Nonetheless, this simplification still faithfully describes the high-level behavior of the between-vehicle interactions our method reasons about. For vehicles classified as anomalous, we simulate them using a single policy accounting only for their current state and map of the environment, since they are not likely to be modeled by the set of behaviors in our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Reward Function</head><p>The reward function for evaluating the outcome of a rollout Ψ involving all vehicles is a weighted combination of metrics m q (•) ∈ M, with weights w q that express user importance. The construction of a reward function based on a flexible set of metrics derives from our previous work <ref type="bibr" target="#b10">[11]</ref>, which we extend here to handle multiple potential policies for other vehicles. In our system, typical metrics include the distance to the goal at the end of the evaluation horizon as a measure of accomplishment, minimum distance to obstacles to evaluate safety, a lane choice bias to add a preference for the right lane, and the maximum yaw rate and longitudinal jerk to measure passenger comfort. For a full policy assignment (π, s) with rollout Ψ π,s , we compute the rollout reward r π,s as the weighted sum r π,s = |M| q=1 w q m q (Ψ π,s ). We normalize each m q (Ψ π,s ) across all rollouts to ensure comparability between metrics. To avoid biasing decisions, we set the weight w q to zero when the range of m q (•) across all samples is too small to be informative.</p><p>We finally evaluate each policy reward r π for our vehicle as the expected reward over all rollout rewards r π,s , computed as</p><formula xml:id="formula_21">r π = |S| k=1 r π,s k p(s k ), where p(s k )</formula><p>is the joint probability of the policy assignments in sample s k , computed as a product of the per-vehicle assignment probabilities (Eq. 16). We use expected reward to target better average-case performance, as it is easy to become overly conservative when negotiating traffic if one only accounts for worst-case behavior. By weighting by the probability of each sample, we can avoid overcorrecting for low-probability events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RESULTS</head><p>To evaluate our behavioral anticipation method and our multipolicy sampling strategy, we use traffic-tracking data collected using our autonomous vehicle platform. We first introduce the traffic-tracking dataset and the vehicle used to collect it. Next, we use this dataset to evaluate our prediction and anomaly detection method and the performance of our multipolicy sampling strategy. Finally, we evaluate our multipolicy approach performing integrated behavioral analysis and decision-making on highway traffic scenarios using our multivehicle simulation engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Autonomous Vehicle Platform, Dataset, and Setup</head><p>To collect the traffic-tracking dataset we use in this work, we have used our autonomous vehicle platform (shown in <ref type="figure" target="#fig_1">Fig. 3)</ref>, a 2013 Ford Fusion equipped with a sensor suite including four Velodyne HDL-32E 3D LIDAR scanners, an Applanix POS-LV 420 inertial navigation system (INS), GPS, and several other sensors. The vehicle uses prior maps of the area it operates on that capture information about the environment such as LIDAR reflectivity and road height, and are used for localization and tracking of other agents. The road network is encoded as a metric-topological map that provides information about the location and connectivity of road segments, and lanes therein.</p><p>Estimates over the states of other traffic participants are provided by a dynamic object tracker running on the vehicle, which uses LIDAR range measurements. The geometry and location of static obstacles are also inferred onboard using LIDAR measurements.</p><p>The traffic-tracking dataset consists of 67 dynamic object trajectories recorded in an urban area. Of these 67 trajectories (shown in <ref type="figure" target="#fig_2">Fig. 4</ref>), 18 correspond to "follow the lane" maneuvers and 20 to lane change maneuvers, recorded on a divided highway. The remaining 29 trajectories correspond to maneuvers observed at a four-way intersection regulated by stop signs. All trajectories were recorded by the dynamic object tracker onboard the vehicle and extracted from approximately 3.5 h of total tracking data.</p><p>In all experiments we use a C implementation of our system running on a single 2.8GHz Intel i7 laptop computer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Behavioral Prediction</head><p>For our system, we are interested in correctly identifying the behavior of target vehicles by associating it to the most likely policy according to the observations. Thus, we evaluate </p><p>where the first subset applies to in-lane maneuvers and the second subset applies to intersection maneuvers. For all policies we use a fixed set of parameters tuned empirically to control our autonomous vehicle platform, including maximum longitudinal and lateral accelerations, and allowed distances to nearby cars, among other parameters.</p><p>To assess each classification as correct or incorrect, we leverage the road network map and compare the final lane where the trajectory actually ends to that predicted by the declared policy. In addition, we assess behavioral prediction performance on subsequences of incremental duration of the input trajectory, measuring classification performance on increasingly longer observation sequences. <ref type="figure" target="#fig_3">Fig. 5</ref> shows the accuracy and precision curves for policy classification over the entire dataset. The ambiguity among hypotheses results in poor performance when only an early stage of the trajectories is used, especially under 30% completion. However, we are able to classify the trajectories with over 85% accuracy and precision after only 50% of the trajectory has been completed. Note, however, that the closed-loop nature of our policies allows us to maintain safety at all times regardless of anticipation performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Anomaly Detection</head><p>We now qualitatively explore the performance of our anomaly detection test. We recorded three additional trajectories corresponding to two bikes and a bus. The bikes crossed the intersection from the sidewalk, while the bus made a significantly wide turn. We run the test on these trajectories and on three additional intersection trajectories using the minimum normality value on the intersection portion of the dataset, γ = 0.1233. As shown by the results in <ref type="figure" target="#fig_4">Fig. 6</ref>, our test is able to correctly detect the anomalous behaviors not modeled in our system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Multipolicy Sampling Performance</head><p>To show that our approach makes decision-making tractable, we assess the sampling performance in terms of the likelihood of the samples using the recorded intersection trajectories. We compare our multipolicy sampling strategy to an uninformed sampling strategy such as those used by general decisionmaking algorithms that do not account for domain knowledge to focus sampling (e.g., Silver and Veness <ref type="bibr" target="#b34">[35]</ref>, Thrun <ref type="bibr" target="#b36">[37]</ref>).</p><p>We take groups of coupled trajectories from the dataset involving from one to four vehicles negotiating the intersection simultaneously. For each vehicle in each group, we compute, via Eq. 15, the likelihood of the most likely policy π ML in {turn-right, turn-left, go-straight, yield} according to the corresponding trajectory in the group. We then evaluate the computation time required by each of the two sampling strategies to find a sampled trajectory with a likelihood equal or greater than L(π ML ).</p><p>The uninformed strategy generates, for each vehicle involved, a trajectory that either remains static for the duration of the trajectory to yield or crosses the intersection at constant speed. This decision is made at random. If the decision is to cross, the direction of the vehicle is determined via random steering wheel angle rates in a simple car kinematic model. Conversely, the multipolicy sampling strategy consists of randomly selecting policies for each vehicle and obtaining their rollouts. The computation times for each strategy are shown in <ref type="table" target="#tab_1">Table I</ref>. Times are computed out of 100 simulations for each case (from one to four cars). Although the time required grows dramatically fast for both strategies due to the combinatorial explosion of vehicle intentions, these results show that our multipolicy sampling strategy is able to find high-likelihood samples orders of magnitude faster than an uninformed sampling strategy. A visualization of a sample simulation of this experiment is shown in <ref type="figure">Fig. 1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Decision-Making Results</head><p>We tested the full decision-making algorithm with behavioral prediction in a simulated environment with a multi-lane highway scenario involving two nearby cars. <ref type="figure" target="#fig_5">Fig. 7(a)</ref> shows the scenario used for testing at an illustrative point at half way through the scenario. This simulation uses the same policy models we have developed and tested on our real-world test car <ref type="bibr" target="#b10">[11]</ref>. <ref type="figure" target="#fig_5">Fig. 7(b)</ref> shows the policy reward function, in which the chosen policy is the maximum of the available policies. Note that this decision process is instantaneous, which explains the oscillations when policies are near decision surfaces. We prevent the executed policy from oscillating with a simple pre-emption model that ensures we only switch policies when distinct maneuvers (such as lane-changes) are complete.</p><p>We collected timing information on different operations in the experiment to evaluate runtime performance. The main expense is forward simulation and metric evaluation for each rollout, however, these tasks are easily parallelizable. In the test scenario in which we rollout all sample permutations, the theoretical maximum number of rollouts is 27 given 3 policy options per vehicle, but in practice the maximum number of rollouts was 12, with a mean of 8.6. This smaller number of rollouts is because not all policies are applicable at once. Parallel evaluation performance is bounded by the maximum time for a single rollout, for which the mean worst time was 84ms, and the worst time over the whole experiment was 106ms. Even in the worst case, our real-time decision-making target of 1 Hz is acheiveable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>We introduced a principled framework for integrated behavioral anticipation and decision-making in environments with extensively coupled interactions between agents. By explicitly modeling reasonable behaviors of both our vehicle and other vehicles as policies, we make informed high-level behavioral decisions that account for the consequences of our actions.</p><p>We presented a behavior analysis and anticipation system based on Bayesian changepoint detection that infers the likelihood of policies of other vehicles. Furthermore, we provided a normality test to detect unexpected behavior of other traffic participants. We have shown that our behavioral anticipation approach can identify the most-likely underlying policies that explain the observed behavior of other cars, and to detect anomalous behavior not modeled by the policies in our system.</p><p>In future work we will explicitly model unexpected behavior, such as the appearance of a pedestrian or vehicles occluded by large objects. We can also extend the system to scale to larger environments by strategically sampling policies to focus on those outcomes that most affect our choices. Exploring principled methods for reacting to detected anomalous behavior is also an avenue for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4 foreach 6 Ψ</head><label>46</label><figDesc>s ∈ S do // Policies for other cars 5 if APPLICABLE(π, x 0 ) then π,s ← SIMULATEFORWARD(x 0 , π, s, H) // Ψ π,s captures all vehicles 7 R ← R ∪ {(π, s, COMPUTEREWARD(Ψ π,s ))} 8 return π * ← SELECTBEST(R) A. Policy Design There are many possible design choices for engineering the set of available policies in our approach, which we wish to explore in future work. However, in this work we use a set of policies that covers many in-lane and intersection driving situations, comprising the following policies: lane-nominal, drive in the current lane and maintain distance to the car directly in front; lane-change-right/lane-change-left, separate policies for a single lane change in each direction; and turnright, turn-left, go-straight, or yield at an intersection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Our autonomous car platform, used to record the traffic-tracking dataset we use in this work. The vehicle is equipped with a sensor suite including four LIDAR units and survey-grade INS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Trajectories in the traffic-tracking dataset used to evaluate our multipolicy framework. (a) 29 trajectories recorded at a four-way intersection. (b) 38 trajectories comprising lane change and "follow the lane" maneuvers on a divided highway, plotted on a common frame of reference. our behavioral analysis method in the context of a classification problem, where we want to map each trajectory to the underlying policy (class) that is generating it at the current timestep. The available policies used in this evaluation are: Π = {lane-nominal, lane-change-left, lane-change-right} ∪ {turn-right, turn-left, go-straight, yield},</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Precision and accuracy curves of current policy identification via changepoint detection, evaluated at increasing subsequences of the trajectories. Our method provides over 85% accuracy and precision after only 50% of trajectory completion, while the closed loop nature of our policies guarantee safety at all times regardless of anticipation performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Anomaly detection examples. Top row: normal trajectories driven by cars from the intersection dataset. Bottom row: anomalous trajectories driven by bikes (d), (e), and a bus (f). Our test is able to correctly detect the anomalous trajectories not modeled by our intersection policies (γ = 0.1233).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>(a) Results of a simulated multi-car interaction scenario, in which the car under our control (shown in green) approaches the slower vehicles A and B from behind. Vehicle B starts by executing a lane change from the center to left lane, which it is just completing at the time shown, while A remains in the right lane. Cyan lines show the simulated rollouts for our vehicle, while magenta lines show the simulated rollouts for each of the other vehicles. (b) Evaluation of the policy reward functions for each of the three policies over the course of the simulated scenario. Note that not all policies are applicable at all times, which we render as a discontinuity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Policy selection procedure. Draw a set of samples s ∈ S via Eq. 16, where each sample assigns a policy to each nearby vehicle. 2 R ← ∅ // Rewards for each rollout 3 foreach π ∈ Π do // Policies for our car</figDesc><table /><note>Input:• Current MAP estimate of the state, x 0 .• Set of available policies Π.• Policy assignment probabilities (Eq. 16).• Planning horizon H.1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I COMPARISON</head><label>I</label><figDesc>OF SAMPLING STRATEGIES.</figDesc><table><row><cell>STRATEGY</cell><cell>NUM. CARS</cell><cell>AVG. COMP. TIME</cell><cell>STD. DEVIATION</cell></row><row><cell>Uninformed Multipolicy</cell><cell>1</cell><cell>15.3990 s 0.0012 s</cell><cell>9.1014 s 0.0004 s</cell></row><row><cell>Uninformed Multipolicy</cell><cell>2</cell><cell>39.6037 s 0.0036 s</cell><cell>24.4575 s 0.0014 s</cell></row><row><cell>Uninformed Multipolicy</cell><cell>3</cell><cell>99.5785 s 0.0100 s</cell><cell>76.3222 s 0.0050 s</cell></row><row><cell>Uninformed Multipolicy</cell><cell>4</cell><cell>296.9633 s 0.0247 s</cell><cell>232.5125 s 0.0142 s</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t , a v t , π v t ) = p(a v t |x t , z v t , π v t )p(π v t |x t , z 0:t ),(5)where p(π v t |x t , z 0:t ) is the probability that vehicle v is executing the policy π v t (we describe how we infer this probability in §IV). Thus, the per-vehicle joint density from Eq. 3 can now be approximated in terms of π v t :p v (x v t , x v t+1 , z v t , a v t , π v t ) = p(x v t+1 |x v t , a v t )p(z v t |x v t ) p(a v t |x v t , z v t , π v t )p(π v t |x t , z 0:t )p(x v t ). (6)Finally, since we have full authority over the policy executed by our controlled car q ∈ V , we can separate our vehicle from the other agents in p(x t+1 ) as follows:p(x t+1 ) ≈ X q Z q p q (x q t , x q t+1 , z q t , a q t , π q t ) dz q t dx q t v∈V |v =q   Π X v Z v p v (x v t , x v t+1 , z v t , a v t , π v t ) dz v t dx v t   . (7)We have thus far factored out the action space from p(x t+1 ) by assuming actions are given by the available policies. However, Eq. 7 still requires integration over the state and observation spaces. Our second approximation addresses this issue. Given samples from p(π v t |x t , z 0:t ) that assign a policy to each vehicle, we simulate forward in time the interactions of our vehicle and other vehicles under their assigned policies, and obtain a corresponding sequence of future states and observations. We are thereby able to evaluate the reward function over the entire decision horizon.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by a grant from Ford Motor Company via the Ford-UM Alliance under award N015392 and in part by DARPA under award D13AP00059.</p><p>The authors are sincerely grateful to Patrick Carmody for his help in collecting the traffic-tracking data used in this work and to Ryan Wolcott for his helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Probabilistically safe motion planning to avoid dynamic obstacles with uncertain motion patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Aoude</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Luders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>How</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Auton. Robot</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="76" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Integrated perception and planning in the continuous space: A POMDP approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Robot. Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1288" to="1302" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Intention-aware motion planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frazzoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Work. Alg. Foundation of Robotics</title>
		<editor>E. Frazzoli, T. Lozano-Perez, N. Roy, and D. Rus</editor>
		<meeting>Int. Work. Alg. Foundation of Robotics</meeting>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="475" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning. Information Science and Statistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Solving continuous pomdps: Value iteration with incremental learning of an efficient space representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brechtel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gindele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dillmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Machine Learning</title>
		<editor>S. Dasgupta and D. Mcallester</editor>
		<meeting>Int. Conf. Machine Learning<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-05" />
			<biblScope unit="page" from="370" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic decision-making under uncertainty for autonomous driving using continuous POMDPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brechtel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gindele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dillmann</surname></persName>
		</author>
		<idno type="DOI">10.1109/ITSC.2014.6957722</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Intell. Transp. Syst</title>
		<meeting>IEEE Int. Conf. Intell. Transp. Syst<address><addrLine>Qingdao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="392" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Monte carlo road safety reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Broadhurst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intell. Veh. Symp</title>
		<meeting>IEEE Intell. Veh. Symp<address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="319" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploiting domain knowledge in planning for uncertain robot systems modeled as pomdps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Candido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hutchinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. and Automation</title>
		<meeting>IEEE Int. Conf. Robot. and Automation<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="page" from="3596" to="3603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Anomaly detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analytic collision anticipation technology considering agents&apos; future behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Eoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots and Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots and Syst<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="1656" to="1661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MPDM: Multipolicy decision-making in dynamic, uncertain environments for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Galceran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Eustice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. and Automation</title>
		<meeting>IEEE Int. Conf. Robot. and Automation<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Darpa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Darpa Urban Challenge</surname></persName>
		</author>
		<ptr target="http://archive.darpa.mil/grandchallenge/" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robotic motion planning in dynamic, cluttered, uncertain environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Du</forename><surname>Toit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Burdick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. and Automation</title>
		<meeting>IEEE Int. Conf. Robot. and Automation<address><addrLine>Anchorage, AK, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="page" from="966" to="973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robot motion planning in dynamic, uncertain environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Du Toit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Burdick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On-line inference for multiple changepoint problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fearnhead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="589" to="605" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Detection, prediction, and avoidance of dynamic obstacles in urban environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Darms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Urmson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kolski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intell. Veh. Symp</title>
		<meeting>IEEE Intell. Veh. Symp<address><addrLine>Eindhoven, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="1149" to="1154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Motion planning in urban environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Likhachev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Field Robot</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="939" to="960" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic navigation in dynamic environment using rapidly-exploring random trees and gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fulgenzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Spalanzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Laugier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots and Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots and Syst<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09" />
			<biblScope unit="page" from="1056" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A probabilistic model for estimating driver behaviors and vehicle trajectories in traffic environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gindele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brechtel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dillmann</surname></persName>
		</author>
		<idno type="DOI">10.1109/ITSC.2010.5625262</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Intell. Transp. Syst</title>
		<meeting>IEEE Int. Conf. Intell. Transp. Syst<address><addrLine>Madeira Island, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09" />
			<biblScope unit="page" from="1625" to="1631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning context sensitive behavior models from observations for predicting traffic situations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gindele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brechtel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dillmann</surname></persName>
		</author>
		<idno type="DOI">10.1109/ITSC.2013.6728484</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Intell. Transp. Syst</title>
		<meeting>IEEE Int. Conf. Intell. Transp. Syst<address><addrLine>The Hague</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1764" to="1771" />
		</imprint>
	</monogr>
	<note>The Netherlands</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Contingency planning over probabilistic obstacle predictions for autonomous road vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="913" to="929" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discrete and continuous, probabilistic anticipation for autonomous robots in urban environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Havlak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robot</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="461" to="474" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient planning under uncertainty with macro-actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brunskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="523" to="570" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Bayesian nonparametric approach to modeling motion patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Auton. Robot</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="383" to="400" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gaussian process regression flow for analysis of motion trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis</title>
		<meeting>IEEE Int. Conf. Comput. Vis<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-11" />
			<biblScope unit="page" from="1164" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kurniawati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Robot.: Sci. &amp; Syst. Conf</title>
		<meeting>Robot.: Sci. &amp; Syst. Conf<address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the undecidability of probabilistic planning and related stochastic optimization problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Madani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hanks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Condon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="5" to="34" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Team Cornell&apos;s Skynet: Robust perception and planning in an urban environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Field Robot</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="493" to="527" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The Stanford entry in the Urban Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Montemerlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Field Robot</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="569" to="597" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">CHAMP: Changepoint detection using approximate model parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Niekum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osentoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Atkeson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<idno>CMU-RI-TR- 14-10</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>Robotics Institute, Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Collision avoidance method for mobile robot considering motion and personal spaces of evacuees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ohki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nagatani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots and Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots and Syst<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="1819" to="1824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The complexity of Markov decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="441" to="450" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Safe motion planning in dynamic environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fraichard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots and Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots and Syst<address><addrLine>Edmonton, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-08" />
			<biblScope unit="page" from="2210" to="2215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On-line trajectory clustering for anomalous events detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Piciarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Foresti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1835" to="1842" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Monte-carlo planning in large POMDPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 23</title>
		<editor>J. Lafferty, C. Williams, J. Shawe-Taylor, R. Zemel, and A. Culotta</editor>
		<imprint>
			<biblScope unit="page" from="2164" to="2172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">DESPOT: Online POMDP planning with regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Somani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1772" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Monte Carlo POMDPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances Neural Inform. Process. Syst. Conf</title>
		<meeting>Advances Neural Inform. ess. Syst. Conf</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1064" to="1070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Modelling of traffic situations at urban intersections with probabilistic non-parametric regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Firl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intell. Veh. Symp</title>
		<meeting>IEEE Intell. Veh. Symp<address><addrLine>Gold Coast City, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="334" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Online maneuver recognition and multimodal trajectory prediction for intersection assistance using non-parametric regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Firl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Intell. Veh. Symp</title>
		<meeting>IEEE Intell. Veh. Symp<address><addrLine>Dearborn, MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="918" to="923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unfreezing the robot: Navigation in dense, interacting crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Trautman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/RSJ Int. Conf. Intell. Robots and Syst</title>
		<meeting>IEEE/RSJ Int. Conf. Intell. Robots and Syst<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="797" to="803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Autonomous driving in urban environments: Boss and the Urban Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Urmson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Field Robot</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="425" to="466" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A real-time motion planner with trajectory optimization for autonomous vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Robot. and Automation</title>
		<meeting>IEEE Int. Conf. Robot. and Automation<address><addrLine>Saint Paul, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-05" />
			<biblScope unit="page" from="2061" to="2067" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
