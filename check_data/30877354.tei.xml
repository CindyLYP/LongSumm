<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systematic Testing of Convolutional Neural Networks for Autonomous Driving</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Dreossi</surname></persName>
							<email>&lt;dreossi@berkeley.edu&gt;</email>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shromona</forename><surname>Ghosh</surname></persName>
							<email>&lt;shromona.ghosh@berkeley.edu&gt;.</email>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Sangiovanni-Vincentelli</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjit</forename><forename type="middle">A</forename><surname>Seshia</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Bichen, Iandola, Forrest</roleName><forename type="first">Jin</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Squeezedet</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Shromona Ghosh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Systematic Testing of Convolutional Neural Networks for Autonomous Driving</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>We present a framework to systematically analyze convolutional neural networks (CNNs) used in classification of cars in autonomous vehicles. Our analysis procedure comprises an image generator that produces synthetic pictures by sampling in a lower dimension image modification subspace and a suite of visualization tools. The image generator produces images which can be used to test the CNN and hence expose its vulnerabilities. The presented framework can be used to extract insights of the CNN classifier, compare across classification models, or generate training and validation datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Convolutional neural networks (CNN) are powerful models that have recently achieved the state of the art in object classification and detection tasks. It is no surprise that they are used extensively in large scale Cyber-Physical Systems (CPS). For CPS used in safety critical purposes, verifying CNN models is of utmost importance <ref type="bibr" target="#b3">(Dreossi et al., 2017</ref>). An emerging domain where CNNs have found application is autonomous driving where object detectors are used to identify cars, pedestrians, or road signs <ref type="bibr" target="#b2">(Dougherty, 1995;</ref><ref type="bibr" target="#b1">Bojarski et al., 2016)</ref>.</p><p>CNNs are usually composed of extensively parallel nonlinear layers that allow the networks to learn highly nonlinear functions. While CNNs are able to achieve high accuracy for object detection, their analysis has proved to be extremely difficult. Proving their correctness, i.e., to show that a CNN always correctly detects a particular object, has become practically impossible. One approach to address this problem analyzes the robustness of CNNs with respect to perturbations. Using optimization-based techniques <ref type="bibr" target="#b14">(Szegedy et al., 2013;</ref><ref type="bibr" target="#b11">Papernot et al., 2016)</ref> or gen-Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). erative NNs <ref type="bibr" target="#b5">(Goodfellow et al., 2014)</ref>, it is possible to find minimal adversarial modifications that can cause a CNN to misclassify an altered picture. Another approach inspired by formal methods aims at formally proving the correctness of neural networks by using, e.g., Linear Programming or SMT solvers <ref type="bibr" target="#b7">(Huang et al., 2016;</ref><ref type="bibr" target="#b8">Katz et al., 2017)</ref>. Unfortunately, these verification techniques usually impose restrictions on treated CNNs and suffer from scalability issues.</p><p>In this work, we present a framework to systematically test CNNs by generating synthetic datasets. In contrast to the adversarial generation techniques, we aim at generating realistic pictures rather than introducing perturbations into preexisting ones. In this paper, we focus on self-driving applications, precisely on CNNs used for detection of cars. However, the presented techniques are general enough for application to other domains.</p><p>Our framework consists of three main modules: an image generator, a collection of sampling methods, and a suite of visualization tools. The image generator renders realistic images of road scenarios. The images are obtained by arranging basic objects (e.g., road backgrounds, cars) and by tuning image parameters (e.g., brightness, contrast, saturation). By preserving the aspect ratios of the objects, we generate more realistic images. All possible configurations of the objects and image parameters define a modification space whose elements map to a subset of the CNN feature space (in our case, road scenarios). The goal of the sampling methods is to provide modification points to the image generator that produces pictures used to extract information from the CNN. We provide different sampling techniques, depending on the user needs. In particular, we focus on samplings methods that cover the modification space evenly and active optimization-based methods to generate images that are misclassified by the analyzed CNN. Finally, the visualization tools are used to display the gathered information. Our tool can display the sampled modifications against metrics of interest such as the probability associated with the predicted bounding boxes (the box containing the car) or the intersection over union (IOU) used to measure the accuracy of the prediction box.</p><p>The contributions provided by our framework are twofold: arXiv:1708.03309v2 [cs.CV] 11 Aug 2017</p><p>• Analysis of Neural Network Classifiers. The systematic analysis is useful to obtain insights of the considered CNN classifier, such as the identification of blind spots or corner cases. Our targeted testing can also be used to compare across CNN models;</p><p>• Dataset Generator. Our picture generator can generate large data sets for which the diversity of the pictures can be controlled by the user. This overcomes a lack of training data, one of the limiting problems in training of CNNs. Also, a target synthesized dataset can be used as a benchmark for a specific domain of application.</p><p>We present a systematic methodology for finding failure cases of CNN classifiers. This is a first attempt towards verifying machine learnt components in complex systems.</p><p>The paper is organized as follows: Sec. 2 describes the analysis framework and defines the picture generator, sampling methods, and visualization tools; Sec. 3 to implementation details and experimental evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">CNN Analyzer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Overview</head><p>We begin by introducing some basic notions and by giving an overview of our CNN analysis framework.</p><p>Let f : X → Y be a CNN that assigns to every feature vector x ∈ X a label y ∈ Y , where X and Y are a feature and a label space, respectively. In our case x can be a picture of a car and y is the CNN prediction representing information such as the detected object class, the prediction confidence, or the object position.</p><p>Our analysis technique (Alg. 1) consists in a loop where at each step an image modification configuration m is sampled, an image x is generated using the modification m, and a prediction y is returned by the analyzed CNN. Intuitively, m describes the configuration of the synthetic picture x to be generated. y is then the prediction of the CNN on this generated image x. A modification m can specify, for instance, the x and y coordinates of a car in a picture as well as the brightness or contrast of the image to be generated. At each loop iteration, the information m, x, y are stored in the data structure D that is later used to inspect and visualize the CNN behavior. The loop is repeated until a condition on D is met. Some examples of halting conditions can be the discovery of a misclassified picture, a maximum number of generated images, or the achievement of coverage threshold on the modification space.</p><p>The key steps of this algorithm are the picture generation (i.e., how an image is rendered from a modification choice) and how modifications are sampled (i.e., how to chose a</p><formula xml:id="formula_0">Algorithm 1 Analyze CNN function CNNanalysis repeat m ← sample(M ) x ← generateImage(m) y ← f (x) D.add(m, x, y) until condition(D) visualize(D) end function</formula><p>modification in such a way to achieve the analysis goal). In the following, we define image modifications and show how synthetic pictures are generated (Sec. 2.2). Next, we introduce some sampling methods (Sec. 2.3), and finally some visualization tools (Sec 2.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Image Generation</head><p>LetX ⊆ X be a subset of the feature space of f : X → Y . A generation function γ : M →X is a function that maps every modification m ∈ M to a feature γ(m) ∈X.</p><p>Modification functions can be used to compactly represent a subset of the feature space. For instance, modifications of a given picture, such as displacement of a car and brightness, can be seen as the dimensions of a 2-D modification space. Low-dimensional modification spaces allow us to analyze CNNs on compact domains as opposite to intractable feature spaces. Let us clarify these concepts with the following example where a set of pictures is abstracted into a 3-D box.</p><p>Let X be the set of 1242 × 375 RBG pictures (Kitti image resolution <ref type="bibr" target="#b4">(Geiger et al., 2013)</ref>). Since we are interested in the automotive context, we consider the subsetX ⊂ X of pictures of cars in different positions on a particular background with different color contrasts. In these settings, we can define, for instance, the generation function γ that maps M = [0, 1] 3 toX, where the dimensions of M characterize the x, y positions of the car and the image contrast, respectively. For instance, γ(0, 0, 0) places the car on the left close to the observer with high contrast, γ(1, 0, 0) shifts the car to the right, or γ(1, 1, 1) sees the car on the right, far from the observer, with low contrast. <ref type="figure" target="#fig_0">Fig. 1</ref> shows some images ofX disposed accordingly to their location in the modification space M . When moving on the x-axis of M , the car shifts horizontally; a change on the y-axis affects the position of the car in depth; the z-axis affects the contrast of the picture. This simple example shows how the considered feature space can be abstracted in a 3-D modification space in which every point corresponds to a particular image.  In this examples, we chose the extreme positions of the car (i.e., maximum and minimum x and y position of the car) on the sidelines of the road and the image vanishing point. Both the sidelines and the vanishing point can be automatically detected <ref type="bibr" target="#b0">(Aly, 2008;</ref><ref type="bibr" target="#b9">Kong et al., 2009)</ref>. The vanishing point is useful to determine the vanishing lines necessary to resize and place the car when altering its position in the y modification dimension. For instance, the car is placed and shrunk towards the vanishing point as the y coordinate of its modification element gets close to 1 (see <ref type="figure" target="#fig_1">Fig. 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Sampling Methods</head><p>We now consider some methods to efficiently sample the modification space. Good sampling techniques should provide a high coverage of the abstract space and identify samples whose concretizations lead to misclassifying images.</p><p>Low-discrepancy Sequences A low-discrepancy (or quasi-random) sequence is a sequence of n-tuples that fills an n-D space more uniformly than uncorrelated random points. Low-discrepancy sequences are useful to cover boxes by reducing gaps and clustering of points.</p><p>Let U = [0, 1] n be a n-D box, J ⊆ U be a sub-box, and X ⊂ U be a set of m points. The discrepancy D(J, X) of J is the difference between the proportion of points in J compared to U and the volume of J compared to U :</p><formula xml:id="formula_1">D(J, X) = |#(J)/m − vol(J)|<label>(1)</label></formula><p>where #(J) is the number of points of X in J and vol(J) is the volume of J. The star-discrepancy D * (X) is the worst case distribution of X:</p><formula xml:id="formula_2">D * (X) = max J D(J, X)<label>(2)</label></formula><p>Low-discrepancy sequences generate sets of points that minimize the star-discrepancy. Some examples of lowdiscrepancy sequences are the Van der Corput, <ref type="bibr" target="#b6">Halton (Halton, 1960)</ref>, or Sobol <ref type="bibr" target="#b13">(Sobol, 1976)</ref> sequences. In our experiments, we used the Halton and lattice-based <ref type="bibr" target="#b10">(Niederreiter, 1988)</ref> sequences. These sampling methods ensure an optimal coverage of the abstract space and allows us to identify clusters of misclassified pictures as well as isolated corner cases otherwise difficult to spot with a uniform sampling technique.</p><p>Active Learning At every step, given a sample, we generate images which are presented as input to the neural network under test. This becomes an expensive process when the number of samples necessary for the covering the input space is large. We propose using active learning to minimize the number of images generated and only sample points which have a high probability of being a counter example.</p><p>We model the function from the sample space U = [0, 1] n to the score (output) of the CNN as a Gaussian Process (GP). GPs are a popular choice for nonparametric regression in machine learning, where the goal is to find an approximation of a nonlinear map p(u) : U → R from an input sample u ∈ U to the score produced by the neural network. The main assumption is that the values of p, associated with the different sample inputs, are random variables and have a joint Gaussian distribution. This distribution is specified by a mean function, which is assumed to be zero without loss of generality, and a covariance function k(u, u), called kernel function.</p><p>The GP framework can be used to predict the score p(u) at an arbitrary sample u ∈ U based on a set of t past observations y t = [p(u 1 ), . . . ,p(u t )] T at samples U t = {u 1 , . . . , u t } without generating the image for u. The observations of the function valuesp(u t ) = p(u t ) + w t are corrupted by Gaussian noise w t ∼ N (0, σ 2 ). Conditioned on these observations, the mean and variance of the prediction at u are given by:</p><formula xml:id="formula_3">µ t (u) = k t (u)(K t + I t σ 2 ) −1 y t σ 1 t (u) = k(u, u) − k t (u)(K t + I t σ 2 ) −1 k T t (u)<label>(3)</label></formula><p>where the vector k t (u) = [k(u, u 1 ), . . . , k(u, u t )] contains the covariances between the new input, u, and the past data points in U t , the covariance matrix, K t ∈ R t×t , has entries [K t ](i, j) = k(u i , u j ) for i, j ∈ {1, . . . , t}, and the identity matrix is denoted by I t ∈ R t×t .</p><p>Given a GP, any Bayesian optimization algorithm is designed to find the global optimum of an unknown func-  tion within few evaluations on the real system. Since we search for counterexamples, i.e, samples where the score returned by the neural network is low, we use GP-Lower Confidence Bound (GP-LCB) as our objective function. Since the optimal sample u * t is not known a priori, the optimal strategy has to balance learning about the location of the most falsifying sample (exploration), and selecting a sample that is known to lead to low scores (exploitation). We formulate the objective function as,</p><formula xml:id="formula_4">u t = argmin u∈U µ t−1 (u) − β 1/2 t σ t−1 (u)</formula><p>where β t is a constant which determines the confidence bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Visualization</head><p>We now show how the gathered information can be visualized and interpreted.</p><p>In our data analysis, we consider two factors: the confidence score and the Intersection Over Union (IOU) that is a metric used to measure the accuracy of detections. IOU is defined as the area of overlap over the area of the union of the predicted and ground-truth bounding boxes. Our visualization tool associates the center of the car of the generated images to the confidence score and IOU returned by the treated CNN. <ref type="figure" target="#fig_3">Fig. 3</ref> depicts some examples where the x and y are the center coordinates of the car, z is the IOU, and the color represents the CNN confidence score. We also offer the possibility to superimpose the experimental data on the background used to render the pictures (see <ref type="figure" target="#fig_5">Fig. 4</ref>). In this case, the IOU is represented by the dimension of the marker. This representation helps us to identify particular regions of interest on the road. In the next section, we will see how these data can be interpreted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Implementation and Evaluation</head><p>We implemented the presented framework in a tool available at https://github.com/shromonag/ FalsifyNN. The tool comes with a library composed by a dozen of road backgrounds and car models, and it interfaces to the CNNs SqueezeDet (Wu et al., 2016), Kit-  tiBox <ref type="bibr" target="#b15">(Teichmann et al., 2016)</ref>, and Yolo <ref type="bibr" target="#b12">(Redmon et al., 2016)</ref>. Both the image library and CNN interfaces can be personalized by the user.</p><p>As an illustrative case study, we considered a countryside background and a Honda Civic and we generated 1k synthetic images using our rendering techniques (Sec. 2.2) and the Halton sampling sequence (Sec. 2.3). We used the generated pictures to analyze SqueezeDet (Wu et al., 2016), a CNN for object detection for autonomous driving, and Yolo <ref type="bibr" target="#b12">(Redmon et al., 2016)</ref>, a multipurpose CNN for realtime detection. <ref type="figure" target="#fig_3">Fig. 3</ref> displays the center of the car in the generated pictures associated with the confidence score and IOU returned by both SqueezeDet and Yolo. <ref type="figure" target="#fig_5">Fig. 4</ref> superimposes the heat maps of <ref type="figure" target="#fig_3">Fig. 3</ref> on the used background.</p><p>There are several interesting insights that emerge from the graphs obtained(for this combination of background and car model). SqueezeDet has, in general, a high confidence and IOU, but has a blind spot for cars in the middle of the road on the right(see the cluster of blue points in <ref type="figure" target="#fig_3">Fig. 3(b)</ref> and 4(a)). Yolo's confidence and IOU decrease with the car distance (see <ref type="figure" target="#fig_3">Fig. 3(b)</ref>). We were able to detect a blind area in Yolo, corresponding to cars on the far left (see blue points in <ref type="figure" target="#fig_3">Fig. 3(b)</ref>).</p><p>Note how our analysis can be used to visually compare the two CNNs by graphically highlighting their differences in terms of detections, confidence scores, and IOUs. A comprehensive analysis and comparison of these CNNs should involve images generated by combinations of different cars and backgrounds. However, this experiment already shows the benefits in using the presented framework and highlights the quantity and quality of information that can be extracted from a CNN even with a simple study.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Modification space (surrounding box) and corresponding synthetic images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Car resizing and displacement using vanishing point and lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>CNN analysis showing car coordinates (x, y), IOU (z), and confidence (color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Superimposition of the analysis on road background.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The authors acknowledge Forrest Iandola and Kurt Keutzer for giving the presentation of this work at Reliable Machine Learning in the Wild -ICML 2017 Workshop.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real time detection of lane markers in urban streets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Aly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium, IV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">End to end learning for self-driving cars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariusz</forename><surname>Bojarski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Testa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Del</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dworakowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Firner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flepp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">D</forename><surname>Prasoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Urs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiakai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Zieba</surname></persName>
		</author>
		<idno>abs/1604.07316</idno>
		<ptr target="http://arxiv.org/abs/1604.07316" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A review of neural networks applied to transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dougherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="247" to="260" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Compositional falsification of cyber-physical systems with machine learning components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Dreossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Donzé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanjit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NASA Formal Methods Symposium</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="357" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Robotics Research</title>
		<imprint>
			<date type="published" when="2013" />
			<publisher>IJRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Warde</forename><forename type="middle">-</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sherjil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the efficiency of certain quasi-random sequences of points in evaluating multi-dimensional integrals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">H</forename><surname>Halton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische Mathematik</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.06940</idno>
		<title level="m">Safety verification of deep neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Reluplex: An efficient smt solver for verifying deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Julian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykel</forename><surname>Kochenderfer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01135</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Vanishing point detection for road detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">-</forename><surname>Audibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Low-discrepancy and low-sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Niederreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of number theory</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="70" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ananthram. The limitations of deep learning in adversarial settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Somesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Celik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Berkay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy (EuroS&amp;P)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="372" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Uniformly distributed sequences with an additional uniform property</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sobol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ilya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USSR Computational Mathematics and Mathematical Physics</title>
		<imprint>
			<date type="published" when="1976" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="236" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wojciech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dumitru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fergus</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6199</idno>
		<title level="m">Rob. Intriguing properties of neural networks</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Multinet: Real-time joint semantic reasoning for autonomous driving. Computing Research Repository, CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Teichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zöllner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<idno>abs/1612.07695</idno>
		<ptr target="http://arxiv.org/abs/1612.07695" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
