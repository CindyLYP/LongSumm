<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THE MARKOV CHAIN MONTE CARLO REVOLUTION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Persi</forename><surname>Diaconis</surname></persName>
						</author>
						<title level="a" type="main">THE MARKOV CHAIN MONTE CARLO REVOLUTION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Received by the editors August 5, 2008.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Mathematics Subject Classification. Primary 60J20</keywords>
			</textClass>
			<abstract>
				<p>The use of simulation for high-dimensional intractable computations has revolutionized applied mathematics. Designing, improving and understanding the new tools leads to (and leans on) fascinating mathematics, from representation theory through micro-local analysis.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Many basic scientific problems are now routinely solved by simulation: a fancy random walk is performed on the system of interest. Averages computed from the walk give useful answers to formerly intractable problems. Here is an example drawn from course work of Stanford students Marc Coram and Phil Beineke.</p><p>Example 1 (Cryptography). Stanford's Statistics Department has a drop-in consulting service. One day, a psychologist from the state prison system showed up with a collection of coded messages. <ref type="figure" target="#fig_0">Figure 1</ref> shows part of a typical example. The problem was to decode these messages. Marc guessed that the code was a simple substitution cipher, each symbol standing for a letter, number, punctuation mark or space. Thus, there is an unknown function f f : {code space} −→ {usual alphabet}.</p><p>One standard approach to decrypting is to use the statistics of written English to guess at probable choices for f , try these out, and see if the decrypted messages make sense.</p><p>To get the statistics, Marc downloaded a standard text (e.g., <ref type="bibr">War and Peace)</ref> and recorded the first-order transitions: the proportion of consecutive text symbols from x to y. This gives a matrix M (x, y) of transitions. One may then associate a plausibility to f via</p><formula xml:id="formula_0">Pl(f ) = i M (f (s i ), f(s i+1 )) ,</formula><p>where s i runs over consecutive symbols in the coded message. Functions f which have high values of Pl(f ) are good candidates for decryption. Maximizing f 's were searched for by running the following Markov chain Monte Carlo algorithm:</p><p>• Start with a preliminary guess, say f .</p><p>• Compute Pl(f ).</p><p>• Change to f * by making a random transposition of the values f assigns to two symbols. • Compute Pl(f * ); if this is larger than Pl(f ), accept f * .</p><p>• If not, flip a Pl(f * )/Pl(f ) coin; if it comes up heads, accept f * .</p><p>• If the coin toss comes up tails, stay at f . The algorithm continues, trying to improve the current f by making random transpositions. The coin tosses allow it to go to less plausible f 's, and keep it from getting stuck in local maxima.</p><p>Of course, the space of f 's is huge <ref type="bibr">(40! or so)</ref>. Why should this Metropolis random walk succeed? To investigate this, Marc tried the algorithm out on a problem to which he knew the answer. <ref type="figure" target="#fig_2">Figure 2</ref> shows a well-known section of Shakespeare's Hamlet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2:</head><p>The text was scrambled at random and the Monte Carlo algorithm was run. <ref type="figure">Figure 3</ref> shows sample output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3:</head><p>After 100 steps, the message is a mess. After two thousand steps, the decrypted message makes sense. It stays essentially the same as further steps are tried. I find it remarkable that a few thousand steps of this simple optimization procedure work so well. Over the past few years, friends in math and computer science courses have designed homework problems around this example <ref type="bibr" target="#b17">[17]</ref>. Students are usually able to successfully decrypt messages from fairly short texts; in the prison example, about a page of code was available.</p><p>The algorithm was run on the prison text. A portion of the final result is shown in <ref type="figure" target="#fig_1">Figure 4</ref>. It gives a useful decoding that seemed to work on additional texts. I like this example because a) it is real, b) there is no question the algorithm found the correct answer, and c) the procedure works despite the implausible underlying assumptions. In fact, the message is in a mix of English, Spanish and prison jargon. The plausibility measure is based on first-order transitions only. A preliminary attempt with single-letter frequencies failed. To be honest, several practical details have been omitted: we allowed an unspecified "?" symbol in the deviation (with transitions to and from "?" being initially uniform). The display in <ref type="figure" target="#fig_1">Figure 4</ref> was "cleaned up" by a bit of human tinkering. I must also add that the algorithm described has a perfectly natural derivation as Bayesian statistics. The decoding function f is a parameter in a model specifying the message as the output of a Markov chain with known transition matrix M (x, y). With a uniform prior on f , the plausibility function is proportional to the posterior distribution. The algorithm is finding the mode of the posterior.</p><p>In Section 2, I explain Markov chains and the Metropolis algorithm more carefully. A closely related Markov chain on permutations is analyzed in Section 3. The arguments use symmetric function theory, a bridge between combinatorics and representation theory.</p><p>A very different example -hard discs in a box -is introduced in Section 4. The tools needed for study are drawn from analysis, micro-local techniques (Section 5) along with functional inequalities (Nash and Sobolev inequalities).</p><p>Throughout, emphasis is on analysis of iterates of self-adjoint operators using the spectrum. There are many other techniques used in modern probability. A brief overview, together with pointers on how a beginner can learn more, is in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="182">PERSI DIACONIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A brief treatise on Markov chains</head><p>2.1. A finite case. Let X be a finite set. A Markov chain is defined by a matrix K(x, y) with K(x, y) ≥ 0, y K(x, y) = 1 for each x. Thus each row is a probability measure so K can direct a kind of random walk: from x, choose y with probability K(x, y); from y choose z with probability K(y, z), and so on. We refer to the outcomes X 0 = x, X 1 = y, X 2 = z, . . . , as a run of the chain starting at x. From the definitions P (X 1 = y|X 0 = x) = K(x, y), P (X 1 = y, X 2 = z|X 0 = x) = K(x, y)K(y, z). From this,</p><formula xml:id="formula_1">P (X 2 = z|X 0 = x) = y K(x, y)K(y, z),</formula><p>and so on. The nth power of the matrix has x, y entry P (X n = y|X 0 = x).</p><p>All of the Markov chains considered in this article have stationary distributions</p><formula xml:id="formula_2">π(x) &gt; 0, x π(x) = 1 with π satisfying (2.1) x π(x)K(x, y) = π(y).</formula><p>Thus π is a left eigenvector of K with eigenvalue 1. The probabilistic interpretation of (2.1) is "pick x from π and take a step from K(x, y); the chance of being at y is π(y)." Thus π is stationary for the evolution. The fundamental theorem of Markov chains (a simple corollary of the Peron-Frobenius theorem) says, under a simple connectedness condition, π is unique and high powers of K converge to the rank one matrix with all rows equal to π.</p><p>Theorem 1 (Fundamental theorem of Markov chains). Let X be a finite set and K(x, y) a Markov chain indexed by X . If there is n 0 so that K n (x, y) ≥ 0 for all n &gt; n 0 , then K has a unique stationary distribution π and, as n → ∞,</p><formula xml:id="formula_3">K n (x, y) → π(y) for each x, y ∈ X .</formula><p>The probabilistic content of the theorem is that from any starting state x, the nth step of a run of the Markov chain has a chance close to π(y) of being at y if n is large. In computational settings, |X | is large, it is easy to move from x to y according to K(x, y), and it is hard to sample from π directly.</p><p>Consider the cryptography example in the Introduction. There, X is the set of all one-to-one functions f from code space to the usual alphabet {A, B, . . . , Z, 1, 2, . . . , 9, 0, * , ., ?, . . . }. Assume there are m distinct code symbols and n symbols in the alphabet space. The stationary distribution is</p><formula xml:id="formula_4">(2.2) π(f ) = z −1 i M (f (s i ), f(s i+1 )) ,</formula><p>where M is the (assumed given) first-order transition matrix of English and the product ranges over consecutive coded symbols in the fixed message. The normalizing constant z is defined by</p><formula xml:id="formula_5">z = f i (M (f (s i ), f(s i+1 ))) .</formula><p>Note that z is unknowable practically.</p><p>The problem considered here is to sample f 's repeatedly from π(f ). This seems daunting because of the huge size of X and the problem of unknown z. The Metropolis Markov chain K(f, f * ) solves this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2.</head><p>Metropolis algorithm. Let X be a finite state space and π(x) a probability on X (perhaps specified only up to an unknown normalizing constant). Let J(x, y) be a Markov matrix on X with J(x, y) &gt; 0 ↔ J(y, x) &gt; 0. At the start, J is unrelated to π. The Metropolis algorithm changes J to a new Markov matrix K(x, y) with stationary distribution π. It is given by a simple recipe:</p><formula xml:id="formula_6">(2.3) K(x, y) = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ J(x, y) i f x = y, A(x, y) ≥ 1, J(x, y)A(x, y) i f x = y, A(x, y) &lt; 1, J(x, y) + z:A(x,z)&lt;1 J(x, z)(1 − A(x, z)) if x = y.</formula><p>In <ref type="formula">(2</ref>3), the acceptance ratio is A(x, y) = π(y)J(y, x)/π(x)J(x, y). The formula (2.3) has a simple interpretation: from x, choose y with probability J(x, y); if A(x, y) ≥ 1, move to y; if A(x, y) &lt; 1, flip a coin with this success probability and move to y if success occurs; in other cases, stay at x. Note that the normalizing constant for π cancels out in all calculations. The new chain satisfies</p><formula xml:id="formula_7">π(x)K(x, y) = π(y)K(y, x),</formula><p>and thus</p><formula xml:id="formula_8">x π(x)K(x, y) = x π(y)K(y, x) = π(y) x K(y, x) = π(y),</formula><p>so that π is a left eigenvector with eigenvalue 1. If the chain (2.3) is connected, Theorem 1 is in force. After many steps of the chain, the chance of being at y is approximately π(y), no matter what the starting state X . Textbook treatments of the Metropolis algorithm are in <ref type="bibr" target="#b44">[44]</ref> or <ref type="bibr" target="#b64">[62]</ref>. A literature review can be found in <ref type="bibr" target="#b31">[31]</ref>.</p><p>In the cryptography example X is all one-to-one functions from symbol space (say of size m) to alphabet space (say of size n ≥ m). Thus</p><formula xml:id="formula_9">|X | = n(n−1) • • • (n−m+1)</formula><p>. This is large if, e.g., m = n = 50. The stationary distribution is given in (2.2). The proposal chain J(f, f * ) is specified by a random switch of two symbols,</p><formula xml:id="formula_10">J(f, f * ) = 1 n(n−1)(m−n+2)(m−n+1)</formula><p>if f, f * differ in at most two places, 0 o t h e r w i s e .</p><formula xml:id="formula_11">Note that J(f, f * ) = J(f * , f), so A(f, f * ) = π(f * )/π(f ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Convergence.</head><p>A basic problem of Markov chain theory concerns the rate of convergence in K n (x, y) → π(y). How long must the chain be run to be suitably close to π? It is customary to measure distances between two probabilities by total variation distance:</p><formula xml:id="formula_12">K n x − π TV = 1 y |K n (x, y) − π(y)| = max A⊆X |K n (x, A) − π(A)|.</formula><p>This yields the math problem: Given K, π, x and &gt; 0, how large n so K n x − π TV &lt; ? Sadly, there are very few practical problems where this question can be answered. In particular, no useful answer in known for the cryptography problem. In Section 3, a surrogate problem is set up and solved. It suggests that when n . = m, order n log n steps suffice for mixing.</p><p>License or copyright restrictions may apply to redistribution; see https://www.ams.org/journal-terms-of-use</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PERSI DIACONIS</head><p>Suppose, as is the case for the examples in this paper, that the Markov chain is reversible:</p><formula xml:id="formula_13">π(x)K(x, y) = π(y)K(y, x). Let L 2 (π) be {g : X → R} with inner product g, h = x g(x)h(x)π(x). Then K operates on L 2 by Kg(x) = g(y)K(x, y).</formula><p>Reversibility implies Kg, h = g, Kh , so K is self-adjoint. Now, the spectral theorem says there is an orthonormal basis of eigenvectors ψ i and eigenvalues β i (so</p><formula xml:id="formula_14">Kψ i = β i ψ i ) for 0 ≤ i ≤ |X | − 1 and 1 = β 0 ≥ β 1 ≥ • • • ≥ β |X |−1 ≥ −1. By elementary manipulations, K(x, y) = π(y) |X |−1 i=0 β i ψ i (x)ψ i (y), K n (x, y) = π(y) |X |−1 i=0 β n i ψ i (x)ψ i (y).</formula><p>Using the Cauchy-Schwartz inequality, we have</p><formula xml:id="formula_15">(2.4) 4 K n x − π 2 TV ≤ y (K n (x, y) − π(y)) 2 π(y) = |X |−1 i=1 β 2n i ψ 2 i (x).</formula><p>The bound (2.4) is the basic eigenvalue bound used to get rates of convergence for the examples presented here. To get sharp bounds on the right hand side requires good control of both eigenvalues and eigenvectors. For more detail and many examples, see <ref type="bibr" target="#b82">[79]</ref>. A detailed example on the permutation group is given in Section 3 below. Examples on countable and continuous spaces are given in Section 5.</p><p>2.4. General state spaces. Markov chains are used to do similar calculations on Euclidean and infinite-dimensional spaces. My favorite introduction to Markov chains is the book by Bremaud <ref type="bibr" target="#b10">[10]</ref>, but there are many sources: For finite state spaces see <ref type="bibr" target="#b86">[83]</ref>. For a more general discussion, see <ref type="bibr" target="#b6">[7]</ref> and the references in Section 6.1. Briefly, if (X , B) is a measurable space, a Markov kernel K(x, dy) is a probability measure K(x, •) for each x. Iterates of the kernel are given by, e.g.,</p><formula xml:id="formula_16">K 2 (x, A) = K(z, A)K(x, dz).</formula><p>A stationary distribution is a probability π(dx) satisfying</p><formula xml:id="formula_17">π(A) = K(x, A)π(dx)</formula><p>under simple conditions K n (x, A) → π(A) and exactly the same problems arise.</p><p>Reversible Markov chains yield bounded self-adjoint operators and spectral techniques can again be tried. Examples are in Section 4, Section 5, and Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">From cryptography to symmetric function theory</head><p>This section answers the question, "What does a theorem in this subject look like?" It also illustrates how even seemingly simple problems can call on tools from disparate fields, in this case, symmetric function theory, a blend of combinatorics, and representation theory. This section is drawn from joint work with Phil Hanlon <ref type="bibr" target="#b21">[21]</ref>.</p><p>3.1. The problem. Let X = S n , the symmetric group on n letters. Define a probability measure on S n by</p><formula xml:id="formula_18">(3.1) π(σ) = z −1 θ d(σ,σ 0 ) for σ, σ 0 ∈ S n , 0 &lt; θ ≤ 1. In (3.1), d(σ, σ 0 )</formula><p>is a metric on the symmetric group, here taken to be d(σ, σ 0 ) = minimum number of transpositions required to bring σ to σ 0 .</p><p>This is called Cayley's distance in <ref type="bibr" target="#b20">[20]</ref> because a result of A. Cayley implies that d(σ, σ 0 ) = n − c(σ −1 σ 0 ) with c(σ) the number of cycles in σ. The metric is biinvariant:</p><formula xml:id="formula_19">d(σ, σ 0 ) = d(τ σ, τ σ 0 ) = d(στ, σ 0 τ ).</formula><p>The normalizing constant z is known in this example:</p><formula xml:id="formula_20">z = σ θ d(σ,σ 0 ) = n i=1 (1 + θ(i − 1)).</formula><p>If θ = 1, π(σ) is the uniform distribution on S n . For θ &lt; 1, π(σ) is largest at σ 0 and falls off from its maximum as σ moves away from σ 0 . It serves as a natural non-uniform distribution on S n , peaked at a point. Further discussion of this construction (called Mallows model through Cayley's metric) with examples from psychology and computer science is in <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b28">28]</ref>. The problem studied here is How can samples be drawn from σ?</p><p>One route is to use the Metropolis algorithm, based on random transpositions. Thus, from σ, choose a transposition (i, j) uniformly at random and consider</p><formula xml:id="formula_21">(i, j)σ = σ * . If d(σ * , σ 0 ) ≤ d(σ, σ 0 ), the chain moves to σ * . If d(σ * , σ 0 ) &gt; d(σ, σ 0 )</formula><p>, flip a θ-coin. If this comes up heads, move to σ * ; else stay at σ. In symbols, (3.2)</p><formula xml:id="formula_22">K(σ, σ * ) = ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ 1/ n 2 if σ * = (i, j)σ, d(σ * , σ 0 ) &lt; d(σ, σ 0 ), θ/ n 2 if σ * = (i, j)σ, d(σ * , σ 0 ) &gt; d(σ, σ 0 ), c 1 − θ/ n 2 if σ * = σ, with c =# {(i, j) : d((i, j)σ, σ 0 ) &gt;d(σ, σ 0 )} , 0</formula><p>o t h e r w i s e .</p><p>Observe that this Markov chain is "easy to run". The Metropolis construction guarantees that</p><formula xml:id="formula_23">π(σ)K(σ, σ * ) = π(σ * )K(σ * , σ), 1 1 1 0 0 0 1 1 1 0 0 ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ . id (12) (13) (23) (123) (132)</formula><p>The stationary distribution is the left eigenvector proportional to (1, θ, θ, θ, θ 2 , θ 2 ).</p><p>This example bears a passing resemblance to the cryptography example: the set of one-to-one functions of an m-set to an n-set is replaced by the symmetric group. Presumably, the stationary distribution in the cryptography example is peaked at a point (the best decoding) and the algorithms are essentially the same.</p><p>To analyze the chain (3.2) using spectral theory requires knowledge of the eigenvalues and vectors. By what still seems like a miracle, these are available in closed form. When θ = 1, the chain (3.2) reduces to the transpose at random chain, perhaps the first Markov chain given a sharp analysis <ref type="bibr" target="#b32">[32]</ref>. Here is a typical result drawn from work with Phil Hanlon <ref type="bibr" target="#b21">[21]</ref>. </p><formula xml:id="formula_24">K k − π TV ≤ f (θ, c), with f (θ, c) → 0 for c → 0.</formula><p>Remarks. The result shows that order n log n steps suffice to make the distance to stationarity small. The function f (θ, c) is explicit but a bit of a mess. There is a matching lower bound showing that order n log n steps are necessary as well. In the theorem, σ 0 was chosen as the identity and the chain starts at σ 0 . If the chain starts far from the identity, for example at an n-cycle, it can be shown that order n 2 log n steps suffice. When, e.g., n = 52, n log n . = 200, while n 2 log n . = 11, 000. These numbers give a useful feel for the running time.</p><p>3.2. Tools from symmetric function theory. The first step of analysis is to reduce the state space from the full symmetric group to the set of conjugacy classes. (Recall these are indexed by partitions of n.) The matrix K(σ, σ * ) commutes with the action of the symmetric group by conjugation, so only transitions between conjugacy classes are needed. When n = 3, the transition matrix becomes 1 <ref type="bibr" target="#b2">3</ref> 1, 2</p><formula xml:id="formula_25">3 1 3 ⎛ ⎜ ⎝ 1 − θ θ 0 1 2 (1 − θ) 2 θ 0 1 0 ⎞ ⎟ ⎠ 1, 2 3 with stationary distribution proportional to (1, 3θ, 2θ 2 ). Let (3.3) M (µ, λ), m(λ)</formula><p>be the transition matrix and let stationary distribution be indexed by partitions λ, µ.</p><formula xml:id="formula_26">Theorem 3. For 0 &lt; θ ≤ 1, the Markov chain (3.3) has an eigenvalue β λ for each partition (λ 1 , λ 2 , . . . , λ r ) of n with β λ = (1 − θ) + θn(λ t ) + n(λ) n 2 , n(λ) = n i=1 (i − 1)λ i .</formula><p>The corresponding right eigenfunction, normed to be orthonormal in</p><formula xml:id="formula_27">L 2 (m), is (3.4) c λ (•) m(λ){j λ π/θ n n!} 1/2 .</formula><p>In (3.4), c λ are the change of basis coefficients in expressing the Jack symmetric functions in terms of the power-symmetric functions. The normalizing constant in (3.4) involves closed form, combinatorially defined terms, which will not be detailed further.</p><p>Here is an aside on the c λ (•). Classical combinatorics involves things like partitions, permutations, graphs, balls in boxes, and so on. A lot of this has been unified and extended in the subject of algebraic combinatorics. A central theme here is the ring Λ n (x 1 . . . x k ) of homogeneous symmetric polynomials of degree n. There are various bases for this space. For example, if  <ref type="bibr" target="#b85">[82]</ref>.</p><formula xml:id="formula_28">P i (x 1 . . . x k ) = x i j and P λ = P λ 1 P λ 2 • • • P λ n ,</formula><p>The Jack symmetric functions J λ (x; α) are one of the many bases. Here</p><formula xml:id="formula_29">x = (x 1 • • • x k )</formula><p>and α is a positive real parameter. When α = 1, the Jacks become the Schur functions. When α = 2, the Jacks become the zonal polynomials (spherical functions of GL n /O n ). Before the work with Hanlon, no natural use for other values of α was known. Denote the change of basis coefficients from Jacks to power sums by</p><formula xml:id="formula_30">J λ (x; α) = µ n c(λ, µ)P µ (x).</formula><p>The c(λ, µ) are rational functions of α. For example, when n = 3, <ref type="bibr" target="#b2">3</ref> 1 − 3αP 12 + 2α 2 P 3 . The algebraic combinatorics community had developed properties of Jack symmetric functions "because they were there". Using this knowledge allowed us to properly normalize the eigenfunctions and work with them to prove Theorems 1 and 2. Many more examples of this type of interplay are in <ref type="bibr" target="#b14">[14]</ref>. A textbook account of our work is in <ref type="bibr" target="#b48">[48]</ref>.</p><formula xml:id="formula_31">J 1 3 = P 3 1 − 3P 12 − 2P 3 , J 12 = P 3 1 + (α − 1)P 12 − αP 3 , J 3 = P</formula><p>There is a fascinating research problem opened up by this analysis. When θ = 1, the Jack symmetric functions are Schur functions and the change of basis coefficients are the characters of the symmetric group. The Markov chain becomes random transpositions. This was analyzed in joint work with Shahshahani <ref type="bibr" target="#b32">[32]</ref>. Adding in the deformation by the Metropolis algorithm deforms the eigenvalues and eigenvectors in a mathematically natural way. Is there a similar deformation that gets the coefficients of the Macdonald polynomials? This is ongoing joint work with Arun Ram. Changing the metric on S n , using pairwise adjacent transpositions instead of all transpositions, gives a deformation to Hecke algebras. The Metropolis algorithm gives a probabilistic interpretation of the multiplication in these algebras. This again is joint work with Ram <ref type="bibr" target="#b28">[28]</ref>. This affinity between the physically natural Metropolis algorithm and algebra is a mystery which cries out for explanation.</p><p>Turning back toward the cryptography example, how do things change if we go from the permutation group to the set of one-to-one functions from an m-set to an n-set? When θ = 1, this was worked out by Andrew Greenhalgh. The analysis involves the algebra of functions on S n which are invariant under conjugation by the subgroup S m × S n−m and bi-invariant under the subgroup S n−m . These doubly invariant functions form a commutative algebra discussed further in <ref type="bibr" target="#b14">[14,</ref><ref type="bibr">Sect. 9.8]</ref>. Do things deform well when θ = 1? It is natural to guess the answer is Yes.</p><p>It is important to end these fascinating success stories with the observation that any similarly useful analysis of the original cryptography example seems remote. Further, getting rates of convergence for the Metropolis algorithm for other metrics in (3.1) is a challenging open problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Hard discs in a box</head><p>Consider possible placements of n discs of radius in the unit square. The discs must be non-overlapping and completely contained in the unit square. Examples at low and high density (kindly provided by Werner Krauth from <ref type="bibr" target="#b57">[57]</ref>) are shown in <ref type="figure" target="#fig_4">Figure 5</ref>. In applications, n is fairly large (e.g., 100-10 ) and of course should be suitably small. The centers of the discs give a point in R 2n . We know very, very little about the topology of the set X (n, ) of configurations: for fixed n, what are useful bounds on for the space to be connected? What are the Betti numbers? Of course, for small this set is connected but very little else is known. By its embedding in R 2n , X (n, ) inherits a natural uniform distribution, Lebesgue measure restricted to X (n, ). The problem is to pick points in X (n, ) uniformly. If X 1 , X 2 , . . . , X k are chosen from the uniform distribution and f : X (n, ) → R is a function, we may approximate (4.1)</p><formula xml:id="formula_32">η = 0.48 η = 0.72</formula><formula xml:id="formula_33">X (n, ) f (x)dx by 1 k k i=1 f (X i ).</formula><p>Motivation for this task and some functions f of interest will be given at the end of this section. This hard disc problem is the original motivation for the Metropolis algorithm. Here is a version of the Metropolis algorithm for hard discs.</p><p>• Start with some x ∈ X (n, ).</p><p>• Pick a disc center at random (probability 1/n).</p><p>• Pick a point in a disc of radius h, centered at the chosen disc center at random (from Lebesgue measure). • Try to move the chosen disc center to the chosen point; if the resulting configuration is in X (n, ), accept the move; else, stay at x. The algorithm continues, randomly moving coordinates. If X 1 , X 2 , . . . , X k denotes the successive configurations, theory shows that X k becomes uniformly distributed provided , k are small. For large k, the X i can be used as in (4.1).</p><p>Motivation. The original motivation for this problem comes from the study of phase transition in statistical mechanics. For many substances (e.g., water), experiments produce phase diagrams such as that shown in <ref type="figure" target="#fig_5">Figure 6</ref>. Every aspect of such phase diagrams is intensely studied. The general picture, a finite length liquid-vapor phase transition line ending in a critical point, a triple point where all three forms co-exist and a solid-liquid phase line seemingly extending to infinity, seems universal. The physicist G. Uhlenbeck <ref type="bibr">[87, p. 11]</ref> writes "Note that since these are general phenomena, they must have general explanation; the precise details of the molecular structure and of the intermolecular forces should not matter." In discussing the solid-liquid transition, Uhlenbeck <ref type="bibr">[87, p. 18]</ref> notes that the solid-liquid transition seemingly occurs at any temperature provided the pressure is high enough. He suggests that at high pressure, the attractive intermolecular force does not play a role ". . . and that it is the sharp repulsive forces that are responsible for the solid-fluid transition. It is this train of thought that explains the great interest of the so-called Kirkwood transition. In 1941, Kirkwood posed the problem of whether a gas of hard spheres would show a phase transition. . . ".</p><p>From then to now, chemists and physicists have studied this problem using a variety of tools. Current findings indicate a phase transition when the density of discs is large (about .71, still well below the close packing density). Below this transition density, the discs "look random"; above this density the discs look close to a lattice packing. These notions are quantified by a variety of functions f . For example,</p><formula xml:id="formula_34">f (x) = 1 N N j=1 1 N j k e 6iθ jk ,</formula><p>where the sum is over the N particles encoded by x ∈ R 2N , the sum in k is over the N j neighbors of the jth particle, and θ jk is the angle between the particles j and k in an arbitrary but fixed reference frame. If the configuration x has a local hexatic structure, this sum should be small. Typical values of f are studied by simulation. Different functions are used to study long-range order.</p><p>The above rough description may be supplemented by the useful survey of <ref type="bibr" target="#b66">[64]</ref>. A host of simulation methods are detailed in <ref type="bibr" target="#b1">[2]</ref>. An up-to-date tutorial on hard discs appears in <ref type="bibr" target="#b57">[57,</ref><ref type="bibr">Chap. 2]</ref>.</p><p>For the purposes of this paper, the main points are i) the hard disc model is a basic object of study and ii) many key findings have been based on variants of the Metropolis algorithm. In the next section, we flush out the Metropolis algorithm to more standard mathematics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Some mathematics</head><p>Here is a generalization of the hard discs Metropolis algorithm.</p><formula xml:id="formula_35">Let Ω ⊆ R d be a bounded connected open set. Letp(x) &gt; 0, z = Ωp (x)dx &lt; ∞, p(x) = z −1p (x)</formula><p>specify a probability density on Ω. If required, extend p to have value 0 outside the closure of Ω. Many sampling problems can be stated thus:</p><p>Givenp, choose points in Ω from p.</p><p>Note that the normalizing constant z may not be given and is usually impossible to usefully approximate. As an example, consider placing fifty hard discs in the unit square when = 1/100. The set of allowable configurations is a complex, cuspy set. Whilep ≡ 1 on Ω, it would not be practical to compute z. Here is one version of the Metropolis algorithm which samples from p. From x ∈ Ω, fix a small, positive h.</p><p>• Choose y ∈ B x (h), from normalized Lebesgue measure on this ball.</p><p>• If p(y) ≥ p(x), move to y.</p><p>• If p(y) &lt; p(x), move to y with probability p(y)/p(x).</p><p>• Else stay at x.</p><p>Note that this algorithm does not require knowing z. The transition from x to y yields a transition kernel (5.1)</p><formula xml:id="formula_36">P (x, dy) = m(x)δ x + h −d Vol(B 1 ) δ B 1 x − y h min p(x) p(y) , 1 dy with m(x) = 1 − R d h −d Vol(B 1 ) δ B 1 x − y h min p(x) p(y) , 1 dy.</formula><p>This kernel operates on L 2 (p) via</p><formula xml:id="formula_37">P • f (x) = R d f (y)P (x, dy).</formula><p>It is easy to see that P (x, dy) is a bounded self-adjoint operator on L 2 (p). The associated Markov chain may be described "in English" by</p><formula xml:id="formula_38">• Start at X 0 = x ∈ Ω. • Pick X 1 from P (x, dy). • Pick X 2 from P (X 1 , dy).</formula><p>• And so on . . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thus</head><formula xml:id="formula_39">P {X 2 ∈ A} = P 2 x (A) = R d P (z, A)P (x, dz), P {X k ∈ A} = P k x (A) = R d P (z, A)P k−1 (x, dz).</formula><p>Under our assumptions (Ω connected, h small), for all x ∈ Ω and A ⊆ Ω, the algorithm works:</p><formula xml:id="formula_40">P k x (A) k −→ ∞ A p(y)dy.</formula><p>It is natural to ask how fast this convergence takes place: how many steps should the algorithm be run to do its job? In joint work with Gilles Lebeau and Laurent Michel, we prove the following. Note that the Metropolis algorithm (5.1) is based on steps in the full-dimensional ball B (x) while the Metropolis algorithm for discs in Section 2 is based on just changing two coordinates at a time. With extra effort, a result like (5.2) can be shown for the hard disc problem as well. Details are in <ref type="bibr" target="#b25">[25]</ref>. As a caveat, note that we do not have good control on c 1 in terms of the dimension d or smoothness of Ω. The results are explicit but certainly not sharp.</p><p>The Metropolis algorithm of this section is on a Euclidean space with basic steps driven by a ball walk. None of this is particularly important. The underlying state space can be quite general, from finite (all one-to-one functions from one finite set to another as in our cryptography example) to infinite-dimensional (Markov chains on spaces of measures). The proposal distribution needn't be symmetric. All of the introductory books on simulation discussed in Section 6 develop the Metropolis algorithm. In <ref type="bibr" target="#b7">[8]</ref> it is shown to be the L 1 projection of the proposal distribution to the p self-adjoint kernels on Ω. A survey of rates of convergence results on finitestate spaces with extensive references to the work of computer science theorists on approximate counting and mathematical physicists on Ising models is in <ref type="bibr" target="#b31">[31]</ref>. Finally, there are many other classes of algorithms and proof techniques in active development. This is brought out in Section 6 below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Ideas and tools.</head><p>To analyze rates of convergence it is natural to try spectral theory, especially if the operators are self-adjoint. This sometimes works. It is sometimes necessary to supplement with tools, such as comparison and extension theory, Weyl-type bounds on eigenvalues, bounds on eigenvectors, and Nash-Sobolev inequalities. These are basic tools of modern analysis. Their use in a concrete problem may help some readers come into contact with this part of the mathematical world.</p><p>Spectral bounds for Markov chains. Let X be a set, µ(dx) a reference measure and m(x) a probability density with respect to µ (so m(x) ≥ 0, m(x)µ(dx) = 1). Let P (x, dy) be a Markov kernel on X . This means that for each x, P (x, •) is a probability measure on X . This P may be used to "run a Markov chain" X 0 , X 1 , X 2 , . . . , with starting state X 0 = x say, by choosing X 1 from P (x, •) and then X 2 from P (X 1 , •), and so on. The pair (m, P ) is called reversible (physicists say "satisfies detailed balance") if P operating on L 2 (m) by P f(x) = f (y)P (x, dy) is self-adjoint: P f, g = f, P g . Often, P (x, dy) = p(x, y)µ(dy) has a kernel and reversibility becomes m(x)p(x, y) = m(y)p(y, x) for all x, y. This says the chain run forward is the same as the chain run backward, in analogy with the time reversibility of the laws of mechanics. Here P operates on all of L 2 (m) so we are dealing with bounded self-adjoint operators.</p><p>Suppose for a moment that P has a square integrable kernel p(x, y), so P f(x) = X p(x, y)f (y)µ(dy). Then P is compact and there are eigenvectors f i and eigenvalues</p><formula xml:id="formula_41">β i so P f i = β i f i under a mild connectedness condition f 0 ≡ 1, β 0 = 1 and 1 = β 0 &gt; β 1 ≥ β 2 ≥ • • • &gt; −1. Then p(x, y) = m(x) ∞ i=0 β i f i (x)f i (y),</formula><p>and the iterated kernel satisfies</p><formula xml:id="formula_42">p n (x, y) = m(y) ∞ i=0 β n i f i (x)f i (y).</formula><p>If f i (x), f i (y) are bounded (or at least controllable), since f 0 ≡ 1,</p><formula xml:id="formula_43">p n (x, y) → m(y) as n → ∞.</formula><p>This is the spectral approach to convergence. Note that to turn this into a quantitative bound (From starting state x, how large must n be to have P n x − m &lt; ?), the β i and f i must be well understood.</p><p>The Metropolis algorithm on the permutation group discussed in Section 3 gives an example on finite spaces. Here is an example with an infinite state space drawn from my work with Khare and Saloff-Coste <ref type="bibr" target="#b23">[23]</ref> where this program can be usefully pushed through. Note that this example does not arise from the Metropolis construction. It arises from a second basic construction, Glauber dynamics. This Markov chain is used to model population dynamics with immigration. If the population size at generation n is denoted X, then, given X n = x,</p><formula xml:id="formula_44">X n+1 = x i=1 N i,n + M n+1 ,</formula><p>where N i,n , the number of offspring of the ith member of the population at time n, are assumed to be independent and identically distributed with</p><formula xml:id="formula_45">p(N i,n = j) = 2 3 1 3 j , 0 ≤ j &lt; ∞.</formula><p>Here M n+1 is migration, assumed to have the same distribution as N i,n . Note that m(x)p(x, y) = m(y)p(y, x) so reversibility is in force.</p><p>In <ref type="formula">(5</ref>3) the eigenvalues are shown to be β j = 1/2 j , 0 ≤ j &lt; ∞. The eigenfunctions are the orthogonal polynomials for the measure 1/2 j+1 . These are Meixner</p><formula xml:id="formula_46">polynomials M j (x) = 2 F 1 −j−x 1</formula><p>| − 1 . Now, the spectral representation gives the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 1. For any starting state x for all</head><formula xml:id="formula_47">n ≥ 0, χ 2 x (n) = ∞ y=0 (p n (x, y) − m(y)) 2 m(y) = ∞ i=1 β 2n i M 2 i (x) 1 2 i .</formula><p>Next, there is an analysis problem: Given the starting population x, how large should n be so that this chi-square distance to m is small? For this simple case, the details are easy enough to present in public.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 2. With notation as in</head><formula xml:id="formula_48">Proposition 1, χ 2 x (n) ≤ 2 −2c for n = log (1 + x) + c, c &gt; 0, χ 2 x (n) ≥ 2 2c for n = log (x − 1) − c, c &gt; 0.</formula><p>Proof. Meixner polynomials satisfy for all j and x &gt; 0</p><formula xml:id="formula_49">|M j (x)| = j∧x i=0 (−1) i j i x(x − 1) • • • (x − i + 1) ≤ j i=0 j i x i = (1 + x) j .</formula><p>Thus, for n ≥ log</p><formula xml:id="formula_50">2 (1 + x) + c, χ 2 x (n) = ∞ j=1 M 2 j (x)2 −j(2n+1) ≤ ∞ j=1 (1 + x) 2j 2 −j(2n+1) ≤ (1 + x) 2 2 −(2n+1) − (1 + x) 2 2 −(2n+1) ≤ 2 −2c−1 − 2 −2c−1 ≤ 2 −2c .</formula><p>The lower bound follows from using only the lead term. Namely</p><formula xml:id="formula_51">χ 2 x (n) ≥ (1 − x) 2 2 −2n ≥ 2 2c for n = log (x − 1) − c.</formula><p>The results show that convergence is rapid: order log 2 (x) steps are necessary and sufficient for convergence to stationarity.</p><p>We were suprised and delighted to see classical orthogonal polynomials appearing in a natural probability problem. The account <ref type="bibr" target="#b23">[23]</ref> develops this and gives dozens of other natural Markov chains explicitly diagonalized by orthogonal polynomials.</p><p>Alas, one is not always so lucky. The Metropolis chain of (5.1) has the form P f(x) = m(x)f (x) + h(x, y)f (y)dy. The multiplier m(x) leads to a continuous spectrum. One of our discoveries <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b60">59]</ref> is that for many chains, this can be side-stepped and the basic outline above can be pushed through to give sharp useful bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Some theorems.</head><p>Return to the Metropolis algorithm of Theorem 4. We are able to prove the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 5. For a bounded Lipshitz domain in</head><formula xml:id="formula_52">R d , let p(x) satisfy 0 &lt; m ≤ p(x) ≤ M &lt; ∞ for all x ∈ Ω.</formula><p>Let P h be defined by <ref type="bibr">(5.1)</ref>. There are h 0 &gt; 0, δ 0 ∈ (0, 1), and c i &gt; 0 so that</p><formula xml:id="formula_53">• Spec P h ⊆ [−1 + δ 0 , 1] for all h ≤ h 0 . • 1 is a simple eigenvalue of P h . • Spec P h ∩ [1 − δ 0 , 1] is discrete. • The number of eigenvalues of P h in [1 − h 2 λ, 1], 0 ≤ λ ≤ δ 0 h −2 (with multiplicity), is bounded above by c 1 (1 + λ) d/2 . • The spectral gap G(h) satisfies c 2 h 2 ≤ G(h) ≤ c 3 h 2 . • For all n ≥ 1 and any x ∈ Ω, P n x,h − p TV ≤ c 4 e −nG(h) .</formula><p>More precise evaluation of the gap is available if the boundary of the domain is quasi-regular. Then consider the operator </p><formula xml:id="formula_54">Lf (x) = −1 2(d + 1) f + p p • f with domain L = {f ∈ H 2 (p) : |∂ n f | ∂Ω =</formula><formula xml:id="formula_55">lim h→0 h −2 G(h) = ν 1 .</formula><p>Reducing to the Neuman problem for L sometimes allows accurate evaluation of the gap <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b60">59]</ref>.</p><p>We are able to show that for the hard disc problem of Section 2, a suitable power of the operator of (5.3) satisfies the conditions of Theorems 5 and 6. The associated Ω for hard discs is a complex cuspy set and the extension of standard theory to Lipshitz domains is truly forced.</p><p>Again, several caveats are in order. The theorems are satisfactory for a small number of discs but for questions of physical relevance (the dense case), our results have very little content. At present, we do not have good control over the dependence of the constants on the various Lipshitz constants or dimensions. Previous efforts to quantify such things <ref type="bibr" target="#b30">[30]</ref> lead to results like c . = (d/4) d/4 . With 100 discs, d = 200 and the practical relevance of the results may be questioned. Further, the restriction to densities bounded below is a limitation. Of course, we hope to deal with such issues in future work.</p><p>A second caveat: the Metropolis algorithm is not cutting-edge simulation technology. There are block analysis techniques and ways of making non-local moves of several particles <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b51">51]</ref> which seem useful and call out for analysis.</p><p>Finally, spectral techniques are only one of many routes to analysis. Marvelous theorems can be proved by coupling, and Harris recurrence techniques which combine Lyapounov functions and coupling are often useful. Coupling arguments for hard discs are in <ref type="bibr" target="#b26">[26]</ref> and <ref type="bibr" target="#b54">[54]</ref>.</p><p>There is also a widely studied discrete version of the problem. There, n particles are placed on the vertices of a connected graph. At each step, a particle is chosen at random and a neighboring site is chosen at random. If the neighboring site is empty, the chosen particle moves there; otherwise the particle stays where it was. This is called "Kawasaki dynamics for the simple exclusion process". This process, with many variations, has a large literature usefully surveyed in <ref type="bibr" target="#b61">[60]</ref>. Concrete rates of convergence can be found in <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b40">[40]</ref>, <ref type="bibr" target="#b69">[67]</ref>, <ref type="bibr" target="#b92">[89]</ref>, . . . . It is only fair to warn the reader that the similar problem where particles move with a drift on a lattice subject to exclusion (asymmetric exclusion process) has an even larger literature and has evolved into quite a separate subject.</p><p>5.3. One idea. One contribution of the analysis which should be broadly useful is an approach to avoiding the continuous spectrum. A wide variety of techniques for bounding eigenvalues and decay of powers for stochastic (e.g., positive) kernels has been developed by the probability community over the past 25 years. These include inequalities of Poincaré, Nash, Sobolev, and the log-Sobolev type. A useful reference for this material is <ref type="bibr" target="#b82">[79]</ref>. The new idea is to apply these techniques to pieces of the operators (which need not be stochastic). The discovery is that this can be pushed through.</p><p>In more detail, consider the kernel P h of (5.1) operating on L 2 (p). Write</p><formula xml:id="formula_56">P h = Π + P 1 h + P 2 h + P 3 h</formula><p>with Π the orthogonal projection onto the constants</p><formula xml:id="formula_57">P 1 h (x, y) = β j close to 1 β j (h)f j,h (x)f j,h (y), P 2 h (x, y) = 1 10 &lt; 1−β j h 2 &lt; 9 β j,h f j,h (x)f j,h (y),</formula><p>and</p><formula xml:id="formula_58">P 3 h = P h − Π − P 1 h − P 2</formula><p>h . The pieces are orthogonal, so powers of P h equal the sum of powers of the pieces. Now P 1 h and P 2 h can be analyzed as above. Of course, bounds on eigenvalues and eigenfunctions are still needed. The continuous spectrum is hidden in P <ref type="bibr" target="#b2">3</ref> h and one easily gets the crude bounds</p><formula xml:id="formula_59">P 3 h L ∞ →L ∞ ≤ ch −3d/2 , P 3 h L 2 →L 2 ≤ (1 − δ 0 )</formula><p>. These can be iterated to give (P 3 h ) n L ∞ →L ∞ ≤ ce −µn for a universal µ &gt; 0 and all n &gt; 1/h. Thus P <ref type="bibr" target="#b2">3</ref> h is negligible. The work is fairly technical but the big picture is fairly stable. It holds for natural walks on compact Riemannian manifolds <ref type="bibr" target="#b60">[59]</ref> and in the detailed analysis of the one-dimensional hard disc problem <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b27">27]</ref>.</p><p>The main purpose of this section is to show how careful analysis of an applied algorithm can lead to interesting mathematics. In the next section, several further applications of Markov chain Monte Carlo are sketched. None of these have been analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PERSI DIACONIS</head><p>6. Going further, looking back; contacts with math, contacts outside math This section covers four topics: how someone outside probability can learn more about the present subject; a literature review on rates of convergence; a list of examples showing how a wide spectrum of mathematical tools have been used in analyzing Markov chains; and pointers to applications in various scientific applications.</p><p>6.1. Going further. Suppose you are a "grown-up mathematician" who wants to learn some probability. The problem is, probability has its own language and images. It's a little like learning quantum mechanics -the mathematical tools are not a problem but the basic examples and images are foreign. There are two steps. The first is elementary probability -the language of random variables, expectation, independence, conditional probability, and the basic examples (binomial, Poisson, geometric, normal, gamma, beta) with their distribution theory. The second is mathematical probability -σ-algebras, laws of large numbers, central limit theory, martingales, and brownian motion. Not to mention Markov chains.</p><p>The best procedure is to first sit in on an elementary probability course and then sit in on a first-year graduate course. There are hundreds of books at all levels. Two good elementary books are <ref type="bibr" target="#b39">[39]</ref> and <ref type="bibr" target="#b81">[78]</ref>. This last is a very readable classic (don't miss Chapter 3!). I use Billingsley's book <ref type="bibr" target="#b8">[9]</ref> to teach graduate probability.</p><p>To learn about Monte Carlo, the classic book <ref type="bibr" target="#b44">[44]</ref> is short and contains most of the important ideas. The useful books ( <ref type="bibr" target="#b15">[15]</ref> or <ref type="bibr" target="#b64">[62]</ref>) bring this up to date. Two very good accounts of applied probability which develop Markov chain theory along present lines are <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b10">[10]</ref>. The advanced theory of Markov chains is well covered by <ref type="bibr" target="#b2">[3]</ref> (analytic theory), <ref type="bibr" target="#b38">[38]</ref> (semi-group theory), and <ref type="bibr" target="#b42">[42]</ref> (Dirichlet forms). Two very useful survey articles on rigorous rates of convergence are <ref type="bibr" target="#b69">[67]</ref> and <ref type="bibr" target="#b82">[79]</ref>. The on-line treatise <ref type="bibr" target="#b0">[1]</ref> has a wealth of information about reversible Markov chains. All of the cited works contain pointers to a huge literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Looking back.</head><p>In this article, I have focused on using spectral theory to give rates of convergence for Markov chains. There are several other tools and schools. Two important ones are coupling and Harris recurrence. Coupling is a pure probability approach in which two copies of a Markov chain are considered. One begins in stationarity, the second at a fixed starting point. Each chain evolves marginally according to the given transition operator. However, the chains are also set up to move towards each other. When they hit a common point, they couple and then move on together. The chain started in stationarity is stationary at every step, in particular at the coupling time T . Thus, at time T , the chain starting from a fixed point is stationary. This approach transforms the task of bounding rates of convergence to bounding the coupling time T . This can sometimes be done by quite elementary arguments. Coupling is such a powerful and original tool that it must have applications far from its origins. A recent example is Robert Neel's proof <ref type="bibr" target="#b73">[71]</ref> of Liouville theorems for minimal surfaces.</p><p>Book-length treatments of coupling are <ref type="bibr" target="#b63">[61]</ref> and <ref type="bibr" target="#b89">[86]</ref>. The very useful path coupling variant in <ref type="bibr" target="#b11">[11]</ref> and <ref type="bibr" target="#b35">[35]</ref> is developed into a marvelous theory of Ricci curvature for Markov chains by <ref type="bibr" target="#b76">[73]</ref>. The connections between coupling and eigenvalues is discussed in <ref type="bibr" target="#b12">[12]</ref>. The coupling from the past algorithm of Propp-Wilson <ref type="bibr" target="#b80">[77]</ref> has made a real impact on simulation. It sometimes allows exact samples to be drawn from intractable probability distributions. It works for the Ising model. I clearly remember my first look at David Wilson's sample of a 2, 000 × 2, 000 Ising model at the critical temperature. I felt like someone seeing Mars through a telescope for the first time.</p><p>Harris recurrence is a sophisticated variant of coupling which has a well-developed user interface. This avoids the need for clever, ad hoc constructions. The two chains can be exactly coupled for general state spaces when they hit a small set. They can be driven to the small set by a Lyapounov function. A splendid introduction to Harris recurrence is in <ref type="bibr" target="#b53">[53]</ref>. A book-length development is <ref type="bibr" target="#b70">[68]</ref>. The topic is often developed under the name of geometric ergodicity. This refers to bounds of the form K l</p><p>x − π TV ≤ A(x)γ l for A(x) &gt; 0 and 0 &lt; γ &lt; 1. Observe that usually, proofs of geometric ergodicity give no hold on A(x) or on γ. In this form, the results are practically useless, saying little more than "the chain converges for large l". Bounds with explicit A(x), γ are called "honest" in the literature <ref type="bibr" target="#b53">[53]</ref>. The work of Jim Hobert and his collaborators is particularly rich in useful bounds for real examples. For further discussion and references, see <ref type="bibr" target="#b23">[23]</ref> and <ref type="bibr" target="#b50">[50]</ref>.</p><p>In the presence of geometric ergodicity, a wealth of useful auxiliary results becomes available. These include central limit theorems and large deviations bounds for averages 1/N f (X i ) <ref type="bibr" target="#b56">[56]</ref>. The variance of such averages can be usefully estimated <ref type="bibr" target="#b46">[46]</ref>. One can even hope to do perfect sampling from the exact stationary distribution <ref type="bibr" target="#b55">[55]</ref>. There has been a spirited effort to understand what the set-up required for Harris recurrence says about the spectrum <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. (Note that coupling and Harris recurrence do not depend on reversibility.) 6.3. Contacts with math. The quest for sharp analysis of Markov chains has led to the use and development of tools from various areas of mathematics. Here is a personal catalog.</p><p>Group representations. Natural mixing schemes can sometimes be represented as random walks on groups or homogeneous spaces. Then, representation theory allows a useful Fourier analysis. If the walks are invariant under conjugation, only the characters are needed. If the walks are bi-invariant under a subgroup giving a Gelfand pair, the spherical functions are needed. A book-length discussion of this approach can be found in <ref type="bibr" target="#b14">[14]</ref>. Sometimes, the probability theory calls for new group theory. An example is the random walk on the group of upper-triangular matrices with elements in a finite field: Starting at the identity, pick a row at random and add it to the row above. The character theory of this group is wild. Carlos-Andre has created a cruder super-character theory which is sufficiently rich to handle random walk problems. The detailed use of this required a new formula <ref type="bibr" target="#b3">[4]</ref> and leads to an extension of the theory to algebra groups in joint work with Isaacs and Theme <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b34">34]</ref>. This has blossomed into thesis projects <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b87">84,</ref><ref type="bibr" target="#b88">85]</ref>. This thread is a nice example of the way that applications and theory interact.</p><p>Algebraic geometry. The creation of Markov chains to efficiently perform a sampling task can lead to interesting mathematics. As an example, consider the emerging field of algebraic statistics. I was faced with the problem of generating (uniformly) random arrays with given row and column sums. These arrays (called "contingency tables" in statistics) have non-negative integer entries. For two-dimensional arrays, a classical Markov chain Monte Carlo algorithm proceeds as follows. Pick a pair of rows and a pair of columns at random; this delineates four entries. Change these entries by adding and subtracting in one of the following patterns:</p><formula xml:id="formula_60">+ − − + or − + + − .</formula><p>This doesn't change the row/column sums. If the resulting array still has nonnegative entries, the chain moves there. Otherwise, the chain stays at the original array. I needed to extend this to higher-dimensional arrays and similar problems on the permutation group and other structures where linear statistics are to be preserved. The problem is that the analog of the + − − + moves that statisticians have thought of does not connect the space. Bernd Sturmfels recognized the original + − − + moves as generators of a determinental ideal and suggested coding the problem up as finding generators of a toric ideal. All of the problems fit into this scheme and the emerging fields of computational algebra and Gröbner bases allow practical solutions. The story is too long to tell here in much detail. The original ideas are worked out in <ref type="bibr" target="#b33">[33]</ref>. There have been many extensions, bolstered by more than a dozen Ph.D. theses. A flavor of this activity and references can be gathered from <ref type="bibr" target="#b49">[49]</ref>. The suite of computational resources in the computer package Latte also contains extensive documentation. The subject of algebraic statistics has expanded in many directions. See <ref type="bibr" target="#b77">[74]</ref> for its projection into biology, and <ref type="bibr" target="#b79">[76]</ref> for its projection into the design of experiments. As usual, the applications call for a sharpening of algebraic geometric tools and raise totally new problems.</p><p>For completeness I must mention that despite much effort, the running time analysis of the original Markov chain on contingency tables has not been settled. There are many partial results suggesting that (diam) steps are necessary and sufficient, where diameter refers to the graph with an edge between two arrays if they differ by a + − − + move. There are also other ways of sampling that show great promise <ref type="bibr" target="#b16">[16]</ref>. Carrying either the analysis or the alternative procedures to the other problems in <ref type="bibr" target="#b33">[33]</ref> is a healthy research area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PDE.</head><p>The analysis of Markov chains has a very close connection with the study of long time behavior of the solutions of differential equations. In the Markov chain context we are given a kernel K(x, dy) with reversible stationary measure π(dx) on a space X . Then K operates as a self-adjoint contraction on L 2 (π) via Kf(x) = f (y)K(x, dy). The associated quadratic form E(f |g) = (I − K)f, g is called the Dirichlet form in probability. A Poincaré inequality for K has the form f <ref type="bibr" target="#b1">2</ref> 2 ≤ AE(f |f ) for all f ∈ L 2 (π) with fdπ = 0.</p><p>Using the minimax characterization, a Poincaré inequality shows that there is no spectrum for the operator in [1 − 1/A, 1) (Markov operators always have 1 as an eigenvalue). There is a parallel parity form which allows bounding negative spectrum. If the spectrum is supported on [−1 + 1/A, 1 − 1/A] and the Markov chain is started at a distribution σ with L 2 density g, then</p><formula xml:id="formula_61">K l σ − π 2 TV ≤ g − 1 2 2 1 − 1 A 2l .</formula><p>This is a useful, explicit bound but it is often "off", giving the wrong rate of convergence by factors of n or more in problems on the symmetric group S n . A host of more complex techniques can give better results. For example, K satisfies a Nash inequality if for all suitable f ,</p><formula xml:id="formula_62">f 2+1/D 2 ≤ A E(f |f ) + 1 N f 2 2 f 1/D 1 ,</formula><p>and a log-Sobolev inequality if</p><formula xml:id="formula_63">L(f ) ≤ AE(f |f ), L(f ) = f 2 (x) log f (x) 2 f 2 2 π(dx).</formula><p>Here A, N and D are constants which enter into any conclusions. These inequalities are harder to establish and have stronger conequences. Related inequalities of Cheeger and Sobolev are also in widespread use. For surveys of this technology, see <ref type="bibr" target="#b71">[69]</ref> or <ref type="bibr" target="#b82">[79]</ref>. The point here is that most of these techniques were developed to study PDE. Their adaptation to the analysis of Markov chains requires some new ideas. This interplay between the proof techniques of PDE and Markov chains has evolved into the small but healthy field of functional inequalities <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> which contributes to both subjects. Modern PDE is an enormous subject with many more tools and ideas. Some of these, for example, the calculus of pseudo-differential operators and micro-local techniques, are just starting to make inroads into Markov chain convergence <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b60">59]</ref>.</p><p>A major omission in the discussion above are the contributions of the theoretical computer science community. In addition to a set of problems discussed in the final part of this section, a host of broadly useful technical developments have emerged. One way of saying things is this: How does one establish any of the inequalities above (from Poincaré through log-Sobolev) in an explicit problem? Mark Jerrum and Alistair Sinclair introduced the use of paths to prove Cheeger inequalities (called "conductance" in computer science). Dyer, Frieze, Lovász, Kannan and many students and coauthors have developed and applied these ideas to a host of problems, most notably the problems of approximating the permanent of a matrix and approximating the volume of a convex set. Alas, this work suffers from the "polynomial time bug". The developers are often satisfied with results showing that n 17 steps suffice (after all, it's a polynomial). This leads to theory of little use in practical problems. I believe that the ideas can be pushed to give useful results, but at the present writing much remains to be done. A good survey of this set of ideas can be found in <ref type="bibr" target="#b71">[69]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Contacts outside math.</head><p>To someone working in my part of the world, asking about applications of Markov chain Monte Carlo (MCMC) is a little like asking about applications of the quadratic formula. The results are really used in every aspect of scientific inquiry. The following indications are wildly incomplete. I believe you can take any area of science, from hard to social, and find a burgeoning MCMC literature specifically tailored to that area. I note that essentially none of these applications is accompanied by any kind of practically useful running time analysis. Thus the following is really a list of open research problems.</p><p>Chemistry and physics. From the original application to hard discs through lattice gauge theory <ref type="bibr" target="#b68">[66]</ref>, MCMC calculations are a mainstay of chemistry and physics. I will content myself by mentioning four very readable books, particularly good at describing the applications to an outsider; I have found them useful ways to learn the science. For physics, <ref type="bibr" target="#b57">[57]</ref> and <ref type="bibr" target="#b74">[72]</ref>. For chemistry, <ref type="bibr" target="#b41">[41]</ref> and <ref type="bibr" target="#b59">[58]</ref>. A good feeling for the ubiquity of MCMC can be gleaned from the following quote from the introductory text of the chemist Ben Widom <ref type="bibr">[88, p. 101]</ref>:</p><p>"Now, a generation later, the situation has been wholly transformed, and we are able to calculate the properties of ordinary liquids with nearly as much assurance as we do those of dilute gases and harmonic solids . . . . What is new is our ability to realize van der Waal's vision through the intervention of high speed digital computing."</p><p>Biology. One way to access applications of MCMC in various areas of biology is to look at the work of the statistical leaders of groups driving this research: Jun Liu (Harvard), Michael Newton (Wisconsin), Mike West (Duke) and Wing Wong (Stanford). The homepages of each of these authors contain dozens of papers, essentially all driven by MCMC. Many of these contain innovative, new algorithms (waiting to be studied). In addition, I mention the online resources "Mr. Bayes" and "Bugs". These give hundreds of tailored programs for MCMC biological applications.</p><p>Statistics. Statisticians work with scientists, engineers, and businesses in a huge swathe of applications. Perhaps 10-15% of this is driven by MCMC. An overview of applications may be found in the books <ref type="bibr" target="#b43">[43]</ref> or <ref type="bibr" target="#b64">[62]</ref>. For the very active area of particle filters and their many engineering applications (tracking, filtering), see <ref type="bibr" target="#b36">[36]</ref>. For political science-flavored applications, see <ref type="bibr" target="#b43">[43]</ref>. Of course, statisticians have also contributed to the design and analysis of these algorithms. An important and readable source is <ref type="bibr" target="#b13">[13]</ref>.</p><p>Group theory. This is a much smaller application. It seems surprising, because group theory (the mathematics of symmetry) seems so far from probability. However, computational group theory, as coded up in the online libraries Gap and Magma, makes heavy use of randomized algorithms to do basic tasks such as deciding whether a group (usually given as the group generated by a few permutations or a few large matrices) is all of S n (GL n ). Is it solvable, can we find its lower central series, normal closure, Sylow(p) subgroups, etc.? Splendid accounts of this subject are in <ref type="bibr" target="#b47">[47]</ref> or <ref type="bibr" target="#b83">[80]</ref>. Bounding the running time of widely available used algorithms, such as the meat axe or the product replacement algorithm <ref type="bibr" target="#b78">[75]</ref>, are important open problems on the unlikely interface of group theory and probability.</p><p>Computer science (theory). The analysis of algorithms and complexity theory is an important part of computer science. One central theme is the polynomial/nonpolynomial dichotomy. A large class of problems such as computing the permanent of a matrix or the volume of a convex polyhedron have been proved to be # pcomplete. Theorists (Broder, Jerrum, Vazarani) have shown that while it may take exponential time to get an exact answer to these problems, one can find provably accurate approximations in a polynomial number of operations (in the size of the input) provided one can find a rapidly mixing Markov chain to generate problem instances at random. The above rough description is made precise in the readable book <ref type="bibr" target="#b84">[81]</ref>. This program calls for methods of bounding the running time of Markov chains. Many clever analyses have been carried out in tough problems without helpful symmetries. It would take us too far afield to develop this further. Three of my favorite papers (which will lead the reader into the heart of this rich literature) are the analysis <ref type="bibr" target="#b65">[63]</ref> of the hit-and-run algorithm, the analysis <ref type="bibr" target="#b52">[52]</ref> of the problem of approximating permanents, and the analysis <ref type="bibr" target="#b72">[70]</ref> of knapsack problems. All of these contain deep, original mathematical ideas which seem broadly useful. As a caveat, recent results of Widgerson suggest a dichotomy: either randomness can be eliminated from these algorithms or P = NP . Since nobody believes P = NP , there is true excitement in the air.</p><p>To close this section, I reiterate that almost none of these applications comes with a useful running time estimate (and almost never with careful error estimates). Also, for computer science, the applications are to computer science theory. Here the challenge is to see if practically useful algorithms can be made from the elegant mathematics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 2 .</head><label>2</label><figDesc>For 0 &lt; θ ≤ 1, the Markov chain K(σ, σ * ) in (3.2) has stationary distribution π from (3.1). Let k = an log n + cn with a = 1/2θ + 1/4θ(1/θ − θ) and c &gt; 0. Then, with σ 0 = id and starting from the identity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>the P λ form a basis as λ runs through the partitions of n (fundamental theorem of symmetric functions). Other well-known bases are the monomial and elementary symmetric functions. The stars of the show are the Schur functions (character of the general linear group). The change of basis matrices between these codes up a lot of classical combinatorics. A two-parameter family of bases, the Macdonald polynomials, is a central focus of modern combinatorics. Definitive, inspiring accounts of this are in Macdonald [65] and Stanley</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Theorem 4 .</head><label>4</label><figDesc>Let Ω be a connected Lipshitz domain inR d . For p measurable (with 0 &lt; m ≤ p(x) ≤ M &lt; ∞ on Ω)and h fixed and small, the Metropolis algorithm (5.1) satisfies (5.2) P k x (A) − A p(y)dy ≤ c 1 e −c 2 kh 2 uniformly in x ∈ Ω, A ⊆ Ω. In (5.2), c 1 , c 2 are positive constants that depend onp and Ω but not on x, k or h. The result is sharp in the sense that there is a matching lower bound. Good estimates of c 2 are available (see the following section).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Example 2 ( 1 x+y+1 x + y x 1 x+1.</head><label>211</label><figDesc>Birth and immigration). The state space X = {0, 1, 2, . . . }. Let µ(dx) be a counting measure and (5.3) m(x) = 1 2 x+1 , p(x, y) =</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This paper leans on 30 years of joint work with students and coauthors. It was presented at the 25th anniversary of the amazing, wonderful MSRI. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Reversible Markov chains and random walks on graphs. Monograph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Aldous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Computer simulation of liquids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Tildesely</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Continuous-time Markov chains. An applications-oriented approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer Series in Statistics: Probability and its Applications</title>
		<meeting><address><addrLine>New York. MR1118840 (92k</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page">60170</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A super-class walk on upper-triangular matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arias-Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stanley</surname></persName>
		</author>
		<idno>739-765. MR2071663</idno>
	</analytic>
	<monogr>
		<title level="j">J. Algebra</title>
		<imprint>
			<biblScope unit="volume">278</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">60101</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rate of convergence for ergodic continuous Markov processes: Lyapunov versus Poincaré</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bakry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cattiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guillin</surname></persName>
		</author>
		<idno>727-759. MR2381160</idno>
	</analytic>
	<monogr>
		<title level="j">J. Funct. Anal</title>
		<imprint>
			<biblScope unit="volume">254</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Poincaré inequalities for logconcave probability measures: a Lyapounov function approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bakry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cattiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guillin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron Comm. Probab</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="60" to="66" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Stochastic processes with applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Waymire</surname></persName>
		</author>
		<idno>MR1054645 (91m:60001</idno>
	</analytic>
	<monogr>
		<title level="m">Wiley Series in Probability and Mathematical Statistics: Applied Probability and Statistics</title>
		<imprint>
			<publisher>John Wiley &amp; Sons Inc., New York. A Wiley-Interscience Publication</publisher>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A geometric interpretation of the Metropolis-Hastings algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Billera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<idno>335-339. MR1888448</idno>
	</analytic>
	<monogr>
		<title level="j">Statist. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">60133</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probability and measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Billingsley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wiley Series in Probability and Mathematical Statistics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons Inc</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note>third edition. A Wiley-Interscience Publication. MR1324786 (95k:60001</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Persi Diaconis</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Markov chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brémaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">simulation, and queues. MR1689633</title>
		<meeting><address><addrLine>New York. Gibbs fields, Monte Carlo</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">60137</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Path coupling: a technique for proving rapid mixing in Markov chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bubley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FOCS</title>
		<imprint>
			<biblScope unit="page" from="223" to="231" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient Markovian couplings: examples and counterexamples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Burdzy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Kendall</surname></persName>
		</author>
		<idno>362-409. MR1768241</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Probab</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">60129</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robert&apos;s to Chapters 6, 7 and 13, With Chapter 14 by Gersende Fort</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Cappé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rydén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philippe Soulier and Moulines, and Chapter</title>
		<editor>Stéphane Boucheron and Elisabeth Gassiat. MR2159833</editor>
		<imprint>
			<biblScope unit="page">60002</biblScope>
			<date type="published" when="2005" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Springer Series in Statistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Harmonic analysis on finite groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ceccherini-Silberstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarabotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cambridge Studies in Advanced Mathematics</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">2389056</biblScope>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>Representation theory, Gelfand pairs and Markov chains</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Monte Carlo methods in Bayesian computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Ibrahim</surname></persName>
		</author>
		<idno>MR1742311</idno>
	</analytic>
	<monogr>
		<title level="j">Springer Series in Statistics</title>
		<imprint>
			<biblScope unit="page">65014</biblScope>
			<date type="published" when="2000" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sequential Monte Carlo methods for statistical analysis of tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<idno>109-120. MR2156822</idno>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">469</biblScope>
			<biblScope unit="page">62062</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Simulation and solving substitution codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Conner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, University of Warwick</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Metric methods for analyzing partially ranked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Critchlow</surname></persName>
		</author>
		<idno>Berlin. MR818986</idno>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Statistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">62044</biblScope>
			<date type="published" when="1985" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Group representations in probability and statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Institute of Mathematical Statistics Lecture Notes-Monograph Series</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="1988" />
			<publisher>Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
	<note>MR964069 (90a:60001</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spearman&apos;s footrule as a measure of disarray</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
		<idno>262-268. MR0652736</idno>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">31575</biblScope>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Eigen-analysis for some examples of the Metropolis algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanlon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hypergeometric functions on domains of positivity, Jack polynomials, and applications</title>
		<meeting><address><addrLine>Tampa, FL; Providence</addrLine></address></meeting>
		<imprint>
			<publisher>Amer. Math. Soc</publisher>
			<date type="published" when="1991" />
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page" from="99" to="117" />
		</imprint>
	</monogr>
	<note>RI. MR1199117 (93h:33001</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Supercharacters and superclasses for algebra groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Isaacs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Amer. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2359" to="2392" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gibbs sampling, exponential families and orthogonal polynomials, with discussion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Khare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saloff-Coste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Sci</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Micro-local analysis for the Metropolis algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lebeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Z</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Geometric analysis for the Metropolis algorithm on Lipshitz domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lebeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Michel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Spectral gap of the hard-core model on the unit interval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Limic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Department of Statistics, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Numerical results for the Metropolis algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Neuberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experiment. Math</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="213" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Analysis of systematic scan Metropolis algorithms using Iwahori-Hecke algebra techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Michigan Math. J</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="157" to="190" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Dedicated to William Fulton on the occasion of his 60th birthday. MR1786485 (2001j:60132</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Comparison theorems for reversible Markov chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saloff-Coste</surname></persName>
		</author>
		<idno>696-730. MR1233621 (94i:60074</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Probab</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Nash inequalities for finite Markov chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saloff-Coste</surname></persName>
		</author>
		<idno>459-510. MR1385408 (97d:60114</idno>
	</analytic>
	<monogr>
		<title level="j">J. Theoret. Probab</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">What do we know about the Metropolis algorithm?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saloff-Coste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th Annual ACM Symposium on the Theory of Computing (STOC&apos;95)</title>
		<meeting><address><addrLine>Las Vegas, NV</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">68094</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generating a random permutation with random transpositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shahshahani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Z. Wahrsch. Verw. Gebiete</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="179" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
	<note>MR626813 (82h:60024</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Algebraic algorithms for sampling from conditional distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sturmfels</surname></persName>
		</author>
		<idno>MR1608156 (99j:62137</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="363" to="397" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Supercharacter formulas for pattern groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Amer. Math. Soc</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Prescribing a system of random variables by conditional distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Dobrushin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Probab. Appl.-Engl. Tr</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="453" to="486" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Sequential Monte Carlo in Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Cluster algorithm for hard spheres and related systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dress</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Krauth</surname></persName>
		</author>
		<idno>L597-L601. MR1381129</idno>
	</analytic>
	<monogr>
		<title level="j">J. Phys. A</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">23</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Ethier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kurtz</surname></persName>
		</author>
		<title level="m">Markov processes. Wiley Series in Probability and Mathematical Statistics: Probability and Mathematical Statistics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons Inc</publisher>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
	<note>Characterization and convergence. MR838085 (88a:60130</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">An introduction to probability theory and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feller</surname></persName>
		</author>
		<idno>MR0228020</idno>
		<imprint>
			<date type="published" when="1968" />
			<publisher>John Wiley &amp; Sons Inc</publisher>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">3604</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Eigenvalue bounds on convergence to stationarity for nonreversible Markov chains, with an application to the exclusion process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fill</surname></persName>
		</author>
		<idno>62- 87. MR1097464 (92h:60104</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Probab</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Understanding molecular simulation: From algorithms to applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Frenkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Smit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Science Series</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2002" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Dirichlet forms and symmetric Markov processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fukushima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ōshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Takeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">de Gruyter Studies in Mathematics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="1994" />
			<publisher>Walter de Gruyter &amp; Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Bayesian methods: a social and behavioral sciences approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Social and Behavioral Sciences. Chapman &amp; Hall/CRC</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>2nd ed. Statistics in. Second edition</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Monte Carlo methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hammersley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Handscomb</surname></persName>
		</author>
		<idno>London. MR0223065</idno>
		<imprint>
			<date type="published" when="1965" />
			<publisher>Methuen &amp; Co. Ltd</publisher>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">6114</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Supercharacter theories of finite simple groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O F</forename><surname>Hendrickson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On the applicability of regenerative simulation in Markov chain Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Hobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Presnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<idno>731-743. MR1946508</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">60200</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Eick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Brien</surname></persName>
		</author>
		<idno>FL. MR2129747</idno>
		<title level="m">Handbook of computational group theory. Discrete Mathematics and its Applications</title>
		<meeting><address><addrLine>Boca Raton; Boca Raton</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Quantum probability and spectral analysis of graphs. Theoretical and Mathematical Physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Obata</surname></persName>
		</author>
		<editor>Luigi Accardi. MR2316893</editor>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hosten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Preface. J. Symb. Comput</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="124" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Geometric ergodicity of Metropolis algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Jarner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hansen</surname></persName>
		</author>
		<idno>341-361. MR1731030</idno>
	</analytic>
	<monogr>
		<title level="j">Stochastic Process. Appl</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">60108</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The hexatic phase of the two-dimensional hard disks system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jaster</surname></persName>
		</author>
		<idno>cond-mat/0305239</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. A</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page" from="120" to="125" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A polynomial-time approximation algorithm for the permanent of a matrix with nonnegative entries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jerrum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinclair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vigoda</surname></persName>
		</author>
		<idno>electronic). MR2147852</idno>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">15013</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Honest exploration of intractable probability distributions via Markov chain Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Hobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="312" to="334" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Rapid mixing of several Markov chains for a hard-core model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Mahoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Montenegro</surname></persName>
		</author>
		<idno>Berlin. MR2088246</idno>
	</analytic>
	<monogr>
		<title level="m">Algorithms and computation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page">68160</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Geometric ergodicity and perfect simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Kendall</surname></persName>
		</author>
		<idno>electronic). MR2108860</idno>
	</analytic>
	<monogr>
		<title level="j">Electron. Comm. Probab</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">60098</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Spectral theory and limit theorems for geometrically ergodic Markov processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kontoyiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Meyn</surname></persName>
		</author>
		<idno>304-362. MR1952001</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Probab</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">60187</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Oxford Master Series in Physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Krauth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Oxford Master Series in Statistical Computational, and Theoretical Physics</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page">2370557</biblScope>
		</imprint>
	</monogr>
	<note>Algorithms and computations</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Persi Diaconis</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">A Guide to Monte Carlo Simulations in Statistical Physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Landau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Binder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page">82051</biblScope>
			<pubPlace>Cambridge. MR1781083</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Semiclassical analysis of a random walk on a manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lebeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Michel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0802.0644</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Probab</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Interacting particle systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Liggett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">of Grundlehren der Mathematischen Wissenschaften</title>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="volume">276</biblScope>
		</imprint>
	</monogr>
	<note>Fundamental Principles of Mathematical Sciences</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer-Verlag</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">60089</biblScope>
			<pubPlace>New York. MR776231 (86e</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Lectures on the coupling method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lindvall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Dover Publications Inc</publisher>
			<pubPlace>Mineola, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Corrected reprint of the 1992 original. MR1924231</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Monte Carlo Strategies in Scientific Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Springer Series in Statistics</title>
		<imprint>
			<biblScope unit="page">65006</biblScope>
			<date type="published" when="2001" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Hit-and-run from a corner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lovász</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vempala</surname></persName>
		</author>
		<idno>985- (electronic). MR2203735</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">60041</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Fun with hard spheres</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Löwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical physics and spatial statistics</title>
		<meeting><address><addrLine>Wuppertal; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">554</biblScope>
			<biblScope unit="page">1870950</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Symmetric functions and Hall polynomials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">G</forename><surname>Macdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>The Clarendon Press Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Oxford Mathematical Monographs. second edition. With contributions by A. Zelevinsky, Oxford Science Publications. MR1354144 (96h:05207</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The fundamental constants of nature from lattice gauge theory simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mackenzie</surname></persName>
		</author>
		<idno type="DOI">10.1088/1742-6596/16/1/018</idno>
	</analytic>
	<monogr>
		<title level="j">J. Phys. Conf. Ser</title>
		<imprint>
			<biblScope unit="page" from="140" to="149" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Relaxation times of Markov chains in statistical mechanics and combinatorial structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Martinelli</surname></persName>
		</author>
		<idno>Berlin. MR2023653</idno>
	</analytic>
	<monogr>
		<title level="m">Probability on discrete structures</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page">60260</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Markov chains and stochastic stability. Communications and Control Engineering Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Meyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Tweedie</surname></persName>
		</author>
		<idno>London. MR1287609 (95j:60103</idno>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Springer-Verlag London Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Mathematical aspects of mixing times in Markov chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Montenegro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tetali</surname></persName>
		</author>
		<idno>x+121. MR2341319</idno>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Random walks on truncated cubes and sampling 0 − 1 knapsack solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinclair</surname></persName>
		</author>
		<idno>electronic). MR2114310</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">68095</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A martingale approach to minimal surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Neel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jfa.2008.06.033</idno>
		<idno type="arXiv">arXiv:0805.0556v2</idno>
	</analytic>
	<monogr>
		<title level="j">J. Funct. Anal</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>math.DG] (in press</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Barkema</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Monte Carlo methods in statistical physics</title>
		<imprint>
			<date type="published" when="2000" />
			<publisher>The Clarendon Press Oxford University Press</publisher>
			<biblScope unit="page">82030</biblScope>
			<pubPlace>New York. MR1691513</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Ricci curvature of Markov chains on metric spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ollivier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Preprint, submitted</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Algebraic statistics for computational biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pachter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sturmfels</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page">92002</biblScope>
			<pubPlace>New York. MR2205865</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">What do we know about the product replacement algorithm?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pak</surname></persName>
		</author>
		<idno>Berlin. MR1829489</idno>
	</analytic>
	<monogr>
		<title level="m">Groups and computation</title>
		<meeting><address><addrLine>III (Columbus, OH</addrLine></address></meeting>
		<imprint>
			<publisher>de Gruyter</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="301" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Algebraic statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pistone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riccomagno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Wynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational commutative algebra in statistics. MR2332740</title>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page">62098</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Exact sampling with coupled Markov chains and applications to statistical mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Propp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Random Structures and Algorithms</title>
		<meeting>the Seventh International Conference on Random Structures and Algorithms<address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="223" to="252" />
		</imprint>
	</monogr>
	<note>MR1611693 (99k:60176</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">A First Course in Probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Ross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
	<note>7th Edition</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Lectures on finite Markov chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saloff-Coste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lectures on probability theory and statistics</title>
		<meeting><address><addrLine>Saint-Flour</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">1665</biblScope>
			<biblScope unit="page" from="301" to="413" />
		</imprint>
	</monogr>
	<note>Berlin. MR1490046 (99b:60119</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Permutation group algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Á</forename><surname>Seress</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">of Cambridge Tracts in Mathematics</title>
		<meeting><address><addrLine>Cambridge. MR1970241</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">152</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Algorithms for random generation and counting. Progress in Theoretical Computer Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinclair</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Birkhäuser Boston Inc</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
	<note>A Markov chain approach. MR1201590 (93j:65011</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">With a foreword by Gian-Carlo Rota and appendix 1 by Sergey Fomin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cambridge Studies in Advanced Mathematics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1999" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>Enumerative combinatorics.</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">An introduction to stochastic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Academic Press Inc</publisher>
			<biblScope unit="volume">778728</biblScope>
			<biblScope unit="page">60003</biblScope>
			<pubPlace>Orlando, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Superinduction for pattern groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Boulder</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Mathematics, University of Colorado</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Restricting supercharacters of the finite group of unipotent uppertriangular matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Venkateswaran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Boulder</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Mathematics, University of Colorado</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Coupling, stationarity, and regeneration. Probability and its Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Thorisson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page">60003</biblScope>
			<pubPlace>New York; New York. MR1741181</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">An outline of statistical mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Uhlenbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fundamental Problems in Statistical Mechanics</title>
		<editor>Cohen, E. G. D.</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>North-Holland Publishing Co</publisher>
			<date type="published" when="1968" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Statistical Mechanics: A Concise Introduction for Chemists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Widom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page">82001</biblScope>
			<pubPlace>Cambridge. MR1921032</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Logarithmic Sobolev inequality for generalized simple exclusion processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Yau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MR1483598 (99f:60171) Department of Mathematics and Statistics</title>
		<meeting><address><addrLine>Stanford, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="507" to="538" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
