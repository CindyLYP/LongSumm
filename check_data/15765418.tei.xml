<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Under review as a conference paper at ICLR 2016 IMPORTANCE WEIGHTED AUTOENCODERS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-11-07">7 Nov 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
							<email>yburda@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto Toronto</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
							<email>rgrosse@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto Toronto</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto Toronto</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Under review as a conference paper at ICLR 2016 IMPORTANCE WEIGHTED AUTOENCODERS</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-11-07">7 Nov 2016</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1509.00519v4[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>The variational autoencoder (VAE; Kingma &amp; Welling (2014)) is a recently proposed generative model pairing a top-down generative network with a bottom-up recognition network which approximates posterior inference. It typically makes strong assumptions about posterior inference, for instance that the posterior distribution is approximately factorial, and that its parameters can be approximated with nonlinear regression from the observations. As we show empirically, the VAE objective can lead to overly simplified representations which fail to use the network&apos;s entire modeling capacity. We present the importance weighted autoencoder (IWAE), a generative model with the same architecture as the VAE, but which uses a strictly tighter log-likelihood lower bound derived from importance weighting. In the IWAE, the recognition network uses multiple samples to approximate the posterior, giving it increased flexibility to model complex posteriors which do not fit the VAE modeling assumptions. We show empirically that IWAEs learn richer latent space representations than VAEs, leading to improved test log-likelihood on density estimation benchmarks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCITON</head><p>In recent years, there has been a renewed focus on learning deep generative models <ref type="bibr" target="#b11">(Hinton et al., 2006;</ref><ref type="bibr" target="#b25">Salakhutdinov &amp; E., 2009;</ref><ref type="bibr" target="#b8">Gregor et al., 2014;</ref><ref type="bibr" target="#b24">Rezende et al., 2014)</ref>. A common difficulty faced by most approaches is the need to perform posterior inference during training: the log-likelihood gradients for most latent variable models are defined in terms of posterior statistics (e.g. <ref type="bibr" target="#b25">Salakhutdinov &amp; E. (2009)</ref>; <ref type="bibr" target="#b22">Neal (1992)</ref>; <ref type="bibr" target="#b8">Gregor et al. (2014)</ref>). One approach for dealing with this problem is to train a recognition network alongside the generative model <ref type="bibr" target="#b3">(Dayan et al., 1995)</ref>. The recognition network aims to predict the posterior distribution over latent variables given the observations, and can often generate a rough approximation much more quickly than generic inference algorithms such as MCMC.</p><p>The variational autoencoder (VAE; ; <ref type="bibr" target="#b24">Rezende et al. (2014)</ref>) is a recently proposed generative model which pairs a top-down generative network with a bottom-up recognition network. Both networks are jointly trained to maximize a variational lower bound on the data loglikelihood. VAEs have recently been successful at separating style and content <ref type="bibr" target="#b15">Kulkarni et al., 2015)</ref> and at learning to "draw" images in a realistic manner <ref type="bibr" target="#b9">(Gregor et al., 2015)</ref>.</p><p>VAEs make strong assumptions about the posterior distribution. Typically VAE models assume that the posterior is approximately factorial, and that its parameters can be predicted from the observables through a nonlinear regression. Because they are trained to maximize a variational lower bound on the log-likelihood, they are encouraged to learn representations where these assumptions are satisfied, i.e. where the posterior is approximately factorial and predictable with a neural network. While this effect is beneficial, it comes at a cost: constraining the form of the posterior limits the expressive power of the model. This is especially true of the VAE objective, which harshly penalizes approximate posterior samples which are unlikely to explain the data, even if the recognition network puts much of its probability mass on good explanations.</p><p>In this paper, we introduce the importance weighted autoencoder (IWAE), a generative model which shares the VAE architecture, but which is trained with a tighter log-likelihood lower bound de-rived from importance weighting. The recognition network generates multiple approximate posterior samples, and their weights are averaged. As the number of samples is increased, the lower bound approaches the true log-likelihood. The use of multiple samples gives the IWAE additional flexibility to learn generative models whose posterior distributions do not fit the VAE modeling assumptions. This approach is related to reweighted wake sleep <ref type="bibr" target="#b1">(Bornschein &amp; Bengio, 2015)</ref>, but the IWAE is trained using a single unified objective. Compared with the VAE, our IWAE is able to learn richer representations with more latent dimensions, which translates into significantly higher log-likelihoods on density estimation benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>In this section, we review the variational autoencoder (VAE) model of . In particular, we describe a generalization of the architecture to multiple stochastic hidden layers. We note, however, that  used a single stochastic hidden layer, and there are other sensible generalizations to multiple layers, such as the one presented by <ref type="bibr" target="#b24">Rezende et al. (2014)</ref>.</p><p>The VAE defines a generative process in terms of ancestral sampling through a cascade of hidden layers:</p><formula xml:id="formula_0">p(x|θ) = h 1 ,...,h L p(h L |θ)p(h L−1 |h L , θ) • • • p(x|h 1 , θ).<label>(1)</label></formula><p>Here, θ is a vector of parameters of the variational autoencoder, and h = {h 1 , . . . , h L } denotes the stochastic hidden units, or latent variables. The dependence on θ is often suppressed for clarity. For convenience, we define h 0 = x. Each of the terms p(h |h +1 ) may denote a complicated nonlinear relationship, for instance one computed by a multilayer neural network. However, it is assumed that sampling and probability evaluation are tractable for each p(h |h +1 ). Note that L denotes the number of stochastic hidden layers; the deterministic layers are not shown explicitly here. We assume the recognition model q(h|x) is defined in terms of an analogous factorization:</p><formula xml:id="formula_1">q(h|x) = q(h 1 |x)q(h 2 |h 1 ) • • • q(h L |h L−1 ),<label>(2)</label></formula><p>where sampling and probability evaluation are tractable for each of the terms in the product.</p><p>In this work, we assume the same families of conditional probability distributions as . In particular, the prior p(h L ) is fixed to be a zero-mean, unit-variance Gaussian.</p><p>In general, each of the conditional distributions p(h | h +1 ) and q(h |h −1 ) is a Gaussian with diagonal covariance, where the mean and covariance parameters are computed by a deterministic feed-forward neural network. For real-valued observations, p(x|h 1 ) is also defined to be such a Gaussian; for binary observations, it is defined to be a Bernoulli distribution whose mean parameters are computed by a neural network.</p><p>The VAE is trained to maximize a variational lower bound on the log-likelihood, as derived from Jensen's Inequality:</p><formula xml:id="formula_2">log p(x) = log E q(h|x) p(x, h) q(h|x) ≥ E q(h|x) log p(x, h) q(h|x) = L(x).<label>(3)</label></formula><p>Since</p><formula xml:id="formula_3">L(x) = log p(x) − D KL (q(h|x)||p(h|x))</formula><p>, the training procedure is forced to trade off the data log-likelihood log p(x) and the KL divergence from the true posterior. This is beneficial, in that it encourages the model to learn a representation where posterior inference is easy to approximate.</p><p>If one computes the log-likelihood gradient for the recognition network directly from Eqn. 3, the result is a REINFORCE-like update rule which trains slowly because it does not use the log-likelihood gradients with respect to latent variables <ref type="bibr" target="#b3">(Dayan et al., 1995;</ref>. Instead,  proposed a reparameterization of the recognition distribution in terms of auxiliary variables with fixed distributions, such that the samples from the recognition model are a deterministic function of the inputs and auxiliary variables. While they presented the reparameterization trick for a variety of distributions, for convenience we discuss the special case of Gaussians, since that is all we require in this work. (The general reparameterization trick can be used with our IWAE as well.)</p><p>In this paper, the recognition distribution q(h |h −1 , θ) always takes the form of a Gaussian N (h |µ(h −1 , θ), Σ(h −1 , θ)), whose mean and covariance are computed from the the states of the hidden units at the previous layer and the model parameters. This can be alternatively expressed by first sampling an auxiliary variable ∼ N (0, I), and then applying the deterministic mapping</p><formula xml:id="formula_4">h ( , h −1 , θ) = Σ(h −1 , θ) 1/2 + µ(h −1 , θ).</formula><p>(4) The joint recognition distribution q(h|x, θ) over all latent variables can be expressed in terms of a deterministic mapping h( , x, θ), with = ( 1 , . . . , L ), by applying Eqn. 4 for each layer in sequence. Since the distribution of does not depend on θ, we can reformulate the gradient of the bound L(x) from Eqn. 3 by pushing the gradient operator inside the expectation:</p><formula xml:id="formula_5">∇ θ log E h∼q(h|x,θ) p(x, h|θ) q(h|x, θ) = ∇ θ E 1 ,..., L ∼N (0,I) log p(x, h( , x, θ)|θ) q(h( , x, θ)|x, θ) (5) = E 1 ,..., L ∼N (0,I) ∇ θ log p(x, h( , x, θ)|θ) q(h( , x, θ)|x, θ) .<label>(6)</label></formula><p>Assuming the mapping h is represented as a deterministic feed-forward neural network, for a fixed , the gradient inside the expectation can be computed using standard backpropagation. In practice, one approximates the expectation in Eqn. 6 by generating k samples of and applying the Monte</p><formula xml:id="formula_6">Carlo estimator 1 k k i=1 ∇ θ log w (x, h( i , x, θ), θ)<label>(7)</label></formula><p>with w(x, h, θ) = p(x, h|θ)/q(h|x, θ). This is an unbiased estimate of ∇ θ L(x). We note that the VAE update and the basic REINFORCE-like update are both unbiased estimators of the same gradient, but the VAE update tends to have lower variance in practice because it makes use of the log-likelihood gradients with respect to the latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">IMPORTANCE WEIGHTED AUTOENCODER</head><p>The VAE objective of Eqn. 3 heavily penalizes approximate posterior samples which fail to explain the observations. This places a strong constraint on the model, since the variational assumptions must be approximately satisfied in order to achieve a good lower bound. In particular, the posterior distribution must be approximately factorial and predictable with a feed-forward neural network. This VAE criterion may be too strict; a recognition network which places only a small fraction (e.g. 20%) of its samples in the region of high posterior probability region may still be sufficient for performing accurate inference. If we lower our standards in this way, this may give us additional flexibility to train a generative network whose posterior distributions do not fit the VAE assumptions. This is the motivation behind our proposed algorithm, the Importance Weighted Autoencoder (IWAE).</p><p>Our IWAE uses the same architecture as the VAE, with both a generative network and a recognition network. The difference is that it is trained to maximize a different lower bound on log p(x). In particular, we use the following lower bound, corresponding to the k-sample importance weighting estimate of the log-likelihood:</p><formula xml:id="formula_7">L k (x) = E h1,...,h k ∼q(h|x) log 1 k k i=1 p(x, h i ) q(h i |x) .<label>(8)</label></formula><p>Here, h 1 , . . . , h k are sampled independently from the recognition model. The term inside the sum corresponds to the unnormalized importance weights for the joint distribution, which we will denote as</p><formula xml:id="formula_8">w i = p(x, h i )/q(h i |x).</formula><p>This is a lower bound on the marginal log-likelihood, as follows from Jensen's Inequality and the fact that the average importance weights are an unbiased estimator of p(x):</p><formula xml:id="formula_9">L k = E log 1 k k i=1 w i ≤ log E 1 k k i=1 w i = log p(x),<label>(9)</label></formula><p>where the expectations are with respect to q(h|x).</p><p>It is perhaps unintuitive that importance weighting would be a reasonable estimator in high dimensions. Observe, however, that the special case of k = 1 is equivalent to the standard VAE objective shown in Eqn. 3. Using more samples can only improve the tightness of the bound:</p><p>Theorem 1. For all k, the lower bounds satisfy</p><formula xml:id="formula_10">log p(x) ≥ L k+1 ≥ L k . (10)</formula><p>Moreover, if p(h, x)/q(h|x) is bounded, then L k approaches log p(x) as k goes to infinity.</p><p>Proof. See Appendix A.</p><p>The bound L k can be estimated using the straightforward Monte Carlo estimator, where we generate samples from the recognition network and average the importance weights. One might worry about the variance of this estimator, since importance weighting famously suffers from extremely high variance in cases where the proposal and target distributions are not a good match. However, as our estimator is based on the log of the average importance weights, it does not suffer from high variance. This argument is made more precise in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">TRAINING PROCEDURE</head><p>To train an IWAE with a stochastic gradient based optimizer, we use an unbiased estimate of the gradient of L k , defined in Eqn. 8. As with the VAE, we use the reparameterization trick to derive a low-variance upate rule:</p><formula xml:id="formula_11">∇ θ L k (x) = ∇ θ E h 1 ,...,h k log 1 k k i=1 wi = ∇ θ E 1 ,..., k log 1 k k i=1 w(x, h(x, i, θ), θ) (11) = E 1 ,..., k ∇ θ log 1 k k i=1 w(x, h(x, i, θ), θ) (12) = E 1 ,..., k k i=1 wi∇ θ log w(x, h(x, i, θ), θ) ,<label>(13)</label></formula><p>where 1 , . . . , k are the same auxiliary variables as defined in Section 2 for the VAE,</p><formula xml:id="formula_12">w i = w(x, h(x, i , θ), θ)</formula><p>are the importance weights expressed as a deterministic function, and</p><formula xml:id="formula_13">w i = w i / k i=1</formula><p>w i are the normalized importance weights. In the context of a gradient-based learning algorithm, we draw k samples from the recognition network (or, equivalently, k sets of auxiliary variables), and use the Monte Carlo estimate of Eqn. 13:</p><formula xml:id="formula_14">k i=1 w i ∇ θ log w (x, h( i , x, θ), θ) .<label>(14)</label></formula><p>In the special case of k = 1, the single normalized weight w 1 takes the value 1, and one obtains the VAE update rule.</p><p>We unpack this update because it does not quite parallel that of the standard VAE. <ref type="bibr">1</ref> The gradient of the log weights decomposes as:</p><formula xml:id="formula_15">∇ θ log w(x, h(x, i , θ), θ) = ∇ θ log p(x, h(x, i , θ)|θ) − ∇ θ log q(h(x, i , θ)|x, θ).<label>(15)</label></formula><p>The first term encourages the generative model to assign high probability to each h given h +1 (following the convention that x = h 0 ). It also encourages the recognition network to adjust the hidden representations so that the generative network makes better predictions. In the case of a single stochastic layer (i.e. L = 1), the combination of these two effects is equivalent to backpropagation in a stochastic autoencoder. The second term of this update encourages the recognition network to have a spread-out distribution over predictions. This update is averaged over the samples with weight proportional to the importance weights, motivating the name "importance weighted autoencoder."</p><p>The dominant computational cost in IWAE training is computing the activations and parameter gradients needed for ∇ θ log w(x, h(x, i , θ), θ). This corresponds to the forward and backward passes in backpropagation. In the basic IWAE implementation, both passes must be done independently for each of the k samples. Therefore, the number of operations scales linearly with k. In our GPU-based implementation, the samples are processed in parallel by replicating each training example k times within a mini-batch.</p><p>One can greatly reduce the computational cost by adding another form of stochasticity. Specifically, only the forward pass is needed to compute the importance weights. The sum in Eqn. 14 can be stochastically approximated by choosing a single sample i proprtional to its normalized weight w i and then computing ∇ θ log w(x, h(x, i , θ), θ). This method requires k forward passes and one backward pass per training example. Since the backward pass requires roughly twice as many addmultiply operations as the forward pass, for large k, this trick reduces the number of add-multiply operations by roughly a factor of 3. This comes at the cost of increased variance in the updates, but empirically we have found the tradeoff to be favorable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>There are several broad families of approaches to training deep generative models. Some models are defined in terms of Boltzmann distributions <ref type="bibr">(Smolensky, 1986;</ref><ref type="bibr" target="#b25">Salakhutdinov &amp; E., 2009)</ref>. This has the advantage that many of the conditional distributions are tractable, but the inability to sample from the model or compute the partition function has been a major roadblock <ref type="bibr">(Salakhutdinov &amp; Murray, 2008)</ref>. Other models are defined in terms of belief networks <ref type="bibr" target="#b22">(Neal, 1992;</ref><ref type="bibr" target="#b8">Gregor et al., 2014)</ref>. These models are tractable to sample from, but the conditional distributions become tangled due to the explaining away effect.</p><p>One strategy for dealing with intractable posterior inference is to train a recognition network which approximates the posterior. A classic approach was the wake-sleep algorithm, used to train Helmholtz machines <ref type="bibr" target="#b3">(Dayan et al., 1995</ref>). The generative model was trained to model the conditionals inferred by the recognition net, and the recognition net was trained to explain synthetic data generated by the generative net. Unfortunately, wake-sleep trained the two networks on different objective functions. Deep autoregressive networks <ref type="bibr" target="#b8">(Gregor et al., 2014)</ref> consisted of deep generative and recognition networks trained using a single variational lower bound. Neural variational inference and learning  is another algorithm for training recognition networks which reduces stochasticity in the updates by training a third network to predict reward baselines in the context of the REINFORCE algorithm <ref type="bibr">(Williams, 1992)</ref>. <ref type="bibr" target="#b26">Salakhutdinov &amp; Larochelle (2010)</ref> used a recognition network to approximate the posterior distribution in deep Boltzmann machines.</p><p>Variational autoencoders <ref type="bibr" target="#b24">Rezende et al., 2014)</ref>, as described in detail in Section 2, are another combination of generative and recognition networks, trained with the same variational objective as DARN and NVIL. However, in place of REINFORCE, they reduce the variance of the updates through a clever reparameterization of the random choices. The reparameterization trick is also known as "backprop through a random number generator" (Williams, 1992).</p><p>One factor distinguishing VAEs from the other models described above is that the model is described in terms of a simple distribution followed by a deterministic mapping, rather than a sequence of stochastic choices. Similar architectures have been proposed which use different training objectives. Generative adversarial networks <ref type="bibr" target="#b7">(Goodfellow et al., 2014</ref>) train a generative network and a recognition network which act in opposition: the recognition network attempts to distinguish between training examples and generated samples, and the generative model tries to generate samples which fool the recognition network. Maximum mean discrepancy (MMD) networks <ref type="bibr" target="#b19">(Li et al., 2015;</ref><ref type="bibr" target="#b4">Dziugaite et al., 2015)</ref> attempt to generate samples which match a certain set of statistics of the training data. They can be viewed as a kind of adversarial net where the adversary simply looks at the set of pre-chosen statistics <ref type="bibr" target="#b4">(Dziugaite et al., 2015)</ref>. In contrast to VAEs, the training criteria for adversarial nets and MMD nets are not based on the data log-likelihood.</p><p>Other researchers have derived log-probability lower bounds by way of importance sampling. Tang &amp; <ref type="bibr" target="#b16">Salakhutdinov (2013)</ref> and <ref type="bibr" target="#b0">Ba et al. (2015)</ref> avoided recognition networks entirely, instead performing inference using importance sampling from the prior. <ref type="bibr" target="#b6">Gogate et al. (2007)</ref> presented a variety of graphical model inference algorithms based on importance weighting. Reweighted wake-sleep (RWS) of <ref type="bibr" target="#b1">Bornschein &amp; Bengio (2015)</ref> is another recognition network approach which combines the original wake-sleep algorithm with updates to the generative network equivalent to gradient ascent on our bound L k . However, <ref type="bibr" target="#b1">Bornschein &amp; Bengio (2015)</ref> interpret this update as following a biased estimate of ∇ θ log p(x), whereas we interpret it as following an unbiased estimate of ∇ θ L k . The IWAE also differs from RWS in that the generative and recognition networks are trained to maximize a single objective, L k . By contrast, the q-wake and sleep steps of RWS do not appear to be related to L k . Finally, the IWAE differs from RWS in that it makes use of the reparameterization trick.</p><p>Apart from our approach of using multiple approximate posterior samples, another way to improve the flexibility of posterior inference is to use a more sophisticated algorithm than importance sampling. Examples of this approach include normalizing flows <ref type="bibr" target="#b23">(Rezende &amp; Mohamed, 2015)</ref>  After the publication of this paper the authors learned that the idea of using an importance weighted lower bound for training variational autoencoders has been independently explored by Laurent Dinh and Vincent Dumoulin, and preliminary results of their work were presented at the 2014 CIFAR NCAP Deep Learning summer school.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head><p>We have compared the generative performance of the VAE and IWAE in terms of their held-out loglikelihoods on two density estimation benchmark datasets. We have further investigated a particular issue we have observed with VAEs and IWAEs, namely that they learn latent spaces of significantly lower dimensionality than the modeling capacity they are allowed. We tested whether the IWAE training method ameliorates this effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">EVALUATION ON DENSITY ESTIMATION</head><p>We evaluated the models on two benchmark datasets: MNIST, a dataset of images of handwritten digits <ref type="bibr" target="#b18">(LeCun et al., 1998)</ref>, and Omniglot, a dataset of handwritten characters in a variety of world alphabets <ref type="bibr" target="#b16">(Lake et al., 2013)</ref>. In both cases, the observations were binarized × 28 images. <ref type="bibr">2</ref> We used the standard splits of MNIST into 60,000 training and 10,000 test examples, and of Omniglot into 24,345 training and 8,070 test examples.</p><p>We trained models with two architectures:</p><p>1. An architecture with a single stochastic layer h 1 with 50 units. In between the observations and the stochastic layer were two deterministic layers, each with 200 units.</p><p>2. An architecture with two stochastic layers h 1 and h 2 , with 100 and 50 units, respectively. In between x and h 1 were two deterministic layers with 200 units each. In between h 1 and h 2 were two deterministic layers with 100 units each.</p><p>All deterministic hidden units used the tanh nonlinearity. All stochastic layers used Gaussian distributions with diagonal covariance, with the exception of the visible layer, which used Bernoulli distributions. An exp nonlinearity was applied to the predicted variances of the Gaussian distributions. The network architectures are summarized in Appendix C.</p><p>All models were initialized with the heuristic of <ref type="bibr" target="#b5">Glorot &amp; Bengio (2010)</ref>. For optimization, we used Adam <ref type="bibr" target="#b12">(Kingma &amp; Ba, 2015)</ref> with parameters β 1 = 0.9, β 2 = 0.999, = 10 −4 and minibaches of size 20. The training proceeded for 3 i passes over the data with learning rate of 0.001 • 10 −i/7 for i = 0 . . . 7 (for a total of 7 i=0 3 i = 3280 passes over the data). This learning rate schedule was chosen based on preliminary experiments training a VAE with one stochastic layer on MNIST.</p><p>Unfortunately, the generative modeling literature is inconsistent about the method of binarization, and different choices can lead to considerably different log-likelihood values. We follow the procedure of <ref type="bibr">Salakhutdinov &amp; Murray (2008)</ref>: the binary-valued observations are sampled with expectations equal to the real values in the training set. See Appendix D for an alternative binarization scheme.  <ref type="table">Table 1</ref>: Results on density estimation and the number of active latent dimensions. For models with two latent layers, "k1+k2" denotes k1 active units in the first layer and k2 in the second layer. The generative performance of IWAEs improved with increasing k, while that of VAEs benefitted only slightly. Two-layer models achieved better generative performance than one-layer models.</p><p>For each number of samples k ∈ {1, 5, 50} we trained a VAE with the gradient of L(x) estimted as in Eqn. 7 and an IWAE with the gradient estimated as in Eqn. 14. For each k, the VAE and the IWAE were trained for approximately the same length of time.</p><p>All log-likelihood values were estimated as the mean of L 5000 on the test set. Hence, the reported values are stochastic lower bounds on the true value, but are likely to be more accurate than the lower bounds used for training.</p><p>The log-likelihood results are reported in <ref type="table">Table 1</ref>. Our VAE results are comparable to those previously reported in the literature. We observe that training a VAE with k &gt; 1 helped only slightly. By contrast, using multiple samples improved the IWAE results considerably on both datasets. Note that the two algorithms are identical for k = 1, so the results ought to match up to random variability.</p><p>On MNIST, IWAE with two stochastic layers and k = 50 achieves a log-likelihood of -82.90 on the permutation-invariant model on this dataset. By comparison, deep belief networks achieved loglikelihood of approximately -84.55 nats <ref type="bibr" target="#b21">(Murray &amp; Salakhutdinov, 2009)</ref>, and deep autoregressive networks achieved log-likelihood of -84.13 nats <ref type="bibr" target="#b8">(Gregor et al., 2014)</ref>. <ref type="bibr" target="#b9">Gregor et al. (2015)</ref>, who exploited spatial structure, achieved a log-likelihood of -80.97. We did not find overfitting to be a serious issue for either the VAE or the IWAE: in both cases, the training log-likelihood was 0.62 to 0.79 nats higher than the test log-likelihood. We present samples from our models in Appendix E.</p><p>For the OMNIGLOT dataset, the best performing IWAE has log-likelihood of -103.38 nats, which is slightly worse than the log-likelihood of -100.46 nats achieved by a Restricted Boltzmann Machine with 500 hidden units trained with persistent contrastive divergence <ref type="bibr" target="#b2">(Burda et al., 2015)</ref>. RBMs trained with centering or FANG methods achieve a similar performance of around -100 nats <ref type="bibr" target="#b10">(Grosse &amp; Salakhudinov, 2015)</ref>. The training log-likelihood for the models we trained was 2.39 to 2.65 nats higher than the test log-likelihood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">LATENT SPACE REPRESENTATION</head><p>We have observed that both VAEs and IWAEs tend to learn latent representations with effective dimensions far below their capacity. Our next set of experiments aimed to quantify this effect and determine whether the IWAE objective ameliorates this effect.</p><p>If a latent dimension encodes useful information about the data, we would expect its distribution to change depending on the observations. Based on this intuition, we measured activity of a latent dimension u using the statistic A u = Cov x E u∼q(u|x) <ref type="bibr">[u]</ref> . We defined the dimension u to be active if A u &gt; 10 −2 . We have observed two pieces of evidence that this criterion is both well-defined and meaningful:</p><p>1. The distribution of A u for a trained model consisted of two widely separated modes, as shown in Appendix C.  2. To confirm that the inactive dimensions were indeed insignificant to the predictions, we evaluated all models with the inactive dimensions removed. In all cases, this changed the test log-likelihood by less than 0.06 nats.</p><p>In <ref type="table">Table 1</ref>, we report the numbers of active units for all conditions. In all conditions, the number of active dimensions was far less than the total number of dimensions. Adding more latent dimensions did not increase the number of active dimensions. Interestingly, in the two-layer models, the second layer used very little of its modeling capacity: the number of active dimensions was always less than 10. In all cases with k &gt; 1, the IWAE learned more latent dimensions than the VAE. Since this coincided with higher log-likelihood values, we speculate that a larger number of active dimensions reflects a richer latent representation.</p><p>Superficially, the phenomenon of inactive dimensions appears similar to the problem of "units dying out" in neural networks and latent variable models, an effect which is often ascribed to difficulties in optimization. For example, if a unit is inactive, it may never receive a meaningful gradient signal because of a plateau in the optimization landscape. In such cases, the problem may be avoided through a better initialization. To determine whether the inactive units resulted from an optimization issue or a modeling issue, we took the best-performing VAE and IWAE models from <ref type="table">Table 1</ref>, and continued training the VAE model using the IWAE objective and vice versa. In both cases, the model was trained for an additional 3 7 passes over the data with a learning rate of −4 .</p><p>The results are shown in <ref type="table" target="#tab_2">Table 2</ref>. We found that continuing to train the VAE with the IWAE objective increased the number of active dimensions and the test log-likelihood, while continuing to train the IWAE with the VAE objective did the opposite. The fact that training with the VAE objective actively reduces both the number of active dimensions and the log-likelihood strongly suggests that inactivation of the latent dimensions is driven by the objective functions rather than by optimization issues. On the other hand, optimization also appears to play a role, as the results in <ref type="table" target="#tab_2">Table 2</ref> are not quite identical to those in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we presented the importance weighted autoencoder, a variant on the VAE trained by maximizing a tighter log-likelihood lower bound derived from importance weighting. We showed empirically that IWAEs learn richer latent representations and achieve better generative performance than VAEs with equivalent architectures and training time. We believe this method may improve the flexibility of other generative models currently trained with the VAE objective. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A</head><p>Proof of Theorem 1. We need to show the following facts about the log-likelihood lower bound L k :</p><formula xml:id="formula_16">1. log p(x) ≥ L k , 2. L k ≥ L m for k ≥ m, 3. log p(x) = lim k→∞ L k , assuming p(h, x)/q(h|x) is bounded.</formula><p>We prove each in turn:</p><p>1. It follows from Jensen's inequality that</p><formula xml:id="formula_17">L k = E log 1 k k i=1 p(x, h i ) q(h i |x) ≤ log E 1 k k i=1 p(x, h i ) q(h i |x) = log p(x)<label>(16)</label></formula><p>2. Let I ⊂ {1, . . . , k} with |I| = m be a uniformly distributed subset of distinct indices from {1, . . . , k}. We will use the following simple observation: E I={i1,...,im}</p><formula xml:id="formula_18">ai 1 +...+ai m m = a1+...+a k k</formula><p>for any sequence of numbers a 1 , . . . , a k . Using this observation and Jensen's inequality, we get</p><formula xml:id="formula_19">L k = E h1,...,h k log 1 k k i=1 p(x, h i ) q(h i |x) (17) = E h1,...,h k   log E I={i1,...,im}   1 m m j=1 p(x, h ij ) q(h ij |x)     (18) ≥ E h1,...,h k   E I={i1,...,im}   log 1 m m j=1 p(x, h ij ) q(h ij |x)     (19) = E h1,...,hm log 1 m m i=1 p(x, h i ) q(h i |x) = L m<label>(20)</label></formula><p>3. Consider the random variable</p><formula xml:id="formula_20">M k = 1 k k i=1 p(x,hi) q(hi|x) . If p(h, x)/q(h|x)</formula><p>is bounded, then it follows from the strong law of large numbers that M k converges to E q(hi|x)</p><formula xml:id="formula_21">p(x,hi) q(hi|x) = p(x) almost surely. Hence L k = E log[M k ] converges to log p(x) as k → ∞.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B</head><p>It is well known that the variance of an unnormalized importance sampling based estimator can be extremely large, or even infinite, if the proposal distribution is not well matched to the target distribution. Here we argue that the Monte Carlo estimator of L k , described in Section 3, does not suffer from large variance. More precisely, we bound the mean absolute deviation (MAD). While this does not directly bound the variance, it would be surprising if an estimator had small MAD yet extremely large variance.</p><p>Suppose we have a strictly positive unbiased estimatorẐ of a positive quantity Z, and we wish to use logẐ as an estimator of log Z. By Jensen's inequality, this is a biased estimator, i.e. E[logẐ] ≤ log Z. Denote the bias as δ = log Z − E[logẐ]. We start with the observation that logẐ is unlikely to overestimate log Z by very much, as can be shown with Markov's Inequality:</p><formula xml:id="formula_22">Pr(logẐ &gt; log Z + b) ≤ e −b .<label>(21)</label></formula><p>Let (X) + denote max(X, 0). We now use the above facts to bound the MAD:</p><formula xml:id="formula_23">E logẐ − E[logẐ] = 2E logẐ − E[logẐ] + (22) = 2E logẐ − log Z + log Z − E[logẐ] + (23) ≤ 2E logẐ − log Z + + log Z − E[logẐ] + (24) = 2E logẐ − log Z + + 2δ (25) = 2 ∞ 0 Pr logẐ − log Z &gt; t dt + 2δ (26) ≤ 2 ∞ 0 e −t dt + 2δ (27) = 2 + 2δ<label>(28)</label></formula><p>Here, (22) is a general formula for the MAD, (26) uses the formula E[Y ] = ∞ 0 Pr(Y &gt; t) dt for a nonnegative random variable Y , and (27) applies the bound (21). Hence, the MAD is bounded by 2 + 2δ. In the context of IWAE, δ corresponds to the gap between L k and log p(x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C NETWORK ARCHITECTURES</head><p>Here is a summary of the network architectures used in the experiments: In Section 5.2, we defined the activity statistic A u = Cov x E u∼q(u|x) <ref type="bibr">[u]</ref> , and chose a threshold of 10 −2 for determining if a unit is active. One justification for this is that the distribution of this statistic consisted of two widely separated modes in every case we looked at. Here is the histogram of log A u for a VAE with one stochastic layer: </p><formula xml:id="formula_24">q(h 1 |x) = N (h 1 |µ q,1 , diag(σ q,1 )) x 200d 200d µ q,1 σ q,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VISUALIZATION OF POSTERIOR DISTRIBUTIONS</head><p>We show some examples of true and approximate posteriors for VAE and IWAE models trained with two latent dimensions. Heat maps show true posterior distributions for 6 training examples, and the pictures in the bottom row show the examples and their reconstruction from samples from q(h|x). Left: VAE. Middle: IWAE, with k = 5. Right: IWAE, with k = 50. The IWAE prefers less regular posteriors and more spread out posterior predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX D RESULTS FOR A FIXED MNIST BINARIZATION</head><p>Several previous works have used a fixed binarization of the MNIST dataset defined by <ref type="bibr" target="#b17">Larochelle (2011)</ref>. We repeated our experiments training the models on the 50000 examples from the training dataset, and evaluating them on the 10000 examples from the test dataset. Otherwise we used the same training procedure and hyperparameters as in the experiments in the main part of the paper.  <ref type="table">Table 3</ref>: Results on density estimation and the number of active latent dimensions on the fixed binarization MNIST dataset. For models with two latent layers, "k1 + k2" denotes k1 active units in the first layer and k2 in the second layer. The generative performance of IWAEs improved with increasing k, while that of VAEs benefitted only slightly. Two-layer models achieved better generative performance than one-layer models. <ref type="table">Table 4</ref>: Random samples from VAE (left column) and IWAE with k = 50 (right column) models. Row 1: models with one stochastic layer. Row 2: models with two stochastic layers. Samples are represented as the means of the corresponding Bernoulli distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX E SAMPLES</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and the Hamiltonian variational approximation of Salimans et al. (2015).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results of continuing to train a VAE model with the IWAE objective, and vice versa. Training the VAE with the IWAE objective increased the latent dimension and test log-likelihood, while training the IWAE with the VAE objective had the opposite effect.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Salakhutdinov, R. and Murray, I. On the quantitative analysis of deep belief networks. In International Conference on Machine Learning, 2008. Salimans, T., Kingma, D. P., and Welling, M. Markov chain Monte Carlo and variational inference: bridging the gap. In International Conference on Machine Learning, pp. 1218-1226, 2015.</figDesc><table><row><cell>Smolensky, P. Information processing in dynamical systems: foundations of harmony theory. In Rumelhart,</cell></row><row><cell>D. E. and McClelland, J. L. (eds.), Parallel Distributed Processing: Explorations in the Microstructure of</cell></row><row><cell>Cognition. MIT Press, 1986.</cell></row><row><cell>Tang, Y. and Salakhutdinov, R. Learning stochastic feedforward neural networks. In Neural Information</cell></row><row><cell>Processing Systems, 2013.</cell></row><row><cell>Williams, R. J. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Ma-</cell></row><row><cell>chine Learning, 8:229-256, 1992.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>The results in table 3 indicate that the conclusions about the relative merits of VAEs and IWAEs are unchanged in the new experimental setup. In this setup we noticed significantly larger amounts of overfitting.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">VAE</cell><cell cols="2">IWAE</cell></row><row><cell># stoch.</cell><cell></cell><cell></cell><cell>active</cell><cell></cell><cell>active</cell></row><row><cell>layers</cell><cell>k</cell><cell>NLL</cell><cell>units</cell><cell>NLL</cell><cell>units</cell></row><row><cell>1</cell><cell>1</cell><cell>88.71</cell><cell>19</cell><cell>88.71</cell><cell>19</cell></row><row><cell></cell><cell>5</cell><cell>88.83</cell><cell>19</cell><cell>87.63</cell><cell>22</cell></row><row><cell></cell><cell cols="2">50 89.05</cell><cell>20</cell><cell>87.10</cell><cell>24</cell></row><row><cell></cell><cell>1</cell><cell cols="4">88.08 16+5 88.08 16+5</cell></row><row><cell></cell><cell>5</cell><cell cols="4">87.63 17+5 86.17 21+5</cell></row><row><cell></cell><cell cols="5">50 87.86 17+6 85.32 24+7</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1"> separated out the KL divergence in the bound of Eqn. 3 in order to achieve a simpler and lower-variance update. Unfortunately, no analogous trick applies for k &gt; 1. In principle, the IWAE updates may be higher variance for this reason. However, in our experiments, we observed that the performance of the two update rules was indistinguishable in the case of k = 1.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGEMENTS</head><p>This research was supported by NSERC, the Fields Institute, and Samsung.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiple object recognition with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bornschein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Reweighted wake</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Accurate and conservative estimates of MRF log-likelihood using reverse annealing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="102" to="110" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Helmholtz machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Training generative neural networks via maximum mean discrepancy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="249" to="256" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Studies in lower bounding probability of evidence using the Markov inequality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gogate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bidyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dechter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<title level="m">Deep autoregressive networks. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">DRAW: A recurrent neural network for image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1462" to="1471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scaling up natural gradient by sparsely factorizing the inverse fisher matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhudinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Whitney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.03167</idno>
		<title level="m">Deep convolutional inverse graphics network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">One-shot learning by inverting a compositional causal process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="29" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generative moment matching networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1718" to="1727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1791" to="1799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluating probabilities under high-dimensional latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1137" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Connectionist learning of belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1530" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep Boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient learning of deep Boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
