[{"id": 1000, "pred": "we consider a practically motivated scenario , in which we want to leverage existing resources from a resource-rich language ( like english ) when building tools for resource-poor foreign languages . to this end , we construct a bilingual graph over word types to establish a connection between the two languages , and then use graph label propagation to project syntactic information from english to the foreign language . \n second , we treat the projected labels as features in an unsuper- 1for simplicity of exposition we refer to the resource-poor language as the foreign language . similarly , we use english as the resource-rich language , but any other language with labeled resources could be used instead . we evaluate our approach on eight european languages , and show that both our contributions provide consistent and statistically significant improvements . our final average pos tagging accuracy of compares very favorably to the average accuracy of supervised pos tagging , and considerably bridges the gap to fully supervised pos tagging performance ( 96.6 ) . this paper presents the design and evaluation of an unsupervised foreign language pos tagger , based on a feature - based hmm and a graph - based approach . \n our objective is to provide a high - quality pos tagger for a large number of languages in which no labeled resources are available . to this end \n , we first extract a vector tag from the treebanks of every language . \n we then use this vector tag to prune hidden states that are inconsistent with the thresholded tag . \n finally , we use this vector tag to train a supervised hmm on the treebanks of every language . \n our full model outperforms the hitherto state - of - the - art hmm baselines , and performs better than the no lp and unsupervised baselines , when we macro - average over all languages ."}, {"id": 1001, "pred": "this paper presents a novel approach for representation of sequences using a recurrent neural network ( rnn ) . \n the rnn is trained to predict the next element of a sequence , given the previous elements . \n the new representation is sensitive to ordering and therefore mitigates the disadvantage of using the standard fisher vector ( fv ) representation . \n it is applied to two different tasks : video action recognition and image annotation by sentences . in both tasks , \n the proposed rnn-fv method is used for the representation of sentences and achieves state-of-the - art results on the hmdb51 and ucf101 datasets . in image annotation and image search , the rnn-fv method is used for the representation of sentences and achieves state-of-the - art results on the flickr8k dataset and competitive results on other benchmarks . in this paper , we present a new approach to video classification based on the gradient of a loss function . \n this loss function is not used to update the network s weights , and hence it is not a generative model . instead , it is used as a feature vector extractor for new sequences . \n experiments on two large action recognition benchmarks show that the proposed approach is competitive with state - of - the - art loss functions .  \n convolutional neural network , vector space this paper presents the first results on the bidirectional image and video action recognition transfer benchmark ( ucf101 and hmdb51 ) . \n the state of the art is hmdb51 , which is above current state of the art on the same dataset . \n we introduce a novel feature representation , rnn-fv , which is sensitive to the element ordering in the sequence and provides a richer model than the additive bag model typically used for conventional fvs . \n when used for representing sentences , the rnnfv representation achieves state-of-the - art or competitive results on image annotation and image search tasks . \n a transfer learning result from the image annotation task to the video action recognition task is shown . \n this result supports a human development - like way of training , in which visual labeling is learned through natural language , as opposed to , e.g. , associating bounding boxes with nouns ."}, {"id": 1002, "pred": "the rate of publications of scientific papers is increasing and it is almost impossible for re- searchers to keep up with relevant research . in general , there are two com- mon approaches to summarizing scientific papers : citations- based , and content- based , based on the paper itself . \n recently , academic conferences started publishing talks ( e.g. , acl , naacl , emnlp1 , icml2 , and more ) . in such talks , the presenter ( usually a co- author ) must describe their paper coherently and concisely ( since there is a time limit ) , provid- ing a good basis for generating extractive summaries . based on this idea , in this paper , we propose a new method , talksumm ( acronym for talk- based summarization ) , to automatically generate extractive content-based summaries for scientific papers based on video talks . our approach uti- lizes the transcripts of video talks , and treat them as spoken summaries of pa- pers . then , using unsupervised alignment , we create extractive summaries for papers from several computer science conferences , that can be this paper presents a novel approach for automatic gener- ate summarization of conference talks . \n we propose an els model trained on automatically generated conference talks , which is able to achieve competitive results compared to state - of - the - art mod- els trained over scisummnet . \n we also show that our model , trained on automatically generated summaries , performs on par with gcn cited text spans and abstract8"}, {"id": 1003, "pred": "this work studies the use of pretrained word vectors for emotion detection from text . \n we propose an ensemble approach that combines both a linear model based on bag-of - words ( bow ) 1url , and a non - linear model based on pretrained word vectors . \n in addition , we propose a new method for realizing a sentence level representation from the single words vectors . \n our results show that combining bow and embedded document representations using pretrained word vectors outperforms previous approaches for text classi cation including pretrained representations based on word2vec and glove algorithms ."}, {"id": 1004, "pred": "social media are becoming an important part of customer service . yet there are limited tools for assessing this . in this paper , we analyze customer support dialogues using the twitter platform and show the utility of such analyses . \n the particular aspect of such dialogues that we concentrate on is emotions . \n emotions are a cardinal aspect of inter- personal communication : they are an implicit or explicit part of essentially any communication , and of particular importance in the setting of customer service , as they relate directly to customer satisfaction and experience . \n typical emotions expressed by customers in the context of social media service dialogues include anger and frustration , as well as gratitude and more . on the other hand , customer service agents also express emotions in service conversations , for example apologize or empathy . \n thus , the analysis of emotions expressed in service conversations can take two applications : ( 1 ) to discern and compute quality of service indicators and ( 2 ) to provide real - time clues to customer service agents regarding the cus- service-barometer . in this paper , we focus on the problem of emotion detection and classification in social media . we propose a novel approach for emotion detection and classification in social media , based on the timeline of a dialogue . \n the timeline of a dialogue is represented by a feature vector representing the turn of a customer or an agent . \n this feature is extracted from the past turn timeline using a variety of state - of - the - art text - based features . \n we propose two models for emotion detection and classification in social media . \n our baseline model uses standard svm classifiers for emotion classification , while our baseline model uses state - of - the - art text - based classifiers for emotion detection . \n we evaluate the performance of our models on two tasks : 1 ) the detection of emotions in agent turns , and 2 ) the detection of emotions in customer turns . \n our results show that the svm-hmm classifier outperforms the baseline model , in terms of both macro and micro average f1-scores ."}, {"id": 1005, "pred": "in this paper , we explore methods for neural architecture search ( nas ) , their meta-adaptation and optimization for few-shot classification ( fsc ) . in particular , we show how differentiable architecture search ( d-nas ) , combined with a set of metadapt controllers , can be used to learn a specialized backbone architecture for few-shot classification ( fsc ) with novel n categories . using this architecture , \n fsc performance can be significantly improved w.r.t . \n the backbone architecture . \n we also show that adding small neural networks , metadapt controllers , that adapt the connections in the main network further ( and significantly ) improves performance . \n using the proposed method , we obtain improvements over fsc state-of-the - art on two popular fsc benchmarks : miniimagenet and fc100 . in this paper , we propose a new approach for few - shot architecture search , based on the idea of adapting a block of search space operations to the task at hand . \n the metadapt controller is used to predict , given a few - shot task , the best way of adapting the corresponding edge operations . \n experiments on both the miniimagenet and fc100 few - shot benchmarks show that our approach is competitive with state - of - the - art methods . \n we also show that our approach is able to transfer the adapted architecture to a larger dataset . \n we believe that this work will stimulate further research on few - shot architecture search .  \n @xmath0department of computer science , university of california , berkeley , ca 94720 . \n + @xmath1department of computer science , university of california , berkeley , ca 94720 . \n + @xmath2department of computer science , university of california , berkeley , ca 94720 . \n + @xmath3department of computer science , university of california , berkeley , ca 94720"}, {"id": 1006, "pred": "automated conversational agents ( chatbots ) are becoming widely used for various tasks such as personal assistants or customer service agents . due to the increasing prevalence of chatbots , even a small fraction of such egregious3 conversations could be problematic for the companies deploying and the providers of services . in this paper \n we study detecting these egregious conversations that can arise in numerous ways . \n for example , incomplete or internally inconsistent training data can lead to false classification of user intent . failure to maintain adequate context can lead to dead ends . still , \n a conversation may become egregious due to a combination of problems . \n such failure may include loss of customer goodwill and associated revenue , and even exposure to litigation if the failures can be shown to include fraudulent claims . \n consequences of these failures may include loss of customer goodwill and associated revenue , and even exposure to litigation if the failures can be shown to include fraudulent claims . in this paper , we focus on detecting egregious conversations in customer care systems . \n specifically , we consider customer inputs throughout a whole conversation , and detect cues such as rephrasing , the presence of heightened emotions , and queries about whether the agent is a human or requests to speak to an actual human . this paper presents an analysis of conversations between a customer and a virtual agent using a combination of qualitative and quantitative measures . \n specifically , we focus on the issue of egregiousness , i.e. , conversations that a virtual agent does not explain to a customer correctly , or that the agent does not explain to the customer in a way that is consistent with the customer s intent . to address this issue \n , we first train a rule - based classifier that is able to recognize whether a conversation is egregious or not . \n then , we use a text - based classifier that is able to recognize whether a conversation is egregious or not , based on the similarity between a conversation s turn and the response of the virtual agent . \n our results show that the text - based classifier is able to detect egregious conversations more accurately than the rule- or text - based classifiers . \n we also show that egregious conversations are more likely to be captured by the text - based classifier than by the rule- or text - based classifiers . \n finally , we show that the text - based classifier is able to capture more egregious conversations than the rule- or text - based classifiers ."}, {"id": 1007, "pred": "convolutional neural networks ( cnns ) have shown strong performance on natural language processing ( nlp ) tasks such as text classification . as with other architectures of neural networks , explaining the learned functionality of cnns is still an active research area . \n the problem of interpretability in machine learning can be divided into two concrete tasks : model interpretability aims to supply a structured explanation which captures what the model has learned , and prediction interpretability aims to explain how the model arrived at its prediction . in this work \n , we examine and attempt to understand how cnns process text , and then use this information for the more practical goals of improving model-level and prediction-level interpretability . \n we identify and refine current intuitions as to how cnns work . \n specifically , we show that max-pooling induces a thresholding behavior , and values below a given threshold are ignored when ( i.e. irrelevant to ) making a prediction . \n filters are not homogeneous , i.e. a single filter can , and often does , detect multiple distinctly different families of ngrams . \n filters also detect negative items in ngrams they not only select for a family we investigate the relationship between the linguistic patterns captured by a filter and its ability to identify good and bad ngrams . specifically , we show that a single filter s ability to identify good ngrams may be due to a systematic breakdown in how the filter activation patterns are maximized . \n we also show that filters may not only identify good ngrams , but may also actively supress bad ones . \n finally , we use our findings to suggest improvements to model- and prediction- based interpretability of cnns for text ."}, {"id": 1008, "pred": "in this work , we present editnet , a novel mixed extractive-abstractive summarization approach . a summary generated by editnet may include sentences that were either extracted , abstracted or of both types . moreover , per considered sentence , editnet may decide not to take either of these decisions and completely reject the sentence . using the cnn/dailymail dataset \n we demonstrate that , editnet s summarization quality is highly competitive to that obtained by both state-of-the - art abstractive-only and extractive-only baselines .  \n example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore in this paper , we propose a novel alternative summarization approach based on an aligned decoder network called editnet . \n editnet is an aligned decoder network that is designed to be used in conjunction with an alternative summarization approach . in particular , instead of applying solely an extraction or an abstraction approach to the summarization process , editnet mixes both together . \n moreover , editnet implements a novel sentence rejection decision , allowing to correct initial selection decisions which are predicted to negatively effect summarization quality ."}, {"id": 1009, "pred": "incorrect homophones and synophones , whether used in error or in grammar , pose challenges for a wide range of nlp tasks , such as named entity identification , text normalization and spelling correction . incorrect homophones and synophones , whether used in error or in grammar , pose challenges for a wide range of nlp tasks this paper presents dimsim , a chinese phonetic similarity learning algorithm for identifying phonetically similar words . \n we identify and account for several confounding factors that may affect annotation : 1 ) the position of the character containing the initial or final being compared ; 2 ) the word length ; and 3 ) the combination of initials and finals . \n we also incorporate a penalty function , p , for pairs deviating from the manually annotated distance so that more phonetically similar pairs are penalized more highly . \n we train our model using the all possible pinyins with component p1 such as ( b , p ) , bao and bing . for each pinyin \n py , we retrieve all the words with length two in the dictionary which also have first or second character with the same py . for each created word w , we change the initial ( or final ) from p1 to p2 , retrieve the corresponding words from the dictionary and generate word pairs with the lowest similarity . finally , from the full list we randomly select five word pairs vary the first character , and five word pairs that vary the second character . for each pair of finals ( or initials ) , we phonetic transcription is a widely observed phenomenon in chinese social media and informal language . \n we propose dimsim , a chinese phonetic similarity algorithm that generates phonetically similar candidate words based on learned encodings that capture the pronunciation characteristics of pinyin initial , final , and tone components . using a real world dataset , \n we demonstrate that dimsim effectively improves mrr by 7.5x , recall by 1.5x and precision by 1.4x over existing approaches ."}, {"id": 1010, "pred": "knowledge base question answering ( kbqa ) performs two key tasks : entity linking , which links n-grams in questions to kb entities , and relation detection , which identifies the kb relation ( s ) a question refers to . \n although general relation detection1 methods are well studied in the nlp community , such studies usually do not take the end task of kbqa into consideration . as a result , \n there is a significant gap between general relation detection studies and kb-specific relation detection . \n first , in most general relation detection tasks , the number of target relations is limited , normally smaller than in contrast , in kbqa even a small kb , like freebase2m , contains more than 6,000 relation types . \n second , relation detection for kbqa often becomes a zero - shot learning task , since some test instances may have unseen relations in the training data . \n third , for some kbqa tasks like webquestions , we need to predict a chain of relations instead of a single relation . \n this increases the number of target relation types and the sizes of candidate relation pools , further increasing the difficulty of  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ kb relation detection is a key step in kbqa and is significantly different from general relation extraction tasks . \n we propose a novel kb relation detection model , hr-bilstm , that performs hierarchical matching between questions and kb relations . \n our model outperforms the previous methods on kb relation detection tasks and allows our kbqa system to achieve state-of-the - art results ."}, {"id": 1011, "pred": "in this work we propose a feature agnostic approach for dictionary expansion based on neural language models , such as word2vec to prevent semantic drift during the dictionary expansion , we effectively include humanin-the-loop ( huml ) . given an input corpus and a set of examples , the proposed runs in two phases , the proposed runs in two phases , i.e. , the exploit phase tries to identify similar instances to the dictionary , and the explore phase tries to construct more complex multi-term phrases based on the instances already in the input dictionary . this paper presents an interactive dictionary expansion tool based on a neural language model . \n our algorithm is iterative and purely statistical , hence does not require any feature extraction beyond tokenization . \n it incorporates human feedback to improve performance and control semantic drift at every iteration cycle . \n the experiments show high importance of tight huml integration on discovery efficiency ."}, {"id": 1012, "pred": "we present an interpretable mechanism for grounding of textual phrases , i.e. , finding bounding boxes in images which relate to textual phrases . \n our approach is based on a number of image concepts , such as semantic segmentations , fitnesss and priors for any number of objects of interest . based on those image concepts , we formulate textual grounding as a search over all possible bounding boxes . \n we find the bounding box with highest accumulated score contained in its interior . \n the search for this box can be solved via an efficient branch and bound 31st conference on neural information processing systems ( nips 2017 ) . \n we evaluate our proposed approach on the referitgame and flickr 30k entities dataset 35 . at the time of submission , our approach outperformed state - of - the - art techniques on the referitgame and flickr 30k entities dataset by and respectively using the iou metric . in this paper , we present a framework for loss - augmented inference based on the concept of structured support vector machines ( svms ) . \n we show that loss - augmented inference can be achieved by training a structured svm on a regularized product space . \n we then show that loss - augmented inference can be achieved by training a structured svm on the same product space . \n we also demonstrate that loss - augmented inference can be achieved by training a structured svm on a regularized product space . \n finally , we show that loss - augmented inference can be achieved by training a structured svm on the same product space ."}, {"id": 1013, "pred": "the use of features from deep convolutional neural networks ( dcnns ) on imagenet has led to important advances in computer vision . moment matching approaches for implicit generative models trained through moment matching \n are based on the assumption that one can learn the data distribution by matching the moments of the model distribution to the empirical data distribution . \n however , current moment matching approaches are based on maximum mean discrepancy ( mmd ) 11 , 12 , and the method of moments ( mom ) . ods of this family \n are based on maximum mean discrepancy ( mmd ) 11 , 12 , and the method of moments ( mom ) while mom based methods embed a probability distribution into a finite-dimensional vector ( i.e. , matching of a finite number of moments ) . a challenge for mmd methods is to define a kernel function that is statistically efficient and can be used with small minibatch sizes . \n a solution comes by using adversarial learning for the online training of kernel functions , however , this solution inherits the problematic min/max game of adversarial learning . in this work \n we demonstrate that , by using perceptual features ( pfs ) to perform moment matching , one we propose the generative moment matching network autoencoder ( gfmn ) . \n gfmn is a nonadversarial feature matching method that uses pretrained probability function ( pf ) extractors to perform moment matching in a pf space induced by a non - linear kernel function ( dcnn ) . \n we argue that gfmn is universal in the image domain . \n our proposed model differs from adversarial generative models ( ae ) in that it uses pretrained ae feature extractors to play the role of feature extractors , while these methods aim to impose a prior distrib . on the latent space of ae . \n our proposed model differs from adversarial ae by using fixed pretrained pf extractors for moment matching . \n our proposed generative latent optimization ( glo ) model jointly optimizes model parameters and noise input vectors z , while avoiding adversarial training . \n our experiments show that gfmn achieves better or similar results compared to state - of - the - art spectral gan ( sn-gan ) for challenging datasets such as cifar10 and stl10 . in this paper , we present a new approach for unsupervised learning with networks . \n we call it generalized gradient model ( gfmn ) . \n we show that gfmn is able to achieve state - of - the - art results in terms of generalization accuracy ( is ) and frechet inception distance ( fid ) in both autoencoders and generative moment matching networks ( gfmn ) . \n we also show that gfmn is able to achieve state - of - the - art results in terms of is and fid when it is trained with a simple moving average ( ma ) or a moving average of second order moments ( adam ) . \n we also show that gfmn is able to achieve state - of - the - art results in terms of is and fid when it is trained with a simple moving average ( ma ) or adam moving average of second order moments ( ama ) .  \n generalized gradient model ( gfmn ) is a new approach for unsupervised learning with networks . \n gfmn is able to achieve state - of - the - art results in terms of generalization accuracy ( is ) and frechet inception distance ( fid "}, {"id": 1014, "pred": "e- recommender systems aim to present items with high utility to the consumers into form utility : the item is desired as it is , and time utility : the item is desired at the given point in time 28 . \n however , users only purchase durable goods when the time is right and recommend items for which a user has no immediate demand , which can hurt user experience and waste an opportunity to drive sales . to this end , we formulate the problem of learning users s form utility as the problem of learning their time utility . given purchase triplets ( user , item , time ) , the objective is to make recommendations based on users , overall predicted combination of form utility and time utility . to this end , we use a sparse binary tensor to model implicit feedback , and a nonnegative vector d rr to measure the underlying inter-purchase durations in item categories . to this end , we formulate the problem of learning users s form utility as the problem of learning users s time utility . to this end , we first relax severely the optimization problem with nested hinge losses , and develop an efficient alternating minimization algorithm . \n we then show that its time complexity is only approximately in this paper , we study the problem of one - sided recommendation of items , where the objective function is highly non - smooth with nested hinge losses . \n we propose an extremely efficient optimization algorithm by effectively exploring the sparse structure of the tensor p and low - rank structure of the matrix x . \n we show that ( i ) the problem can be solved within o ( p0 ( k log ( p0 ) ) time ) , where k is the rank of x , and ( ii ) the algorithm converges to the critical points of f ( x , d ) time . \n since there are o ( mnl ) terms in the objective function , a naive implementation will take at least o ( mnl ) time , which is computationally infeasible when the data is large . to address this issue , we use proximal gradient descent to solve the problem . \n experiments with simulated data show that it takes only iterations to optimize a problem with million users , million items , and more than million purchase records . \n finally , we evaluate the proposed recommendation algorithm on two real - world datasets , tmall6 and amazon review7 , and compare it with six in this paper , we examine the problem of demand-aware recommendation in settings when users purchase within categories . \n we formulate it as nuclear norm minimization problem that seeks to jointly learn the form utility tensor and a vector of inter- purchase durations , and propose a scalable optimization algorithm with a tractable time complexity . \n our empirical studies show that the proposed approach can yield perfect recovery of duration vectors in noiseless settings ; it is robust to noise and scalable as analyzed theoretically . on two real - world datasets , tmall and amazon review , \n we show that our algorithm outperforms six state-of-the-art recommendation algorithms on the tasks of category , item , and purchase time predictions ."}, {"id": 1015, "pred": "we present a personality - based neural response generation model for automated conversational agents . in our model , personality traits are represented as high level features learned in a hidden layer of a sequence-to-sequence ( seq2seq ) model . \n responses are then generated conditioned on these personality traits . \n we experimented with a dataset of 87.5k real customer-agent utterance pairs from social media . \n we find that leveraging personality encoding improves relative performance up to in bleu score , compared to a baseline seq2seq model . to our knowledge , this work is the first to train a neural response generation model that encodes target personality traits ."}, {"id": 1016, "pred": "in this paper , we propose a fully neuromorphic event- based stereo disparity algorithm for autonomous mobile agents to navigate in the real world . \n the proposed method is implemented using a stereo pair of davis sensors and nine truenorth ns1e boards , however , the method is applicable to other spiking neuromorphic architectures , and it is also tested offline on larger models using a truenorth simulator . \n input rectification , spatiotemporal scaling , feature matching , search for best matches , morphological erosion and dilation , and bidirectional consistency check are all performed on truenorth , for a fully neuromorphic disparity solution . the winner-take-all ( wta ) neural network is a feed - forward neural network that finds the disparity with the largest value , at every tick , for a set of neuron activations . \n we introduce a novel encoding technique for inputs , based on the base4 representation of numbers using a 3-bits thermometer code , and propose a scalable wta system on a neuromorphic hardware . \n we evaluate the performance of the system on sequences of random dot stereograms ( rds ) representing a rotating fan and two real world sets of sequences , consisting of a fast rotating fan and a rotating toy butterfly . on the synthetic dataset , \n wta finds the disparity with the largest value , at each time step , out of a large number of candidate disparity levels . on the non- synthetic dataset , \n wta finds the disparity with the largest value , at each time step , out of a large number of candidate disparity levels .  \n winner-take-all ( wta ) is a feed - forward neural network that finds the disparity with the largest value , at every tick , for a set of neuron activations @xcite . \n the wta system is we present a fully end - to - end event - based neuromorphic stereo system capable of running on live input event streams , using a fully graph - based computation model , where no frames , arrays or other such data -structures are used . \n we compare our approach with the literature on event based disparity . \n the implemented neuromorphic stereo disparity system achieves these advantages , while consuming less power per pixel per disparity map compared to the stateof- the - art the homogeneous computational substrate provides the first example of a fully end - to - end low - power , high throughput fully event - based neuromorphic stereo system capable of running on live input event streams , using a fully graph - based computation model , where no frames , arrays or other such data -structures are used ."}, {"id": 1017, "pred": "learning the causal structure of a complex system is one of the fundamental challenges in science . \n causal graphs are one of the most popular graphical models used to encode the invariances needed to reason about causal relations , for both learning and inference . \n the task of learning the causal structure entails a search over the space of causal graphs that are compatible with the observed data ; the collection of these graphs forms what is called an equivalence class . \n the most popular mark imprinted on the data by the underlying causal structure that is used to delineate an equivalence class are conditional independence ( ci ) relations . \n these relations are the most basic type of probabilistic invariances used in the field and have been the driving force behind some of the most prominent structural learning algorithms in the field 16 , 21 , including the pc , fci . while cis are powerful and have been the driving force behind some of the most prominent structural learning algorithms in the field , these are constraints specific for one distribution . in this paper , we start by noting something very simple , albeit powerful , that happens when a combination of observational and experimental distributions are available : there are constraints over the graphical structure that emerge by comparing these different distributions , and in this paper , we propose the notion of the augmented graph , which is a new representation of a causal graph . \n we show that two causal graphs are i-markov equivalent if their corresponding augmented mags satisfy the three conditions given in theorem 1 . \n we also characterize when two causal graphs are i-markov equivalent in accordance to the proposed definition . \n finally , we show that two causal graphs are i-markov equivalent if their corresponding augmented mags satisfy the three conditions given in theorem 2 . we present a modification of the function createaugmentednodes ( fci ) algorithm to learn augmented pags . given an independence model over the measured variables , the algorithm initializes a complete graph with circle edges , then it removes the edge between any pair of nodes if a separating set between the pair exists and records the set . in phase \n i , it learns the skeleton of the augmented pag . in phase ii , it identifies unshielded triples a , b , c and orients the edges into b if b is not in the separating set of a and c . finally , in phase iii , fci applies the orientation rules . only one of the rules uses separating sets while the rest use mag properties , and soundness and completeness of the previous phases the skeleton is correct and all the unshielded colliders are discovered . algorithm presents a modification of the fci algorithm to learn augmented pags ."}, {"id": 1018, "pred": "complex questions can be posed using structured knowledge bases ( kbqa ) , such as wikidata , freebase , and other relational data sets . \n these can be evaluated as an expression graph over nodes representing kb set , logical , and arithmetic operators . \n however , such systems show copying or learning access when boolean or open numeric domains are involved . \n more complex queries need to be evaluated as an expression graph over nodes representing kb set , logical , and arithmetic operators . with this approach \n it is now possible to first train separate modules for each of the atomic operations involved and then train a program induction model that learns to use symbolic constraints guided by kb schema and inferred answer as ( very distant ) supervision for inducing such complex programs . in this paper , we present complex imperative program induction ( cipitr ) , an advanced program induction ( npi ) model that is able to answer complex queries by inducing programs of length up to 7 , using atomic operators and variable types . \n cipitr reduces the combinatorial program space to only semantically mitigating subgoals , thereby incorporating symbolic constraints guided by kb schema and inferred answer as ( very distant ) supervision for in this paper , we describe cipitr , a natural language interpreter for learning and problem - solving . \n cipitr takes as input the natural language question , the kb , and the prepopulated variable memory tables to generate a program . \n the interpreter executes the generated program with the help of the kb and scratch memory and outputs the system answer . during training , the predicted answer is compared with the gold to obtain a reward , which is sent back to cipitr to update its model parameters through a reinforce ( williams , 1992 ) objective . \n the current version of cipitr , the preprocessor consults an oracle to link entities , types and relations in the query to the kb . \n this is to isolate the programming performance of cipitr from the effect of imperfect linkage . extending earlier studies to investigate robustness of cipitr to linkage errors \n may be of future interest . \n we describe some of the foundational modules invoked by the rest of cipitr . we present cipitr , an advanced npi framework that significantly pushes the frontier of complex program induction in absence of gold programs . \n cipitr uses auxiliary rewarding techniques to mitigate the extreme reward sparsity and incorporates generic programming styles to constrain the combinatorial program space to only semantically correct programs"}, {"id": 1019, "pred": "the vast amounts of textual data end users need to consume motivates the need for automatic summarization . \n the summarizer then needs to produce a textual summary that captures the most salient ( general and informative ) content parts within input documents . \n the summarizer will need to produce a focused summary which includes the most relevant information to that need . \n while both saliency and focus goals should be considered within a query-focused summarization setting , these goals may be actually conflicting with each other higher saliency usually comes at the expense of lower focus and vice-versa . \n moreover , such a tradeoff may directly depend on summary length . aiming at better handling the saliency versus focus tradeoff , in this work , we propose dual-ces an extended ces summarizer similar to ces , dual-ces is an unsupervised query-focused multi- document extractive summarizer . in this paper , we propose a novel continuous attention splitting ( ce- ) method for summarization . \n our ce-method consists of two steps . in the first step , \n a focused summary is produced . in this step \n , we introduce an additional predictor whose goal is to enhance the saliency of this focused summary . \n we further make use of the pseudo-reference summary sl , which was produced in the first step , and introduce an additional auxiliary saliency-based predictor . \n this predictor utilizes pseudo-feedback that is distilled from unique unigram words in sl . to this end , we assign b 1sl ssl pos ( s ) as the value of the position-bias hyperparameter within qpos ( sq , d ) . to this end \n , we further assign a new learning parameter lt which defines the maximum length limit for summary production ( sampling ) that is allowed at iteration t of the ce-method . in the second step , \n a focused summary is produced . in this step , we introduce an additional auxiliary predictor whose goal is to enhance the saliency of this focused summary ."}, {"id": 1020, "pred": "in this paper we show that a considerable quality improvement can be achieved by modifying a tts system that produced the world vocoder parameters to predict parameters for lpcnet as in the previous work 6 , we conduct multiple adaptation experiments , applied on multiple vctk voices and show that the new system has much better quality and similarity to the target voices but can still run much faster than real-time in a single-cpu mode . this article presents a fast tts system for high - quality speech synthesis . \n the system is based on three nn models for generating the prosody , acoustic features and the final speech signal . \n we demonstrate that our system produces speech that is comparable to larger and much slower tacotron2 wavenet systems . \n the task of creating a high-quality tts system out of a smaller set of audio data is even more challenging . \n we show that when we reduce the size of the training data , there is some graceful degradation to the quality , but we are still able to maintain good similarity to the original speaker . for future work \n , we plan to allow voice modifications by adding control over voice parameters such as pitch , breathiness and vocal tract ."}, {"id": 1021, "pred": "in this paper we introduce the sobolev independence criterion ( sic ) , a dependency measure based on the gradient of a witness function , or critic , that is regularized integral probability metric ( ipm ) between the joint distribution and the product of marginals . \n we show how sparsity-inducing gradient penalties can be used to define an interpretable dependency measure , that can be reliably used to control the false discovery rate in feature selection . \n sic relies on the statistics of the gradient of a witness function , or critic , for both ( 1 ) defining the ipm constraint and ( 2 ) finding the features that discriminate between the joint and the marginals . intuitively , the magnitude of the average gradient with respect to a feature gives an importance score for each feature . hence , promoting its sparsity is a natural constraint for feature selection in this paper , we introduce sic ( support vector machines , svms ) , which is the first dependency criterion that decomposes in the sum of contributions of each coordinate , and hence it is an interpretable dependency measure . \n moreover , we show that sic can be written in terms of the importance scores of the features , and their ranking can be used to assess feature importance . \n we then show that sic can be trained as a deep neural network , where the feature map is the arithmetic mean or the geometric mean of controlling the false discovery rate ( fdr ) in feature selection . \n finally , we show that using our sparsity inducing gradient penalties with such networks , results in input sparsity at the level of the witness function of sic . \n this is desirable since it allows for an interpretable model , similar to the effect of lasso with linear models , our sparsity inducing gradient penalties result in a nonlinear self - explainable witness function , with explicit sparse dependency on the inputs . in this paper , we propose a novel approach for unsupervised learning of stochastic binary classifiers . \n the proposed method is based on the convexity of f , the learning rate , and the sparsity of the input data . \n we show that the sparsity of the input data can be exploited to improve the performance of the algorithm . \n in particular , we show that the sparsity of the input data can be exploited to improve the performance of the algorithm , and that the sparsity of the output data can be exploited to improve the performance of the algorithm .  \n unsupervised learning , sparsity , convex optimization . in this paper , we investigate the performance of leakyrelu and relu networks in the regression and feature learning tasks on heldout mse . \n these networks are trained with the adam algorithm for updates and linear models for regression and feature selection , respectively . \n we show that the performance of these networks on heldout mse can be improved by a factor of @xmath0 compared to relu networks , and @xmath1 compared to linear models . \n we also show that the performance of relu networks on heldout mse can be improved by a factor of @xmath2 compared to relu networks , and @xmath3 compared to linear models ."}]