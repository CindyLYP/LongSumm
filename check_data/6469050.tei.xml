<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Margin Classification Using the Perceptron Algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">AT&amp;T Labs</orgName>
								<orgName type="laboratory" key="lab2">Shannon Laboratory</orgName>
								<address>
									<addrLine>Park Avenue, Room A205, Florham Park</addrLine>
									<postCode>07932-0971</postCode>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">AT&amp;T Labs, Shannon Laboratory</orgName>
								<address>
									<addrLine>180 Park Avenue, Room A279, Florham Park</addrLine>
									<postCode>07932-0971</postCode>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large Margin Classification Using the Perceptron Algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Friess</term>
					<term>T.</term>
					<term>Cristianini</term>
					<term>N.</term>
					<term>&amp; Campbell</term>
					<term>C. (1998). The kernel-adatron: A fast and simple learning procedure for support vector machines. In Machine Learning: Proceedings of the Fifteenth International Conference. Gallant</term>
					<term>S. I. (1986). Optimal linear discriminants. In Eighth International Conference on Pattern Recognition</term>
					<term>pp. 849-852. IEEE</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We introduce and analyze a new algorithm for linear classification which combines Rosenblatt&apos;s perceptron algorithm with Helmbold and Warmuth&apos;s leave-one-out method. Like Vapnik&apos;s maximal-margin classifier, our algorithm takes advantage of data that are linearly separable with large margins. Compared to Vapnik&apos;s algorithm, however, ours is much simpler to implement, and much more efficient in terms of computation time. We also show that our algorithm can be efficiently used in very high dimensional spaces using kernel functions. We performed some experiments using our algorithm, and some variants of it, for classifying images of handwritten digits. The performance of our algorithm is close to, but not as good as, the performance of maximal-margin classifiers on the same problem, while saving significantly on computation time and programming effort.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>One of the most influential developments in the theory of machine learning in the last few years is Vapnik's work on support vector machines (SVM) <ref type="bibr" target="#b14">(Vapnik, 1982</ref>). Vapnik's analysis suggests the following simple method for learning complex binary classifiers. First, use some fixed mapping 1 to map the instances into some very high dimensional space in which the two classes are linearly separable. Then use quadratic programming to find the vector that classifies all the data correctly and maximizes the margin, i.e., the minimal distance between the separating hyperplane and the instances.</p><p>There are two main contributions of his work. The first is a proof of a new bound on the difference between the training error and the test error of a linear classifier that maximizes the margin. The significance of this bound is that it depends only on the size of the margin (or the number of support vectors) and not on the dimension. It is superior to the bounds that can be given for arbitrary consistent linear classifiers.</p><p>The second contribution is a method for computing the maximal-margin classifier efficiently for some specific high dimensional mappings. This method is based on the idea of kernel functions, which are described in detail in Section 4.</p><p>The main part of algorithms for finding the maximal-margin classifier is a computation of a solution for a large quadratic program. The constraints in the program correspond to the training examples so their number can be very large. Much of the recent practical work on support vector machines is centered on finding efficient ways of solving these quadratic programming problems.</p><p>In this paper, we introduce a new and simpler algorithm for linear classification which takes advantage of data that are linearly separable with large margins. We named the new algorithm the voted-perceptron algorithm. The algorithm is based on the well known perceptron algorithm of <ref type="bibr" target="#b11">Rosenblatt (1958</ref><ref type="bibr" target="#b12">Rosenblatt ( , 1962</ref> and a transformation of online learning algorithms to batch learning algorithms developed by <ref type="bibr" target="#b4">Helmbold and Warmuth (1995)</ref>. Moreover, following the work of <ref type="bibr" target="#b0">Aizerman, Braverman and Rozonoer (1964)</ref>, we show that kernel functions can be used with our algorithm so that we can run our algorithm efficiently in very high dimensional spaces. Our algorithm and its analysis involve little more than combining these three known methods. On the other hand, the resulting algorithm is very simple and easy to implement, and the theoretical bounds on the expected generalization error of the new algorithm are almost identical to the bounds for SVM's given by <ref type="bibr" target="#b15">Vapnik and Chervonenkis (1974)</ref> in the linearly separable case.</p><p>We repeated some of the experiments performed by <ref type="bibr" target="#b7">Cortes and Vapnik (1995)</ref> on the use of SVM on the problem of classifying handwritten digits. We tested both the votedperceptron algorithm and a variant based on averaging rather than voting. These experiments indicate that the use of kernel functions with the perceptron algorithm yields a dramatic improvement in performance, both in test accuracy and in computation time. In addition, we found that, when training time is limited, the voted-perceptron algorithm performs better than the traditional way of using the perceptron algorithm (although all methods converge eventually to roughly the same level of performance).</p><p>Recently, Friess, <ref type="bibr">Cristianini and Campbell (1998)</ref> have experimented with a different online learning algorithm called the adatron. This algorithm was suggested by <ref type="bibr" target="#b1">Anlauf and Biehl (1989)</ref> as a method for calculating the largest margin classifier (also called the "maximally stable perceptron"). They proved that their algorithm converges asymptotically to the correct solution.</p><p>Our paper is organized as follows. In Section 2, we describe the voted perceptron algorithm. In Section 3, we derive upper bounds on the expected generalization error for both the linearly separable and inseparable cases. In Section 4, we review the method of kernels and describe how it is used in our algorithm. In Section 5, we summarize the results of our experiments on the handwritten digit recognition problem. We conclude with Section 6 in which we summarize our observations on the relations between the theory and the experiments and suggest some new open problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Algorithm</head><p>We assume that all instances are points x ' ) ( 1 0</p><p>. We use 2 3 2</p><p>x 2 3 2 t o denote the Euclidean length of x. For most of the paper, we assume that labels 4 are in 5 6 8 7 9 A @ B 7 Â¥ C . The basis of our study is the classical perceptron algorithm invented by <ref type="bibr" target="#b11">Rosenblatt (1958</ref><ref type="bibr" target="#b12">Rosenblatt ( , 1962</ref>. This is a very simple algorithm most naturally studied in the online learning model. The online perceptron algorithm starts with an initial zero prediction vector</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D F E H G</head><p>. It predicts the label of a new instance x to be</p><formula xml:id="formula_0">I 4 P E signQ &amp; D S R</formula><p>xT . If this prediction differs from the label 4 , it updates the prediction vector to</p><formula xml:id="formula_1">D E U D V @ W 4</formula><p>x. If the prediction is correct then D is not changed. The process then repeats with the next example. The most common way the perceptron algorithm is used for learning from a batch of training examples is to run the algorithm repeatedly through the training set until it finds a prediction vector which is correct on all of the training set. This prediction rule is then used for predicting the labels on the test set. <ref type="bibr" target="#b2">Block (1962)</ref>, <ref type="bibr" target="#b10">Novikoff (1962)</ref> and <ref type="bibr" target="#b9">Minsky and Papert (1969)</ref> have shown that if the data are linearly separable, then the perceptron algorithm will make a finite number of mistakes, and therefore, if repeatedly cycled through the training set, will converge to a vector which correctly classifies all of the examples. Moreover, the number of mistakes is upper bounded by a function of the gap between the positive and negative examples, a fact that will be central to our analysis.</p><p>In this paper, we propose to use a more sophisticated method of applying the online perceptron algorithm to batch learning, namely, a variation of the leave-one-out method of <ref type="bibr" target="#b4">Helmbold and Warmuth (1995)</ref>. In the voted-perceptron algorithm, we store more information during training and then use this elaborate information to generate better predictions on the test data. The algorithm is detailed in <ref type="figure">Figure 1</ref>. The information we maintain during training is the list of all prediction vectors that were generated after each and every mistake. For each such vector, we count the number of iterations it "survives" until the next mistake is made; we refer to this count as the "weight" of the prediction vector.</p><p>To calculate a prediction we compute the binary prediction of each one of the prediction vectors and combine all these predictions by a weighted majority vote. The weights used are the survival times described above. This makes intuitive sense as "good" prediction vectors tend to survive for a long time and thus have larger weight in the majority vote.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Analysis</head><p>In this section, we give an analysis of the voted-perceptron algorithm for the case E 7 in which the algorithm runs exactly once through the training data. We also quote a theorem of <ref type="bibr" target="#b15">Vapnik and Chervonenkis (1974)</ref> for the linearly separable case. This theorem bounds the generalization error of the consistent perceptron found after the perceptron algorithm is run to convergence. Interestingly, for the linearly separable case, the theorems yield very similar bounds.</p><p>As we shall see in the experiments, the algorithm actually continues to improve performance after E 7</p><p>. We have no theoretical explanation for this improvement. If the data are linearly separable, then the perceptron algorithm will eventually converge on some consistent hypothesis (i.e., a prediction vector that is correct on all of the training examples). As this prediction vector makes no further mistakes, it will eventually dominate the weighted vote in the voted-perceptron algorithm. Thus, for linearly separable data, when ! , the voted-perceptron algorithm converges to the regular use of the perceptron algorithm, which is to predict using the final prediction vector.</p><p>As we have recently learned, the performance of the final prediction vector has been analyzed by <ref type="bibr" target="#b15">Vapnik and Chervonenkis (1974)</ref>. We discuss their bound at the end of this section.</p><p>We now give our analysis for the case E 7</p><p>. The analysis is in two parts and mostly combines known material. First, we review the classical analysis of the online perceptron algorithm in the linearly separable case, as well as an extension to the inseparable case. Second, we review an analysis of the leave-one-out conversion of an online learning algorithm to a batch learning algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>a labeled training set</p><formula xml:id="formula_2">Â¡ Q x 9 A 4 T 9 Â£ Â¢ Â¤ Â¢ Â£ Â¢ A 9 Q x Â¥ P 9 A 4 Â¤ Â¥ 1 T Â§ Â¦ number of epochs Output: a list of weighted perceptrons Â¡ Q &amp; D 9 Â© T 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 ! QD 9 Â© T Â§ Â¦ Initialize: E , D E G ,Â¨ E .</formula><p>Repeat times:</p><formula xml:id="formula_3">-For Â© E 7 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 Â© : ! Compute prediction: I 4 " E signQ &amp; D # 8 R x$ T ! If I 4 E 4 thenÂ¨ E @ 7 . else D &amp; % E U D @ 4 $ x$ ; &amp; % E 7 ; E @ 7</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction</head><p>Given: the list of weighted perceptrons:</p><formula xml:id="formula_4">Â¡ QD 9 ' T 9 Â£ Â¢ Â¤ Â¢ Â£ Â¢ A 9 Q &amp; D 9 ' T Â§ Â¦</formula><p>an unlabeled instance: x compute a predicted label I 4</p><p>as follows: <ref type="figure">Figure 1</ref>. The voted-perceptron algorithm.</p><formula xml:id="formula_5">( E ) $ 1 0 $ signQ D $ R xT 3 2 I 4 8 E signQ ( T 4 Â¢</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The online perceptron algorithm in the separable case</head><p>Our analysis is based on the following well known result first proved by <ref type="bibr" target="#b2">Block (1962)</ref> and <ref type="bibr" target="#b10">Novikoff (1962)</ref>. The significance of this result is that the number of mistakes does not depend on the dimension of the instances. This gives reason to believe that the perceptron algorithm might perform well in high dimensional spaces. </p><formula xml:id="formula_6">THEOREM 1 (BLOCK, NOVIKOFF) Let Â¡ Q x 9 A 4 T 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 ! Q x Â¥ 94 Â¥ T Â§</formula><formula xml:id="formula_7">Q x $ 94 $ T then 4 $ Q &amp; D R x$ T H 5 and D I % E U D @ 4 $ x$ . We have D &amp; % R P 9 S E U D R 3 9 V @ 4 $ Q Q 9 S R x$ T A @ D R ' 9 @ R B # Â¢ D I % R P 9 @ B . Similarly, 2 3 2D I % 2 3 2G E F 2 3 2D 2 3 2G @ Â¢ Â¡4 Â¤ $ QD 8 R x$ T Â© @ 2 3 2 x $ 22G 5 2 3 2D 2 3 2G @ R 7 G Â¢ Therefore, 2 3 2D &amp; % 2 3 2G 5 7 F G . Combining, gives Â£ 7 @ 22D &amp; % 2 3 2 @ D &amp; % R 3 9 @ B which implies 5 Q7 E B TG</formula><p>proving the theorem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Analysis for the inseparable case</head><p>If the data are not linearly separable then Theorem 1 cannot be used directly. However, we now give a generalized version of the theorem which allows for some mistakes in the training set. As far as we know, this theorem is new, although the proof technique is very similar to that of <ref type="bibr">Klasner and Simon (1995, Theorem 2.2)</ref>. See also the recent work of Shawe-Taylor and Cristianini (1998) who used this technique to derive generalization error bounds for any large margin classifier. </p><formula xml:id="formula_8">THEOREM 2 Let Â¡ A Q x 94 T 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 ! Q x Â¥ 9 A 4 Â¥ TÂ¦</formula><formula xml:id="formula_9">Â¦ $ E Â§ Â© 5 &amp; 9B P 6 W 4 $ Q Q 9 S R x$ T A C 1 9</formula><p>and define</p><formula xml:id="formula_10">E Â¥ $ 1 0 Â¦ G $</formula><p>. Then the number of mistakes of the online perceptron algorithm on this sequence is bounded by</p><formula xml:id="formula_11">7 @ B G Â¢ Proof:</formula><p>The case E follows from Theorem 1, so we can assume that Â¤ . The proof is based on a reduction of the inseparable case to a separable case in a higher dimensional space. As we will see, the reduction does not change the algorithm.</p><p>We extend the instance space</p><formula xml:id="formula_12">( 0 to ( 0 % Â¥ by adding new dimensions, one for each example. Let x $ ' F ( 0 % Â¥</formula><p>denote the extension of the instance x$ . We set the first</p><formula xml:id="formula_13">! coordinates of x $ equal to x$ . We set the Q " ! @ C T ' th coordinate to # where #</formula><p>is a positive real constant whose value will be specified later. The rest of the coordinates of x $ are set to zero.</p><p>Next we extend the comparison vector</p><formula xml:id="formula_14">9 ' U ( 0 to 9 $ ' ( 0 % Â¥</formula><p>. We use the constant % , which we calculate shortly, to ensure that the length of 9 &amp; is one. We set the first</p><formula xml:id="formula_15">! coordinates of 9 $ equal to 9 E % . We set the Q ' ! @ T ' th coordinate to Q4 &amp; $ Â¦ $ TE Q % # T .</formula><p>It is easy to check that the appropriate normalization is</p><formula xml:id="formula_16">% E 7 Â£ @ G E ( # G .</formula><p>Consider the value of</p><formula xml:id="formula_17">4 $ Q Q 9 R x $ T : 4 Â¤ $ A Q 1 9 R x $ T E 4 Â¤ $ 9 R x$ % @ # 4 $ Â¦ $ % # E 4 $ Q 1 9 R x$ T % @ Â¦ $ % @ 4 $ Q 1 9 R x$ T % @ B 6 4 $ Q Q 9 S R x $ T % E B % Â¢</formula><p>Thus the extended prediction vector</p><formula xml:id="formula_18">9 achieves a margin of B E 7 Â£ @ G E # G</formula><p>on the extended examples.</p><p>In order to apply Theorem 1, we need a bound on the length of the instances. As</p><formula xml:id="formula_19">7 @ 2 3 2 x $ 2 3 2 f or all</formula><p>, and the only additional non-zero coordinate has value # , we get that</p><formula xml:id="formula_20">2 3 2 x $ 22G 5 7 F G @ # G .</formula><p>Using these values in Theorem 1 we get that the number of mistakes of the online perceptron algorithm if run in the extended space is at most</p><formula xml:id="formula_21">Q D 7 F G @ # G T Q7 Â£ @ G Â£ E ( # G T B G Â¢ Setting # E Â£ 7</formula><p>minimizes the bound and yields the bound given in the statement of the theorem.</p><p>To finish the proof we show that the predictions of the perceptron algorithm in the extended space are equal to the predictions of the perceptron in the original space. We use of the following three claims:</p><formula xml:id="formula_22">1. The first ! coordinates of D $ are equal to those of D $ . 2. The Q " ! @ R T ' th coordinate of D $ is equal to zero. 3. signQ &amp; D $ R x $ T Â£ E signQ &amp; D $ R x$ T .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Converting online to batch</head><p>We now have an algorithm that will make few mistakes when presented with the examples one by one. However, the setup we are interested in here is the batch setup in which we are given a training set, according to which we generate a hypothesis, which is then tested on a seperate test set. If the data are linearly separable then the perceptron algorithm eventually converges and we can use this final prediction rule as our hypothesis. However, the data might not be separable or we might not want to wait till convergence is achieved.</p><formula xml:id="formula_23">" Â© V $ # Â¦ # $ Â¥ Â¦ Â§ Â¡ Â§ Â¦ Â© % Â¥ " Â¢ Â£</formula><p>In this case, we have to decide on the best prediction rule given the sequence of different classifiers that the online algorithm genarates. One solution to this problem is to use the prediction rule that has survived for the longest time before it was changed. A prediction rule that has survived for a long time is likely to be better than one that has only survived for a few iterations. This method was suggested by <ref type="bibr">Gallant (1986)</ref> who called it the pocket method. <ref type="bibr" target="#b8">Littlestone (1989)</ref>, suggested a two-phase method in which the performance of all of the rules is tested on a seperate test set and the rule with the least error is then used.</p><p>Here we use a different method for converting the online perceptron algorithm into a batch learning algorithm; the method combines all of the rules generated by the online algorithm after it was run for just a single time through the training data. We now describe <ref type="bibr" target="#b4">Helmbold and Warmuth's (1995)</ref> very simple "leave-one-out" method of converting an online learning algorithm into a batch learning algorithm. Our votedperceptron algorithm is a simple application of this general method. We start with the randomized version. Given a training set</p><formula xml:id="formula_24">Â¡ Q x 94 T 9 Â¤ Â¢ Â¤ Â¢ Â£ Â¢ A 9 Q x Â¥ 9 A 4 Â¥ T Â§ Â¦</formula><p>and an unlabeled instance x, we do the following. We select a number Â¡ in</p><formula xml:id="formula_25">5 I 9 Â¤ Â¢ Â¤ Â¢ Â£ Â¢ 9 Â© C</formula><p>uniformly at random. We then take the first Â¡ examples in the training sequence and append the unlabeled instance to the end of this subsequence. We run the online algorithm on this sequence of length Â¡ @ 7</p><p>, and use the prediction of the online algorithm on the last unlabeled instance. In the deterministic leave-one-out conversion, we modify the randomized leave-one-out conversion to make it deterministic in the obvious way by choosing the most likely prediction. That is, we compute the prediction that would result for all possible choices of Â¡ in</p><formula xml:id="formula_26">5 I # 9 Â£ Â¢ Â¤ Â¢ Â¤ Â¢ 9 '</formula><p>) C</p><p>, and we take majority vote of these predictions. It is straightforward to show that taking a majority vote runs the risk of doubling the probability of mistake while it has the potential of significantly decreasing it. In this work we decided to focus primarily on deterministic voting rather than randomization.</p><p>The following theorem follows directly from <ref type="bibr" target="#b4">Helmbold and Warmuth (1995)</ref>. (See also <ref type="bibr" target="#b5">Kivinen and Warmuth (1997)</ref> and <ref type="bibr">Cesa-Bianchi et al. (1997)</ref> </p><formula xml:id="formula_27">Â¡ Â¤ Â¢ E # Q D F @ U 7 ! T .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Putting it all together</head><p>It can be verified that the deterministic leave-one-out conversion of the online perceptron algorithm is exactly equivalent to the voted-perceptron algorithm of <ref type="figure">Figure 1</ref>  </p><formula xml:id="formula_28">Â¢ Â¡ Â¤ Â£Â¥ E Â¦ Â§ Â§Â¥ % ) $ 0 Q Â§ Â© Â§ 5 I # Â§ B B 6 4 $ Q Q 9 S R x $ T C T G Â¢</formula><p>Then the probability (over the choice of all examples). In fact, the same proof yields a slightly stronger statement which depends only on examples on which mistakes occur. Formally, this can be stated as follows:</p><p>COROLLARY 2 Assume all examples are generated i.i.d. at random. Suppose that we run the online perceptron algorithm once on the sequence</p><formula xml:id="formula_29">Â¡ A Q x 9 A 4 T 9 Â£ Â¢ Â¤ Â¢ Â¤ Â¢ 9 Q x Â¥ % 9 A 4 Â¥ % T Â§ Â¦</formula><p>, and that mistakes occur on examples with indices</p><formula xml:id="formula_30">9 Â¤ Â¢ Â¤ Â¢ Â£ Â¢ A 9 ' 1 . Redefine 7 E Â§ Â© Â¦ Â¥ ( ' Â¥ 2 3 2 x $ ) 2 3 2 , and redefine Â¡ Â¤ Â£Â¥ E Â¦ Â§ Â§ ) ' 0 1 0 Â§ Â© Â§ 5 &amp; 9B P 6 4 Â¤ $ ) Q Q 9 R x$ )T A C 3 2 G Â¢</formula><p>Now suppose that we run the voted-perceptron algorithm on training examples </p><formula xml:id="formula_31">Â¡ Q x 94 T 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 ! Q x Â¥ 9 A</formula><formula xml:id="formula_32">Q x 94 T 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 ! Q x Â¥ % 9 A 4 Â¤ Â¥ % T Â§ Â¦</formula><p>repeatedly until convergence, and that mistakes occur on a total of examples with indices</p><formula xml:id="formula_33">9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 Â© . Let 7 U E Â§ Â© Â¥ ' Â¥ 2 3 2 x $ ) 2 3 2</formula><p>, and let</p><formula xml:id="formula_34">B V E Â§ Â© Â¡ 0 Â§ Â¦ Â¥ ( ' Â¥ 4 Â¤ $ ) Q 1 9 R x $ ) ! T 3 Â¢ Assume B Â¤</formula><p>with probability one. Now suppose that we run the perceptron algorithm to convergence on training examples can be set to zero), Corollary 2 is almost identical to Theorem 4. One difference is that in Corolary 2, we lose a factor of 2. This is because we use the deterministic algorithm, rather than the randomized one. The other, more important difference is that , the number of mistakes that the perceptron makes, will almost certainly be larger when the perceptron is run to convergence than when it is run just for a single epoch. This gives us some indication that running the voted-perceptron algorithm with E 7 might be better than running it to convergence; however, our experiments do not support this prediction.</p><formula xml:id="formula_35">Â¡ Q x 94 T 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 ! Q x Â¥ 9 A 4 Â¤ Â¥ 1 TÂ¦ .</formula><p>Vapnik (to appear) also gives a very similar bound for the expected error of supportvector machines. There are two differences between the bounds. First, the set of vectors on which the perceptron makes a mistake is replaced by the set of "essential support vectors." Second, the radius 7 is the maximal distance of any support vector from some optimally chosen vector, rather than from the origin. (The support vectors are the training examples which fall closest to the decision boundary.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Kernel-based Classification</head><p>We have seen that the voted-perceptron algorithm has guaranteed performance bounds when the data are (almost) linearly separable. However, linear separability is a rather strict condition. One way to make the method more powerful is by adding dimensions or features to the input space. These new coordinates are nonlinear functions of the original coordinates. Usually if we add enough coordinates we can make the data linearly separable. If the separation is sufficiently good (in the senses of Theorems 1 and 2) then the expected generalization error will be small (provided we do not increase the complexity of instances too much by moving to the higher dimensional space).</p><p>However, from a computational point of view, computing the values of the additional coordinates can become prohibitively hard. This problem can sometimes be solved by the elegant method of kernel functions. The use of kernel functions for classification problems was proposed by suggested Aizerman, Braverman and Rozonoer (1964) who specifically described a method for combining kernel functions with the perceptron algorithm. Continuing their work, <ref type="bibr" target="#b3">Boser, Guyon and Vapnik (1992)</ref>  For instance, an important kernel function that we use in this paper is the polynomial expansion  , and whereÂ¨is an appropriately chosen constant.</p><formula xml:id="formula_36">Â¥ W Q x 9 y T E Q7 @ x R yT Â© Â¢<label>(1</label></formula><formula xml:id="formula_37">1 Q x T E Q7 9 Â¦ Â¥ G 9 Â§ Â¥ G G 9 Â§ Â¥ G 9 Â£ Â¡ Â¢ Â¥ 9 Â£ Â¡ Â© Â¥ G 9 Â£ Â¡ Â¥ 9 Â£ Â¡ Â¢ Â¥ Â¥ G 9 Â£ Â¡ Â¢ Â¥ Â¥ 9 Â£ Â¡ Â¥ G Â¥ T P Â¢ In</formula><p>Aizerman, Braverman and Rozonoer observed that the perceptron algorithm can be formulated in such a way that all computations involving instances are in fact in terms of inner products x R y between pairs of instances. Thus, if we want to map each instance x to a vector 1 Q</p><p>x T in a high dimensional space, we only need to be able to compute inner products</p><formula xml:id="formula_38">1 Q x T Â£ R 1 Q y T</formula><p>, which is exactly what is computed by a kernel function. Conceptually, then, with the kernel method, we can work with vectors in a very high dimensional space and the algorithm's performance only depends on linear separability in this expanded space. Computationally, however, we only need to modify the algorithm by replacing each inner product computation x In this paper, we observe that all the computations in the voted-perceptron learning algorithm involving instances can also be written in terms of inner products, which means that we can apply the kernel method to the voted-perceptron algorithm as well. Referring to <ref type="figure">Figure 1</ref>, we see that both training and prediction involve inner products between instances x and prediction vectors </p><formula xml:id="formula_39">' % R x E U D ' R x @ 8 4 Â¤ $ ) Q x $ ) R x T</formula><p>, it is clear that we can compute the prediction of the voted-perceptron also using only kernel calculations.</p><p>Thus, calculating the prediction of the voted-perceptron when using kernels is only marginally more expensive than calculating the prediction of the final prediction vector, assuming that both methods are trained for the same number of epochs.  <ref type="figure">Figure 2</ref>. Learning curves for algorithms tested on NIST data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In our experiments, we followed closely the experimental setup used by <ref type="bibr" target="#b7">Cortes and Vapnik (1995)</ref> in their experiments on the NIST OCR database.G We chose to use this setup because the dataset is widely available and because <ref type="bibr" target="#b7">LeCun et al. (1995)</ref> have published a detailed comparison of the performance of some of the best digit classification systems in this setup. Examples in this NIST database consist of labeled digital images of individual handwritten digits. Each instance is a Â¡ Â¡ Â£ Â¢ Â¡ Â¡ matrix in which each entry is an 8-bit representation of a grey value, and labels are from the set</p><formula xml:id="formula_40">5 &amp; 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ 9 Â¥ Â¤ Â§ C</formula><p>. The dataset consists of 60,000 training examples and 10,000 test examples. We treat each image as a vector in <ref type="table">(   Â¦   Â§  Â©</ref> , and, like Cortes and Vapnik, we use the polynomial kernels of Eq. (1) to expand this vector into very high dimensions.</p><p>To handle multiclass data, we essentially reduced to 10 binary problems. That is, we trained the voted-perceptron algorithm once for each of the 10 classes. When training on class , we replaced each labeled example</p><formula xml:id="formula_41">Q x $ A 94 Â¤ $ T (where 4 Â¤ $ ' 5 I 9 Â¤ Â¢ Â¤ Â¢ Â£ Â¢ 9 Â¤ C ) by the binary- labeled example Q x $ 9 A @ B 7 ! T if 4 Â¤ $ E and by Q x $ A 9 6 7 T if 4 I $ E . Let Â¡ QD 9 ' T 9 Â£ Â¢ Â¤ Â¢ Â¤ Â¢ 9 Q &amp; D 9 ' T Â§ Â¦</formula><p>be the sequence of weighted prediction vectors which result from training on class . To make predictions on a new instance x, we tried four different methods. In each method, we first compute a score</p><formula xml:id="formula_42">( for each ' 5 &amp; 9 Â¤ Â¢ Â£ Â¢ Â¤ Â¢ A 9 Â¤ C</formula><p>and then predict with the label receiving the highest score: The first method is to compute each score using the respective final prediction vector:</p><formula xml:id="formula_43">I 4 8 E Â© " ! # Â§ Â© ( Â¢</formula><formula xml:id="formula_44">( E D R xÂ¢</formula><p>This method is denoted "last (unnormalized)" in the results. A variant of this method is to compute scores after first normalizing the final prediction vectors:</p><formula xml:id="formula_45">( E D R x 2 3 2D 2 3 2 Â¢</formula><p>This method is denoted "last (normalized)" in the results. Note that normalizing vectors has no effect for binary problems, but can plausibly be important in the multiclass case. The next method (denoted "vote") uses the analog of the deterministic leave-one-out conversion. Here we set (unnorm) 5.7 2.3 1.9 1.8 1.7 1.7 1.7 (norm) 5.7 2.3 1.9 1.8 1.7 1.7 1.6 Last (unnorm) 6.6 3.0 2.2 1.9 1.9 1.8 1.7 (norm) 6.3 2.9 2.1 1.9 1.9 1.7 1.7 Rand. <ref type="formula">unnorm</ref>11.9 4.7 3.5 3.0 2.7 2.1 1.9 (norm) 11.5 4.5 3.4 2.9 2.6 2.0 1. Â¡ Â§ Â¤ Vote 6.0 2.5 2.1 2.0 1.9 1.9 1.9 Avg.</p><formula xml:id="formula_46">" Â© V $ # Â¦ # $ Â¥ Â¦ Â§ Â¡ Â§ Â¦ Â© % Â¥ " Â¢ Â£</formula><p>(unnorm) 6.2 2.5 2.1 2.0 1.9 1.9 1.9 (norm) 6.0 2.5 2.1 2.0 1.9 1.8 1.8 Last (unnorm) 7.3 3.2 2.4 2.2 2.0 1.9 1.9 (norm) 6.9 3.0 2.3 2.1 2.0 1.9 1.9 Rand. <ref type="bibr">(unnorm)</ref> 12 </p><formula xml:id="formula_47">( E ) $ 1 0 $ signQ D $ R xT P Â¢</formula><p>The third method (denoted "average (unnormalized)") uses an average of the predictions of the prediction vectors</p><formula xml:id="formula_48">( E ) $ 1 0 $ QD $ R xT P Â¢</formula><p>As in the "last" method, we also tried a variant (denoted "average (normalized)") using normalized prediction vectors:  where Â¡ is the index of the final vector which existed at time Â¡ for label . Formally, Â¡ is the largest number in</p><formula xml:id="formula_49">( E ) $ 1 0 $ D $ R x 2 3 2D $ 2 3 2 Â¢</formula><formula xml:id="formula_50">5 I # 9 Â£ Â¢ Â¤ Â¢ Â¤ Â¢ 9 ' C satisfying Â§ ) $ 0 $ 5 Â¡ &amp; Â¢</formula><p>The analogous normalized method ("Random (normalized)") uses</p><formula xml:id="formula_51">( E D R x 2 3 2D 2 3 Â¢</formula><p>Our analysis is applicable only for the cases of voted or randomly chosen predictions and where E 7</p><p>. However, in the experiments, we ran the algorithm with up to Â£</p><p>. When using polynomial kernels of degree 5 or more, the data becomes linearly separable. Thus, after several iterations, the perceptron algorithm converges to a consistent prediction vector and makes no more mistakes. After this happens, the final perceptron gains more and more weight in both "vote" and "average." This tends to have the effect of causing all of the variants to converge eventually to the same solution. By reaching this limit we compare the voted-perceptron algorithm to the standard way in which the perceptron algorithm is used, which is to find a consistent prediction rule.</p><p>We performed experiments with polynomial kernels for dimensions Â¦ E 7</p><p>(which corresponds to no expansion) up to Â¦ E Â¡ . We preprocessed the data on each experiment by randomly permuting the training sequence. Each experiment was repeated 10 times, each time with a different random permutation of the training examples. For</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Â¦ E 7</head><p>, we were only able to run the experiment for ten epochs for reasons which are described below. <ref type="figure">Figure 2</ref> shows plots of the test error as a function of the number of epochs for four of the prediction methods -"vote" and the unnormalized versions of "last," "average" and "random" (we omitted the normalized versions for the sake of readability). Test errors are averaged over the multiple runs of the algorithm, and are plotted one point for every tenth of an epoch.</p><p>Some of the results are also summarized numerically in <ref type="table" target="#tab_9">Tables 1 and 2</ref> which show (average) test error for several values of for the seven different methods in the rows marked "Vote," "Avg. (unnorm)," etc. The rows marked "SupVec" show the number of "support vectors," that is, the total number of instances that actually are used in computing scores as above. In other words, this is the size of the union of all instances on which a mistake occured during training. The rows marked "Mistake" show the total number of mistakes made during training for the 10 different labels. In every case, we have averaged over the multiple runs of the algorithm.</p><p>The column corresponding to</p><formula xml:id="formula_52">E Â¢ 3 7</formula><p>is helpful for getting an idea of how the algorithms perform on smaller datasets since in this case, each algorithm has only used a tenth of the available data (about 6000 training examples).</p><p>Ironically, the algorithm runs slowest with small values of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Â¦</head><p>. For larger values of Â¦ , we move to a much higher dimensional space in which the data becomes linearly separable. For small values of Â¦ -especially for Â¦ E 7 -the data are not linearly separable which means that the perceptron algorithm tends to make many mistakes which slows down the algorithm significantly. This is why, for Â¦ E 7</p><p>, we could not even complete a run out to 30 Â© Â¦ The most significant improvement in performance is clearly between Â¦ E 7</p><formula xml:id="formula_53">Â¢ Â¡ Â¤ Â£ Â© Â¦ Â¢ Â¡ % &amp; %Â¤ % Â¦ Â¥ % Â§ Â© % Â© Â¡ Â¥ " Â© V $ # Â¦ # $ Â¥ Â¦ Â§ Â¡ Â§ Â¦ Â© % Â¥ " Â¢ Â£ Â¤</formula><p>and Â¦ E Â¡ . The migration to a higher dimensional space makes a tremendous difference compared to running the algorithm in the given space. The improvements for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Â¦ Â¤ Â¡</head><p>are not nearly as dramatic.</p><p>Our results indicate that voting and averaging perform better than using the last vector. This is especially true prior to convergence of the perceptron updates. For Â¦ E 7</p><p>, the data are highly inseparable, so in this case the improvement persists for as long as we were able to run the algorithm. For higher dimensions ( Â¦ Â¤ 7</p><p>), the data becomes more separable and the perceptron update rule converges (or almost converges), in which case the performance of all the prediction methods is very similar. Still, even in this case, there is an advantage to using voting or averaging for a relatively small number of epochs.</p><p>There does not seem to be any significant difference between voting and averaging in terms of performance. However, using random vectors performs the worst in all cases. This stands in contrast to our analysis, which applies only to random vectors and gives an upper bound on the error of average vectors which is twice the error of the randomized vectors. A more refined analysis of the effect of averaging is required to better explain the observed behavior.</p><p>Using normalized vectors seems to sometimes help a bit for the "last" method, but can help or hurt performance slightly for the "average" method; in any case, the differences in performance between using normalized and unnormalized vectors are always minor. <ref type="bibr" target="#b7">LeCun et al. (1995)</ref> give a detailed comparison of algorithms on this dataset. The best of the algorithms that they tested is (a rather old version of) boosting on top of the neural net LeNet 4 which achieves an error rate of 0.7%. A version of the optimal margin classifier algorithm <ref type="bibr" target="#b7">(Cortes &amp; Vapnik, 1995)</ref>, using the same kernel function, performs significantly better than ours, achieving a test error rate of 1.1% for Â¦ E Â£ Â¢ . <ref type="table" target="#tab_13">Table 3</ref> shows how the variants of the perceptron algorithm perform on the ten binary problems corresponding to the 10 class labels. For this table, we fix Â¦ E Â¤ Â¢</p><p>, and we also compare performance to that reported by Cortes and <ref type="bibr" target="#b7">Vapnik (1995)</ref> for SVM's. <ref type="table" target="#tab_14">Table 4</ref> gives more details of how the perceptron methods perform on the single binary problem of distinguishing "9" from all other images. Note that these binary problems come closest to the theory discussed earlier in the paper. It is interesting that the perceptron algorithm generally ends up using fewer support vectors than with the SVM algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Summary</head><p>The most significant result of our experiments is that running the perceptron algorithm in a higher dimensional space using kernel functions produces very significant improvements in performance, yielding accuracy levels that are comparable, though still inferior, to those obtainable with support-vector machines. On the other hand, our algorithm is much faster and easier to implement than the latter method. In addition, the theoretical analysis of the expected error of the perceptron algorithm yields very similar bounds to those of support-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>prediction vector used for predicting the instance x$ in the original space and D $ to denote the prediction vector used for predicting the corresponding instance x $ in the extended space. The claim follows by induction over</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>were made by Boser, Guyon and Vapnik for Vapnik's SVM algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>.</head><label></label><figDesc>In order to perform this operation efficiently, we store each prediction vector D in an implicit form, as the sum of instances that were added or subtracted in order to create it. That is, each of mistakes made by the algorithm during training. Naively, the prediction of the voted-perceptron would seem to require , taking advantage of the recurrence D</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>A rather similar theorem was proved byVapnik and Chervonenkis (1974, Theorem 6.1) for training the perceptron algorithm to convergence and predicting with the final perceptron vector.THEOREM 4 (VAPNIK AND CHERVONENKIS) Assume all examples are generated i.i.d. at random. Suppose that we run the online perceptron algorithm on the sequence</figDesc><table><row><cell cols="2">4 examples) that the voted-perceptron algorithm does not predict Â¥ for a single epoch. Then the probability (over the choice of all TÂ¦ 7 ) @ 4 Â¥ on test instance % xÂ¥ % is at most</cell></row><row><cell>Â¡ @ 7 Â© 5 4 ( 6 # 5 (where the expectation is also over the choice of all Â¡ @ 7 Â© Â¡ 0 Â¥ ! # " 7 @ B 7</cell><cell>Â¢ Â¡ Â¤ Â£Â¥ @ 7 G % examples).</cell></row><row><cell>Â¡</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 1 .</head><label>1</label><figDesc>Results of experiments on NIST 10-class OCR data with Mistake give average number of support vectors and average number of mistakes. All other rows give test error rate in percent for the various methods. Â¡</figDesc><table><row><cell cols="4">and 0.1</cell><cell>1</cell><cell>2</cell><cell>Â¢ Â¡ Â¤ Â£ Â¦ Â¥  Â§ Â© Â¥ 3</cell><cell>. The rows marked SupVec 4 10 30</cell></row><row><cell cols="2">Â¡ Â¤ Â£</cell><cell>Vote Avg. Last Rand. (unnorm) (unnorm) (norm) (unnorm) (norm) (norm) SupVec Mistake</cell><cell cols="3">10.7 10.9 10.9 16.0 15.4 22.0 21.5 2,489 19,795 24,263 26,704 28,322 8.5 8.3 8.2 8.2 8.7 8.5 8.4 8.3 8.5 8.3 8.2 8.2 14.7 13.6 13.9 13.7 14.1 13.1 13.5 13.2 15.7 14.7 14.3 14.1 15.2 14.2 13.8 13.6 3,342 25,461 48,431 70,915 93,090 223,657 8.1 8.3 8.1 13.5 13.0 13.8 13.2 32,994</cell></row><row><cell>Â¡</cell><cell>Â§</cell><cell>Vote Avg. Last Rand. (unnorm) (unnorm) (norm) (unnorm) (norm) (norm) SupVec Mistake</cell><cell cols="3">6.0 6.0 6.2 8.6 8.4 13.4 13.2 1,639 2,150 10,201 15,290 19,093 22,100 2.8 2.4 2.2 2.1 2.8 2.4 2.2 2.1 3.0 2.5 2.3 2.2 4.0 3.4 3.0 2.7 3.9 3.3 3.0 2.7 5.9 4.7 4.1 3.8 5.9 4.7 4.1 3.8 8,190 9,888 10,818 11,424</cell><cell>1.8 1.9 1.9 2.3 2.3 2.9 2.9 12,963 13,861 1.8 1.8 1.8 2.0 1.9 2.4 2.3 32,451 41,614</cell></row><row><cell>Â¡</cell><cell></cell><cell>Vote Avg. Last Rand. (unnorm) (unnorm) (norm) (unnorm) (norm) (norm) SupVec Mistake</cell><cell>5.4 5.3 5.5 6.9 6.8 11.6 11.5 1,460 1,937</cell><cell cols="2">2.3 2.3 2.5 3.1 3.1 4.9 4.8 6,774 8,475 11,739 13,757 15,129 1.9 1.8 1.7 1.9 1.8 1.7 2.0 1.8 1.8 2.5 2.2 2.0 2.5 2.2 2.0 3.7 3.2 2.9 3.7 3.2 2.9 8,073 8,715 9,102</cell><cell>1.6 1.6 1.6 1.7 1.7 2.2 2.2 9,883 10,094 1.6 1.5 1.5 1.6 1.6 1.8 1.8 18,422 19,473</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 2 .</head><label>2</label><figDesc>Results of experiments on NIST 10-class OCR data with Mistake give average number of support vectors and average number of mistakes. All other rows give test error rate in percent for the various methods. Â¡</figDesc><table><row><cell>Â¡ Â¡ Â¥ Â£ Â¢ Â© Â¥ Â¥ Â¤</cell><cell>. The rows marked</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 3 .</head><label>3</label><figDesc>Results of experiments on individual classes using polynomial kernels with Â¡ Â¡ . The rows marked SupVec and Mistake give average number of support vectors and average number of mistakes. All other rows give test error rate in percent for the various methods.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>label</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell></row><row><cell>Â¡ Â¡</cell><cell>Â£ Â¢Â£</cell><cell>Vote Avg. Last Rand. SupVec Mistake</cell><cell>(unnorm) (norm)</cell><cell>0.7 0.7 0.7 1.0 2.1 133 133</cell><cell>0.5 0.5 0.5 0.7 1.3 89 89</cell><cell>1.3 1.3 1.3 1.7 3.0 180 180</cell><cell>1.5 1.5 1.5 2.1 3.7 228 228</cell><cell>1.4 1.3 1.4 1.5 3.0 179 179</cell><cell>1.4 1.3 1.4 2.8 3.2 202 202</cell><cell>0.9 0.9 0.9 1.2 2.2 136 136</cell><cell>1.3 1.3 1.3 1.8 2.7 160 160</cell><cell>1.8 1.8 1.8 2.4 4.7 285 285</cell><cell>2.1 2.0 2.1 2.7 4.5 290 290</cell></row><row><cell cols="2">Â¡ Â£</cell><cell>Vote Avg. Last Rand. SupVec Mistake</cell><cell>(unnorm) (norm)</cell><cell cols="2">0.3 0.3 0.3 0.5 0.8 506 407 0.3 0.2 0.2 0.5 0.6 506 407</cell><cell>0.6 0.6 0.6 1.0 1.4 782 782</cell><cell>0.5 0.5 0.6 1.1 1.5 996 996</cell><cell>0.5 0.5 0.5 0.7 1.2 734 734</cell><cell>0.5 0.5 0.5 0.8 1.3 849 849</cell><cell>0.5 0.4 0.4 0.5 0.9 541 541</cell><cell cols="3">0.6 0.6 0.6 1.0 1.2 738 1,183 1,240 0.7 0.9 0.7 0.9 0.8 1.0 1.2 1.3 1.9 2.1 738 1,183 1,240</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 4 .</head><label>4</label><figDesc>Results of experiments on NIST data when distinguishing "9" from all other digits. The rows marked SupVec and Mistake give average number of support vectors and average number of mistakes. All other rows give test error rate in percent for the various methods. Â¡</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>10</cell><cell>30</cell></row><row><cell>Â¢ Â¡</cell><cell>Â£</cell><cell>Vote Avg. Last Rand. SupVec Mistake</cell><cell>(unnorm) (norm)</cell><cell cols="5">4.5 4.5 4.6 7.9 8.3 513 4,085 5,240 3.9 3.8 3.9 3.8 3.9 3.9 6.4 5.7 6.7 6.5 513 4,085 7,880 11,630 15,342 37,408 3.8 3.8 3.7 3.8 3.8 3.7 3.8 3.8 3.8 6.3 5.8 5.9 6.3 6.2 6.2 5,888 6,337 7,661</cell></row><row><cell>Â¢ Â¡</cell><cell>Â§</cell><cell>Vote Avg. Last Rand. SupVec Mistake</cell><cell>(unnorm) (norm)</cell><cell cols="3">2.4 2.4 2.5 4.1 5.5 337 1,668 2,105 1.2 1.0 1.2 1.0 1.3 1.1 1.8 1.6 2.8 2.2 337 1,668 2,541</cell><cell>0.9 1.0 1.0 1.6 1.9 2,358 3,209</cell><cell>0.9 0.9 1.0 1.3 1.8 2,527 3,744</cell><cell>0.8 0.9 0.9 1.1 1.4 2,983 3,290 0.8 0.8 0.8 1.0 1.1 5,694 7,715</cell></row><row><cell>Â¢ Â¡</cell><cell></cell><cell>Vote Avg. Last Rand. SupVec Mistake</cell><cell>(unnorm) (norm)</cell><cell cols="3">2.2 2.1 2.2 2.9 4.9 302 1,352 1,666 1.0 0.8 0.9 0.8 1.0 0.8 1.3 1.0 2.2 1.7 302 1,352 1,867</cell><cell>0.8 0.8 0.8 1.0 1.5 1,842 2,202</cell><cell>0.7 0.7 0.8 0.8 1.4 1,952 2,448</cell><cell>0.7 0.7 0.7 0.7 1.0 2,192 2,283 0.7 0.6 0.6 0.7 0.8 3,056 3,318</cell></row><row><cell>Â¢ Â¡</cell><cell>Â¡</cell><cell>Vote Avg. Last Rand. SupVec Mistake</cell><cell>(unnorm) (norm)</cell><cell cols="3">2.1 2.0 2.1 2.7 4.5 290 1,240 1,528 0.9 0.8 0.9 0.8 1.0 0.8 1.3 1.0 2.1 1.6 290 1,240 1,648</cell><cell>0.7 0.7 0.8 0.8 1.4 1,669 1,882</cell><cell>0.7 0.7 0.7 0.8 1.2 1,746 2,020</cell><cell>0.7 0.7 0.7 0.7 0.9 1,899 1,920 0.7 0.6 0.6 0.7 0.7 2,323 2,367</cell></row><row><cell>Â¢ Â¡</cell><cell>Â¢</cell><cell>Vote Avg. Last Rand. SupVec Mistake</cell><cell>(unnorm) (norm)</cell><cell cols="3">2.2 2.2 2.2 2.7 4.6 294 1,229 1,502 0.9 0.8 0.9 0.8 1.0 0.8 1.3 1.0 2.0 1.5 294 1,229 1,598</cell><cell>0.7 0.7 0.8 0.9 1.3 1,628 1,798</cell><cell>0.7 0.7 0.7 0.8 1.2 1,693 1,908</cell><cell>0.7 0.7 0.7 0.7 0.9 1,817 1,827 0.7 0.7 0.7 0.7 0.8 2,132 2,150</cell></row><row><cell>Â¢ Â¡</cell><cell>Â¤</cell><cell>Vote Avg. Last Rand. SupVec Mistake</cell><cell>(unnorm) (norm)</cell><cell cols="3">2.3 2.3 2.3 2.7 4.7 302 1,263 1,537 0.9 0.8 0.9 0.8 1.0 0.8 1.3 1.0 2.1 1.6 302 1,263 1,625</cell><cell>0.8 0.8 0.8 0.9 1.3 1,655 1,810</cell><cell>0.8 0.8 0.8 0.8 1.2 1,715 1,916</cell><cell>0.8 0.7 0.7 0.8 0.9 1,774 1,776 0.7 0.7 0.7 0.7 0.8 2,035 2,039</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>All running times are on a single SGI MIPS R10000 processor running at 194 MHZ.)</figDesc><table><row><cell>epochs but had to stop at Â¦ E Â¡ , we can run 30 epochs in about 25 hours, and for E 7 Â¤ (after about six days of computation). In comparison, for Â¦ E Â¡ or , a complete run takes about 8 hours. (</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Vladimir Vapnik for some helpful discussions and for pointing us to Theorem 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notes</head><p>1. Storing all of these vectors might seem an excessive waste of memory. However, as we shall see, when perceptrons are used together with kernels, the excess in memory and computition is really quite minimal. 2. National Institute for Standards and Technology, Special Database 3. See http://www.research.att.com/ yann/ocr/ for information on obtaining this dataset and for a list of relevant publications.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The final method (denoted "random (unnormalized)"), is a possible analog of the randomized leave-one-out method in which we predict using the prediction vectors that exist at a randomly chosen "time slice." That is, let Â¦ be the number of rounds executed (i.e., the number of examples processed by the inner loop of the algorithm) so that </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Theoretical foundations of the potential function method in pattern recognition learning. Automation and Remote Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Aizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Braverman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Rozonoer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="821" to="837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The adatron: an adaptive perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Anlauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Biehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Europhysics Letters</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="687" to="692" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The perceptron: A model for brain functioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Block</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosenfeld</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reviews of Modern Physics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="123" to="135" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
	<note>Neurocomputing</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Annual ACM Workshop on Computational</title>
		<meeting>the Fifth Annual ACM Workshop on Computational</meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On weak learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Helmbold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="551" to="573" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Additive versus exponentiated gradient updates for linear prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kivinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Computation</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="64" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">From noise-free to noise-tolerant and from on-line to batch learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Klasner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">U</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Annual Conference on Computational Learning Theory</title>
		<meeting>the Eighth Annual Conference on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="250" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparison of learning algorithms for handwritten digit recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brunot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">A</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sackinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From on-line to batch learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Littlestone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Annual Workshop on Computational Learning Theory</title>
		<meeting>the Second Annual Workshop on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="269" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Perceptrons: An Introduction to Computational Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Papert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On convergence proofs on perceptrons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B J</forename><surname>Novikoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on the Mathematical Theory of Automata</title>
		<meeting>the Symposium on the Mathematical Theory of Automata</meeting>
		<imprint>
			<date type="published" when="1962" />
			<biblScope unit="volume">XII</biblScope>
			<biblScope unit="page" from="615" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The perceptron: A probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="386" to="407" />
			<date type="published" when="1958" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Reprinted in Neurocomputing</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Principles of Neurodynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<publisher>Spartan</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Robust bounds on generalization from the margin distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<idno>NC2-TR-1998-029</idno>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Estimation of Dependences Based on Empirical Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Theory of pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Chervonenkis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nauka, Moscow</title>
		<imprint>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
	<note>In Russian</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
