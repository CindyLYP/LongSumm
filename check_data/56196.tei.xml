<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modular meta-learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-05-02">2 May 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferran</forename><surname>Alet</surname></persName>
							<email>alet@mit.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Lozano-Pérez</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">MIT Computer Science</orgName>
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Zürich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modular meta-learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-05-02">2 May 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1806.10166v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Many prediction problems, such as those that arise in the context of robotics, have a simplifying underlying structure that, if known, could accelerate learning. In this paper, we present a strategy for learning a set of neural network modules that can be combined in different ways. We train different modular structures on a set of related tasks and generalize to new tasks by composing the learned modules in new ways. By reusing modules to generalize we achieve combinatorial generalization, akin to the &quot;infinite use of finite means&quot; displayed in language. Finally, we show this improves performance in two robotics-related problems.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In many situations, such as robot learning, training experience is very expensive. One strategy for reducing the amount of training data needed for a new task is to learn some form of prior or bias using data from several related tasks. The objective of this process is to extract information that will substantially reduce the training-data requirements for a new task. This problem is a form of transfer learning, sometimes also called meta-learning or "learning to learn" <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>Previous approaches to meta-learning have focused on finding distributions over <ref type="bibr" target="#b2">[3]</ref> or initial values of <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> parameters, based on a set of "training tasks," that will enable a new "test task" to be learned with many fewer training examples. Our objective is similar, but rather than focusing on transferring information about parameter values, we focus on finding a set of reusable modules that can form components of a solution to a new task, possibly with a small amount of tuning. By reusing our learned modules, we aim at combinatorial generalization <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>; this is akin to the reuse of words to construct many possible sentences. We propose that this "infinite use of finite means" (Von Humboldt) can be a scalable approach towards transfer and generalization.</p><p>Modular approaches to learning have been very successful in structured tasks such as naturallanguage sentence interpretation <ref type="bibr" target="#b8">[9]</ref>, in which the input signal gives relatively direct information about a good structural decomposition of the problem. We wish to address problems that may benefit from a modular decomposition but do not provide any task-level input from which the structure of a solution may be derived. Nonetheless, we adopt a similar modular structure and parameteradaptation method for learning reusable modules, but use a general-purpose simulated-annealing search strategy to find an appropriate structural decomposition for each new task.</p><p>We provide an algorithm, called BOUNCEGRAD, which learns a set of modules and then combines them appropriately for a new task. We demonstrate its effectiveness by comparing it to MAML <ref type="bibr" target="#b3">[4]</ref>, a popular meta-learning method, on a set of regression tasks that represent the types of predictionlearning problems that are faced by robotics systems, and show that we achieve better prediction performance from a few training examples, and can be much faster to train. In addition, we show that this modular approach offers a strategy for explaining learned solutions to new tasks: by observing the modules that are used in a new task, we can relate this task to previous tasks that use the same modules. This approach also offers opportunities for verification and validation: the modules discovered during meta-learning may be subjected to computationally expensive analytical or empirical validation techniques off-line; they can then be recombined to address new tasks, generating solutions that can be validated more efficiently as compositions of previously understood modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work draws primarily from two sources: multi-task meta-learning and modular networks. Prominent examples of meta-learning in robotic domains are MAML <ref type="bibr" target="#b3">[4]</ref> and follow-up work <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>. They perform "meta-training" on a set of related tasks with the goal of finding network weights that serve as a good starting point for a few steps of gradient descent in each task. Others Parametric strategies such as MAML (left) learn a representation that can be quickly adjusted to solve a new task. Our modular meta-learning method (middle) learns a repertoire of modules that can be quickly recombined to solve a new task. A combination of MAML and modular meta-learning (right) learn initial weights for modules that can be combined and adapted for a new task. <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> perform different types of parametric changes in the network's computation conditioned on few examples. We adapt the same basic setting, but rather than finding good starting weights, we find a good set of modules for later structural combination; see figure 1. This is akin to the distinction in AI and cognitive science between parameter change vs. structural change <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Neural module networks <ref type="bibr" target="#b8">[9]</ref> provide an elegant mechanism for training a set of individual modules that can be recombined to solve new problems, when the input has enough signal to guess an appropriate modular decomposition. Johnson et al. <ref type="bibr" target="#b17">[18]</ref> later showed that the structure controller could be trained with RL; others applied similar frameworks to get more interpretability <ref type="bibr" target="#b18">[19]</ref> or to generalize across robotic tasks with neural programs <ref type="bibr" target="#b19">[20]</ref>. However, as far as we know, this framework has not been applied in problems where the input does not give enough information about an appropriate structure.</p><p>Structured networks have been used for meta-learning in the reinforcement-learning setting. Devin et al. <ref type="bibr" target="#b20">[21]</ref> use a fixed composition of two functions, one related to the robot and one to the task. Frans et al. <ref type="bibr" target="#b21">[22]</ref> jointly optimize a master policy and a set of sub-policies (options) that can be used to solve new problems; this method can be seen as having a single fixed scheme of combination via the master policy; it is in contrast to our ability to handle a variety of computational compositions. PATHNET <ref type="bibr" target="#b22">[23]</ref> is closely related to our work. The architecture is layered, with several modules in each layer. An evolutionary algorithm determines gates on the connections among the modules. After training on an initial task, the weights in the modules that contribute to the solution to that task are frozen, and then the architecture is trained on a second task. If the tasks are sufficiently related, the modules learned in the first task can be directly re-used to make learning more efficient in the second task. Meyerson and Miikkulainen <ref type="bibr" target="#b23">[24]</ref> and later Liang et al. <ref type="bibr" target="#b24">[25]</ref> expanded these ideas to the multitask setting with two particular compositional schemes: soft layer ordering and routing in DAGs. We propose a general framework of which these are two important sub-cases. Moreover, we operate in the meta-learning setting where, with few points per task, it is very easy to prematurely optimize the structure and run into local optima, as shown in <ref type="figure">figure 5</ref>. Therefore, we believe using simulated annealing rather than gradient descent <ref type="bibr" target="#b23">[24]</ref> or irreversible evolution <ref type="bibr" target="#b24">[25]</ref> may be a better fit for our setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Modular meta-learning</head><p>We explore the problem of modular meta-learning in the context of supervised learning problems, in which training and validation sets of input-output pairs are available. Such problems arise in robotics, particularly in learning to predict a next state based on information about previous states and actions. We believe that techniques similar to ours can be applied to reinforcement-learning problems as well, but do not explore that in this paper. We use the same meta-learning problem formulation as Finn et al. <ref type="bibr" target="#b3">[4]</ref> used to apply MAML to supervised learning problems. We assume an underlying distribution p(T ) over tasks: a task is a joint distribution P T (x, y) over (x, y) pairs.</p><p>The learning problem is: Given data drawn from m meta-training tasks and a (small) amount of data drawn from a meta-test task, where all tasks are drawn from P (T ), find a hypothesis h from some given set that incurs low expected loss on unseen data drawn from the meta-test task. In this formulation, each task is characterized by two data sets, D train and D test , each of which consists of a set of input-output pairs (x, y). We assume a differentiable loss function L(ŷ, y) on true vs predicted outputs for all tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Structured hypotheses</head><p>We begin by defining a family of structured hypothesis classes. Given the specification of a composition rule and a basis set of modules, (C, F, Θ) represents a set of possible functional input-output mappings that will serve as the hypothesis space for the meta-test task. F is a basis set of modules, which are functions f 1 , . . . , f k ; each function has a parametric form y = f i (x; θ i ) where θ i is a fixed-dimensional vector of parameters. In this work, all the f i are neural networks, potentially with different architectures, and the parameters Θ = (θ 1 , . . . , θ k ) are the weights of the neural networks, which differ among the modules. C is a compositional scheme for forming complex functions from simpler ones, defined by an initial structure and a set of local modification operations on the structure. Some examples include:</p><formula xml:id="formula_0">• Single module h(x) = f i (x), as fig. 5</formula><p>. The local modification is to change which module is used.</p><p>• A fixed compositional structure, e.g.,</p><formula xml:id="formula_1">h(x) = f i (x) + f j (x) or h(x) = f i (f j (x)).</formula><p>The local modifications are to change which module is used for each of the component functions. We could generalize this to stacking many CNN/ResNet layers <ref type="bibr" target="#b25">[26]</ref> for meta-learning in vision problems. • A weighted ensemble, of the same basic form as an attention mechanism:</p><formula xml:id="formula_2">h(x) = m l=1 e fi l (x) m l =1 e fi l (x) g j l (x)</formula><p>where i 1 , . . . , i m and j 1 , . . . , j m are elements of the set {1, . . . , k}, picking out which modules to use to play these roles in the network. There are modules of two types: the f i have a scalar output and the g i have an output that is the output dimension of the main regression problem. The local modifications are to change which particular f and g modules are used for each role.</p><p>• A general function-composition tree, where the local modifications include both changing which f i is used at each node, as well as adding or deleting nodes from the tree.</p><p>Let S be the set of possible structures and S ∈ S be a particular structure, generated by C, including a choice of which particular functions f i ∈ F are included in the structure. To formulate a structuredhypothesis model, we must specify the number and parametric forms, but not parameter values, of basis functions, F , and compositional scheme C. This is analogous to specifying the architecture of a deep neural network.</p><p>Our approach has two phases: an off-line meta-learning phase and an on-line meta-test learning phase. In the meta-learning phase, we take training and validation data sets for tasks 1, . . . , k as input and generate a parametrization for each module, Θ = (θ 1 , . . . , θ k ) as output; the objective is to construct modules that will work together as good building blocks for future tasks. In the metatest learning phase, we take a training data set for the meta-test task as input, as well as S and Θ; the output is a compositional form S ∈ S which includes a selection of modules f 1 . . . , f ms to be used in that form (a single element f j ∈ F may occur multiple times in S). Since Θ is already specified, the choice of S completely determines a mapping from inputs to outputs; we will abuse notation slightly and write S Θ to stand for the function from input to output generated by structure S and parameters Θ. We may optionally include a meta-test tuning phase, which will adapt the parameter vectors; this is discussed in section 3.3.</p><p>At learning time on the meta-test task, the space of possible structures S and parameters Θ are fixed, and the objective is to find and return the best structure in S. Define e(D, S, Θ) to be the loss of the hypothesis S Θ on data set D: e(D, S, Θ) = {(x,y)∈D} L(S Θ (x), y). Then our hypothesis is</p><formula xml:id="formula_3">S * Θ = arg min S∈S e(D train meta-test , S, Θ)<label>(1)</label></formula><p>The hope is that, by choosing a limited but flexible and appropriate hypothesis space based on previous tasks, a good choice of S * Θ can be made based on a small amount of data in D train meta-test .</p><p>At meta-learning time, S is specified, and the objective is to find parameter values Θ that constitute a set of modules that can be recombined to effectively solve each of the training tasks. We use validation sets for the meta-training tasks to avoid choosing Θ in a way that over-fits. Our training objective is to find Θ that minimizes the average generalization performance of the hypotheses chosen by equation 1 using parameter set Θ:</p><formula xml:id="formula_4">J(Θ) = m j=1 e(D test j , arg min S∈S e(D train j , S, Θ), Θ) .<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning algorithm</head><p>The optimization problems specified by equations 1 and 2 are in general quite difficult, requiring a mixed continuous-discrete search in a space with many local optima. In this section, we describe the BOUNCEGRAD algorithm, which performs local searches based on a combination of simulated annealing and gradient descent to find approximately optimal solutions to these problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Meta-test learning phase</head><p>In the meta-test learning phase, we have fixed the parameters Θ and only need to find an optimal structure S ∈ S according to the objective in equation 1. We use simulated annealing <ref type="bibr" target="#b26">[27]</ref> to perform this search: it is a local search strategy that uses stochasticity to avoid local optima and has asymptotic optimality guarantees. We start with an initial structure, then randomly propose structural changes using local modification operators associated with the compositional scheme S, accept the change if it decreases the error on the task and, with some probability, even if it does not.</p><formula xml:id="formula_5">procedure ONLINE(D train meta−test , S, Θ, T 0 , ∆ T , T end ) S = random simple structure from S for T = T 0 ; T = T − ∆ T ; T &lt; T end do S = PROPOSE S (S) if ACCEPT(e(D, S , Θ), e(D, S, Θ), T ) then S = S return S procedure ACCEPT(v , v, T ) return v &lt; v or rand(0, 1) &lt; exp{(v − v )/T }</formula><p>In order for simulated annealing to converge, the temperature parameter T must be decreased over time. The schedule we use decreases too quickly to satisfy theoretical convergence guarantees, yet is practically effective. Given the training set for the meta-test task, we run ONLINE(D train meta−test , S, Θ) to obtain a hypothesis for that task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Meta-learning phase</head><p>To perform the optimization in equation 2, we might use an algorithm that, in the outer loop, performs optimization over continuous parameters Θ, where the evaluation of Θ consists of running procedure ONLINE on each of the training data sets, and evaluating the resulting structural hypotheses using the validation sets. This strategy is ineffective because of the prevalence of bad local optima in the space, as illustrated in <ref type="figure">figure 5</ref>. As in clustering, we can smooth out some local optima by changing the objective function, although we will do so only during search, so our meta-test objective will remain the same. We formulate a smoothed objective</p><formula xml:id="formula_6">J(Θ, T ) = m j=1 E S∼MC(S,v(s;Θ),T ) e(D test j , S, Θ)<label>(3)</label></formula><p>Here, MC(S, v, T ) is the Markov chain induced by executing the simulated-annealing sampler in the structure space S using its proposal operator, with score function v(s; Θ) = e(D train j , s, Θ) and fixed temperature T . Rather than trying to find the Θ values that work best when we choose the best structure S, we will instead try to find Θ values that work best in expectation given the distribution of structures induced by the Markov chain. This space is smoother and less susceptible to local optima. At the same time as we are optimizing Θ via stochastic gradient, we will cool the temperature of the Markov chain. As T approaches 0, the objective J becomes the same as our original objective J. Given particular structures S j , then for each task T j , we know the parametric form of a differentiable feed-forward function that has parameters drawn from Θ, but possibly with parameter tying within and across the tasks due to re-use of the basis functions in F and possibly with some parameters in Θ left unused. We can adjust Θ using stochastic gradient descent, as defined in procedure GRAD. It takes the structures and training data as input, as well as a step size η and performs one step of standard stochastic gradient descent, or any alternative optimizer:</p><formula xml:id="formula_7">procedure GRAD(Θ, S 1 , . . . , S m , D test 1 , . . . , D test m , η) ∆ = 0 for j = 1 . . . m do (x, y) = rand elt(D test j ); ∆ = ∆ + ∇ Θ L(S j Θ (x), y) Θ = Θ − η∆</formula><p>However, we do not know the appropriate structure for each task, and so, according to the smoothed criterion in equation 3, we sample structures using a stochastic process based on simulated annealing. We define a procedure BOUNCE that takes a simulated annealing step on a structural hypothesis for each task, using the current Θ values, for a fixed temperature T :</p><formula xml:id="formula_8">procedure BOUNCE(S 1 , . . . , S m , D train 1 , . . . , D train m ,T , S, Θ) for j = 1 . . . m do S j = P ropose S (S j , Θ) if Accept(e(D train j , S j , Θ), e(D train j , S j , Θ), T ) then S j = S j</formula><p>Finally, we combine these methods into an overall algorithm for optimizing equation 1 via optimizing equation 3 and decaying T :</p><formula xml:id="formula_9">procedure BOUNCEGRAD(S, D train 1 , . . . , D train m , D test 1 , . . . , D test m , η, T 0 , ∆ T , T end ) S 1 , .</formula><p>. . , S m = random simple structures from S; Θ = neural-network weight initialization for</p><formula xml:id="formula_10">T = T 0 ; T = T − ∆ T ; T &lt; T end do BOUNCE(S 1 , . . . , S m , D train 1 , . . . , D train m , T , S, Θ) GRAD(Θ, S 1 , . . . , S m , D test 1 , . . . , D test m , η)</formula><p>We can think of the state of the optimization algorithm as consisting of both the parameters Θ and the temperature T ; these values induce a distribution on structures. The optimization landscape is illustrated in <ref type="figure" target="#fig_1">figure 2a</ref>. At high temperatures, the distribution over structures is diffuse and the modules will tend to be very generalized. As the temperature decreases, modules can specialize to perform well at the roles they are being selected to play in the structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter tuning in online phase</head><p>In the basic ONLINE method, we search for the best structure for the new task, without modifying parameters Θ. In fact, in many cases it may be useful to perform some additional parameter opti-mization as well. One strategy would be to proceed as we have described before, running BOUNCE-GRAD on the training tasks to get Θ, finding the best S for the meta-test task using ONLINE, and then taking some gradient steps on Θ, given S, to better optimize loss on D train . However, we can do better by incorporating the objective of MAML more deeply into both ONLINE and BOUNCEGRAD, by redefining the inner error function used in the optimization criterion for Θ: instead of using Θ directly, we will evaluate the result of taking one (or a few) gradient steps away from Θ, specialized to optimize D. </p><p>We can therefore use e MAML in place of e in the GRAD and ONLINE procedures, and perform a few additional gradient steps on Θ after obtaining the structure from ONLINE. We will call this overall algorithm MOMA, MOdular MAml.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compare four different learning approaches: training a single network using the combined data from all tasks (POOLED), training a single network using the MAML criterion, training a modular network without weight adaptation in the online training (BOUNCEGRAD), and training a modular network with MAML adaptation in the online training (MOMA). To make the comparisons as fair as possible, for experiments on a given data set, all networks have the same shape: generally, a feedforward structure of 3-4 layers. We selected a set of layer sizes so that POOLED and MAML had about 10 times as many parameters as the structured methods, to compensate for BOUNCEGRAD and MOMA having about 10 modules to combine. We also verified that none of the algorithms' performance was sensitive to modest changes in these parameters. We used Py-Torch and ADAM <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>; the MAML code was adapted from Rakelly <ref type="bibr" target="#b31">[32]</ref>. The code is available on https://github.com/FerranAlet/modular-metalearning. The target output values y in all data-sets were standardized to have mean 0 and standard deviation 1. The loss function then assigns loss 100 to a mean squared error of 1. More experimental details are available in the supplement.</p><p>We tested these methods in three domains: simple functional relationships, predicting the result of a robot manipulator pushing an object, and predicting the next frame of a kinematic skeleton based on previous frames using motion-capture data. The last two domains represent the main motivation for this work: a robot's experience of interacting with various entities in real-world situations should enable it to learn more efficiently about a new entity in a new situation. There is typically some sensible decomposition of the prediction function, but that decomposition is not known in advance. We hope that BOUNCEGRAD can find an appropriate decomposition and that doing so will significantly leverage learning, as well as reveal interesting structure, in the new domain.</p><p>An additional advantage of BOUNCEGRAD is computational efficiency. Unlike MAML, it does not have extra gradient steps embedded in the inner loop at meta-training time, which offers some efficiency; in addition, forward and backward passes can be done much more efficiently on GPUs by parallelizing over tasks. MAML is generally faster at online training time, since BOUNCEGRAD has to search over structures. However, this training took at most 10 seconds in our examples. Moreover, to store a structure we only need a few integers, compared to storing a whole set of weights for parametric methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Functions</head><p>We begin by testing on an extended version of the sine-function prediction problem <ref type="bibr" target="#b3">[4]</ref>, which consisted of data-sets generated from functions of the form sin   prediction tasks. We use 230 randomly selected tasks for meta-training and a different task for testing. Example functions are shown on the left of figure 3. We use the same architectures for this domain as for the sine domain, except that the compositional scheme is h(x) = f i (x) + f j (x).</p><p>The results are shown in table 1. As expected, training a single network on pooled data from all the tasks (POOLED) works poorly in all of these domains. In the sine domain, MAML outperforms BOUNCEGRAD because the detailed parameter values are critical to performing well in a new domain, but MOMA significantly improves on both methods, showing that both the structure and gradient meta-learning methods are useful. For sums of functions, we report results in two cases: one in which we average over performance for 1-4 training examples, and one for 16 training examples. With a small amount of online training data, BOUNCEGRAD outperforms other methods because it has the proper structural prior. With more data, all methods improve, but BOUNCEGRAD and MOMA improve on MAML. The plots in the middle and right of <ref type="figure" target="#fig_4">figure 3</ref> show some of the basis modules learned by BOUNCEGRAD and MOMA, respectively. Those learned by BOUNCEGRAD are an almost perfect recovery of the actual primitives used to generate the data, even though the algorithm had no information about those functions; MOMA has found similar functional shapes, yet with different values because it can still modify its parameters at online training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Learning to model results of pushing actions</head><p>An important sub-problem in robot manipulation is to acquire models of the effects of the robot's motor actions on the objects in the world. The MIT push data-set <ref type="bibr" target="#b27">[28]</ref> contains the results of executing pushing actions with a manipulator hand, for 11 different objects with different shapes on 4 surfaces with different friction properties. The behavior of the object on these surfaces is close to quasi-static , so the state can be characterized by an input x consisting of: position of the object (2d), orientation of the object (1d), position of the pusher (2d), and velocity of the pusher (2d). Given this 7-d input, the objective is to predict the 3-d change in the object's position and orientation. Each task represents experience with a particular object on a particular surface.</p><p>The compositional scheme for BOUNCEGRAD is the weighted ensemble described in section 3.1; F consists of 20 feedforward neural networks, 10 attention modules and 10 regressors. We consider two different meta-learning scenarios. In the first, the object-surface combination in the test case was <ref type="figure">Figure 4</ref>: Shared modules show internal structure of the datasets (left-pushing; right-motion). In particular, less important factors (surfaces and subjects) do not change the structure while bigger changes (objects and actions) do. Within the structural changes, there is more sharing between conceptually similar datasets. present in some meta-training task; in the second, the objects used in the meta-training tasks differ from the object used in the test task. The results in table 1 show that, for previously encountered objects, MOMA performs best, and BOUNCEGRAD outperforms MAML. For unknown objects, all three approaches perform roughly equivalently.</p><p>Another important aspect of the structured hypothesis space is that it can give us insight into the relationships between tasks. <ref type="figure">Figure 4</ref> illustrates the structural relationships that were uncovered in this data. The matrix on the left is indexed according to which object was being pushed. The entry in location i, j represents the average percentage of modules shared by the structure learned to predict results for object i and the structure learned for object j. We can see it distinguishes 3 clusters of data: butterfly, all ellipses, and all triangles. The biggest rectangle shares modules with the biggest triangle, probably due to similar size and aspect ratio. The matrix labeled "Surfaces" does not show dependence on the surface, as expected for the quasi-static regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Predicting skeleton configurations</head><p>Robots that interact with humans should be able to understand and predict human action, both for the purposes of safety and for task-driven collaboration. We applied meta-learning to this problem, using data from the Berkeley MHAD motion capture dataset <ref type="bibr" target="#b28">[29]</ref>. This domain is dynamic, and so we use three previous configurations (at intervals of 0.1 sec) of a human skeleton to predict the next one. Each configuration is characterized by one 3-d position and 90 joint angles describing a kinematic tree, so the input has dimension 279 and the output has dimension 93. There are 12 subjects performing 11 different actions several times, for a few seconds each.</p><p>We constructed a compositional scheme for BOUNCEGRAD that is related to this task. It has a fixed first layer with 128 output units to compress the input, which is the same for all structures, and independent "parallel" modules that take those 128 inputs and produce kinematic sub-trees for each body part (2 legs, 2 arms, and torso). For MAML and POOLED we use a single architecture of the same depth with 4 times more parameters. We again consider two different meta-learning scenarios. In the first, the activities used in the training task are the same as the activities used in the meta-test task, but the human actor varies; in the second, the activities used in the training tasks differ from the activity used in the test task. The results in table 1 show that, for known activities, BOUNCEGRAD and MOMA perform best. For unknown activities, none of the methods perform very well, but MOMA outperforms the others. We obtain a similar pattern of correlation among shared modules, shown in figure 4, in which there is significant module-sharing among similar tasks and no real pattern of module-sharing among human actors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Conclusion</head><p>We have demonstrated that modular compositional structure can provide a useful basis for transferring learned competence from previous tasks to new tasks. It can also yield insight into the underlying structure of the domain. We believe this combinatorial generalization is a promising route to scale to large numbers of tasks and continual learning settings as we can increase our knowledge in modular ways without forgetting previously learned concepts. The structural information to be provided in advance is a few lines of code to describe the possible modifications that can be made to a structure, which is not much more than would be required for specifying a typical neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A More insight into the difficulty of meta-training</head><p>Once the modules are trained, finding the best structure is just a matter of search. Similarly, if someone told us the best structure for each task, we would be able to find the best parameters by pure gradient descent. However, we start in the opposite situation: we don't know the module weights nor the best structure for each dataset. This leads to a chicken-and-egg problem: the concept of best structure is meaningless without first having good modules and we cannot train the modules if we do not know which roles they should play.</p><p>An important problem this causes, illustrated in figure 5 is that if we greedily optimize the structure we have the risk of premature optimization and running into a local optima. This motivated our smoothed objective where modules and structures slowly adapt to one another. <ref type="figure">Figure 5</ref>: Gray lines are different tasks; the composition is just a single module h(x) = f i (x), either the red or the blue. We have to place our modules such that they cover the tasks (grey lines well). The second frame represents the initial state of a search for parameters. If we make local steps in structure and parameter space, we will converge to the solution on the left, without ever updating the blue. However, if we consider a smoothed criterion with a non-point distribution over structures, we will update the parameters for the blue module and eventually arrive at the solution on the far right.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B More results on functions dataset</head><p>In the main text we claim we find the basis set of functions. This is compatible with some modules not having a closeby function, since there are 20 modules for 16 basis functions. To prove our claim, we plot the 16 functions and the closest module to each of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Experimental details</head><p>Functions used in the functions dataset: (abs, arcsinh(4x)/arcsinh(4), arctan(4x)/arctan(4), cbrt, ceil, cos(4πx), cosh(4x)/cosh(4), exp2(4x)/exp2(4), f loor, rint, sign, sin(4πx), sinc(4πx), square, tanh, id).</p><p>To create a dataset we picked all pairs of functions and More information, including the dataset itself, can be found in http://lis.csail.mit.edu/alet/modular-metalearning.html and https://github.com/FerranAlet/modular-metalearning.</p><p>Learning rates and epochs were generally the same. POOLED and BOUNCEGRAD had twice as many epochs in MIT push and Berkeley (500 vs 1000), still taking less amount of time to train thanks to being 4 times faster. We tried several similar architectures and learning rates for all algorithms and checked all algorithms converged appropriately. Other parameters: MAML inner updates: 5, MAML step size 0.001. For an up-to-date version of the implementation please visit https:// github.com/FerranAlet/modular-metalearning. x and arctan(4 * x)/π  Sharing between datasets containing each function, similar to figure 4. The diagonal is very dominant, showing if two datasets which share one function their corresponding structures will likely share a module. Only sinc(x) and |x| don't have near the predictable 50% sharing rate: one because the fitted module is not perfect, the other because it has two modules that fit it perfectly. The other exception is the relation between arctan x and 3 √ x, since a single module is close to both of them. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>All methods train on a set of related tasks and obtain some flexible intermediate representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>(a) A schematic view of the optimization landscape over Θ and T . At each point, there is a distribution over structures. As temperature decreases, the variance of the distribution decreases and modules become more specialized. (b) benchmarked robotic domains: MIT push dataset [28](top), action (throwing a ball) in the Berkeley MHAD dataset [29] (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>So, e MAML (D, S, Θ) = {(x,y)∈D} L(S O(Θ,D,S) (x), y), where the optimized parameters O(Θ, D, S) are obtained by a gradient update: O(Θ, D, S) = Θ − η∇ Θ e(D, S, Θ). Then, the meta-learning objective becomes J MAML (Θ) =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(ax + b) for varying values of a and b. The compositional scheme for BOUNCEGRAD is h(x) = f i (f j (x)); F consists of 20 feedforward neural networks, 10 with 1 hidden layer and 10 with 2. In our experiments in this section MAML and POOLED use the same architecture as the original MAML experiments. We construct an additional illustrative domain consisting of sums of pairs of common non-linear functions, such as exp and abs, scaled so the output is contained in the range [−1, +1], generating 16 2 possible</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Random functions (left); BOUNCEGRAD (center) and MOMA (right) modules. All but one BOUNCEGRAD modules(blue) are nearly identical to a basis function(red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Our learned set of modules recovers all 16 basis functions. The 16 basis functions (never seen alone by the algorithm) are plotted in red, the closest module is plotted in blue. All except the since function near 0 are close matches. All modules are different except for row 2, column 3 and 4: 3 √</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Sharing between datasets containing each function, similar to figure 4. The diagonal is very dominant, showing if two datasets which share one function their corresponding structures will likely share a module. Only sinc(x) and |x| don't have near the predictable 50% sharing rate: one because the fitted module is not perfect, the other because it has two modules that fit it perfectly. The other exception is the relation between arctan x and 3 √ x, since a single module is close to both of them.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>All modules and their closest function, completing figure 3. There are 20 modules: 4 are useless, 2 encode |x|, 13 encode a single function, 1 encodes both the 3 √ x and arctan(4 * x)/π.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of results; lower is better; bold results are not significantly different from best.</figDesc><table><row><cell>Dataset</cell><cell cols="5">POOLED MAML BOUNCEGRAD MOMA Structure</cell></row><row><cell>Parametrized sines</cell><cell>98.1</cell><cell>26.5</cell><cell>32.5</cell><cell cols="2">19.8 composition</cell></row><row><cell>Sum of functions (1-4pts)</cell><cell>32.7</cell><cell>19.7</cell><cell>12.8</cell><cell>18.0</cell><cell>sum</cell></row><row><cell>Sum of functions (16pts)</cell><cell>31.9</cell><cell>8.0</cell><cell>0.4</cell><cell>0.4</cell><cell>sum</cell></row><row><cell>MIT push: known objects</cell><cell>21.5</cell><cell>18.5</cell><cell>16.7</cell><cell>14.9</cell><cell>attention</cell></row><row><cell>MIT push: new objects</cell><cell>18.4</cell><cell>16.9</cell><cell>17.1</cell><cell>17.0</cell><cell>attention</cell></row><row><cell>Berkeley MoCap: known actions</cell><cell>35.7</cell><cell>35.5</cell><cell>32.2</cell><cell>31.9</cell><cell>concatenate</cell></row><row><cell>Berkeley MoCap: new actions</cell><cell>79.5</cell><cell>77.7</cell><cell>77.0</cell><cell>73.8</cell><cell>concatenate</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Summary of number of training plus architectural descriptions.</figDesc><table><row><cell>Dataset</cell><cell>sine</cell><cell>functions</cell><cell>MIT push</cell><cell>Berkeley MoCap</cell></row><row><cell># training metatasks</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell># training points</cell><cell></cell><cell>(1-4),16</cell><cell></cell><cell>128</cell></row><row><cell># validation points</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>#nodes POOLED &amp; MAML</cell><cell>[1-64-64-1]</cell><cell></cell><cell>[7-128-64-3]</cell><cell>[279-512-97]</cell></row><row><cell>#modules per type of module</cell><cell>10,10</cell><cell></cell><cell>10,10</cell><cell>1,3,3x4</cell></row><row><cell cols="5">#nodes BOUNCEGRAD&amp; MOMA [1-16-1], same as left [7-32-1], [279-128],[128-21],</cell></row><row><cell></cell><cell>[1-16-16-1]</cell><cell></cell><cell>[7-64-32-1]</cell><cell>[128-18]x4</cell></row><row><cell>learning rate for all architectures</cell><cell>0.003</cell><cell></cell><cell>0.001</cell><cell>0.001</cell></row><row><cell>statistical variability</cell><cell>0.8</cell><cell>0.4</cell><cell>0.7</cell><cell>0.7</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We gratefully acknowledge support from NSF grants 1420316, 1523767 and 1723381 and from AFOSR grant FA9550-17-1-0165. F. Alet is supported by a La Caixa fellowship. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of our sponsors. We want to thank Zi Wang for her assistance in setting up the experiments, Maria Bauza for her help with the MIT push dataset and Rohan Chitnis for his comments on an initial draft. Finally, we thank reviewers for their useful suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook. PhD thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Technische Universität München</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-task reinforcement learning: A hierarchical Bayesian approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tadepalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Machine Learning</title>
		<meeting>the 24th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>D. Precup and Y. W. Teh</editor>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms. CoRR, abs/1803.02999</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1803.02999" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">On language: On the diversity of human language construction and its influence on the mental development of the human species</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Humboldt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Aspects of the Theory of Syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chomsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
			<publisher>MIT press</publisher>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<title level="m">Relational inductive biases, deep learning, and graph networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural module networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">One-shot imitation from observing humans via domain-adaptive meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dasari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.01557</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">One-shot imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1087" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Rl 2 : Fast reinforcement learning via slow reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02779</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N. De</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3981" to="3989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning a synaptic learning rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cloutier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Neural Networks</title>
		<meeting>the International Joint Conference on Neural Networks</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page">969</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02185</idno>
		<title level="m">Towards a neural statistician</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How to grow a mind: Statistics, structure, and abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="issue">6022</biblScope>
			<biblScope unit="page" from="1279" to="1285" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning physical parameters from dynamic scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stuhlmüller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="57" to="82" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Inferring and executing programs for visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03633</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Al-Shedivat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10301</idno>
		<title level="m">Contextual explanation networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.01813</idno>
		<title level="m">Neural task programming: Learning to generalize across hierarchical tasks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning modular neural network policies for multi-task and multi-robot transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2169" to="2176" />
		</imprint>
	</monogr>
	<note>Robotics and Automation (ICRA</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Frans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09767</idno>
		<title level="m">Meta learning shared hierarchies</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pathnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08734</idno>
		<title level="m">Evolution channels gradient descent in super neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Beyond shared hierarchies: Deep multitask learning through soft layer ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00108</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Evolutionary architecture search for deep multitask networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03745</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Optimization by simulated annealing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">More than a million ways to be pushed. a high-fidelity experimental dataset of planar pushing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fazeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="30" to="37" />
		</imprint>
	</monogr>
	<note>IEEE/RSJ International Conference on</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Berkeley mhad: A comprehensive multimodal human action database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ofli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kurillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Pytorch-maml</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rakelly</surname></persName>
		</author>
		<ptr target="https://github.com/katerakelly/pytorch-maml" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
