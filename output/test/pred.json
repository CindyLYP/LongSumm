[{"id": 1000, "pred": "unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train. unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train. across eight european languages, our approach results in an average absolute improvement of over a state-of-the-art baseline, and over vanilla hidden markov models induced with the expectation maximization algorithm. this paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available."}, {"id": 1001, "pred": "this paper presents a novel approach for fv representation of sequences using a recurrent neural network ( rnn) . the rnn is trained to predict the next element of a sequence given the previous elements. given a sequence of vectors s with n vector elements x1 , ... , xn, we convert it to the input sequence x ( x0 , x1, ... , xn) , where x0 xstart. this special element is used to denote the beginning of the input sequence. this special element is used to denote the beginning of the input sequence, and we use xstart throughout this paper. the rnn is trained to predict the next element of a sequence given the previous elements. therefore, given the input sequence , the target sequence would be : y ( x1 , x2, ... xn) in this paper, we propose a new method to train a convolutional neural network ( rnn) to predict the next word of a sequence of words. the rnn is trained to predict the next word of the sentence, given the previous words w0, ... , r ( w2, ... , r ( wn) xn the rnn is trained to predict the next word of the sentence, given the previous words w0, ... , r ( wn) xn the rnn model consists of three layers: a 200d fullyconnected layer units with leaky-relu activation ( 0.1) , a 200-units long short-term memory ( lstm) layer, and a 500d linear fully connected layer. the rnn-fv is capable of encoding the sequence properties, and as underlying features, we rely on video encodings that are based on single frames or on fixed length blocks of the video. these representations are extracted separately for retrieval of sentences and images. these representations are extracted separately for retrieval of sentences and images. a sentence, being an ordered sequence of words, can be represented as a vector using the rnn-fv scheme. this paper introduces a novel fv representation for sequences that is derived from rnns . the proposed representation is sensitive to the element ordering in the sequence and provides a richer model than the additive bag model typically used for conventional fvs. the rnn-fv representation surpasses the state-of-theart results for video action recognition on two challenging datasets. when used for representing sentences, the rnnfv representation achieves state-of-the-art or competitive results on image annotation and image search tasks. since the length of the sentences in these tasks is usually short and, therefore, the ordering is less crucial, we believe that using the rnn-fv representation for tasks that use longer text will provide an even larger gap between the conventional fv and the rnn-fv . this paper introduces a novel fv representation for sequences that is derived from rnns . the proposed representation is sensitive to the element ordering in the sequence and provides a richer model than the additive bag model typically used for conventional fvs. the rnn-fv representation surpasses the state-of-theart results for video action recognition on two challenging datasets."}, {"id": 1002, "pred": "the rate of publications of scientific papers is increasing and it is almost impossible for re- searchers to keep up with relevant research. thus, the talk must be coherent as viewed by its authors, and is much more comprehensive than the abstract. thus, the talk can be considered as a sum- mary of the paper, as viewed by its authors. to do so, the speaker must describe their paper coherently and concisely ( since there is a time limit), provid- ing a good basis for generating summaries. based on this idea, in this paper, we propose a new method, named talksumm ( acronym for talk- based summarization), to automatically generate extractive content- based summaries for scientific papers based on video talks. our approach uti- lizes the transcripts of video content of conference talks, and treat them as spoken summaries of pa- pers. then, using unsupervised alignment- rithms, we map the transcripts to correspond- ing papers, and create extractive summaries. to our knowl- edge, this is the first approach to automatically cre- ate extractive summaries for scientific papers by utilizing the videos of conference talks. this paper proposes a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors."}, {"id": 1003, "pred": "emotion detection from text has become a popular task due to the key role of emotions in human-machine interaction. current approaches represent text as a sparse bag-of-words vector. in this work, we propose a new approach that utilizes pre-trained, dense word embedding representations. we introduce an ensemble approach combining both sparse and dense representations. for example, cbow representation for glove source showed a improvement in f1-score relative to word2vec. for example, cbow representation for glove source showed a improvement in f1-score relative to word2vec. also, the class method we 2url/ 3url/ 4url 5url/ proposed outperformed the other embedded document representation methods."}, {"id": 1004, "pred": "in this paper we show that, in addition to text based turn features, dialogue features can significantly improve detection of emotions in social media customer service dialogues and help predict emotional techniques used by customer service agents. we defined a dialogue to be a sequence of turns between a specific customer and an agent, where the customer initiates the first turn. consecutive posts of the same party ( customer or agent) uninterrupted by the other party are considered as a single turn ( even if there are several tweets). given the nature of customer support services, we assume the last turn in the dialogue is an agent turn. thus, we expect an even number of turns in the dialogue. we extracted this data from december until june specifically, for each customer that posted a tweet to the customer support accounts, we searched for the previous, if any , turn to which it replied. given this method we traced back previous turns and reconstructed entire dialogues. this analysis reflects our ultimate goal: to enable a computer system to discern the emotions expressed by human customers , and to develop computerized tools that mimic the emotional technique used by a human customer service agent in a particular situation. the goal of this study is to predict the emotions of a customer or an agent turn in social media. the agent turn is represented as a sequence of features that are extracted from the text of the agent turn. these features include agent emotion, customer emotion and agent essence. the goal of this study is to predict the emotions of a customer or an agent turn in social media. the agent turn is represented as a sequence of features that are extracted from the text of the agent turn. these features include agent emotion, customer emotion and agent essence. the goal of this study is to predict the emotions of a customer or an agent turn in social media. the agent turn is represented as a sequence of features that are extracted from the text of the agent turn. these features include agent emotion, customer emotion and agent essence. the goal of this study is to predict the emotions of a customer or an agent turn in social media. the agent turn is represented as a sequence of features that are extracted from the text of the agent turn. these features include agent emotion, customer emotion and agent essence. the goal of this study is to predict the emotions of a customer or an agent turn in social media. in this paper , we have proposed two different models ( svm dialogue and svm-hmm dialogue models ) for support service classification tasks. in the svm dialogue model , we have proposed two different models ( svm-hmm dialogue model and svm-hmm dialogue model ) for these tasks. in the svm-hmm dialogue model , we have proposed two different models ( svm-hmm dialogue model and svm-hmm dialogue model ) for these tasks. in the svm-hmm dialogue model , we have proposed two different models ( svm-hmm dialogue model and svm-hmm dialogue model ) for these tasks. in the svm-hmm dialogue model , we have proposed two different models ( svm-hmm dialogue model and svm-hmm dialogue model ) for these tasks. in the svm-hmm dialogue model , we have proposed two different models ( svm-hmm dialogue model and svm-hmm dialogue model ) for these tasks. we have studied the impact of dialogue features and dialogue history on the quality of the classification and showed improvement in performance for both models and both classification tasks."}, {"id": 1005, "pred": "few-shot learning ( fsl) is a topic of rapidly growing interest. typically, in fsl a model is trained on a dataset consisting of many small tasks ( meta-tasks) and learns to adapt to novel tasks that it will encounter during test time. this is also referred to as meta-learning. another topic closely related to meta-learning with a lot of interest in the community is neural architecture search ( nas) , automatically finding optimal architecture instead of engineering it manually. in this work, we propose to employ tools inspired by the differentiable neural architecture search ( d-nas ) literature in order to optimize the architecture for fsl without overfitting. additionally, to make the architecture task adaptive, we propose the concept of metadapt controllers. these modules are added to the model and predict optimal network connections for a given novel task. using the proposed approach we observe state-of-theart results on two popular few-shot benchmarks: miniimagenet and fc100. this paper proposes a new method for few-shot architecture search called metadapt. it has a graph structure with adaptable connections that can modulate the architecture, adapting it to the few-shot task at hand. metadapt controllers predict the task-specific residuals ( i, j) for the current task as a function of the current task. they are responsible for predicting , given a few-shot task, the best way of adapting the mixing coefficients ( ( i, j) o) for the corresponding edge operations. we find that the architecture transferred from fc100 to miniimagenet is performing well, with results comparable to other state-of-the-art methods, 62.82/79.35 for 1/5-shot. but a search performed on the actual dataset ( miniimagenet training set) is outperforming the transferred one. next we explore the effect of the different design choices made in our approach. we hypothesize that simply using the same algorithm with a larger model architecture would not result in better performance and it might even harm performance. this is also evident by observing the architectures usually used in the few-shot literature. in this paper , we propose an adaptive network architecture for few-shot tasks . in the proposed approach , the last block of the network is used as the training set , and the remaining few blocks are used as the test set . in the proposed approach , the training set and test set are used as the training set and test set , respectively . in the proposed approach , the last block of the network is used as the training set , and the remaining few blocks are used as the test set . in this paper , we propose an adaptive network architecture for few-shot tasks . in the proposed approach , the last block of the network is used as the training set , and the remaining few blocks are used as the test set . in this paper , we propose an adaptive network architecture for few-shot tasks . in the proposed approach , the last block of the network is used as the training set , and the remaining few blocks are used as the test set . in this paper , we propose an adaptive network architecture for few-shot tasks ."}, {"id": 1006, "pred": "the goal of this paper is to detect conversations that are so bad that only a human agent could step in and salvage them . in such settings , a conversation usually becomes egregious due to a combination of the aforementioned problems. the resulting customer frustration may not surface in easily detectable ways such as the appearance of all caps, shouting to a speech recognizer, or the use of anonymized or extreme punctuation. the resulting customer frustration may not surface in easily detectable ways such as the appearance of all caps, shouting to a speech recognizer, or the use of anonymized or extreme punctuation. if detected in real time, a human agent can be pulled in to salvage the conversation. to perform egregious conversation detection , features from both customer inputs and agent responses are extracted, together with features related to the combination of specific inputs and agent responses are extracted. in addition, some of these features are contextual, meaning that they are dependent on where in the conversation they appear. using this set of features for detecting egregious conversations is novel, and as our experimental results show, improves performance compared to a model based solely on features extracted from the conversation text alone. the goal of this work is to give developers of automated agents tools to detect and then solve problems cre- ated by exceptionally bad conversations. in this context, the goal of this work is to give developers of automated agents tools to detect and then solve problems cre- ated by exceptionally bad conversations. in this context, the goal of this work is to give developers of automated agents tools to detect and then solve problems cre- ated by exceptionally bad conversations."}, {"id": 1007, "pred": "this paper presents an analysis into the inner workings of convolutional neural networks ( cnns) for processing text. cnns used for computer vision can be interpreted by projecting filters into image space, but for discrete sequence inputs cnns remain a mystery. we aim to understand the method by which the networks process and classify text. we examine common hypotheses to this problem: that filters, accompanied by global max-pooling, serve as ngram detectors. we show that filters may capture several different semantic classes of ngrams by using different activation patterns, and that global max-pooling induces behavior which separates important ngrams from the rest. finally, we show practical use cases derived from our findings in the form of model interpretability ( explaining a trained model by deriving a concrete identity for each filter, bridging the gap between visualization tools in vision tasks and nlp) and prediction interpretability ( explaining predictions) . this paper proposes a new approach to the analysis of cnns. this approach is based on the idea that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations. the idea is that cnns can be viewed as a sum of word-level activations."}, {"id": 1008, "pred": "a summary generated by editnet may include sentences that were either extracted, abstracted or of both types. moreover, per considered sentence, editnet may decide not to take either of these decisions and completely reject the sentence. by doing so, the network may learn that given the global context, one of the sentence versions may allow to produce a summary with a better coverage. as another example, based on the interaction between both sentence versions with either of the local or global contexts, the network may learn that both sentence versions may only add superfluous or redundant information to the summary, and therefore, decide to reject both. this paper proposes a novel alternative summarization approach that instead of solely applying extraction or abstraction, mixes both together. moreover, editnet implements a novel sentence decision, allowing to correct initial sentence selection decisions which are predicted to negatively effect summarization quality. on average, and of editnet s decisions were to abstract ( a) or reject ( r) , respectively. moreover, on average, per summary, editnet keeps only of the original ( extracted) sentences, while the rest ( 67) are abstracted ones. this demonstrates that, editnet has a high capability of utilizing abstraction, while being able to maintain or reject the original extracted text whenever it is estimated to provide the best benefit for summary s quality."}, {"id": 1009, "pred": "this paper presents dimsim, a learned ndimensional encoding for chinese along with a phonetic similarity algorithm to generate and rank phonetically similar words. dimsim demonstrates a 7.5x improvement on mean reciprocal rank over the state-of-the-art algorithms. this paper proposes a new learning model for chinese word encodings based on annotators and word pairs. the model is based on a set of chinese word encodings and annotators. the model aims to minimize the sum of the absolute differences between the euclidean distances of component pairs and the average distances obtained from the annotated training data across all pairs for initials ( or finals) . we also incorporate a penalty function, p, for pairs deviating from the manually annotated distance so that more phonetically similar pairs are penalized more highly. for each word pair, we use equation to calculate the distance with the average value of labels across the annotators. equation inverts the labels so that the output can be used as a distance metric ( phonetically similar initials or finals are closer together, and scales the result to more accurately measure phonetic similarities. we also ask two native chinese speakers to annotate the quality of the generated candidates. since downstream applications will only consider a limited number of candidates in practice, we evaluate precision via a manual annotation task on the top-k candidates generated by each approach. since the only criteria for picking the best top-k candidate is phonetic similarity , this demonstrates that dimsim ranks the most phonetically similar candidates higher than the other baselines. phonetic transcription is a widely observed phenomenon in chinese social media and informal language. in this paper, we propose an accurate phonetic similarity algorithm called dimsim. dimsim generates phonetically similar candidate words based on learned encodings that capture the pronunciation characteristics of pinyin initial, final , and tone components. using a real world dataset, we demonstrate that dimsim effectively improves mrr by 7.5x, recall by 1.5x and precision by 1.4x over existing approaches. phonetic transcription is a widely observed phenomenon in chinese social media and informal language. in this paper, we propose an accurate phonetic similarity algorithm called dimsim. dimsim generates phonetically similar candidate words based on learned encodings that capture the pronunciation characteristics of pinyin initial, final, and tone components. using a real world dataset, we demonstrate that dimsim effectively improves mrr by 7.5x, recall by 1.5x and precision by 1.4x over existing approaches. phonetic transcription is a widely observed phenomenon in chinese social media and informal language. in this paper, we propose an accurate phonetic similarity algorithm called dimsim. using a real world dataset, we demonstrate that dimsim effectively improves mrr by 7.5x, recall by 1.5x and precision by 1.4x over existing approaches."}, {"id": 1010, "pred": "relation detection is a core component of many nlp applications including knowledge base question answering ( kbqa). although general relation detection1 methods are well studied in the nlp community, such studies usually do not take the end task of kbqa into consideration. as a result, there is a significant gap between general relation detection studies and kb-specific relation detection. owing to these reasons, kb relation detection is significantly more challenging compared to general relation detection tasks. for example, most of the gold test relations in webquestions can be observed during training, thus some prior work on this task adopted the close domain assumption like in the general re research. while for data sets like simple and paralex, the capacity to support large relation sets and unseen relations becomes more necessary. this paper proposes a hierarchical residual bilstm ( hr-bilstm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. the hr-bilstm is a hierarchical residual matching (hrm) model for the relation detection task. kb relation detection is a key step in kbqa and is significantly different from general relation extraction tasks. we propose a novel kb relation detection model, hr-bilstm, that performs hierarchical matching between questions and kb relations. our model outperforms the previous methods on kb relation detection tasks and allows our kbqa system to achieve state-of-the-arts. for future work, we will investigate the integration of our hr-bilstm into end-to-end systems."}, {"id": 1011, "pred": "in this paper, we propose a human-in-the-loop ( huml) dictionary expansion approach that employs a lightweight neural language model coupled with tight huml supervision to assist the user in building and maintaining a domain-specific dictionary from an input text corpus. the approach is based on the explore/exploit paradigm to effectively discover new instances ( explore) from the text corpus as well as predict new unseen terms not currently in the corpus using the accepted dictionary entries ( exploit) this paper proposes an interactive dictionary expansion tool using a lightweight neural language model. our algorithm is iterative and purely statistical, hence does not require any feature extraction beyond tokenization. it incorporates human feedback to improve performance and control semantic drift at every iteration cycle. the experiments showed high importance of tight huml integration on discovery efficiency."}, {"id": 1012, "pred": "this paper presents a novel approach for textual grounding which is based on a deep net based model. the model is based on a set of image concepts, such as semantic segmentations, detections, and word priors. the energy function is based on a set of image concepts, such as semantic segmentations, detections, and word priors. all those concepts come in the form of score maps which we combine linearly before searching for the bounding box containing the highest accumulated over the combined score map. to obtain the prior for a particular word, we search a given training set for each occurrence of the word. to facilitate this operation, we scale each image to a predetermined size. the search over a large number of bounding boxes allows us to retrieve an accurate bounding-box prediction for a given phrase and an image. the search over a large number of bounding boxes allows us to retrieve an accurate bounding-box prediction for a given phrase and an image. the energy function is based on a set of image concepts, such as semantic segmentations, detections, or word priors. all those concepts come in the form of score maps which we combine linearly before searching for the bounding box containing the highest accumulated over the combined score map. in this paper we propose a novel approach to the problem of finding a lower bound on the energy of a product space. the lower bound on the energy of a product space is obtained using a linear combination of word priors and accumulated segmentation masks. the lower bound on the energy of a product space is obtained using a linear combination of word priors and accumulated segmentation masks. in this paper we propose a novel approach to the problem of finding a lower bound on the energy of a product space. the lower bound on the energy of a product space is obtained using a linear combination of word priors and accumulated segmentation masks. in this paper we propose a novel approach to the problem of finding a lower bound on the energy of a product space. the lower bound on the energy of a product space is obtained using a linear combination of word priors and accumulated segmentation masks. in this paper we propose a novel approach to the problem of finding a lower bound on the energy of a product space. the lower bound on the energy of a product space is obtained using a linear combination of word priors and accumulated segmentation masks. in this paper we propose a novel approach to the problem of finding a lower bound on the energy of a product space."}, {"id": 1013, "pred": "perceptual features ( pfs) have been used with great success in tasks such as transfer learning, style transfer, and superresolution. however, the efficacy of pfs as key source of information for learning generative models is not well studied. we investigate here the use of pfs in the context of learning implicit generative models through moment matching ( mm) this paper proposes a new approach to training implicit generative models by using pretrained feature extractors . in this approach , the generator is trained with a dcgan-like architecture and then used as a feature extractor to perform moment matching in a pf space induced by a non - linear kernel function ( a dcnn) that is orders of magnitude larger than the ae latent code, and that we argued is universal in the image domain. gfmn is also related to the recent body of work on mmd and moment matching based generative models 22, 8, 21, 3, the closest to our method is the generative moment matching network autoencoder ( gmmnae) proposed in in gmmnae, the objective is to train a generator g that maps from a prior uniform distribution to the latent code learned by a pretrained ae, and then uses the frozen pretrained decoder to map back to image space. the main benefit of adam moving average ( ama) over the simple moving average ( ma) is the promotion of stable training when using small minibatches. the ability to train with small minibatches is essential due to the large number of features from dcnns, which becomes a challenge in terms of gpu memory usage. the objective of this paper is to show that if a discriminator can distinguish perfectly between real and fake early on , the generator can not learn properly and the min/max game becomes unbalanced, having no good discriminator gradients for the generator to learn from , producing degenerate models. in this appendix, we present a comparison between the simple moving average ( ma) and adam moving average ( ama) for the case where vgg19 imagenet classifier is used as a feature extractor. indeed, the discriminator, being pretrained on imagenet, can quickly learn to distinguish between real and fake images. this limits the reliability of the gradient information from the discriminator, which in turn renders the training of a proper generator extremely challenging or even impossible. this is a well - known issue with gan training where the training of the generator and discriminator must strike a balance. if a discriminator can distinguish perfectly between real and fake early on , the generator can not learn properly and the min/max game becomes unbalanced, having no good discriminator gradients for the generator to learn from, producing degenerate models. figure shows some examples of images generated by the unsuccessfully trained models."}, {"id": 1014, "pred": "we pose the problem of demand-aware recommendation via joint low-rank tensor completion and product category inter- purchase duration vector estimation. given a user s intention for an item by comparing the time utility since her most recent purchase within the item category cj until time k, the larger the value of d t, the less likely she needs this item. in contrast, the function h max ( 0, d t) may be employed to measure the underlying inter- purchase duration times of the r item categories. then a naive optimization algorithm will take at least o ( mnl) time slots, and is intractable for largescale recommendation problems. to overcome this limitation, we develop an efficient alternating algorithm and show that its time complexity is only approximately proportional to the number of nonzero elements in the purchase tensor p since p is usually very sparse , our algorithm is extremely efficient and can solve problems with millions of users and millions of items in a single thread. in this paper , we propose a demand-aware recommendation algorithm that is based on a low - rank tensor x and a high - rank matrix x. the objective is to find the highest ranking of items that are within item i) s category among all items at time t. since each user should make at least one purchase and each item should be purchased at least once to be included in p, n and m are smaller than p0. since the objective is highly non - smooth with nested hinge losses , a naive implementation will take at least o ( mnl) time, which is computationally infeasible when the data is large. to address this issue, we adopt an alternating minimization scheme that iteratively fixes one of d and x and minimizes with respect to the other. to address these challenges, we adopt an alternating minimization scheme that iteratively fixes one of d and x and minimizes with respect to the other. in this paper, we examine the problem of demand-aware recommendation in settings when inter-purchase duration within item categories affects users duration intention in combination with intrinsic properties of the items themselves. we formulate as a norm minimization problem that seeks to jointly learn the form utility tensor and a vector of duration vectors in noiseless settings; it is robust to noise scalable as analyzed theoretically. on two real - world datasets, tmall and amazon review, we show that our algorithm outperforms six state-of-theart recommendation algorithms on the tasks of category, item, and purchase time predictions. in this paper, we examine the problem of demand-aware recommendation in settings when inter-purchase duration within item categories affects users duration intention in combination with intrinsic properties of the items themselves. we formulate as a norm minimization problem that seeks to jointly learn the form utility tensor and a vector of duration vectors in noiseless settings; it is robust to noise scalable as analyzed theoretically. on two real - world datasets, tmall and amazon review, we show that our algorithm outperforms six state-of-theart recommendation algorithms on the tasks of category, item, and purchase time predictions."}, {"id": 1015, "pred": "we present a personality-based neural response generation model that generates responses conditioned on a target personality. the model learns high level features based on the target personality, and uses them to update its hidden state. our model achieves performance improvements in both perplexity and bleu scores over a baseline sequence-to-sequence model, and is validated by human judges."}, {"id": 1016, "pred": "we introduce a stereo correspondence system implemented fully on event-based digital hardware, using a fully graph-based non von-neumann computation model, where no frames, arrays, or any other such data-structures are used. this is the first time that an end-to-end stereo pipeline from image acquisition and rectification , multi- scale spatiotemporal stereo correspondence , winner-take-all, to disparity regularization is implemented fully on event-based hardware. using a cluster of truenorth neurosynaptic processors, we demonstrate their ability to process bilateral event- based inputs streamed live by dynamic vision sensors ( dvs) , at up to 2,000 disparity maps per second, producing high fidelity disparities which are in turn used to reconstruct , at low power , the depth of events produced from rapidly changing scenes. experiments on real-world sequences demonstrate the ability of the system to take full advantage of the asynchronous and sparse nature of dvs sensors for low power depth reconstruction, in environments where conventional frame-based cameras connected to synchronous processors would be inefficient for rapidly moving objects. event-based stereo provides additional advantages over other depth estimation methods that increase accuracy and save energy, such as high temporal resolution, high dynamic range, and robustness to interference with other agents. the winner-take-all ( wta) system is a feed-forward neural network that takes as input d thermometer code representations of the hadamard products for d distinct candidate disparity levels, and finds the disparity with the largest value, at every tick. for designing a scalable and compact wta system, numbers can be efficiently coded using base4 representation where each digit is encoded using a 3-bits thermometer code. in a binary eventbased system, numbers can be efficiently coded using base4 representation where each digit is encoded using a 3-bits thermometer code. note that a thermometer code of length 2n bits can be represented by a qtc of length n/2 bits. now starting from the most significant bits, all the inputs smaller than the maximum will survive at the output of the last cascade network. while it takes a few more bits than a binary code, it allows designing a feed-forward wta network comprising only four cascaded subnetworks, compared to eight for a binary representation, requiring fewer hardware resources as well as half the latency. latency is further improved with larger bases, but the growth in thermometer code length for each digit results in consuming more hardware resources. we have developed a fully event based neuromorphic stereo system capable of running on live input event streams, using a fully graph-based computation model, where no frames, arrays or other such data-structures are used. the implemented neuromorphic stereo disparity system achieves these advantages, while consuming less power per pixel per disparity map compared to the stateof-the-art the homogeneous computational substrate provides the first example of a fully end-to-end low-power , high throughput fully event-based neuromorphic stereo system capable of running on live input event streams, using a fully graph-based computation model, where no frames, arrays or other such data-structures are used."}, {"id": 1017, "pred": "given a collection of distributions , two causal graphs are called interventionally equivalent if they are associated with the same family of interventional distributions, where the elements of the family are indistinguishable using the invariances obtained from a direct application of the calculus rules. we introduce a graphical representation that can be used to determine if two causal graphs are interventionally equivalent. we provide a formal graphical characterization of this equivalence. finally, we extend the fci algorithm, which was originally designed to operate based on cis, to combine observational and interventional datasets, including new orientation rules particular to this setting. in order to characterize causal graphs that are i-markov equivalent, we draw some insight from the markov equivalence of causal graphs with latents . ancestral graphs, and more specifically mags , were proposed as a representation to encode the d-separation statements of a causal graph among the measured variables while not explicitly encoding the latent nodes. the proposed rule is a mixture of rules and as we could be conditioning in w on a subset of the symmetrical difference set i4j. for instance, consider the causal graph d c cd a b, c cd b and suppose we have the interventional distributions pa, b and pc, b. this generalization will soon play a significant role in the characterization and learning of the interventional equivalence class. since b a , c in da, c, then pa, b ( ba) pb, c. this generalization will soon play a significant role in the characterization and learning of the interventional equivalence class. the fci algorithm learns the causal structure underlying a phenomenon of interest from a combination of observational and experimental data. we pursue this endeavor by noting that a generalization of pearl s do-calculus leads to new tests that can be evaluated against data. these tests, in turn, translate into constraints over the structure itself. we then define an interventional equivalence class based on such criteria ( def. 1) , and then derive a graphical characterization for the equivalence of two causal graphs ( thm. finally, we develop an algorithm to learn an interventional equivalence class from data, which includes new orientation rules. we investigate the problem of learning the causal structure underlying a phenomenon of interest from a combination of observational and experimental data. we pursue this endeavor by noting that a generalization of pearl s do-calculus ( thm. 1) leads to new tests that can be evaluated against data. these tests, in turn, translate into constraints over the structure itself. we then define an interventional equivalence class based on such criteria ( def. 1) , and then derive a graphical characterization for the equivalence of two causal graphs ( thm. finally, we develop an algorithm to learn an interventional equivalence class from data, which includes new orientation rules."}, {"id": 1018, "pred": "neural program induction ( npi) is a pragmatic approach toward modularizing the reasoning process by translating a complex natural language query into a multistep executable program. while npi has been commonly trained with the gold sketch or its program sketch, practically only natural language queries and the corresponding answers can be provided for training. the resulting combinatorial explosion in program space, along with extremely sparse rewards, makes npi for kbqa ambitious and challenging. we present complex imperative program induction from terminal rewards ( cipitr) , an advanced neural programmer that mitigates sparsity with auxiliary rewards, and uses high-level constraints, kb schema, and inferred answer type. cipitr solves complex kbqa considerably more accurately than key-value memory networks and neural symbolic machines ( nsm) . for moderately complex queries requiring 2to 5-step programs, cipitr scores at least higher f1 than the competing systems. on one of the hardest class of programs ( comparative reasoning) with steps, cipitr outperforms nsm by a factor of and kvmnet by a factor of further. this paper describes some of the foundational modules invoked by the rest of cipitr. the model is trained with a vocabulary of operators and variable-types in order to sample operators. the model takes as input the natural language question, the kb, and the prepopulated variable memory tables to generate a program. the interpreter executes the generated program with the help of the kb and scratch memory and outputs the system answer. during training, the predicted answer is compared with the gold to obtain a reward, which is sent back to cipitr to update its model parameters through a reinforce objective. handling complex queries by expanding the operator set and generating longer programs ( numop ( maxvar) m this, in absence of gold programs, poses serious training challenges for the programmer. additionally, whereas the relatively simple nsm architecture could explore a large beam size ( 50100) , the complex architecture of cipitr entailed by the cpi problem could only afford to operate with a smaller beam size ( 20), which further exacerbates the sparsity of the reward space. a problem as complex as ours requires not only generic constraints for producing semantically correct programs, but also of prior knowledge, if the model permits. cipitr is an advanced npi model for program induction in absence of gold programs. the model is able to generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training. it can also generate programs with wrong- to postfiltering step during training."}, {"id": 1019, "pred": "the vast amounts of textual data end users need to consume motivates the need for automatic summarization an automatic summarizer gets as an input one or more documents and possibly also a limit on summary length ( e.g., maximum number of words). the summarizer then needs to produce a summary that captures the most salient ( general and informative) content parts within input documents. the summarizer may also be required to satisfy a specific user information need, expressed by one or more queries. therefore, the summarizer will need to produce a focused summary which includes the most relevant information to that need. overall, dual-ces provides a significantly better summarization quality compared to other alternative unsupervised summarizers; and in many cases, it even outperforms that of state-of-the art supervised summarizers. the ce-method is used to produce a 250-word ( lmax 250) topic-focused summary of a set of english documents. given a topic statement, which is expressed by one or more questions, and a set of english documents, the main task is to produce a 250-word ( i.e., lmax 250) topic-focused summary. the ce-method is used to produce a 250-word ( i.e., lmax 250) topic-focused summary of a set of english documents. here, the target measure qfoc ( q, d) guides the optimization towards the production of a focused summary, while still keeping high saliency as much as possible. to achieve that, we use an additional focusdriven predictor which bias summary production towards higher focus. to achieve that, we use an additional focusdriven predictor which bias summary production towards higher focus. moreover , using the pseudo-reference summary sl we introduce an additional auxiliary saliency-based predictor, whose goal is to enhance the saliency of produced focused summary."}, {"id": 1020, "pred": "this paper presents a tts system that can synthesize speech with close to natural quality while running times faster than real-time on a standard cpu. the modular setup of the system allows for simple adaptation to new voices with a small amount of data. we first demonstrate the ability of the system to produce high quality speech when trained on large, high quality datasets. following that, we demonstrate its adaptability by mimicking unseen voices using to minutes long datasets with lower recording quality. large scale mean opinion score quality and similarity tests are presented, showing that the system can adapt to unseen voices with quality gap of and similarity gap of compared to natural speech for male voices and quality gap of and similarity of for female voices. the goal of this paper is to show that it is possible to create a high - quality tts system without an expensive gpu support. the system is built around three nn models for generating the prosody, acoustic features and the final speech signal. we tested this system using two proprietary tts voice datasets and demonstrated that our system produces high quality speech that is comparable to larger and much slower tacotron2 wavenet systems. the task of creating a high-quality tts system out of a smaller set of audio data is even more challenging. we demonstrated that when we reduce the size of the training data, there is some graceful degradation to the quality, but we are still able to maintain good similarity to the original speaker. for future work, we plan to allow voice modifications by adding control over voice parameters such as pitch , breathiness and vocal tract."}, {"id": 1021, "pred": "feature selection is an important problem in statistics and machine learning for interpretable predictive modeling and scientific discoveries. code is available at url.] feature selection is an important problem in statistics and machine learning for interpretable predictive modeling and scientific discoveries. code is available at url.] feature selection is an important problem in statistics and machine learning for interpretable predictive modeling and scientific discoveries. code is available at url.] feature selection is an important problem in statistics and machine learning for interpretable predictive modeling and scientific discoveries. code is available at url.] in this paper we define empirical non convex sic as the arithmetic mean or the geometric mean of controlling the false discovery rate ( fdr) in feature selection is an important problem for reproducible discoveries. in a nutshell, for a feature selection problem given the ground- truth set of features s, and a feature selection method such as sic that gives a candidate set s, our goal is to maximize the tpr ( true positive rate) or the power, and to keep the false discovery rate ( fdr) under control. we propose to learn the feature map as a deep neural network. the architecture of the network can be problem dependent, but we focus here on a particular architecture: deep relu networks with biases removed. as we show below, using our sparsity inducing gradient penalties with such networks, results in input sparsity at the level of the witness function f of sic. this is desirable since it allows for an interpretable model, similar to the effect of lasso with linear models, our sparsity inducing gradient penalties result in a nonlinear self - explainable witness function f 23, with explicit sparse dependency on the inputs. deep relu networks with no biases, homogeneity and input sparsity via gradient penalties. in this paper , we propose a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a neural network model which is based on a is a standard three-layer relu dropout network with no biases, i.e. when using this network, the inputs x and y are first concatenated then given as input to the network. is a standard three-layer relu dropout network with no biases, i.e. when using this network, the inputs x and y are first concatenated then given as input to the network. is a standard three-layer relu dropout network with no biases, i.e. when using this network, the inputs x and y are first concatenated then given as input to the network. is a standard three-layer relu dropout network with no biases, i.e. when using this network, the inputs x and y are first concatenated then given as input to the network. is a standard three-layer relu dropout network with no biases, i.e. when using this network, the inputs x and y are first concatenated then given as input to the network. is a standard three-layer relu dropout network with no biases, i.e. when using this network, the inputs x and y are first concatenated then given as input to the network."}]