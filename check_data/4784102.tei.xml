<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Gan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Summaries Aggregation Query</orgName>
								<address>
									<addrLine>v7, iOS 6.1 CAN, v7, iOS 6.2 CAN, v7, iOS 6.3 CAN, v8, iOS 6.3 USA, v7, iOS 6.1 USA, v7, iOS 6.2 USA, v7, iOS 6.3 USA, v8, iOS 6.1 USA, v8, iOS 6.2 USA, v8, iOS 6.3 … Mergeable</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Ding</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Summaries Aggregation Query</orgName>
								<address>
									<addrLine>v7, iOS 6.1 CAN, v7, iOS 6.2 CAN, v7, iOS 6.3 CAN, v8, iOS 6.3 USA, v7, iOS 6.1 USA, v7, iOS 6.2 USA, v7, iOS 6.3 USA, v8, iOS 6.1 USA, v8, iOS 6.2 USA, v8, iOS 6.3 … Mergeable</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><forename type="middle">Sheng</forename><surname>Tai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Summaries Aggregation Query</orgName>
								<address>
									<addrLine>v7, iOS 6.1 CAN, v7, iOS 6.2 CAN, v7, iOS 6.3 CAN, v8, iOS 6.3 USA, v7, iOS 6.1 USA, v7, iOS 6.2 USA, v7, iOS 6.3 USA, v8, iOS 6.1 USA, v8, iOS 6.2 USA, v8, iOS 6.3 … Mergeable</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vatsal</forename><surname>Sharan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Summaries Aggregation Query</orgName>
								<address>
									<addrLine>v7, iOS 6.1 CAN, v7, iOS 6.2 CAN, v7, iOS 6.3 CAN, v8, iOS 6.3 USA, v7, iOS 6.1 USA, v7, iOS 6.2 USA, v7, iOS 6.3 USA, v8, iOS 6.1 USA, v8, iOS 6.2 USA, v8, iOS 6.3 … Mergeable</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bailis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanford</forename><surname>Infolab</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Moment-Based Quantile Sketches for Efficient High Cardinality Aggregation Queries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.14778/3236187.3236212</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Interactive analytics increasingly involves querying for quantiles over sub-populations of high cardinality datasets. Data processing engines such as Druid and Spark use mergeable summaries to estimate quantiles, but summary merge times can be a bottleneck during aggregation. We show how a compact and efficiently mergeable quantile sketch can support aggregation workloads. This data structure, which we refer to as the moments sketch, operates with a small memory footprint (200 bytes) and computationally efficient (50ns) merges by tracking only a set of summary statistics, notably the sample moments. We demonstrate how we can efficiently estimate quantiles using the method of moments and the maximum entropy principle, and show how the use of a cascade further improves query time for threshold predicates. Empirical evaluation shows that the moments sketch can achieve less than 1 percent quantile error with 15× less overhead than comparable summaries, improving end query time in the MacroBase engine by up to 7× and the Druid engine by up to 60×.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Performing interactive multi-dimensional analytics over data from sensors, devices, and servers increasingly requires computing aggregate statistics for specific subpopulations and time windows <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b65">65]</ref>. In applications such as A/B testing <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b42">42]</ref>, exploratory data analysis <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b74">74]</ref>, and operations monitoring <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14]</ref>, analysts perform aggregation queries to understand how specific user cohorts, device types, and feature flags are behaving. In particular, computing quantiles over these subpopulations is an essential part of debugging and real-time monitoring workflows <ref type="bibr" target="#b26">[26]</ref>. As an example of this quantile-driven analysis, our collaborators on a Microsoft application monitoring team collect billions of telemetry events daily from millions of heterogeneous mobile devices. Each device tracks multiple metrics including request latency and memory usage, and is associated with dimensional metadata such as application version and hardware model. Engineers issue quantile queries on a Druid-like <ref type="bibr" target="#b82">[82]</ref> in-memory data store, aggregating across different dimensions to monitor their application (e.g., examine memory trends across device types) and debug regressions (e.g., examine tail latencies across versions). Querying for a single percentile in this deployment can require aggregating hundreds of thousands of dimension value combinations.</p><p>When users wish to examine the quantiles of specific slices of a dataset, OLAP engines such as Druid and Spark support computing approximate quantiles using compressed representations (summaries) of the data values <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b67">67,</ref><ref type="bibr" target="#b82">82,</ref><ref type="bibr" target="#b83">83]</ref>. By pre-aggregating a summary for each combination of dimension values, Druid and similar engines can reduce query times and memory usage by operating over the relevant summaries directly, effectively constructing a data cube <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b65">65]</ref>.</p><p>Given a time interval and a metric with d associated dimensions, Druid maintains one pre-aggregated summary for each d-tuple of dimension values. These summaries are kept in RAM across a number of nodes, with each node scanning relevant summaries to process subsets of the data specified by a user query. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates how these mergeable <ref type="bibr" target="#b2">[3]</ref> summaries can be aggregated to compute quantile roll-ups along different dimensions without scanning over the raw data.</p><p>More concretely, a Druid-like data cube in our Microsoft deployment with 6 dimension columns, each with 10 distinct values, is stored as a set of up to 10 6 summaries per time interval. On this cube, computing the 99-th percentile latency for a specific app version can require 100,000 merges, or even more for aggregation across complex time ranges. When there are a limited number of dimensions but enormous data volumes, it is cheaper to maintain these summaries than scan over billions of raw datapoints.</p><p>Many quantile summaries support the merge operation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b34">34]</ref>, but their runtime overheads can lead to severe performance penalties on high-cardinality datasets. Based on our experiments (Section 6.2.1), one million 1KB GK-sketches <ref type="bibr" target="#b34">[34]</ref> require more than 3 seconds to merge sequentially, limiting the types of queries users can ask interactively. The merging can be parallelized, but additional worker threads still incur coordination and resource usage overheads. Materialized views <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b61">61]</ref>, sliding window sketches <ref type="bibr" target="#b25">[25]</ref>, and dyadic intervals can also reduce this overhead. However, dyadic intervals only apply to ordered dimensions and maintaining materialized views for multiple dimension rollups can be prohibitively expensive in a real-time stream, so merge time remains a relevant bottleneck.</p><p>In this paper, we enable interactive quantile queries over high-cardinality aggregates by introducing a compact and efficiently mergeable quantile sketch and associated quantile estimation routines. We draw a connection between the classic method of moments for parameter estimation in statistics <ref type="bibr" target="#b79">[79]</ref> and the need for efficient summary data structures. We show that storing the sample moments µi = 1 n x i and log-moments νi = 1 n log i (x) can enable accurate quantile estimation over a range of real-world datasets while utilizing fewer than 200 bytes of memory and incurring merge times of less than 50 nanoseconds. In the context of quantile estimation, we refer to our proposed summary data structure as the moments sketch.</p><p>While constructing the moments sketch is straightforward, the inverse problem of estimating quantiles from the summary is more complex. The statistics in a moments sketch provide only loose constraints on the distribution of values in the original dataset: many distributions might match the moments of a moments sketch but fail to capture the dataset structure. Therefore, we make use of the principle of maximum entropy <ref type="bibr" target="#b41">[41]</ref> to compute a "least-biased" quantile estimate for a moments sketch. On continuous real-valued datasets, we find that this approach yields more accurate estimates than alternative methods, achieving ≤ 1% error with 200 bytes of memory. To achieve this, we also describe a series of practical optimizations to standard entropy maximization that allow us to compute quantile estimates in under 1 millisecond on a range of real-world datasets.</p><p>These query times make the moments sketch a suitable summary when many merges (hundreds of thousands) are required, memory per-summary may be limited to less than 1 kilobyte, and = .01 error is acceptable. The moments sketch and our maximum entropy estimate is most useful in datasets without strong discretization and when very small &lt; 10 −4 error is not required. The maximum entropy principle is less accurate when there are clusters of discrete values in a dataset (Section 6.2.3), and floating point stability (Section 4.3.2) limits the minimum achievable error using this approach.</p><p>Moving beyond simple quantile queries, many complex queries depend on the quantile estimates of multiple subpopulations. For example, data exploration systems such as MacroBase <ref type="bibr" target="#b7">[8]</ref> are interested in finding all subpopulations that match a given threshold condition (e.g., subpopulations where the 95th percentile latency is greater than the global 99th percentile latency). Given a large number of subpopulations, the cost of millisecond-level quantile estimates on thousands of subgroups will accumulate. Therefore, to support threshold queries over multiple populations, we extend our quantile estimator with a cascade <ref type="bibr" target="#b75">[75]</ref>, or sequence of increasingly precise and increasingly expensive estimates based on bounds such as the Markov inequalities. For queries with threshold conditions, the cascades dramatically reduce the overhead of quantile estimation in a moments sketch, by up to 25×.</p><p>We implement the moments sketch both as a reusable library and as part of the Druid and MacroBase analytics engines. We empirically compare its accuracy and efficiency with alternative mergeable quantile summaries on a variety of real-world datasets. We find that the moments sketch offers 16 to 50× faster merge times than alternative summaries with comparable accuracy. This enables 15 to 50× faster query times on real datasets. Moreover, the moments sketch enables up to 7× faster analytics queries when integrated with MacroBase and 60× faster end-to-end queries when integrated with Druid.</p><p>In summary, we make the following contributions:</p><p>• We illustrate how statistical moments are useful as efficient mergeable quantile sketches in aggregation and threshold-based queries over high-cardinality data.</p><p>• We demonstrate how statistical and numerical techniques allow us to solve for accurate quantile estimates in less than 1 ms, and show how the use of a cascade further improves estimation time on threshold queries by up to 25×.</p><p>• We evaluate the use of moments as quantile summaries on a variety of real-world datasets and show that the moments sketch enables 15 to 50× faster query times in isolation, up to 7× faster queries when integrated with MacroBase and up to 60× faster queries when integrated with Druid over comparably-accurate quantile summaries.</p><p>The remainder of this paper proceeds as follows. In Section 2, we discuss related work. In Section 3, we review relevant background material. In Section 4, we describe the proposed moments sketch. In Section 5, we describe a cascade-based approach for efficiently answering thresholdbased queries. In Section 6, we evaluate the moments sketch in a series of microbenchmarks. In Section 7, we evaluate the moments sketch as part of the Druid and MacroBase systems, and benchmark its performance in a sliding window workflow. We conclude in Section 8. We include supplemental appendices in an extended technical report <ref type="bibr" target="#b30">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>High-performance aggregation. The aggregation scenarios in Section 1 are found in many existing streaming data systems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b65">65,</ref><ref type="bibr" target="#b82">82]</ref>, as well as data cube <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b69">69]</ref>, data exploration <ref type="bibr" target="#b1">[2]</ref>, and visualization <ref type="bibr" target="#b16">[17]</ref> systems. In particular, these systems are can perform interactive aggregations over time windows and along many cube dimensions, motivating the design of our sketch. Many of these systems use approximate query processing, sampling, and summaries to improve query performance <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b59">59</ref>], but do not develop data structures specific to quantiles. We believe the moments sketch serves as a useful primitive in these engines.</p><p>Sensor networking is a rich source of algorithms for heavily resource-constrained settings. Sensor network aggregation systems <ref type="bibr" target="#b53">[53]</ref> support large scale roll-ups, but work in this area is largely focused on the complementary problem of communication plans over a network <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b54">54]</ref>. Mean, min, max, and standard deviation in particular are used in <ref type="bibr" target="#b53">[53]</ref> as functions amenable to computation-constrained environments, but the authors do not consider higher moments or their application to quantile estimation.</p><p>Several database systems make use of summary statistics in general-purpose analytics. Muthukrishan et al <ref type="bibr" target="#b60">[60]</ref> observe that the moments are a convenient statistic in streaming settings and use it to fill in missing integers. Data Canopy <ref type="bibr" target="#b78">[78]</ref> uses first and second moments as an efficiently mergeable statistic for computing standard deviations and linear regressions. Similarly, systems on probabilistic data cubes such as <ref type="bibr" target="#b81">[81]</ref> use the first and second moments to prune queries over cube cells that store distributions of values. In addition, many methods use compressed data representations to perform statistical analyses such as linear regression, logistic regression, and PCA <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b63">63,</ref><ref type="bibr" target="#b70">70,</ref><ref type="bibr" target="#b80">80]</ref>. We are not aware of prior work utilizing higher moments to efficiently estimate quantiles for high-dimensional aggregation queries.</p><p>Quantile summaries. There are a variety of summary data structures for the -approximate quantile estimation problem <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b71">71]</ref>. Some of these summaries assume values from a fixed universe <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b71">71]</ref>, while others operate using only comparisons <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b34">34]</ref>. Our proposed moments sketch and others <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b28">28]</ref> operate on real values. Agarwal et al. <ref type="bibr" target="#b2">[3]</ref> provide the initial motivation for mergeable summaries, as well as a proposed mergeable quantile sketch. The authors in <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b77">77]</ref> benchmark a variety of quantile summaries but do not directly evaluate merge time. Zhuang <ref type="bibr" target="#b84">[84]</ref> evaluates merge performance of a variety of quantile summaries in a distributed setting, finding the Random summary to be the fastest. To our knowledge we are the first to introduce and evaluate the moments sketch for fast merge times and low space overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method of moments.</head><p>The method of moments is a wellestablished statistical technique for estimating the parameters of probability distributions <ref type="bibr" target="#b79">[79]</ref>. The main idea behind this approach is that the parameters of a distribution of interest P can be related to the expectations of functions of the random variable X ∼ P . As a general method for consistent statistical parameter estimation, the method of moments is used across a wide range of fields, including econometrics <ref type="bibr" target="#b36">[36]</ref>, physics <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b57">57]</ref>, and machine learning <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b43">43]</ref>. In this work, we demonstrate how the method of moments, applied in conjunction with practical performance optimizations, can scale to support real-world latency-sensitive query processing workloads.</p><p>Maximum entropy principle. The maximum entropy principle prescribes that one should select the least informative distribution that is consistent with the observed data. In the database community, this principle has been applied to estimating cardinality <ref type="bibr" target="#b73">[73]</ref> and predicate selectivity <ref type="bibr" target="#b55">[55]</ref>. Mead and Papanicolaou <ref type="bibr" target="#b57">[57]</ref> apply the maximum entropy principle to the problem of estimating distributions subject to moment constraints; follow-up work proposes the use of Chebyshev polynomials for stability <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b72">72]</ref> and faster approximation algorithms <ref type="bibr" target="#b8">[9]</ref>, though we have not seen any practical implementations suitable for use in a database. The maximum entropy principle is also used in machine learning, notably in the context of maximum entropy models <ref type="bibr" target="#b12">[13]</ref>. For example, in natural language processing, maximum entropy models are a popular choice for tasks such as text classification <ref type="bibr" target="#b62">[62]</ref> and sequence tagging <ref type="bibr" target="#b48">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">BACKGROUND</head><p>In this section, we review the approximate quantile estimation problem, mergeable quantile summaries, and our target query cost model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Quantile Queries</head><p>Given a dataset D with n elements, for any φ ∈ (0, 1), the φ-quantile of D is the item x ∈ D with rank r(x) = φn , where the rank of an element x is the number of elements in D smaller than x.</p><p>An -approximate φ-quantile is an element with rank between (φ − )n and (φ + )n <ref type="bibr" target="#b2">[3]</ref>. Given an estimated φquantileq φ , we can also define its quantile error ε <ref type="bibr" target="#b52">[52]</ref> as the following:</p><formula xml:id="formula_0">ε = 1 n |rank (q φ ) − φn | ,<label>(1)</label></formula><p>such that an -approximate quantile has error at most ε. For example, given a dataset D = {1, . . . , 1000}, an estimatê q0.5 = 504 for the φ = 0.5 quantile would have error ε = 0.003. In this paper, we consider datasets D represented by collections of real numbers D ⊂ R. Quantile summaries are data structures that provide approximate quantile estimates for a dataset given space sublinear in n. These summaries usually have a parameter k that trades off between the size of the summary and the accuracy of its estimates. An -approximate quantile summary provides approximate φ-quantiles, where can be a function of space usage and the dataset <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b71">71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Mergeable Summaries</head><p>Agarwal et al. <ref type="bibr" target="#b2">[3]</ref> introduce the concept of mergeability to accurately combine summaries in distributed settings. Formally, for a summary with parameter k , we use S(D, k ) to denote a valid summary for a dataset D. For any pair of datasets D1 and D2, the summarization routine S is mergeable if there exists an algorithm (i.e., the "merge" procedure) that produces a combined summary S(D1 D2, k ) = merge(S(D1, k ), S(D2, k )) from any two input summaries, where denotes multiset addition.</p><p>Intuitively, a summary is mergeable if there is no accuracy cost to combining pre-computed summaries compared with constructing a summary on the raw data. Thus, mergeable summaries are algebraic aggregate functions in the data cube literature <ref type="bibr" target="#b33">[33]</ref>. As an example, an equi-depth histogram <ref type="bibr" target="#b22">[22]</ref> on its own is not mergeable because there is no way to accurately combine two overlapping histogram buckets without access to additional data.</p><p>Mergeable summaries can be incorporated naturally into a variety of distributed systems. In the MapReduce paradigm, a "map" function can construct summaries over shards while a "reduce" function merges them to summarize a complete dataset <ref type="bibr" target="#b2">[3]</ref>. In the GLADE system <ref type="bibr" target="#b68">[68]</ref>, mergeable summaries are an example of a Generalized Linear Aggregate (GLA), a user-defined computation that can be incrementally aggregated across nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Query Model</head><p>As described in Section 1, we focus on improving the performance of quantile queries over aggregations on high cardinality datasets. Given a dataset with d categorical dimensions, we consider data cubes that maintain summaries for every d-way dimension value tuple as one natural setting for high performance aggregations, and many other settings are also applicable <ref type="bibr" target="#b78">[78]</ref>. In these settings, query time is heavily dependent on the number of merges and the time per merge.</p><p>We consider two broad classes of queries in this paper. First, single quantile queries ask for quantile estimates for a single specified population. For example, we can query the 99th percentile of latency over the last two weeks for a given version of the application:</p><p>SELECT percentile ( latency , 99) FROM requests WHERE time &gt; date_sub ( curdate () , 2 WEEK ) AND app_version = " v8 .2 "</p><p>To process this query in time tquery, we would need to merge nmerge summaries, each with runtime overhead tmerge, and then estimate the quantile from the merged summary with runtime cost test. This results in total query time:</p><formula xml:id="formula_1">tquery = tmerge • nmerge + test.<label>(2)</label></formula><p>We evaluate the different regimes where queries are bottlenecked on merges and estimation in <ref type="figure" target="#fig_5">Figure 6</ref> in Section 6.2.2: merge time begins to dominate at around nmerge ≥ 10 4 . We also consider threshold queries which are conditioned on sub-groups or windows with percentiles above a specified threshold. For example, we may be interested in combinations of application version and hardware platform for which the 99th percentile latency exceeds 100ms:</p><p>SELECT app_version , hw_model , PERCENTILE ( latency , 99) as p99 FROM requests GROUP BY app_version , hw_model HAVING p99 &gt; 100 Such queries are very useful for debugging and data exploration <ref type="bibr" target="#b7">[8]</ref>, but have additional runtime cost that depends on the number of groups ngroups since test can be significant when one is searching for high quantiles over thousands of sub-groups. This results in total query time:</p><formula xml:id="formula_2">tquery = tmerge • nmerge + test • ngroups.<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE MOMENTS SKETCH</head><p>In this section, we describe how we perform quantile estimation using the moments sketch. First, we review the summary statistics stored in the moments sketch and describe how they comprise an efficiently mergeable sketch. Second, we describe how we can use the method of moments and the maximum entropy principle to estimate quantiles from the moments sketch, with details on how we resolve practical difficulties with numerical stability and estimation time. We conclude with a discussion of theoretical guarantees on the approximation error of quantiles estimated from the sketch. Algorithm 1: Moments sketch operations input:</p><formula xml:id="formula_3">number of moments k function Init(x) xmin, xmax ← ∞, −∞ µ, ν, n ← 0, 0, 0 function Accumulate(x) xmin, xmax ← min{x, xmin}, max{x, xmax} n ← n + 1 for i ∈ {1, . . . , k} do µi ← n−1 n µi + 1 n x i Standard moments if x &gt; 0 then νi ← n−1 n νi + 1 n log i (x) Log-moments function Merge(o) o another sketch xmin ← min{o.xmin, xmin} xmax ← max{o.xmax, xmax} µ, ν, n ← µ + o. µ, ν + o. ν, n + o.n</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Moments Sketch Statistics</head><p>The moments sketch of a dataset D is a set of floating point values: the minimum value xmin, the maximum value xmax, the count n, the sample moments µi = 1 n x∈D x i and the sample logarithmic moments νi = 1 n x∈D log i (x) for i ∈ {1, . . . , k} ( <ref type="figure" target="#fig_1">Figure 2</ref>). The moments sketch has an integer parameter k, which describes the highest power used in the moments. We refer to k as the order of a moments sketch. Each sample moment provides additional information about the distribution, so higher-order moments sketches are more precise but have higher space and computation time overheads.</p><p>The moments sketch supports a number of basic operations: init creates an empty sketch, accumulate updates the sketch via point-wise additions, and merge updates the sketch by merging it with another moments sketch. One can construct a moments sketch over a dataset using either accumulate or merge. When accumulating elements pointwise, we update the minimum and maximum, then add to the counts and moments. As an implementation detail, we can accumulate the unscaled sums</p><p>x i and log i (x) instead of the µi, νi. We merge two moments sketches by combining the minimum, maximum, count, and the moments via comparison and potentially vectorized addition. This merge operation preserves the property that a moments sketch constructed using only accumulate is identical (up to floating point precision) to a moments sketch constructed from merging existing sketches of partitions of the data, so there is no accuracy loss in pre-aggregating. We provide pseudocode for these in Algorithm 1. The moments sketch additionally supports quantile estimation routines described in Section 4.2 in order to answer end-user queries. The moments sketch thus supports all of the basic user-defined aggregate operations <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b68">68]</ref> and can be incorporated into data systems using this API.</p><p>Log-moments. The moments sketch records logarithmic moments (log-moments) in order to recover better quantile estimates for long-tailed datasets. In particular, taking the logarithm of data points is useful when values in the dataset can vary over several orders of magnitude. In general, when updating a moments sketch in a streaming manner or when maintaining multiple moments sketches in a distributed setting, we cannot know a priori whether standard moments or log-moments are more appropriate for the given dataset. Therefore, our default approach is to store both sets of moments up to the same order k. Given additional prior knowledge of the data distribution, we may choose to maintain a moments sketch with only a single set of moments.</p><p>Data points with negative values pose a potential problem for the log-moments since the logarithm is undefined for these points. There are several strategies for addressing this, including storing separate sums for positive and negative values and shifting all values so that they are positive. In this paper, we adopt the simple approach of ignoring the log sums when there are any negative values, and computing estimates using the remaining statistics.</p><p>Remark on pathological distributions. The moments of certain "pathological" distributions may be undefined; for example, the Cauchy distribution f (x) = π −1 1 + x 2 −1 does not have finite moments of any order. However, the moments sketch tracks the moments of an empirical dataset, which are always well-defined. This suits our goal of estimating quantiles of a finite dataset, rather than an underlying distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Estimating Quantiles</head><p>Method of moments.</p><p>To estimate quantiles from a moments sketch, we apply the method of moments <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b79">79]</ref> to construct a distribution f (x) whose moments match those recorded in the sketch. Specifically, given a moments sketch with minimum xmin and maximum xmax, we solve for a pdf f (x) supported on <ref type="bibr">[xmin, xmax]</ref> with moments equal to the values in the moments sketch.</p><p>xmax</p><formula xml:id="formula_4">x min x i f (x) dx = µi xmax x min log i (x)f (x) dx = νi</formula><p>We can then report the quantiles of f (x) as estimates for the quantiles of the dataset.</p><p>In general, a finite set of moments does not uniquely determine a distribution <ref type="bibr" target="#b4">[5]</ref>. That is, there are often many possible distributions with varying quantiles that each match a given set of sample moments. Therefore, we must disambiguate between them.</p><p>Maximum entropy. In this work, we use the principle of maximum entropy <ref type="bibr" target="#b41">[41]</ref> to select a unique distribution that satisfies the given moment constraints. Intuitively, the differential Shannon entropy H of a distribution with pdf f (x), defined as H</p><formula xml:id="formula_5">[f ] = − X f (x) log f (x) dx</formula><p>, is a measure of the degree of uninformativeness of the distribution. For example, a uniform distribution has higher entropy than a point mass distribution. Thus, the maximum entropy distribution can be seen as the distribution that encodes the least additional information about the data beyond that captured by the given moment constraints.</p><p>Applying the maximum entropy principle to the moments sketch, we estimate quantiles by solving for the pdf f that maximizes the entropy while matching the moments in the sketch. Following, we estimate quantiles using numeric integration and the Brent's method for root finding <ref type="bibr" target="#b64">[64]</ref> .</p><p>In practice, we find that the use of maximum entropy distributions yields quantile estimates with comparable accuracy to alternative methods on a range of real-world datasets, unless the datasets are more discrete than continuous. We discuss our empirical results further in Section 6.2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization.</head><p>We now describe how to solve for the maximum entropy distribution f . We trade off between accuracy and estimation time by solving for f subject to the first k1 standard moments and k2 log-moments stored in the sketch; incorporating more moments leads to more precise estimates but more computationally expensive estimation. As previously noted, for datasets with non-positive values (i.e., xmin ≤ 0), we set k2 = 0. Therefore, our goal is to find the solution f to the following optimization problem:</p><formula xml:id="formula_6">maximize f ∈F [x min ,xmax] H[f ] (4) subject to xmax x min x i f (x) dx = µi, i ∈ {1, . . . , k1} xmax x min log i (x)f (x) dx = νi, i ∈ {1, . . . , k2}</formula><p>where</p><formula xml:id="formula_7">F[xmin, xmax] denotes the set of distributions sup- ported on [xmin, xmax].</formula><p>It is well known that the solution to Problem (4) is a member of the class of exponential family distributions <ref type="bibr" target="#b41">[41]</ref>:</p><formula xml:id="formula_8">f (x; θ) = exp θ0 + k 1 i=1 θix i + k 2 i=1 θ k 1 +i log i (x) ,</formula><p>where θ0 is a normalization constant such that f (x; θ) integrates to 1 over the domain <ref type="bibr">[xmin, xmax]</ref>. The maximum entropy distribution is determined by the parameter θ such that f (x; θ) satisfies the moment constraints in Problem <ref type="bibr" target="#b3">(4)</ref>.</p><p>In order to solve for θ, we define the potential function L(θ) from <ref type="bibr" target="#b57">[57]</ref>:</p><formula xml:id="formula_9">L(θ) = x min x min exp k 1 i=0 θix i + k 2 i=1 θ k 1 +i log i x dx (5) − θ0 − k 1 i=0 θiµi − k 2 i=1 θ k 1 +i νi L(θ)</formula><p>is a convex function over θ and is constructed so that the minimizing solution θopt = arg min θ∈R k 1 +k 2 −1 L(θ) is exactly the set of coefficients which satisfy the constraints in Problem (4). Equation <ref type="formula">5</ref>thus transforms the constrained optimization problem in (4) into an unconstrained convex optimization problem which we solve using Newton's method <ref type="bibr" target="#b14">[15]</ref>. We show the explicit formulas for the gradient and Hessian that of Equation <ref type="bibr" target="#b4">(5)</ref> in Appendix A in <ref type="bibr" target="#b30">[30]</ref>. First-order optimization routines such as SGD and BFGS <ref type="bibr" target="#b50">[50]</ref> are also viable: they do not use the Hessian but require more steps to achieve convergence. As we will describe in Section 4.3, each additional entry in our Hessian can be computed efficiently using Chebyshev approximations, making second order methods more efficient overall. We provide a lesion study comparison in Section 6.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Practical Implementation</head><p>In this section, we outline implementation concerns that are important for querying the moments sketch in practice. We include a number of optimizations to improve the stability and performance of Newton's method, and also discuss the stability of the moments sketch under floating point precision. Due to space constraints, some equations are omitted and provided in Appendix A and B in <ref type="bibr" target="#b30">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Optimizing Newton's Method</head><p>The primary source of difficulties in implementing Newton's method is the Hessian ∇ 2 L of our objective L. In our case:</p><formula xml:id="formula_10">∇ 2 L(θ)ij = xmax x min mi(x)mj(x)f (x; θ) dx,<label>(6)</label></formula><p>where the functions mi(x) range over the set of functions</p><formula xml:id="formula_11">{x i : i ∈ {1, . . . , k1}} ∪ {log i (x) : i ∈ {1, . . . , k2}}.</formula><p>There are two main challenges in performing a Newton step using this Hessian. First, ∇ 2 L can be nearly singular and cause numerical instabilities in Newton's method that prevent or slow down convergence. Second, since the integral in Eq. <ref type="formula" target="#formula_10">6</ref>has no closed form, the cost of performing O(k 2 ) numerical integrations to compute ∇ 2 L in each iteration can be expensive.</p><p>Conditioning. To quantify the degree of numerical instability, we use the condition number of the Hessian ∇ 2 L. The condition number κ(A) of a matrix A describes how close a matrix is to being singular: matrices with high condition number are close to being singular, and log 10 κ provides an estimate of how many digits of precision are lost when inverting A. In particular, the use of the powers mi(x) ∈ {x i : i ∈ {1, . . . , k1}} can result in ill-conditioned Hessians <ref type="bibr" target="#b31">[31]</ref>. For example, when solving for a maximum entropy distribution with k1 = 8, k2 = 0, xmin = 20, and xmax = 100, we encountered κ(∇ 2 L) ≈ 3 • 10 31 at θ = 0, making even the very first Newton step unstable. We mitigate this issue by using a change of basis from the functions mi(x) = x j and mi(x) = log j (x) to the basis of Chebyshev polynomials Ti(x). Chebyshev polynomials are bounded polynomials supported on [−1, 1] and are often used for polynomial approximation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b64">64]</ref>. Using them we define the new basismi as follows:</p><formula xml:id="formula_12">mi(x) = Ti(s1(x)), i ∈ {1, . . . , k1} T i−k 1 (s2(log(x))), i ∈ {k1 + 1, . . . , k1 + k2}</formula><p>where s1, s2 are linear scaling functions that map to [−1, 1]. The new basis functionsmi(x) can be expressed in terms of x j and log j (x) using standard formulae for Chebyshev polynomials and the binomial expansion <ref type="bibr" target="#b56">[56]</ref>. Using this new basis for mi Equation (6), we found that the condition number for the above example is reduced to κ ≈ 11.3, making precision loss during each Newton step less of a concern.</p><p>On certain datasets, if ill-conditioned matrices are still an issue at query time we further limit ourselves to using the first k1 ≤ k moments and k2 ≤ k log moments by selecting k1, k2 such that the condition number of the Hessian is less than a threshold κmax. Our heuristics select k1, k2 by greedily incrementing k1 and k2 and favoring moments which are closer to the moments expected from a uniform distribution.</p><p>Efficient Integration. Naïvely computing the Hessian in Equation (6) requires evaluating O(k 2 ) numerical integrals per iteration, which can lead to prohibitively slow estimation time. We reduce this computational overhead by using polynomial approximations of the functions appearing in the integrands. If the integrandsmi(x)mj(x)f (x; θ) were expressible as polynomials in x, then each integral can be evaluated in closed form. The factors in the integrand that do not appear as polynomials in x aremi(x), i ∈ {k1 + 1, . . . , k1 + k2}, which are polynomials in log(x), and the pdf f (x; θ). Therefore, we compute Chebyshev polynomial approximations of these factors and replace each instance in the integrands with its corresponding approximation. <ref type="bibr" target="#b0">1</ref> Approximating each of the factors with a degree nc polynomial takes O(nc •log nc) using a fast cosine transform <ref type="bibr" target="#b64">[64]</ref>, so computing the Hessian can be done in O(k2nc log nc + nck1k2). This is not an asymptotic improvement over naive numeric integration, but the number of complex function evaluations (i.e. cos(x), e x ) is reduced substantially. As we show in our empirical evaluation (Section 6.3), polynomial approximations reduce solve times 20× compared to numerically integrating each entry of the Hessian independently. We find in our experiments that the major bottleneck during maximum entropy optimization is the cosine transform used to construct the polynomial approximations. s where s is the relative error in the raw moments sketch power sums. This shift is the primary source of precision loss. We relate the loss to the error bounds in Section 4.4 to show that when using double precision floating point moments up to k ≤ 13.06 0.78 + log 10 (|c| + 1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Floating point stability</head><p>provide numerically useful values. Data centered at 0 (c = 0) have stable higher moments up to k = 16, and in practice we encounter issues when k ≥ 16. We provide derivations and evaluations of this formula in Appendix B and C in <ref type="bibr" target="#b30">[30]</ref> 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.4 Quantile Error Bounds</head><p>Recall that we estimate quantiles by constructing a maximum entropy distribution subject to the constraints recorded in a moments sketch. Since the true empirical distribution is in general not equal to the estimated maximum entropy distribution, to what extent can the quantiles estimated from the sketch deviate from the true quantiles? In this section, we discuss worst-case bounds on the discrepancy between any two distributions which share the same moments, and relate these to bounds on the quantile estimate errors. In practice, error on non-adversarial datasets is lower than these bounds suggest.</p><p>We consider distributions supported on [−1, 1]: we can scale and shift any distribution with bounded support to match. By Proposition 1 in Kong and Valiant <ref type="bibr" target="#b47">[47]</ref>, any two distributions supported on [−1, 1] with densities f and g and standard moments µ f , µg, the Wasserstein distance (or Earth Mover's distance) W1(f, g) between f and g is bounded by:</p><formula xml:id="formula_14">W1(f, g) ≤ O 1 k + 3 k µ f − µg 2 .</formula><p>For univariate distributions f and g, the Wasserstein distance between the distributions is equal to the L1 distance between their respective cumulative distribution functions F and G (see Theorem 6.0.2 in <ref type="bibr" target="#b5">[6]</ref>). Thus:</p><formula xml:id="formula_15">W1(f, g) = +1 −1 |F (x) − G(x)| dx.</formula><p>If f is the true dataset distribution, we estimateq φ by calculating the φ-quantile of the maximum entropy distributionf . The quantile error ε(q φ ) is then equal to the gap between the CDFs: ε(q φ ) = |F (q φ ) −F (q φ )|. Therefore, the average quantile error over the support [−1, 1] is bounded as follows:</p><formula xml:id="formula_16">+1 −1 ε(x) dx ≤ O 1 k + 3 k µ f − µf 2 .<label>(8)</label></formula><p>Since we can run Newton's method until the moments µ f and µf match to any desired precision, the 3 k µ f − µf 2 term is negligible. Equation <ref type="formula" target="#formula_16">8</ref>does not directly apply to the avg used in Section 6, which is averaged over φ for uniformly spaced φquantiles rather than over the support of the distribution. Since φ =F (q φ ), we can relate avg to Eq. (8) using our maximum entropy distributionf :</p><formula xml:id="formula_17">avg = 1 0 ε(q φ ) dφ = +1 −1 ε(x)f (x) dx ≤ O f max k</formula><p>wherefmax is the maximum density of our estimate. Thus, we expect the average quantile error avg to have a decreasing upper bound as k increases, with higher potential error whenf has regions of high density relative to its support. Though these bounds are too conservative to be useful in practice, they provide useful intuition on how worst case error can vary with k andf <ref type="figure" target="#fig_1">(Figure 23</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">THRESHOLD QUERIES</head><p>We described in Section 3.3 two types of queries: single quantile queries and threshold queries over multiple groups. The optimizations in Section 4.3 can bring quantile estimation overhead down to ≤ 1ms, which is sufficient for interactive latencies on single quantile queries. In this section we show how we can further reduce quantile estimation overheads on threshold queries. Instead of computing the quantile on each sub-group directly, we compute a sequence of progressively more precise bounds in a cascade <ref type="bibr" target="#b75">[75]</ref>, and only use more expensive estimators when necessary. We first describe a series of bounds relevant to the moments sketch in Section 5.1 and then show how they can be used in end-toend queries in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Moment-based inequalities</head><p>Given the statistics in a moments sketch, we apply a variety of classical inequalities to derive bounds on the quantiles. These provide worst-case error guarantees for quantile Maximum Entropy return q φ &gt; t estimates, and enable faster query processing for threshold queries over multiple groups.</p><p>One simple inequality we make use of is Markov's inequality. Given a non-negative dataset D with moments µi Markov's inequality tells us that for any value t,</p><formula xml:id="formula_18">rank(t) ≥ n 1 − µ k t k</formula><p>where the rank is the number of elements in D less than t. We can apply Markov's inequality to moments of transformations of</p><formula xml:id="formula_19">D including T + (D) = {x−xmin : x ∈ D}, T − (D) = {xmax − x : x ∈ D}, and T l (D) = {log(x) :</formula><p>x ∈ D} to bound rank(t) and thus also the error for quantile estimates t =q φ . We refer to this procedure as the MarkovBound procedure.</p><p>The authors in <ref type="bibr" target="#b66">[66]</ref> provide a procedure (Section 3, <ref type="figure" target="#fig_0">Figure  1</ref> in <ref type="bibr" target="#b66">[66]</ref>) for computing tighter but more computationally expensive bounds on the CDF F (t) of a distribution given its moments. We refer to this procedure as the RTTBound procedure, and as with the MarkovBound procedure, use it to bound the error of a quantile estimateq φ . The RTTBound procedure does not make use of the standard moments and log moments simultaneously, so we run RTTBound once on the standard moments and once on log moments and take the tighter of the bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cascades for Threshold queries</head><p>Given a moments sketch, Algorithm 2 shows how we calculate Threshold(t, φ): whether the dataset has quantile estimateq φ above a fixed cutoff t. We use this routine whenever we answer queries on groups with a predicateq φ &gt; t, allowing us to check whether a subgroup should be included in the results without computingq φ directly. The threshold check routine first performs a simple filter on whether the threshold t falls in the range <ref type="bibr">[xmin, xmax]</ref>. Then, we can use the Markov inequalities MarkovBound to calculate lower and upper bounds on the rank of the threshold rank(t) in the subpopulation. Similarly the RTTBound routine uses more sophisticated inequalities in <ref type="bibr" target="#b66">[66]</ref> to obtain tighter bounds on the rank. These bounds are used to determine if we can resolve the threshold predicate immediately. If not, we solve for the maximum entropy distribution as described in Section 4.2 (MaxEntQuantile) and calculateq φ .</p><p>The Markov and RTTBound bounds are cheaper to compute than our maximum entropy estimate, making threshold predicates cheaper to evaluate than explicit quantile estimates. The bounds apply to any distribution or dataset that matches the moments in a moments sketch, so this routine has no false negatives and is consistent with calculating the maximum entropy quantile estimate up front.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EVALUATION</head><p>In this section we evaluate the efficiency and accuracy of the moments sketch in a series of microbenchmarks, and then show how the moments sketch provides end-to-end performance improvements in the Druid and Macrobase data analytics engines <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b82">82]</ref>.</p><p>This evaluation demonstrates that: 1. The moments sketch supports 15 to 50× faster query times than comparably accurate summaries on quantile aggregations.</p><p>2. The moments sketch provides avg ≤ 0.01 estimates across a range of real-world datasets using less than 200 bytes of storage.</p><p>3. Maximum entropy estimation is more accurate than alternative moment-based quantile estimates, and our solver improves estimation time by 200× over naive solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Integrating the moments sketch as a user-defined sketch provides 7× faster quantile queries than the default quantile summary in Druid workloads.</p><p>5. Cascades can provide 25× higher query throughput compared to direct moments sketch usage in Macrobase threshold queries. Throughout the evaluations, the moments sketch is able to accelerate a variety of aggregation-heavy workloads with minimal space overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>We implement the moments sketch and its quantile estimation routines in Java 2 . This allows for direct comparisons with the open source quantile summaries <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b67">67]</ref> and integration with the Java-based Druid <ref type="bibr" target="#b82">[82]</ref> and MacroBase <ref type="bibr" target="#b7">[8]</ref> systems. In our experimental results, we use the abbreviation M-Sketch to refer to the moments sketch.</p><p>We compare against a number of alternative quantile summaries: a mergeable equi-width histogram (EW-Hist) using power-of-two ranges <ref type="bibr" target="#b65">[65]</ref>, the 'GKArray' (GK) variant of the Greenwald Khanna <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b52">52]</ref> sketch, the AVL-tree T-Digest (T-Digest) <ref type="bibr" target="#b28">[28]</ref> sketch, the streaming histogram (S-Hist) in <ref type="bibr" target="#b11">[12]</ref> as implemented in Druid, the 'Random' (RandomW) sketch from <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b77">77]</ref>, reservoir sampling (Sampling) <ref type="bibr" target="#b76">[76]</ref>, and the low discrepancy mergeable sketch (Merge12) from <ref type="bibr" target="#b2">[3]</ref>, both implemented in the Yahoo! datasketches library <ref type="bibr" target="#b0">[1]</ref>. The GK sketch is not usually considered mergeable since its size can grow upon merging <ref type="bibr" target="#b2">[3]</ref>, this is especially dramatic in the production benchmarks in Appendix D.4 in <ref type="bibr" target="#b30">[30]</ref>. We do not compare against fixed-universe quantile summaries such as the Q-Digest <ref type="bibr" target="#b71">[71]</ref> or Count-Min sketch <ref type="bibr" target="#b23">[23]</ref> since they would discretize continuous values.</p><p>Each quantile summary has a size parameter controlling its memory usage, which we will vary in our experiments. Our implementations and benchmarks use double precision floating point values. During moments sketch quantile estimation we run Newton's method until the moments match to within δ = 10 −9 , and select k1, k2 using a maximum https://github.com/stanford-futuredata/msketch condition number κmax = 10 4 . We construct the moments sketch to store both standard and log moments up to order k, but choose at query time which moments to make use of as described in Section 4.3.2.</p><p>We quantify the accuracy of a quantile estimate using the quantile error ε as defined in Section 3.1. Then, as in <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b77">77]</ref> we can compare the accuracies of summaries on a given dataset by computing their average error avg over a set of uniformly spaced φ-quantiles. In the evaluation that follows, we test on 21 equally spaced φ between 0.01 and 0.99.</p><p>We evaluate each summary via single-threaded experiments on a machine with an Intel Xeon E5-4657L 2.40GHz processor and 1TB of RAM, omitting the time to load data from disk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Datasets</head><p>We make use of six real-valued datasets in our experiments, whose characteristics are summarized in <ref type="table" target="#tab_1">Table 1</ref>. The milan dataset consists of Internet usage measurements from Nov. 2013 in the Telecom Italia Call Data Records <ref type="bibr" target="#b40">[40]</ref>. The hepmass dataset consists of the first feature in the UCI <ref type="bibr" target="#b49">[49]</ref> HEPMASS dataset. The occupancy dataset consists of CO2 measurements from the UCI Occupancy Detection dataset. The retail dataset consists of integer purchase quantities from the UCI Online Retail dataset. The power dataset consists of Global Active Power measurements from the UCI Individual Household Electric Power Consumption dataset. The exponential dataset consists of synthetic values from an exponential distribution with λ = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Performance Benchmarks</head><p>We begin with a series of microbenchmarks evaluating the moments sketch query times and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Query Time</head><p>Our primary metric for evaluating the moments sketch is total query time. We evaluate quantile aggregation query times by pre-aggregating our datasets into cells of 200 values and maintaining quantile summaries for each cell. Then we measure the time it takes to performing a sequence of merges and estimate a quantile. In this performance microbenchmark, the cells are grouped based on their sequence in the dataset, while the evaluations in Section 7 group based on column values. We divide the datasets into a large number of cells to simulate production data cubes, while in Appendix D.3 and D.4 in <ref type="bibr" target="#b30">[30]</ref> we vary the cell sizes. Since the moments sketch size and merge time are data-independent, the results generalize as we vary cell size. <ref type="figure" target="#fig_3">Figure 3</ref> shows the total query time to merge the summaries and then compute a quantile estimate when each summary is instantiated at the smallest size sufficient to achieve avg ≤ .01 accuracy. We provide the parameters we used and average observed space usage in   the long-tailed milan dataset, the S-Hist and EW-Hist summaries are unable to achieve avg ≤ .01 accuracy with less than 100 thousand buckets, so we provide timings at 100 buckets for comparison. The moments sketch provides 15 to 50× faster query times than RandomW, the next fastest accurate summary. As a baseline, sorting the milan dataset takes 7.0 seconds, selecting an exact quantile online takes 880ms, and streaming the data pointwise into a RandomW sketch with = 1/40 takes 220ms. These methods do not scale as well as using pre-aggregated moments sketches as dataset density grows but the number of cells remains fixed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Merge and Estimation Time</head><p>Recall that for a basic aggregate quantile query tquery = tmerge • nmerge + test. Thus we also measure tmerge and test to quantify the regimes where the moments sketch performs well. In these experiments, we vary the summary size parameters, though many summaries have a minimum size, and the moments sketch runs into numeric stability issues past k ≥ 15 on some datasets (see Section 4.3.2).</p><p>In <ref type="figure">Figure 4</ref> we evaluate the average time required to merge one of the cell summaries. Larger summaries are more expensive to merge, and the moments sketch has faster (&lt; 50ns) merge times throughout its size range. When comparing summaries using the parameters in <ref type="table" target="#tab_0">Table 2</ref>, the moments sketch has up to 50× faster merge times than other summaries with the same accuracy.</p><p>One can also parallelize the merges by sharding the data and having separate nodes operate over each partition, generating partial summaries to be aggregated into a final result. Since each parallel worker can operate independently, in these settings the moments sketch maintains the same relative performance improvements over alternative summaries when we can amortize fixed overheads, and we include sup-  plemental parallel experiments in Appendix F in <ref type="bibr" target="#b30">[30]</ref>. The other major contributor to query time is estimation time. In <ref type="figure" target="#fig_4">Figure 5</ref> we measure the time to estimate quantiles given an existing summary. The moments sketch provides on average 2 ms estimation times, though estimation time can be higher when our estimator chooses higher k1, k2 to achieve better accuracy. This is the cause for the spike at k = 4 in the milan dataset and users can can mitigate this by lowering the condition number threshold κmax. Other summaries support microsecond estimation times. The moments sketch thus offers a tradeoff of better merge time for worse estimation time. If users require faster estimation times, the cascades in Section 5.2 and the alternative estimators in Section 6.3 can assist. We show how the merge time and estimation time tradeoff define regimes where each component dominates depending on the number of merges. In <ref type="figure" target="#fig_5">Figure 6</ref> we measure how the query time changes as we vary the number of summaries (cells of size 200) we aggregate. We use the moments sketch with k = 10 and compare against the mergeable Merge12 and RandomW summaries with parameters from <ref type="table" target="#tab_0">Table 2</ref>. When nmerge ≥ 10 4 merge time dominates and the moments sketch provides better performance than alternative summaries. However, the moments sketch estimation times dominate when nmerge ≤ 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Accuracy</head><p>The moments sketch accuracy is dataset dependent, so in this section we compare the average quantile error on our evaluation datasets. <ref type="figure" target="#fig_6">Figure 7</ref> illustrates the average quantile error avg for summaries of different sizes constructed using pointwise accu-  mulation on the complete dataset. The moments sketch achieves ≤ 10 −4 accuracy on the synthetic exponential dataset, and ≤ 10 −3 accuracy on the high entropy hepmass dataset. On other datasets it is able to achieve avg ≤ 0.01 with fewer than 200 bytes of space. On the integer retail dataset we round estimates to the nearest integer. The EW-Hist summary, while efficient to merge, provides less accurate estimates than the moments sketch, especially in the long-tailed milan and retail datasets. We provide further experiments in <ref type="bibr" target="#b30">[30]</ref> showing how the moments sketch worst-case error bounds are comparable to other summaries (Appendix E), that the moments sketch is robust to changes in skew and the presence of outliers (Appendix D), and that the moments sketch generalizes to a production workload (Appendix D.4). However, on datasets with low-entropy, in particular datasets consisting of a small number of discrete point masses, the maximum entropy principle provides poor accuracy. In the worst case, the maximum entropy solver can fail to converge on datasets with too few distinct values. <ref type="figure">Figure illustrates</ref> how the error of the maximum entropy estimate increases as we lower the cardinality of a dataset consisting of uniformly spaced points in  <ref type="figure">Figure 9</ref>: Accuracy with and without log moments. Given the same total space budget, log moments improve accuracy on the long-tailed milan and retail datasets, and do not affect accuracy significantly on other datasets such as occupancy the range [−1, 1], eventually failing to converge on datasets with fewer than five distinct values. If users are expecting to run queries on primarily low-cardinality datasets, fixeduniverse sketches or heavy-hitters sketches may be more appropriate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Quantile Estimation Lesion Study</head><p>To evaluate each component of our quantile estimator design, we compare the accuracy and estimation time of a variety of alternative techniques on the milan and hepmass datasets. We evaluate the impact of using log moments, the maximum entropy distribution, and our optimizations to estimation.</p><p>To examine effectiveness of log moments, we compare our maximum entropy quantile estimator accuracy with and without log moments. For a fair comparison, we compare the estimates produced from k standard moments and no log moments with those produced from up to k of each. <ref type="figure">Figure 9</ref> illustrates how on some long-tailed datasets, notably milan and retail, log moments reduce the error from &gt; .15 to &lt; .015. On other datasets, log moments do not have a significant impact.</p><p>We compare our estimator (opt) with a number of other estimators that make use of the same moments. The gaussian estimator fits a Gaussian distribution to the mean and standard deviation. The mnat estimator uses the closed form discrete CDF estimator in <ref type="bibr" target="#b58">[58]</ref>. The svd estimator discretizes the domain and uses singular value decomposition to solve for a distribution with matching moments. The cvxmin estimator also discretizes the domain and uses a convex solver to construct a distribution with minimal maximum density and matching moments. The cvx-maxent estimator discretizes the domain and uses a convex solver to maximize  <ref type="figure" target="#fig_0">Figure 10</ref>: Lesion study comparing our optimized maximum entropy solver to other estimators. Our opt estimator provides at least 5× less error than estimators that do not use maximum entropy, and up to 200× faster estimation times than naive maximum entropy solvers. the entropy, as described in Chapter 7 in <ref type="bibr" target="#b14">[15]</ref>. The newton estimator implements our estimator without the integration techniques in Sec. 4.3, and uses adaptive Romberg integration instead <ref type="bibr" target="#b64">[64]</ref>. The bfgs estimator implements maximum entropy optimization using the first-order L-BFGS <ref type="bibr" target="#b50">[50]</ref> method as implemented in a Java port of liblbfgs <ref type="bibr" target="#b46">[46]</ref>. <ref type="figure" target="#fig_0">Figure 10</ref> illustrates the average quantile error and estimation time for these estimators. We run these experiments with k = 10 moments. For uniform comparisons with other estimators, on the milan dataset we only use the log moments, and on the hepmass dataset we only use the standard moments. We perform discretizations using 1000 uniformly spaced points and make use of the ECOS convex solver <ref type="bibr" target="#b27">[27]</ref>. Solvers that use the maximum entropy principle provides at least 5× less error than estimators that do not. Furthermore, our optimizations are able to improve the estimation time by a factor of up to 200× over an implementation using generic solvers, and provide faster solve times than naive Newton's method or BFGS optimizers. As described in Section 4.3, given the computations needed to calculate the gradient, one can compute the Hessian relatively cheaply, so our optimized Newton's method is faster than BFGS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">APPLYING THE MOMENTS SKETCH</head><p>In this section, we evaluate how the moments sketch affects performance when integrated with other data systems. We examine how the moments sketch improves query performance in the Druid analytics engine, as part of a cascade in the Macrobase feature selection engine <ref type="bibr" target="#b7">[8]</ref>, and as part of exploratory sliding window queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Druid Integration</head><p>To illustrate the utility of the moments sketch in a modern analytics engine, we integrate the moments sketch with Druid <ref type="bibr" target="#b82">[82]</ref>. We do this by implementing moments sketch as an user-defined aggregation extension, and compare the total query time on quantile queries using the moments sketch with the default S-Hist summary used in Druid and introduced in <ref type="bibr" target="#b11">[12]</ref>. The authors in <ref type="bibr" target="#b11">[12]</ref> observe on average 5% error for an S-Hist with 100 centroids, so we benchmark a sum M-Sketch@10 S-Hist@10 S-Hist@100 S-Hist@1000 Quantile Summary 10 1  <ref type="figure" target="#fig_0">Figure 11</ref>: Druid end-to-end query benchmark. The moments sketch allows for faster query times than the comparable S-Hist summary with 100 bins. Runtime for a native sum operation is a lower bound on query time.</p><p>moments sketch with k = 10 against S-Hists with 10, 100, and 1000 centroids.</p><p>In our experiments, we deploy Druid on a single nodethe same machine described in section 6.1 -with the same base configuration used in the default Druid quickstart. In particular, this configuration dedicates 2 threads to process aggregations. Then, we ingest 26 million entries from the milan dataset at a one hour granularity and construct a cube over the grid ID and country dimensions, resulting in 10 million cells. <ref type="figure" target="#fig_0">Figure 11</ref> compares the total time to query for a quantile on the complete dataset using the different summaries. The moments sketch provides 7× lower query times than a S-Hist with 100 bins. Furthermore, as discussed in Section 6.2.1, any S-Hist with fewer than 10 thousand buckets provides worse accuracy on milan data than the moments sketch. As a best-case baseline, we also show the time taken to compute a native sum query on the same data. The 1 ms cost of solving for quantile estimates from the moments sketch on this dataset is negligible here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Threshold queries</head><p>In this section we evaluate how the cascades described in Section 5.2 improve performance on threshold predicates. First we show in Section 7.2.1 how the MacroBase analytics engine can use the moments sketch to search for anomalous dimension values. Then, we show in Section 7.2.2 how historical analytics queries can use the moments sketch to search and alert on sliding windows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">MacroBase Integration</head><p>The MacroBase engine searches for dimension values with unusually high outlier rates in a dataset <ref type="bibr" target="#b7">[8]</ref>. For example, given an overall 2% outlier rate, MacroBase may report when a specific app version has an outlier rate of 20%. We integrate the moments sketch with a simplified deployment of MacroBase where all values greater than the global 99th percentile t99 are considered outliers. We then query Mac-roBase for all dimension values with outlier rate at least r = 30× greater than the overall outlier rate. This is equivalent to finding subpopulations whose 70th percentile is greater than t99.</p><p>Given a cube with pre-aggregated moments sketches for each dimension value combination and no materialized rollups, MacroBase merges the moments sketches to calculate the global t99, and then runs Algorithm 2 on every dimensionvalue subpopulation, searching for subgroups with q.7 &gt; t99. We evaluate the performance of this query on 80 million rows of the milan internet usage data from November 2013, pre-aggregated by grid ID, country, and at a four hour granularity. This resulted in 13 million cube cells, each with its own moments sketch. Running the MacroBase query produces 19 candidate dimension values. We compare the total time to process this query using direct quantile estimates, our cascades, and the alternative Merge12 quantile sketch. In the first approach (Merge12a), we merge summaries during MacroBase execution as we do with a moments sketch. In the second approach (Merge12b), we calculate the number of values greater than the t99 for each dimension value combination and accumulate these counts directly, instead of the sketches. We present this as an optimistic baseline, and is not always a feasible substitute for merging summaries. <ref type="figure" target="#fig_0">Figure 12</ref> shows the query times for these different methods: the baseline method calculates quantile estimates directly, we show the effect of incrementally adding each stage of our cascade ending with +RTTBound. Each successive stage of the cascade improves query time substantially. With the complete cascade, estimation time is negligible compared to merge time. Furthermore, the moments sketch with cascades has 7.9× lower query times than using the Merge12 sketch, and even 3.7× lower query times than the Merge12b baseline.</p><p>In <ref type="figure" target="#fig_0">Figure 13</ref> we examine the impact the cascade has on estimation time directly. Each additional cascade stage improves threshold query throughput and is more expensive than the last. The complete cascade is over 250× faster than this baseline, and 25× faster than just using a simple range check. Estimation Merge <ref type="figure" target="#fig_0">Figure 14</ref>: Sliding window query: moments sketch with cascades runs 13× faster than Merge12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Sliding Window Queries</head><p>Threshold predicates are broadly applicable in data exploration queries. In this section, we evaluate how the moments sketch performs on sliding window alerting queries. This is useful when, for instance, users are searching for time windows of unusually high CPU usage spikes.</p><p>For this benchmark, we aggregated the 80 million rows of the milan dataset at a 10-minute granularity, which produced 4320 panes that spanned the month of November. We augmented the milan data with two spikes corresponding to hypothetical anomalies. Each spike spanned a two-hour time frame and contributed 10% more data to those time frames. Given a global 99th percentile of around 500 and a maximum value of 8000, we added spikes with values x = 2000 and x = 1000</p><p>We then queried for the 4-hour time windows whose 99th percentile was above a threshold t = 1500. When processing this query using a moments sketch, we can update sliding windows using turnstile semantics, subtracting the values from the oldest pane and merging in the new one, and use our cascade to filter windows with quantiles above the threshold. <ref type="figure" target="#fig_0">Figure 14</ref> shows the runtime of the sliding window query using both the moments sketch and Merge12. Faster moments sketch merge times and the use of turnstile semantics then allow for 13× faster queries than Merge12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">CONCLUSION</head><p>In this paper, we show how to improve the performance of quantile aggregation queries using statistical moments. Low merge overhead allows the moments sketch to outperform comparably accurate existing summaries when queries aggregate more than 10 thousand summaries. By making use of the method of moments and the maximum entropy principle, the moments sketch provides avg ≤ 0.01 accuracy on real-world datasets, while the use of numeric optimizations and cascades keep query times at interactive latencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. MAXIMUM ENTROPY ESTIMATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Newton's Method Details</head><p>Recall that we wish to solve the following optimization problem:</p><formula xml:id="formula_20">maximize f ∈F [x min ,xmax] H[f ] subject to xmax x min x i f (x) dx = µi, i ∈ {1, . . . , k1} xmax x min log i (x)f (x) dx = νi, i ∈ {1, . . . , k2}</formula><p>.</p><p>Throughout this section it is easier to reformulate this problem in more general terms, using the functions</p><formula xml:id="formula_21">mi(x) = x i 0 ≤ i ≤ k1 h(x) i−k 1 k1 + 1 ≤ i ≤ k1 + k2.<label>(9)</label></formula><p>where h(x) = log(x) or h(x) = e x depending on whether we work using the x or log-transformed x = log(x) as our primary metric. Letting kt = k1 + k2, and folding the νi into a larger µ vector, our optimization problem is then:</p><formula xml:id="formula_22">maximize f ∈F [x min ,xmax] H[f ] (10) subject to xmax x min mi(x)f (x) dx = µi, i ∈ {0, . . . , kt} .</formula><p>Functional analysis <ref type="bibr" target="#b41">[41]</ref> tells us that a maximal entropy solution to Eq. (10) has the form:</p><formula xml:id="formula_23">f (x; θ) = exp k t i=0 θimi(x) ,</formula><p>Then if we define the potential function L(θ) from <ref type="bibr" target="#b57">[57]</ref>:</p><formula xml:id="formula_24">L(θ) = x min x min exp k t i=0 θimi(x) − k t i=0 θiµi<label>(11)</label></formula><p>We can calculate the gradient and Hessian of L(θ) as follows:</p><formula xml:id="formula_25">∂L ∂θi = x min x min mi(x) exp k t i=0 θimi(x) − µi (12) ∂ 2 Γ ∂θi∂θj = x min x min mi(x)mj(x) exp k t i=0 θimi(x)<label>(13)</label></formula><p>Note that when the gradient given in Eq. (12) is zero then the constraints in Eq. (10) are satisfied. Since L(θ) is convex and has domain R k d , this means that by solving the unconstrained minimization problem over L(θ) we can find a solution θ we can find a solution to the constrained maximum entropy problem. Since Newton's method is a second order method, we can use Equations <ref type="bibr" target="#b10">(11)</ref>, <ref type="bibr" target="#b11">(12)</ref>, <ref type="bibr" target="#b12">(13)</ref> are to execute Newton's method with backtracking line search <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Practical Implementation Details</head><p>Chebyshev Polynomial Basis Functions.</p><p>As described in Section 4.3, we can improve the stability of our optimization problem by using Chebyshev polynomials. To do so, we must redefine our mi(x)</p><formula xml:id="formula_26">mi(x) = Ti(s1(x)), i ∈ {1, . . . , k1} T i−k 1 (s2(h(x))), i ∈ {k1 + 1, . . . , k1 + k2}</formula><p>where Ti(x) are Chebyshev polynomials of the first kind <ref type="bibr" target="#b64">[64]</ref> and the s1, s2 are linear scaling functions to map onto [−1, 1] defined as:</p><formula xml:id="formula_27">s1(x) = x − xmax + xmin / xmax − xmin s2(x) = x − h(xmax) + h(xmin) / h(xmax) − h(xmin) .</formula><p>The formulae for µi, Γ, ∇Γ, ∇ 2 Γ still hold, but now the µi are</p><formula xml:id="formula_28">µi = 1 n x Ti(s1(x)) 0 ≤ i ≤ k1 x T i−ka (s2(h(x))) k1 + 1 ≤ i ≤ k1 + k2. .<label>(14)</label></formula><p>These can be computed from the quantities µi =</p><p>x x i , νi =</p><p>x h(x) i originally stored in the moments sketch by using the binomial expansion and standard formulae for expressing Chebyshev polynomials in terms of standard monomials <ref type="bibr" target="#b56">[56]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chebyshev Polynomial Integration.</head><p>In this section we will show how Chebyshev approximation provides for efficient ways to compute the gradient and Hessian. Here it is easier to work with the change of variables u = s1(x) so that f u (u) = f (s −1 1 (u)) has domain [−1, 1]. First, we will examine the case when k2 = 0. If we can approximate f (u; θ) as a linear combination of chebyshev polynomials:</p><formula xml:id="formula_29">f u (u; θ) = exp k t i=0 θimi(u) (15) ≈ nc j=0 cjTj(u)<label>(16)</label></formula><p>Then using polynomial identities such as Ti(x)Tj(x) = 1 (Ti+j(x) + T |i−j| (x)) we can evaluate the Gradient and Hessian in Eqs. <ref type="bibr" target="#b11">(12)</ref>, <ref type="bibr" target="#b12">(13)</ref> using O(k1nc) algebraic operations.</p><p>We can approximate f u (u; θ) using the Clenshaw Curtis quadrature formulas to approximate a function f supported on [−1, 1] (Eq. 5.9.4 in <ref type="bibr" target="#b64">[64]</ref>):</p><formula xml:id="formula_30">aj = 2 nc f (1) − f (−1) + nc−1 i=1 f cos πi nc cos πi nc (17) Then f (x) ≈ 1 T0(x) + nc i=1 aiTi(x)<label>(18)</label></formula><p>where Eq. (17) can be evaluated in nc log nc time using the Fact Cosine Transform <ref type="bibr" target="#b64">[64]</ref>. The case when k2 &gt; 0 is similar except we need to approximate not just f u (u; θ) but also Ti(s2(h(s −1 1 (u)))f u (u; θ) for i ≤ k2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. NUMERIC STABILITY OF MOMENTS</head><p>As mentioned in Section 4.3.2, floating point arithmetic limits the usefulness of higher moments. This is because the raw moments 1 n x i are difficult to optimize over and analyze: both maximum entropy estimation (Section 4.3) and theoretical error bounds (Section 4.4) apply naturally to moments on data in the range [−1, 1]. In particular, shifting the data improves the conditoning of the optimization problem dramatically. However, when merging sketches from different datasets, users may not know the full range of the data ahead of time, so the power sums stored in a moments sketch correspond to data in an arbitrary range <ref type="bibr">[a, b]</ref>. Thus, we will analyze how floating point arithmetic affects the process of scaling and shifting the data so that it is supported in the range <ref type="bibr">[−1, 1]</ref>. This is similar to the process of calculating a variance by shifting the data so that it is centered at zero.</p><p>We can calculate the moments of scaling data x scale = k•x with error only in the last digit, so we can assume we have data in the range [c − 1, c + 1]. Let µi be the moments of the x scale , and let µ s i be the moments of the shifted data x shif t = x scale − c. Using the binomial expansion</p><formula xml:id="formula_31">µ s k = 1 n x∈x scale (x − c) k = k i=0 k i µi(−c) k−i</formula><p>Using numerically stable addition, we can calculate µ k to a relative precision δ close to machine precision δ ≈ 2 −53 . Then, the absolute error δ k in estimating µ s k is bounded by:</p><formula xml:id="formula_32">δ k ≤ k i=0 k i |µi||c| k−i δ δ k ≤ k i=0 k i (|c| + 1) k δ ≤ 2 k (|c| + 1) k δ</formula><p>We know that the average quantile error (Equation 8 in Section 4.4) is bounded by</p><formula xml:id="formula_33">avg ≤ O 1 k + 3 k µ f − µf 2 ,</formula><p>so if we can calculate all of the µ s i to within precision</p><formula xml:id="formula_34">δ k ≤ 3 −k 1 k − 1 − 1 k</formula><p>then we have enough precision to bound the quantile estimate by O 1 k−1 . This way, we can show that the error bound from using the first k moments will be at least as tight as the bound from using the first k − 1 moments. As k and |c| grow, achieving this precision becomes more and more difficult, and we can solve for the cutoff point using base-10 log. Precision Loss hepmass occupancy <ref type="figure" target="#fig_0">Figure 16</ref>: Precision loss from shifting and converting higher moments to chebyshev moments. The occupancy dataset exhibits more precision loss because it is centered further away from zero. </p><formula xml:id="formula_35">2 k (|c| + 1) k δ ≤ 3 −k 1 k − 1 − 1 k (19) k (log 6 + log (|c| + 1)) ≤ log 1 δ − log (k 2 − k))<label>(20)</label></formula><p>Equation 22 is a conservative bound on the number of numerically stable moments we can extract from an moments sketch, and suggests that when our data is centered at 0, we have at least 17 stable moments. When the raw data have range <ref type="bibr">[xmin, 3xmin]</ref>, then c = 2, and we have at least 10 stable moments. In our evaluations, 10 stable moments are enough to achieve quantile error ≈ .01. . This confirms that our formula is a conservative bound on the true precision loss due to the shift. If the raw data are centered even further from 0, users can consider pre-shifting all of their data to make better use of numeric precision.</p><p>As a measure of the downstream impact of this effect on some of our evaluation datasets, <ref type="figure" target="#fig_0">Figure 16</ref> shows the precision loss during Chebyshev polynomial calculation ∆µ = |µi −μi| where µi is the true Chebyshev moment andμi is the value calculated from the moments sketch. Precision loss is more severe on the occupancy dataset which is centered away from zero (c ≈ 1.5) compared with the hepmass dataset (c ≈ 0.4). See <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. LOW-PRECISION STORAGE</head><p>In Appendix B we discussed how floating point precision limits the usability of higher moments. Conversely, in settings where space is heavily constrained, the data is wellcentered, and we only need a limited number of moments,  the moments sketch can be compressed by reducing the precision of the sketch contents using randomized rounding.</p><p>As a proof-of-concept of this approach, we created an encoder that compresses the double precision floating point values in a moments sketch using reduced floating point precision, quantizing the significand and removing unused bits in the exponent. This low-precision representation has a negligible impact on merge times since we can convert them to and from native double precision using simple bit manipulation.</p><p>We evaluate the encoding by constructing 100 thousand pre-aggregated moments sketches, reducing their precision, and then merging them and querying for quantiles on the aggregation. <ref type="figure" target="#fig_0">Figure 17</ref> illustrates how the quality of the final estimate remains stable as the precision is decreased until we reach a minimum threshold, after which accuracy degrades. On the milan dataset, a moments sketch with k = 10 can be stored with 20 bits per value without noticeably affecting our quantile estimates, representing a 3× space reduction compared to standard double precision floating point.</p><p>These results are consistent with the bounds in Section B and show how higher moments require more bits of precision. However, the bounds are conservative since they only consider the midpoint c of a dataset and are otherwise both dataset-independent and agnostic to the maximum entropy principle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. ADDITIONAL WORKLOADS</head><p>The moments sketch accuracy and performance generalizes across a range of workloads. In this section we evaluate its performance on datasets with varying skew, in the presence of outlier values, under a coarser pre-aggregation policy, and on a production workload.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Data Skew</head><p>Our usage of log-moments greatly reduces the impact of data skew on the accuracy of moments sketch quantile estimates. In <ref type="figure" target="#fig_0">Figure 18</ref> we vary the shape parameter ks of a Gamma distribution with scale factor θ = 1. The skew of this distribution is 2 √ ks so ks = 0.1 corresponds to very high skew. For ks = 0.1, 1.0, 10.0, our estimator can achieve avg ≤ 10 −3 error. The accuracy regressions on orders 3 and 7 occur when the solver stops making use of all available moments to reduce the condition number of the Hessian (Section 4.3). In this specific case, our solver uses a heuristic to decide that given a maximum condition number, optimizing using 3 log moments is more valuable than 2 log moments and 2 standard moments. This choice leads to worse accuracy on a Gamma distribution, but in general it is difficult to know which subset of moments will yield the most accurate  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Outlier Values</head><p>The moments sketch, unlike histogram-based sketches, is also somewhat robust to the presence of large outlier values in a dataset. In <ref type="figure" target="#fig_0">Figure 19</ref> we evaluate the effect of adding a fixed fraction δ = 0.01 of outlier values from a Gaussian with mean µo and standard deviation σ = 0.1 to a dataset of 10 million standard Gaussian points. As we increase the magnitude µo of the outliers, the EW-Hist summaries with 20 and 100 bins lose accuracy though a moments sketch with k = 10 remains accurate. The Merge12 sketch is agnostic to value magnitudes and is unaffected by the outliers. If extremely large outliers are expected, floating point precision suffers and the moments sketch can be used in conjunction with standard outlier removal techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Varying Aggregation</head><p>In our main evaluations, we group our datasets into cells of 200 elements and construct sketches for each cell to maintain a pre-aggregated collection of data summaries. We do not target deployments where very few elements can be preaggregated per summary: in these cases merging moments sketches is relatively expensive. On the other hand production data systems can have much larger data volumes and opportunities to pre-aggregate more elements per cell. Since the moments sketch is fixed-size regardless of the data, increasing the number of elements per cell does not affect its merge time performance, while other sketches which which have not reached their maximum capacity will be correspondingly larger and slower to merge.</p><p>In <ref type="figure" target="#fig_1">Figure 20</ref> we measure the time taken per merge for different summaries constructed on cells of 2000 elements  <ref type="figure" target="#fig_1">Figure 20</ref>: Merge times on with sketches on cells of 2000 elements, and on a Gaussian dataset with cells of 10000 elements. Since the moments sketch has a fixed size, its per-merge times remain faster than alternative sketches with comparable accuracy. for the milan, hepmass, and exponential dataset, and cells of 10000 elements on a synthetic Gaussian dataset with 1 billion points. The relative performance of different sketches matches closely with <ref type="figure">Figure 4</ref>, except that larger Sampling and Merge12 summaries are now slower when constructed on more than 200 elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 Production workload</head><p>In this section we evaluate merge time and accuracy on a production workload from Microsoft that contains 165 million rows of application telemetry data for an integer-valued performance metric. We group and pre-aggregate based on four columns that encode information about application version, network type, location, and time, resulting in 400 thousand cells. Notably, these cells do not correspond to equal sized partitions, but have a minimum size of 5 elements, a maximum size of 722044 elements, and an average size of 2380 elements. <ref type="figure" target="#fig_0">Figure 21</ref> illustrates the distribution of integer data values and the cell sizes.</p><p>Then, we measure the performance and accuracy of merging the cells to perform a quantile aggregation query. <ref type="figure">Figure</ref> 22 illustrates that on this workload with variable sized cells, the moments sketch still provides faster merge times than comparably accurate summaries (c.f. Appendix D.3). The moments sketch achieves avg &lt; .01 error when we round estimates to the nearest integer on this integral dataset. Since the GK sketch is not strictly mergeable <ref type="bibr" target="#b2">[3]</ref>, it grows considerably when merging the heterogenous summaries in this workload to preserve its accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. ERROR UPPER BOUNDS</head><p>Thus far we have evaluated observed accuracy. For comparison, <ref type="figure" target="#fig_1">Figure 23</ref> shows the average guaranteed upper bound error provided by different summaries constructed using pointwise accumulation on the datasets (no merging). These are in general higher than the observed errors. We use the RT-TBound routine in Section 5.1 to bound the moments sketch error. We omit the S-Hist since it does not provide upper bounds. When merging is not a concern, the GK summary provides the best guaranteed error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. PARALLEL MERGES</head><p>In Section 6.2.1, we evaluated merge time through singlethreaded experiments. We evaluate how well throughput generalizes to parallel aggregation by sharding pre-computed summaries into equal sized batches, and merging the summaries in each batch on an independent worker thread. After all threads have completed, we combine the merged result from each batch using a sequential merge to obtain a final summary for the complete dataset.</p><p>In <ref type="figure" target="#fig_1">Figure 24</ref> we evaluate strong scalability by measuring the total throughput in merging 400 thousand summaries (constructed from blocks of 200 elements) as we increase the number of threads. In our experiments we needed to duplicate the hepmass dataset to yield 400 thousand summaries, and initialized summaries using the parameters in <ref type="table" target="#tab_0">Table 2</ref>. The moments sketch remains faster than alternate summaries as we increase the amount of parallelism, though thread overheads and variance in stragglers limits parallelism on these datasets past 8 threads when there is less work per thread. In <ref type="figure" target="#fig_1">Figure 25</ref> we evaluate weak scalability by performing a similar experiment but increase the dataset size alongside thread count, keeping number of merges per thread constant. Under these conditions, the moments sketch and other summaries achieve even better scalability.</p><p>These experiments confirm our intuition that since merges can be performed independently, single-threaded performance is indicative of parallel performance, and the relative speedup provided by the moments sketch remains stable in parallel settings. The moments sketch and other summaries can be used in more sophisticated distributed aggregation plans as well, such as in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b68">68]</ref>, though since the moments sketch is so compact and cheap to merge, multi-level hierarchical aggregation is only profitable when enormous numbers of cores are available.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Given a data cube with pre-aggregated summaries, we can compute roll-ups along specific dimensions by merging the relevant summaries. Efficiently mergeable summaries enable scalable aggregations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The moments sketch is an array of floating point values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Numeric floating point stability limits the range of useful k in a moments sketch. Both our estimation routine and error bounds (Section 4.4) use moments corresponding to data shifted onto the range [−1, 1]. On scaled data with range [c − 1, c + 1], this leads to numeric error k in the k-th shifted moment, bounded by k ≤ 2 k (|c| + 1) k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Total query time using different summaries to estimate quantiles with avg ≤ .01. The moments sketch enables significantly faster queries at this accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Quantile Estimation time. Estimation time on the moments sketch is slower than other sketches but under 3ms for k = 10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Comparing total query time using different mergeable summaries as we vary the number of merges. The moments sketch provides performance improvements when nmerge ≥ 10 4 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Average error for summaries of different sizes. The moments sketch delivers consistent avg ≤ 0.015 with fewer than 200 bytes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Accuracy of maximum entropy estimates on distributions with varying cardinality. The moments sketch is less accurate on discretized datasets, and fails to converge for cardinalities n &lt; 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 12 :Figure 13 :</head><label>1213</label><figDesc>Runtime of MacroBase queries: the final moments sketch cascade outperforms queries using alternate sketches. Cascades in MacroBase: (a) as we incrementally add cascade stages, threshold query throughput increases. (b) The cascade proceeds from faster to slower estimates. (c) Each stage of the cascade processes a smaller fraction of queries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 15 :</head><label>15</label><figDesc>Highest order usable moments for data centered at different locations. Our data-independent bound is conservative compared to values on a uniform dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Figure 15describes how the bound in Equation 22 varies with c, and compares it with the highest order stable moment of a uniform distribution supported on [c − 1, c + 1]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 17 :</head><label>17</label><figDesc>Average error for low-precision moments sketches after 100 thousand merges. Twenty bits of precision is sufficient to maintain accuracy for both datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 18 :</head><label>18</label><figDesc>Accuracy of estimates on Gamma distributions with varying shape parameter ks. The maximum entropy principle is able to construct an accurate estimate across a range of parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 19 :</head><label>19</label><figDesc>Mean error on a Gaussian dataset with outliers of different magnitudes added. The moments sketch remains accurate for large outliers, but the EW-Hist accuracy degrades. estimate. More effective heuristics for choosing subsets of moments that do not exceed a condition number threshold is an open direction for future research.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 21 :</head><label>21</label><figDesc>Microsoft data values and cell sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 22 :Figure 23 :</head><label>2223</label><figDesc>Merge times and accuracy on the Microsoft dataset. The merge performance of the moments sketch generalizes to workloads with variable sized cells, and exhibits an error rate of avg &lt; .01. Average bound size for summaries of different sizes. No summary is able to provide bound ≤ .01 guarantees with less than 1000 bytes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 24 :Figure 25 :</head><label>2425</label><figDesc>Strong scaling of parallel merging. For fixed number of merges, the throughput of the moments sketch scales with the number of threads available up to 8-way parallelism, and remains faster than alternatives. The solid line shows ideal moments sketch scaling. Weak scaling of parallel merging. For fixed number of merges per thread, the moments sketch and other summaries scale nearly linearly with parallelism.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 2 :</head><label>2</label><figDesc>Threshold Query Cascade macro CheckBound(r lower , rupper, rt) if r lower &gt; rt then return true else if rupper &lt; rt then return false function Threshold(threshold t, quantile φ) if t &gt; xmax then return false if t &lt; xmin then return true r lower , rupper ← MarkovBound(t) Markov Bound CheckBound(r lower , rupper, nφ) r lower , rupper ← RTTBound(t) RTT Bound CheckBound(r lower , rupper, nφ) q</figDesc><table /><note>φ ← MaxEntQuantile(φ)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dataset Characteristics</figDesc><table><row><cell></cell><cell>milan</cell><cell>hepmass</cell><cell>occupancy</cell><cell>retail</cell><cell>power</cell><cell>expon</cell></row><row><cell>size</cell><cell>81M</cell><cell>10.5M</cell><cell>20k</cell><cell>530k</cell><cell>2M</cell><cell>100M</cell></row><row><cell>min</cell><cell>2.3e−6</cell><cell>−1.961</cell><cell>412.8</cell><cell>1</cell><cell>0.076</cell><cell>1.2e−7</cell></row><row><cell>max</cell><cell>7936</cell><cell>4.378</cell><cell>2077</cell><cell>80995</cell><cell>11.12</cell><cell>16.30</cell></row><row><cell>mean</cell><cell>36.77</cell><cell>0.0163</cell><cell>690.6</cell><cell>10.66</cell><cell>1.092</cell><cell>1.000</cell></row><row><cell>stddev</cell><cell>103.5</cell><cell>1.004</cell><cell>311.2</cell><cell>156.8</cell><cell>1.057</cell><cell>0.999</cell></row><row><cell>skew</cell><cell>8.585</cell><cell>0.2946</cell><cell>1.654</cell><cell>460.1</cell><cell>1.786</cell><cell>1.994</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>. On</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Summary size parameters for avg ≤ .01.</figDesc><table><row><cell>dataset</cell><cell>milan</cell><cell></cell><cell>hepmass</cell><cell></cell></row><row><cell>sketch</cell><cell>param</cell><cell cols="2">size (b) param</cell><cell>size (b)</cell></row><row><cell cols="2">M-Sketch k = 10</cell><cell>200</cell><cell>k = 3</cell><cell>72</cell></row><row><cell>Merge12</cell><cell>k = 32</cell><cell>5920</cell><cell>k = 32</cell><cell>5150</cell></row><row><cell>RandomW GK</cell><cell>= 1 40 = 1</cell><cell>3200 720</cell><cell>= 1 = 1</cell><cell>496</cell></row><row><cell cols="2">T-Digest δ = 5.0</cell><cell>769</cell><cell>δ = 1.5</cell><cell>93</cell></row><row><cell cols="3">Sampling 1000 samples 8010</cell><cell>1000</cell><cell>8010</cell></row><row><cell>S-Hist</cell><cell>100 bins</cell><cell>1220</cell><cell>100</cell><cell>1220</cell></row><row><cell>EW-Hist</cell><cell>100 bins</cell><cell>812</cell><cell>15</cell><cell>132</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Plugging in double precision for δ into Eq.(20), we know that k ≤ 53 log 2 log 6 ≤ 20, so log (k 2 − k) ≤ 2.58</figDesc><table><row><cell>k ≤</cell><cell>53 log 2 − 2.58 log 6 + log (|c| + 1)</cell><cell>(21)</cell></row><row><cell>≤</cell><cell>13.35 .78 + log (|c| + 1)</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Compare with Clenshaw-Curtis integration<ref type="bibr" target="#b64">[64]</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was made possible with feedback and assistance from our collaborators at Microsoft including Atul Shenoy, Will Mortl, Cristian Grajdeanu, Asvin Ananthanarayan, and John Sheu. This research was supported in part by affiliate members and other supporters of the Stanford DAWN project -Facebook, Google, Intel, Microsoft, NEC, Teradata, VMware, and SAP -as well as Toyota, Keysight Technologies, Hitachi, Northrop Grumman, Amazon Web Services, Juniper, NetApp, and the NSF under CA-REER grant CNS-1651570 and GRFP grant DGE-114747.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Yahoo! data sketches library</title>
		<ptr target="https://datasketches.github.io/" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Barykin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Borkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gerea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Merl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Wiener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Zed</surname></persName>
		</author>
		<title level="m">Scuba: Diving into data at facebook. VLDB</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1057" to="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yi</surname></persName>
		</author>
		<title level="m">Mergeable summaries. In PODS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Blinkdb: Queries with bounded errors and bounded response times on very large data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mozafari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Milner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroSys</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="29" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The Classical Moment Problem and Some Related Questions in Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Akhiezer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
			<publisher>Oliver &amp; Boyd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Gradient flows: in metric spaces and in the space of probability measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ambrosio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Savaré</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A method of moments for mixture models and hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="33" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">MacroBase: Prioritizing attention in fast data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bailis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="541" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Maximum entropy based numerical algorithms for approximation of probability density functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balestrino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">'</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Parenti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Control Conference (ECC)</title>
		<imprint>
			<biblScope unit="page" from="796" to="801" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Maximum entropy and the problem of moments: A stable algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Drabold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page">57701</biblScope>
			<date type="published" when="2005-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Polynomial learning of distribution families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A streaming parallel decision tree algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ben-Haim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tom-Tov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="849" to="872" />
			<date type="published" when="2010-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A maximum entropy approach to natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J D</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A D</forename><surname>Pietra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="71" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Site Reliability Engineering: How Google Runs Production Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Petoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>O&apos;Reilly Media, Incorporated</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Convex Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Analytics in motion: High performance event-processing and real-time analytics in the same database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Etter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gasparis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kossmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Widmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Avitzur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iliopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="251" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Interacting with Large Distributed Datasets Using Sketch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Budiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Isaacs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Plotkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Al-Kiswany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boshmaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Andoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Symposium on Parallel Graphics and Visualization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Quantiles on streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buragohain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Database Systems</title>
		<imprint>
			<biblScope unit="page" from="2235" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Regression cubes with lossless compression and aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1585" to="1599" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">User-defined aggregate functions: bridging theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="49" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Streaming in a connected world: querying and tracking distributed data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garofalakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1178" to="1181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Synopses for massive data: Samples, histograms, wavelets, sketches. Foundations and Trends in Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garofalakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jermaine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An improved data stream summary: The count-min sketch and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Algorithms</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="75" />
			<date type="published" when="2005-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gigascope: A stream database for network applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cranor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Spataschek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shkapenyuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="647" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Maintaining stream statistics over sliding windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gionis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on computing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1794" to="1813" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The tail at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Barroso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="74" to="80" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ECOS: An SOCP solver for embedded systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Domahidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Control Conference (ECC)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3071" to="3076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Computing extremeley accurate quantiles using t-digests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dunning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ertl</surname></persName>
		</author>
		<ptr target="https://github.com/tdunning/t-digest" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Streamcube: Hierarchical spatio-temporal hashtag clustering for event exploration over the twitter stream</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1561" to="1572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Moment-based quantile sketches for efficient high cardinality aggregation queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bailis</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1803.01969" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Questions of numerical condition related to polynomials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gautschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Numerical Analysis</title>
		<editor>C. D. Boor and G. H. Golub</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1978" />
			<biblScope unit="page" from="45" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The method of moments in electromagnetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bosworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Layman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Venkatrao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirahesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data mining and knowledge discovery</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="53" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Space-efficient online computation of quantile summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Greenwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="58" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Trading off accuracy for speed in powerdrill</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tudorica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Buruiana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-I</forename><surname>Ganceanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2121" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Large sample properties of generalized method of moments estimators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="page" from="1029" to="1054" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Implementing data cubes efficiently</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Harinarayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="205" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An efficient bandit algorithm for realtime multivariate optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nassif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1813" to="1821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Approximate algorithms in apache spark: Hyperloglog and quantiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Falaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradley</surname></persName>
		</author>
		<ptr target="https://databricks.com/blog/2016/05/19/approximate-algorithms-in-apache-spark-hyperloglog-and-quantiles.html" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Telecommunications -sms, call, internet -mi</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Italia</surname></persName>
		</author>
		<idno type="DOI">10.7910/DVN/EGZHFV</idno>
		<ptr target="http://dx.doi.org/10.7910/DVN/EGZHFV" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Information theory and statistical mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Jaynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="620" to="630" />
			<date type="published" when="1957-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Peeking at a/b tests: Why it matters, and what to do about it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Johari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koomen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pekelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1517" to="1525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficiently learning mixtures of two gaussians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STOC</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="553" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Distributed and interactive cube exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kamat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jayachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tunga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IDCE</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="472" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Gossip-based computation of aggregate information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kempe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dobra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FOCS</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="482" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Khuc</surname></persName>
		</author>
		<ptr target="https://github.com/vinhkhuc/lbfgs4j" />
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Spectrum estimation from samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2218" to="2247" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">On the limited memory bfgs method for large scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Kodiak: Leveraging materialized views for very low-latency analytics over high-dimensional web-scale data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gangam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Elmeleegy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">VLDB</biblScope>
			<biblScope unit="page" from="1269" to="1280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Quantiles over data streams: experimental comparisons, new analyses, and further improvements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="449" to="472" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Tag: A tiny aggregation service for ad-hoc sensor networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Tributaries and deltas: Efficient and robust aggregation in sensor network streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Manjhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Gibbons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="287" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Consistent selectivity estimation via maximum entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Markl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kutsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Megiddo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Tran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>VLDB</publisher>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="55" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Handscomb</surname></persName>
		</author>
		<title level="m">Chebyshev polynomials</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Maximum entropy in the problem of moments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Mead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papanicolaou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2404" to="2417" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Hausdorff moment problem: Reconstruction of distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Mnatsakanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics &amp; Probability Letters</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1612" to="1618" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Trust, but verify: Optimistic visualizations of approximate queries for exploring big data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2904" to="2915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Data streams: Algorithms and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="236" />
			<date type="published" when="2005-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Distributed cube materialization on holistic measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bohannon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="183" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Using maximum entropy for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI Workshop on Machine Learning for Information Filtering</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="61" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The gamma matrix to summarize dense and sparse data sets for big data analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cabrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1905" to="1918" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Numerical recipes 3rd edition: The art of scientific computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Aggregation and degradation in jetstream: Streaming analytics in the wide area</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Freedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="275" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A moments based distribution bounding method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Racz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Telek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical and Computer Modelling</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1367" to="1382" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ray</surname></persName>
		</author>
		<ptr target="http://druid.io/blog/2013/09/12/the-art-of-approximating-distributions.html" />
		<title level="m">The art of approximating distributions: Histograms and quantiles at scale</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Glade: A scalable framework for efficient analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dobra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGOPS Oper. Syst. Rev</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="18" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">User-adaptive exploration of multidimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="307" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Compressed data cubes for olap aggregate query approximation on continuous dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shanmugasundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Fayyad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Bradley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="223" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Medians and beyond: new aggregation techniques for sensor networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buragohain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on Embedded networked sensor systems</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="239" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Calculation of densities of states and spectral functions by chebyshev recursion and maximum entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Röder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">4822</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Isomer: Consistent histogram construction using query feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Markl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kutsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="39" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Seedb: Efficient data-driven visualization recommendations to support visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vartak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>VLDB</publisher>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2182" to="2193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>pages I-511-I-518</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Random sampling with a reservoir</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Vitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Math. Softw</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="57" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Quantiles over data streams: An experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD, SIGMOD &apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="737" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Data canopy: Accelerating exploratory statistical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wasay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Idreos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="557" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">All of Statistics: A Concise Course in Statistical Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wasserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Compression and aggregation for logistic regression analysis in data cubes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="479" to="492" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Olap over probabilistic data cubes i: Aggregating, materializing, and querying</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2016-05" />
			<biblScope unit="page" from="799" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Druid: A real-time analytical data store</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tschetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Léauté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Merlino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="157" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NSDI</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">An experimental study of distributed quantile estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhuang</surname></persName>
		</author>
		<idno>abs/1508.05710</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
