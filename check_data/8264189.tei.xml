<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-07-27">27 Jul 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
							<email>sporia@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">Nanyang Technological University Nanyang Ave</orgName>
								<address>
									<postCode>639798</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
							<email>cambria@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">Nanyang Technological University Nanyang Ave</orgName>
								<address>
									<postCode>639798</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
							<email>devamanyu@sentic.net</email>
							<affiliation key="aff0">
								<orgName type="institution">Nanyang Technological University Nanyang Ave</orgName>
								<address>
									<postCode>639798</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Vij</surname></persName>
							<email>prateek@sentic.net</email>
							<affiliation key="aff0">
								<orgName type="institution">Nanyang Technological University Nanyang Ave</orgName>
								<address>
									<postCode>639798</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-07-27">27 Jul 2017</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1610.08815v2[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an &quot;apparently positive&quot; sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network&apos;s baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sarcasm is defined as "a sharp, bitter, or cutting expression or remark; a bitter gibe or taunt". As the fields of affective computing and sentiment analysis have gained increasing popularity , it is a major concern to detect sarcastic, ironic, and metaphoric expressions. Sarcasm, especially, is key for sentiment analysis as it can completely flip the polarity of opinions. Understanding the ground truth, or the facts about a given event, allows for the detection of contradiction between the objective polarity of the event (usually negative) and its sarcastic characteristic by the author (usually positive), as in "I love the pain of breakup". Obtaining such knowledge is, however, very difficult.</p><p>In our experiments, we exposed the classifier to such knowledge extracted indirectly from Twitter. Namely, we used Twitter data crawled in a time period, which likely contain both the sarcastic and nonsarcastic accounts of an event or similar events. We believe that unambiguous non-sarcastic sentences provided the classifier with the ground-truth polarity of those events, which the classifier could then contrast with the opposite estimations in sarcastic sentences. Twitter is a more suitable resource for this purpose than blog posts, because the polarity of short tweets is easier to detect (as all the information necessary to detect polarity is likely to be contained in the same sentence) and because the Twitter API makes it easy to collect a large corpus of tweets containing both sarcastic and non-sarcastic examples of the same event.</p><p>Sometimes, however, just knowing the ground truth or simple facts on the topic is not enough, as the text may refer to other events in order to express sarcasm. For example, the sentence "If Hillary wins, she will surely be pleased to recall Monica each time she enters the Oval Office :P :D", which refers to the 2016 US presidential election campaign and to the events of early 1990's related to the US president Clinton, is sarcastic because Hillary, a candidate and Clinton's wife, would in fact not be pleased to recall her husband's alleged past affair with Monica Lewinsky. The system, however, would need a considerable amount of facts, commonsense knowledge, anaphora resolution, and logical reasoning to draw such a conclusion. In this paper, we will not deal with such complex cases.</p><p>Existing works on sarcasm detection have mainly focused on unigrams and the use of emoticons <ref type="bibr" target="#b14">(González-Ibánez et al., 2011;</ref><ref type="bibr" target="#b9">Carvalho et al., 2009;</ref><ref type="bibr" target="#b1">Barbieri et al., 2014)</ref>, unsupervised pattern mining approach <ref type="bibr" target="#b20">(Maynard and Greenwood, 2014)</ref>, semi-supervised approach <ref type="bibr" target="#b30">(Riloff et al., 2013)</ref> and ngrams based approach <ref type="bibr" target="#b28">Ptácek et al., 2014;</ref><ref type="bibr" target="#b15">Joshi et al., 2015)</ref> with sentiment features. Instead, we propose a framework that learns sarcasm features automatically from a sarcasm corpus using a convolutional neural network <ref type="bibr">(CNN)</ref>. We also investigate whether features extracted using the pre-trained sentiment, emotion and personality models can improve sarcasm detection performance. Our approach uses relatively lower dimensional feature vectors and outperforms the state of the art on different datasets. In summary, the main contributions of this paper are the following:</p><p>• To the best of our knowledge, this is the first work on using deep learning for sarcasm detection.</p><p>• Unlike other works, we exploit sentiment and emotion features for sarcasm detection. As user profiling is also an important factor for detecting sarcastic content, moreover, we use personalitybased features for the first time in the literature.</p><p>• Pre-trained models are commonly used in computer vision. In the context of natural language processing (NLP), however, they are barely used. Hence, the use of pre-trained models for feature extraction is also a major contribution of this work.</p><p>The rest of the paper is organized as follows: Section 2 proposes a brief literature review on sarcasm detection; Section 4 presents the proposed approach; experimental results and thorough discussion on the experiments are given in Section 5; finally, Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>NLP research is gradually evolving from lexical to compositional semantics <ref type="bibr" target="#b5">(Cambria and White, 2014)</ref> through the adoption of novel meaning-preserving and context-aware paradigms such as convolutional networks <ref type="bibr" target="#b25">(Poria et al., 2016a)</ref>, recurrent belief networks <ref type="bibr" target="#b11">(Chaturvedi et al., 2016)</ref>, statistical learning theory <ref type="bibr" target="#b22">(Oneto et al., 2016)</ref>, convolutional multiple kernel learning <ref type="bibr" target="#b26">(Poria et al., 2016b)</ref>, and commonsense reasoning <ref type="bibr" target="#b4">(Cambria and Hussain, 2015)</ref>. But while other NLP tasks have been extensively investigated, sarcasm detection is a relatively new research topic which has gained increasing interest only recently, partly thanks to the rise of social media analytics and sentiment analysis.Sentiment analysis <ref type="bibr" target="#b35">(Zadeh et al., 2016b)</ref> and using multimodal information as a new trend <ref type="bibr" target="#b34">(Zadeh et al., 2016a;</ref><ref type="bibr" target="#b23">Poria et al., 2015a;</ref><ref type="bibr" target="#b32">Tong et al., 2017;</ref><ref type="bibr" target="#b27">Poria et al., 2017;</ref><ref type="bibr" target="#b26">Poria et al., 2016b</ref>) is a popular branch of NLP research that aims to understand sentiment of documents automatically using combination of various machine learning approaches <ref type="bibr" target="#b38">(Zadeh, 2015;</ref><ref type="bibr">Zadeh et al., 2017b;</ref><ref type="bibr" target="#b27">Poria et al., 2017;</ref><ref type="bibr" target="#b36">Zadeh et al., 2017a)</ref>.</p><p>An early work in this field was done by  on a dataset of 6,600 manually annotated Amazon reviews using a kNN-classifier over punctuation-based and pattern-based features, i.e., ordered sequence of high frequency words. <ref type="bibr" target="#b14">(González-Ibánez et al., 2011)</ref> used support vector machine (SVM) and logistic regression over a feature set of unigrams, dictionary-based lexical features and pragmatic features (e.g., emoticons) and compared the performance of the classifier with that of humans. (Reyes et al., 2013) described a set of textual features for recognizing irony at a linguistic level, especially in short texts created via Twitter, and constructed a new model that was assessed along two dimensions: representativeness and relevance. <ref type="bibr" target="#b30">(Riloff et al., 2013)</ref> used the presence of a positive sentiment in close proximity of a negative situation phrase as a feature for sarcasm detection. <ref type="bibr" target="#b18">(Liebrecht et al., 2013)</ref> used the Balanced Window algorithm for classifying Dutch tweets as sarcastic vs. non-sarcastic; n-grams (uni, bi and tri) and intensifiers were used as features for classification. <ref type="bibr" target="#b3">(Buschmeier et al., 2014)</ref> compared the performance of different classifiers on the Amazon review dataset using the imbalance between the sentiment expressed by the review and the user-given star rating. Features based on frequency (gap between rare and common words), written spoken gap (in terms of difference between usage), synonyms (based on the difference in frequency of synonyms) and ambiguity (number of words with many synonyms) were used by <ref type="bibr" target="#b1">(Barbieri et al., 2014)</ref> for sarcasm detection in tweets. <ref type="bibr" target="#b15">(Joshi et al., 2015)</ref> proposed the use of implicit incongruity and explicit incongruity based features along with lexical and pragmatic features, such as emoticons and punctuation marks. Their method is very much similar to the method proposed by <ref type="bibr" target="#b30">(Riloff et al., 2013)</ref> except <ref type="bibr" target="#b15">(Joshi et al., 2015)</ref> used explicit incongruity features. Their method outperforms the approach by <ref type="bibr" target="#b30">(Riloff et al., 2013)</ref> on two datasets. <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref> compared the performance with different language-independent features and preprocessing techniques for classifying text as sarcastic and non-sarcastic. The comparison was done over three Twitter dataset in two different languages, two of these in English with a balanced and an imbalanced distribution and the third one in Czech. The feature set included n-grams, word-shape patterns, pointedness and punctuation-based features.</p><p>In this work, we use features extracted from a deep CNN for sarcasm detection. Some of the key differences between the proposed approach and existing methods include the use of a relatively smaller feature set, automatic feature extraction, the use of deep networks, and the adoption of pre-trained NLP models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Sentiment Analysis and Sarcasm Detection</head><p>Sarcasm detection is an important subtask of sentiment analysis . Since sarcastic sentences are subjective, they carry sentiment and emotion-bearing information. Most of the studies in the literature <ref type="bibr" target="#b16">(Joshi et al., 2016;</ref><ref type="bibr" target="#b2">Bosco et al., 2013;</ref><ref type="bibr" target="#b15">Joshi et al., 2015;</ref><ref type="bibr" target="#b13">Farías et al., 2016)</ref> include sentiment features in sarcasm detection with the use of a state-of-the-art sentiment lexicon. Below, we explain how sentiment information is key to express sarcastic opinions and the approach we undertake to exploit such information for sarcasm detection.</p><p>In general, most sarcastic sentences contradict the fact. In the sentence "I love the pain present in the breakups" <ref type="figure" target="#fig_0">(Figure 1</ref>), for example, the word "love" contradicts "pain present in the breakups", because in general no-one loves to be in pain. In this case, the fact (i.e., "pain in the breakups") and the contradictory statement to that fact (i.e., "I love") express sentiment explicitly. Sentiment shifts from positive to negative but, according to sentic patterns <ref type="bibr" target="#b24">(Poria et al., 2015b)</ref>, the literal sentiment remains positive. Sentic patterns, in fact, aim to detect the polarity expressed by the speaker; thus, whenever the construction "I love" is encountered, the sentence is positive no matter what comes after it (e.g., "I love the movie that you hate"). In this case, however, the sentence carries sarcasm and, hence, reflects the negative sentiment of the speaker.</p><p>In another example <ref type="figure" target="#fig_0">(Figure 1</ref>), the fact, i.e., "I left the theater during the interval", has implicit negative sentiment. The statement "I love the movie" contradicts the fact "I left the theater during the interval"; thus, the sentence is sarcastic. Also in this case the sentiment shifts from positive to negative and hints at the sarcastic nature of the opinion.</p><p>The above discussion has made clear that sentiment (and, in particular, sentiment shifts) can largely help to detect sarcasm. In order to include sentiment shifting into the proposed framework, we train a sentiment model for sentiment-specific feature extraction. Training with a CNN helps to combine the local features in the lower layers into global features in the higher layers. We do not make use of sentic patterns <ref type="bibr" target="#b24">(Poria et al., 2015b)</ref> in this paper but we do plan to explore that research direction as a part of our future work. In the literature, it is found that sarcasm is user-specific too, i.e., some users have a particular tendency to post more sarcastic tweets than others. This acts as a primary intuition for us to extract personality-based features for sarcasm detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Proposed Framework</head><p>As discussed in the literature <ref type="bibr" target="#b30">(Riloff et al., 2013)</ref>, sarcasm detection may depend on sentiment and other cognitive aspects. For this reason, we incorporate both sentiment and emotion clues in our framework. Along with these, we also argue that personality of the opinion holder is an important factor for sarcasm detection. In order to address all of these variables, we create different models for each of them, namely: sentiment, emotion and personality. The idea is to train each model on its corresponding benchmark dataset and, hence, use such pre-trained models together to extract sarcasm-related features from the sarcasm datasets. Now, the viable research question here is -Do these models help to improve sarcasm detection performance?' Literature shows that they improve the performance but not significantly. Thus, do we need to consider those factors in spotting sarcastic sentences? Aren't n-grams enough for sarcasm detection? Throughout the rest of this paper, we address these questions in detail. The training of each model is done using a CNN. Below, we explain the framework in detail. Then, we discuss the pre-trained models. <ref type="figure">Figure 2</ref> presents a visualization of the proposed framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">General CNN Framework</head><p>CNN can automatically extract key features from the training data. It grasps contextual local features from a sentence and, after several convolution operations, it forms a global feature vector out of those local features. CNN does not need the hand-crafted features used in traditional supervised classifiers. Such hand-crafted features are difficult to compute and a good guess for encoding the features is always necessary in order to get satisfactory results. CNN, instead, uses a hierarchy of local features which are important to learn context. The hand-crafted features often ignore such a hierarchy of local features.</p><p>Features extracted by CNN can therefore be used instead of hand-crafted features, as they carry more useful information. The idea behind convolution is to take the dot product of a vector of k weights w k also known as kernel vector with each k-gram in the sentence s(t) to obtain another sequence of features</p><formula xml:id="formula_0">c(t) = (c 1 (t), c 2 (t), . . . , c L (t)). c j = w k T .x i∶i+k−1<label>(1)</label></formula><p>Thus, a max pooling operation is applied over the feature map and the maximum valueĉ(t) = max{c(t)} is taken as the feature corresponding to this particular kernel vector. Similarly, varying kernel vectors and window sizes are used to obtain multiple features <ref type="bibr" target="#b17">(Kalchbrenner et al., 2014)</ref>. For each word x i in the vocabulary, a d-dimensional vector representation is given in a look up table that is learned from the data <ref type="bibr" target="#b21">(Mikolov et al., 2013)</ref>. The vector representation of a sentence, hence, is a concatenation of vectors for individual words. Similarly, we can have look up tables for other features. One might want to provide features other than words if these features are suspected to be helpful. The convolution kernels are then applied to word vectors instead of individual words.</p><p>We use these features to train higher layers of the CNN, in order to represent bigger groups of words in sentences. We denote the feature learned at hidden neuron h in layer l as F l h . Multiple features may be learned in parallel in the same CNN layer. The features learned in each layer are used to train the next layer:</p><formula xml:id="formula_1">F l = n h h=1 w h k * F l−1 (2)</formula><p>where * indicates convolution and w k is a weight kernel for hidden neuron h and n h is the total number of hidden neurons. The CNN sentence model preserves the order of words by adopting convolution kernels of gradually increasing sizes that span an increasing number of words and ultimately the entire sentence. As mentioned above, each word in a sentence is represented using word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Embeddings</head><p>We employ the publicly available word2vec vectors, which were trained on 100 billion words from Google News. The vectors are of dimensionality 300, trained using the continuous bag-of-words architecture <ref type="bibr" target="#b21">(Mikolov et al., 2013)</ref>. Words not present in the set of pre-trained words are initialized randomly. However, while training the neural network, we use non-static representations. These include the word vectors, taken as input, into the list of parameters to be learned during training.</p><p>Two primary reasons motivated us to use non-static channels as opposed to static ones. Firstly, the common presence of informal language and words in tweets resulted in a relatively high random initialization of word vectors due to the unavailability of these words in the word2vec dictionary. Secondly, sarcastic sentences are known to include polarity shifts in sentimental and emotional degrees. For example, "I love the pain present in breakups" is a sarcastic sentence with a significant change in sentimental polarity. As word2vec was not trained to incorporate these nuances, we allow our models to update the embeddings during training in order to include them. Each sentence is wrapped to a window of n, where n is the maximum number of words amongst all sentences in the dataset. We use the output of the fully-connected layer of the network as our feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN-SVM</head><p>We have done two kinds of experiments: firstly, we used CNN for the classification; secondly, we extracted features from the fully-connected layer of the CNN and fed them to an SVM for the final classification. The latter CNN-SVM scheme is quite useful for text classification as shown by <ref type="bibr" target="#b23">Poria et al. (Poria et al., 2015a)</ref>. We carry out n-fold cross-validation on the dataset using CNN. In every fold iteration, in order to obtain the training and test features, the output of the fully-connected layer is treated as features to be used for the final classification using SVM.  <ref type="table" target="#tab_0">Pooling Layer Output  S  4,5  50  2  3   2  100  3  E  3,4,5   2  2  100  2  150  6  P  3,4,5  50  2  2  100  2  150  2  B  4,5  50  2  3  100  2  100  2   Table 1</ref> The network configurations of all models developed in this work are given in <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sentiment Feature Extraction Model</head><p>As discussed above, sentiment clues play an important role for sarcastic sentence detection. In our work, we train a CNN (see Section 4.1 for details) on a sentiment benchmark dataset. This pre-trained model is then used to extract features from the sarcastic datasets. In particular, we use Semeval 2014 <ref type="bibr" target="#b31">(Rosenthal et al., 2014)</ref> Twitter Sentiment Analysis Dataset for the training. This dataset contains 9,497 tweets out of which 5,895 are positive, 3,131 are negative and 471 are neutral. The fully-connected layer of the CNN used for sentiment feature extraction has 100 neurons, so 100 features are extracted from this pre-trained model. The final softmax determines whether a sentence is positive, negative or neutral. Thus, we have three neurons in the softmax layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Emotion Feature Extraction Model</head><p>We use the CNN structure as described in Section 4.1 for emotional feature extraction. As a dataset for extracting emotion-related features, we use the corpus developed by <ref type="bibr" target="#b0">(Aman and Szpakowicz, 2007)</ref>. This dataset consists of blog posts labeled by their corresponding emotion categories. As emotion taxonomy, the authors used six basic emotions, i.e., Anger, Disgust, Surprise, Sadness, Joy and Fear. In particular, the blog posts were split into sentences and each sentence was labeled. The dataset contains 5,205 sentences labeled by one of the emotion labels. After employing this model on the sarcasm dataset, we obtained a 150-dimensional feature vector from the fully-connected layer. As the aim of training is to classify each sentence into one of the six emotion classes, we used six neurons in the softmax layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Personality Feature Extraction Model</head><p>Detecting personality from text is a well-known challenging problem. In our work, we use five personality traits described by <ref type="bibr" target="#b19">(Matthews and Gilliland, 1999)</ref>, i.e., Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism, sometimes abbreviated as OCEAN (by their first letters). As a training dataset, we use the corpus developed by <ref type="bibr" target="#b19">(Matthews and Gilliland, 1999)</ref>, which contains 2,400 essays labeled by one of the five personality traits each. The fully-connected layer has 150 neurons, which are treated as the features. We concatenate the feature vector of each personality dimension in order to create the final feature vector. Thus, the personality model ultimately extracts a 750-dimensional feature vector (150-dimensional feature vector for each of the five personality traits). This network is replicated five times, one for each personality trait. In particular, we create a CNN for each personality trait and the aim of each CNN is to classify a sentence into binary classes, i.e., whether it expresses a personality trait or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Baseline Method and Features</head><p>CNN can also be employed on the sarcasm datasets in order to identify sarcastic and non-sarcastic tweets. We term the features extracted from this network baseline features, the method as baseline method and the CNN architecture used in this baseline method as baseline CNN. Since the fully-connected layer has neurons, we have 100 baseline features in our experiment. This method is termed baseline method as it directly aims to classify a sentence as sarcastic vs non-sarcastic. The baseline CNN extracts the inherent semantics from the sarcastic corpus by employing deep domain understanding. The process of using baseline features with other features extracted from the pre-trained model is described in Section 5.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results and Discussion</head><p>In this section, we present the experimental results using different feature combinations and compare them with the state of the art. For each feature we show the results using only CNN and using CNN-SVM (i.e., when the features extracted by CNN are fed to the SVM). Macro-F1 measure is used as an evaluation scheme in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Sarcasm Datasets Used in the Experiment</head><p>Dataset 1 (Balanced Dataset) This dataset was created by <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref>. The tweets were downloaded from Twitter using #sarcasm as a marker for sarcastic tweets. It is a monolingual English dataset which consists of a balanced distribution of 50,000 sarcastic tweets and 50,000 non-sarcastic tweets.</p><p>Dataset 2 (Imbalanced Dataset) Since sarcastic tweets are less frequently used <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref>, we also need to investigate the robustness of the selected features and the model trained on these features on an imbalanced dataset. To this end, we used another English dataset from <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref>. It consists of 25,000 sarcastic tweets and 75,000 non-sarcastic tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset 3 (Test Dataset)</head><p>We have obtained this dataset from The Sarcasm Detector . It contains 120,000 tweets, out of which 20,000 are sarcastic and 100,000 are non-sarcastic. We randomly sampled 10,000 sarcastic and 20,000 non-sarcastic tweets from the dataset. Visualization of both the original and subset data show similar characteristics.</p><p>Pre-processing A two-step methodology has been employed in filtering the datasets used in our experiments. Firstly, we identified and removed all the "user", "URL" and "hashtag" references present in the tweets using efficient regular expressions. Special emphasis was given to this step to avoid traces of hashtags, which might trigger the models to provide biased results. Secondly, we used NLTK Twitter Tokenizer to ensure proper tokenization of words along with special symbols and emoticons. Since our deep CNNs extract contextual information present in tweets, we include emoticons as part of the vocabulary. This enables the emoticons to hold a place in the word embedding space and aid in providing information about the emotions present in the sentence.</p><p>http://thesarcasmdetector.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Merging the Features</head><p>Throughout this research, we have carried out several experiments with various feature combinations. For the sake of clarity, we explain below how the features extracted using difference models are merged.</p><p>• In the standard feature merging process, we first extract the features from all deep CNN based feature extraction models and then we concatenate them. Afterwards, SVM is employed on the resulted feature vector.</p><p>• In another setting, we use the features extracted from the pre-trained models as the static channels of features in the CNN of the baseline method. These features are appended to the hidden layer of the baseline CNN, preceding the final output softmax layer.</p><p>For comparison, we have re-implemented the state-of-the-art methods. Since <ref type="bibr" target="#b15">(Joshi et al., 2015)</ref> did not mention about the sentiment lexicon they use in the experiment, we used SenticNet  in the re-implementation of their method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results on Dataset 1</head><p>As shown in <ref type="table" target="#tab_2">Table 2</ref>, for every feature CNN-SVM outperforms the performance of the CNN. Following , we have carried out a 5-fold cross-validation on this dataset. The baseline features (4.5) perform best among other features. Among all the pre-trained models, the sentiment model (F1-score: 87.00%) achieves better performance in comparison with the other two pre-trained models. Interestingly, when we merge the baseline features with the features extracted by the pre-trained deep NLP models, we only get 0.11% improvement over the F-score. It means that the baseline features alone are quite capable to detect sarcasm. On the other hand, when we combine sentiment, emotion and personality features, we obtain 90.70% F1-score. This indicates that the pre-trained features are indeed useful for sarcasm detection. We also compare our approach with the best research study conducted on this dataset <ref type="table">(Table 3)</ref>. Both the proposed baseline model and the baseline + sentiment + emotion + personality model outperform the state of the art <ref type="bibr" target="#b15">(Joshi et al., 2015;</ref><ref type="bibr" target="#b28">Ptácek et al., 2014)</ref>. One important difference with the state of the art is that <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref> used relatively larger feature vector size (&gt;500,000) than we used in our experiment (1,100). This not only prevents our model to overfit the data but also speeds up the computation. Thus, we obtain an improvement in the overall performance with automatic feature extraction using a relatively lower dimensional feature space.</p><p>In the literature, word n-grams, skipgrams and character n-grams are used as baseline features. According to Ptacek et al. <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref>, these baseline features along with the other features (sentiment features and part-of-speech based features) produced the best performance. However, Ptacek et al. did not analyze the performance of these features when they were not used with the baseline features. Pre-trained word embeddings play an important role in the performance of the classifier because, when we use randomly generated embeddings, performance falls down to 86.23% using all features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results on Dataset 2</head><p>5-fold cross-validation has been carried out on Dataset 2. Also for this dataset, we get the best accuracy when we use all features. Baseline features have performed significantly better (F1-score: 92.32%) than all other features. Supporting the observations we have made from the experiments on Dataset 1, we see CNN-SVM outperforming CNN on Dataset 2. However, when we use all the features, CNN alone (F1-score: 89.73%) does not outperform the state of the art <ref type="bibr" target="#b28">(Ptácek et al., 2014</ref>) (F1-score: 92.37%). As shown in <ref type="table">Table 3</ref>, CNN-SVM on the baseline + sentiment + emotion + personality feature set outperforms the state of the art (F1-score: 94.80%). Among the pre-trained models, the sentiment model performs best (F1-score: 87.00%). <ref type="table" target="#tab_2">Table 2</ref> shows the performance of different feature combinations. The gap between the F1-scores of only baseline features and all features is larger on the imbalanced dataset than the balanced dataset. This supports our claim that sentiment, emotion and personality features are very useful for sarcasm detection, thanks to the pre-trained models. The F1-score using sentiment features when combined with baseline   <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref> 94.66% 92.37% 63.37% 53.02% <ref type="bibr" target="#b15">(Joshi et al., 2015)</ref> 65  <ref type="table">Table 3</ref>: Performance comparison of the proposed method and the state-of-the-art approaches. Legenda: D3 =&gt; D1 is the model trained on Dataset 3 and tested on Dataset 1.</p><p>features is 94.60%. On both of the datasets, emotion and sentiment features perform better than the personality features. Interestingly, using only sentiment, emotion and personality features, we achieve 90.90% F1-score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Results on Dataset 3</head><p>Experimental results on Dataset 3 show the similar trends <ref type="table">(Table 3)</ref> as compared to Dataset 1 and Dataset 2. The highest performance (F1-score 93.30%) is obtained when we combine baseline features with sentiment, emotion and personality features. In this case, also CNN-SVM consistently performs better than CNN for every feature combination. The sentiment model is found to be the best pre-trained model. F1-score of 84.43% is obtained when we merge sentiment, emotion and personality features. Dataset 3 is more complex and non-linear in nature compared to the other two datasets. As shown in <ref type="table">Table 3</ref>, the methods by <ref type="bibr" target="#b15">(Joshi et al., 2015)</ref> and <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref> perform poorly on this dataset. The TP rate achieved by <ref type="bibr" target="#b15">(Joshi et al., 2015)</ref> is only 10.07% and that means their method suffers badly on complex data 3 . The approach of <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref> has also failed to perform well on Dataset 3, achieving 62.37% with a better TP rate of 22.15% than <ref type="bibr" target="#b15">(Joshi et al., 2015)</ref>. On the other hand, our proposed model performs consistently well on this dataset achieving 93.30%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Testing Generalizability of the Models and Discussions</head><p>To test the generalization capability of the proposed approach, we perform training on Dataset 1 and test on Dataset 3. The F1-score drops down dramatically to 33.05%. In order to understand this finding, we visualize each dataset using PCA <ref type="figure" target="#fig_3">(Figure 3)</ref>. It depicts that, although Dataset 1 is mostly linearly separable, Dataset 3 is not. A linear kernel that performs well on Dataset 1 fails to provide good performance on Dataset 3. If we use RBF kernel, it overfits the data and produces worse results than what we get using linear kernel. Similar trends are seen in the performance of other two state-of-the-art approaches <ref type="bibr" target="#b15">(Joshi et al., 2015;</ref><ref type="bibr" target="#b28">Ptácek et al., 2014)</ref>. Thus, we decide to perform training on Dataset 3 and test on the Dataset 1. As expected better performance is obtained 4 with F1-score 76.78%. However, the other two state-of-the-art approaches fail to perform well in this setting. While the method by <ref type="bibr" target="#b15">(Joshi et al., 2015)</ref> obtains F1-score of 47.32%, the approach by <ref type="bibr" target="#b28">(Ptácek et al., 2014)</ref> achieves 53.02% F1-score when trained on Dataset 3 and tested on Dataset 1. Below, we discuss about this generalizability issue of the models developed or referred in this paper.  As discussed in the introduction, sarcasm is very much topic-dependent and highly contextual. For example, let us consider the tweet "I am so glad to see Tanzania played very well, I can now sleep well :P". Unless one knows that Tanzania actually did not play well in that game, it is not possible to spot the sarcastic nature of this sentence. Thus, an n-gram based sarcasm detector trained at time t i may perform poorly to detect sarcasm in the tweets crawled at time t j (given that there is a considerable gap between these time stamps) because of the diversity of the topics (new events occur, new topics are discussed) of the tweets. Sentiment and other contextual clues can help to spot the sarcastic nature in this kind of tweets. A highly positive statement which ends with a emoticon expressing joke can be sarcastic.</p><p>State-of-the-art methods lack these contextual information which, in our case, we extract using pretrained sentiment, emotion and personality models. Not only these pre-trained models, the baseline method (baseline CNN architecture) performs better than the state-of-the-art models in this generalizability test setting. In our generalizability test, when the pre-trained features are used with baseline features, we get 4.19% F1-score improvement over the baseline features. On the other hand, when they are not used with the baseline features, together they produce 64.25% F1-score.</p><p>Another important fact is that an n-grams model cannot perform well on unseen data unless it is trained on a very large corpus. If most of the n-grams extracted from the unseen data are not in the vocabulary of the already trained n-grams model, in fact, the model will produce a very sparse feature vector representation of the dataset. Instead, we use the word2vec embeddings as the source of the features, as word2vec allows for the computation of similarities between unseen data and training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Baseline Features vs Pre-trained Features</head><p>Our experimental results show that the baseline features outperform the pre-trained features for sarcasm detection. However, the combination of pre-trained features and baseline features beats both of themselves alone. It is counterintuitive, since experimental results prove that both of those features learn almost the same global and contextual features. In particular, baseline network dominates over pre-trained network as the former learns most of the features learned by the latter. Nonetheless, the combination of baseline and pre-trained classifiers improves the overall performance and generalizability, hence proving their effectiveness in sarcasm detection. Experimental results show that sentiment and emotion features are the most useful features, besides baseline features <ref type="figure" target="#fig_5">(Figure 4</ref>). Therefore, in order to reach a better understanding of the relation between personality features among themselves and with other pre-trained features, we carried out Spearman correlation testing. Results, displayed in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this work, we developed pre-trained sentiment, emotion and personality models for identifying sarcastic text using CNN, which are found to be very effective for sarcasm detection. In the future, we plan to evaluate the performance of the proposed method on a large corpus and other domain-dependent corpora. Future work will also focus on analyzing past tweets and activities of users in order to better understand their personality and profile and, hence, further improve the disambiguation between sarcastic and non-sarcastic text.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Sentiment shifting can be an indicator of sarcasm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>trained on Sentiment CNN pre-trained on Personality Figure 2: The proposed framework: deep CNNs are combined together to detect sarcastic tweets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>:</head><label></label><figDesc>Training settings for each deep model. Legenda: FC = Fully-Connected, S = Sentiment model, E = Emotion model, P = Personality model, B = Baseline model. CNN model developed in this work. ReLU is used as the non-linear activation function of the network 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Visualization of the data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) F1-score using different feature combinations.(b) Comparison with the state of the art on benchmark datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Plot of the performance of different feature combinations and methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>shows the training settings for each Feature Map Pooling Kernel Size Feature Map</figDesc><table><row><cell>Convolution Layer 1</cell><cell>1st Max</cell><cell>Convolution Layer 2</cell><cell>2nd Max-</cell><cell>FC</cell><cell>Softmax</cell></row><row><cell>Kernel Size</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">: Experimental Results. Legenda: B = Baseline, S = Sentiment, E = Emotion, P = Personality,</cell></row><row><cell cols="2">5-fold cross-validation is carried out for all the experiments.</cell></row><row><cell>Method</cell><cell>Dataset 1 Dataset 2 Dataset 3 D3 =&gt; D1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>, show that those features are highly correlated with each other.</figDesc><table><row><cell></cell><cell cols="2">Sentiment Happy</cell><cell>Fear</cell><cell cols="2">Openness Conscientiousness</cell></row><row><cell>Sentiment</cell><cell>1.0</cell><cell>0.04  *</cell><cell>0.03  *</cell><cell>0.59  *</cell><cell>0.83  *</cell></row><row><cell>Happy</cell><cell></cell><cell>1.0</cell><cell>-0.48  *</cell><cell>0.14  *</cell><cell>0.12  *</cell></row><row><cell>Fear</cell><cell></cell><cell></cell><cell>1.0</cell><cell>-0.10  *</cell><cell>-0.09  *</cell></row><row><cell>Openness</cell><cell></cell><cell></cell><cell></cell><cell>1.0</cell><cell>0.23  *</cell></row><row><cell>Conscientiousness</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Spearman's correlations between different features. * Correlation is significant at the 0.05 level.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">We show the optimal training settings of the CNNs used in this work. Changing kernels' size or adding/removing layers does not improve results.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We use RBF kernel, C=8 and gamma=0.01 to evaluate the method of Joshi et al. on Dataset 3 with 5-fold cross-validation.4  We report the result using all the features in this case.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Identifying expressions of emotion in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz2007] Saima Aman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Text, Speech and Dialogue</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Francesco Barbieri, Horacio Saggion, and Francesco Ronzano</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Barbieri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="50" to="58" />
		</imprint>
	</monogr>
	<note>Modelling sarcasm in Twitter</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Developing corpora for sentiment analysis and opinion mining: A survey and the Senti-TUT case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Bosco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="55" to="63" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An impact analysis of features in a classification approach to irony detection in product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Buschmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Sentic Computing: A Common-Sense-Based Framework for Concept-Level Sentiment Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
			<pubPlace>Cham, Switzerland</pubPlace>
		</imprint>
	</monogr>
	<note>Cambria and Hussain2015</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Jumping NLP curves: A review of natural language processing research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bebo</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="48" to="57" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The CLSA model: A novel framework for concept-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SenticNet 4: A semantic resource for sentiment analysis based on conceptual primitives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Erik Cambria, Soujanya Poria, Rajiv Bajpai, and Björn Schuller</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Affective computing and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="102" to="107" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Clues for detecting irony in user-generated contents: oh</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Carvalho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">s so easy;-)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>!! It</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International CIKM workshop on Topicsentiment analysis for mass opinion</title>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="53" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning word dependencies in text by means of a deep recurrent belief network. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Chaturvedi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="144" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semi-supervised recognition of sarcastic sentences in Twitter and Amazon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Davidov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on computational natural language learning</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Irony detection in Twitter: The role of affective content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Farías</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Internet Technology</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Identifying sarcasm in Twitter: A closer look</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>González-Ibánez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="581" to="586" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Harnessing context incongruity for sarcasm detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="757" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Automatic sarcasm detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Joshi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03426</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<idno>abs/1404.2188</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The perfect solution for detecting sarcasm in tweets # not</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liebrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="41" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The personality theories of H.J. Eysenck and J.A. Gray: A comparative review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilliland1999] Gerald</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirby</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gilliland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and Individual differences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="583" to="626" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Greenwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4238" to="4243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Statistical learning theory and ELM for big social data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Oneto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="45" to="55" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep convolutional neural network textual features and multiple kernel learning for utterance-level multimodal sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Poria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2539" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sentiment data flow analysis by means of dynamic linguistic patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bisio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="26" to="36" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Poria et al.2015b</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Aspect extraction for opinion mining with a deep convolutional neural network. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Poria</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
	<note>Soujanya Poria, Erik Cambria, and Alexander Gelbukh</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolutional MKL based multimodal emotion recognition and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Poria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<meeting><address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Context-dependent sentiment analysis in user-generated videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Poria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sarcasm detection on Czech and English Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Ptácek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="213" to="223" />
		</imprint>
	</monogr>
	<note>Tomás Ptácek, Ivan Habernal, and</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A multidimensional approach for detecting irony in Twitter. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reyes</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="239" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sarcasm as contrast between a positive sentiment and negative situation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashequl</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Surve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lalindra De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="704" to="714" />
		</imprint>
	</monogr>
	<note>Riloff et al.2013</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 9: Sentiment analysis in Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International workshop on semantic evaluation</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Combating human trafficking with deep multimodal models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<editor>Tong, Amir Zadeh, and Louis-Philippe Morency</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">ICWSM-a great catchy name: Semisupervised recognition of sarcastic sentences in online product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Tsur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="162" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Mosi: multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06259</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="88" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Convolutional experts constrained local model for facial landmark detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshop</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Amir Zadeh, Tadas Baltrušaitis, and Louis-Philippe Morency</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Tensor fusion network for multimodal sentiment analysis</title>
	</analytic>
	<monogr>
		<title level="j">In Empirical Methods in NLP</title>
		<editor>Zadeh et al.2017b] Amir Zadeh, Minghai Chen, Soujanya Poria, Erik Cambria, and Louis-Philippe Morency</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Micro-opinion sentiment intensity analysis and summarization in online videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 ACM on International Conference on Multimodal Interaction</title>
		<meeting>the 2015 ACM on International Conference on Multimodal Interaction</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="587" to="591" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
