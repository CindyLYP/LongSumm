<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identifying Impactful Service System Problems via Log Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilin</forename><surname>He</surname></persName>
							<email>slhe@cse.cuhk.edu.hk</email>
							<affiliation key="aff6">
								<orgName type="department">Also with Shenzhen Research Institute</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
							<email>qlin@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
							<email>jlou@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
							<email>hongyu.zhang@newcastle.edu.au</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
							<email>lyu@cse.cuhk.edu.hk</email>
							<affiliation key="aff6">
								<orgName type="department">Also with Shenzhen Research Institute</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
							<email>dongmeiz@microsoft.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong Kong Hong Kong</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">The University of Newcastle NSW</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">The Chinese University of Hong Kong Hong Kong</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<address>
									<addrLine>11 pages</addrLine>
									<settlement>New York</settlement>
									<region>NY, USA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Identifying Impactful Service System Problems via Log Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3236024.3236083</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Log Analysis</term>
					<term>Problem Identification</term>
					<term>Clustering</term>
					<term>Service Systems</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Logs are often used for troubleshooting in large-scale software systems. For a cloud-based online system that provides 24/7 service, a huge number of logs could be generated every day. However, these logs are highly imbalanced in general, because most logs indicate normal system operations, and only a small percentage of logs reveal impactful problems. Problems that lead to the decline of system KPIs (Key Performance Indicators) are impactful and should be fixed by engineers with a high priority. Furthermore, there are various types of system problems, which are hard to be distinguished manually. In this paper, we propose Log3C, a novel clustering-based approach to promptly and precisely identify impactful system problems, by utilizing both log sequences (a sequence of log events) and system KPIs. More specifically, we design a novel cascading clustering algorithm, which can greatly save the clustering time while keeping high accuracy by iteratively sampling, clustering, and matching log sequences. We then identify the impactful problems by correlating the clusters of log sequences with system KPIs. Log3C is evaluated on real-world log data collected from an online service system at Microsoft, and the results confirm its effectiveness and efficiency. Furthermore, our approach has been successfully applied in industrial practice. CCS CONCEPTS • Software and its engineering → Software testing and debugging; Maintaining software;</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>For large-scale software systems, especially cloud-based online service systems such as Microsoft Azure, Amazon AWS, Google Cloud, high service quality is vital. Since these systems provide services to hundreds of millions of users around the world, a small service problem could lead to great revenue loss and user dissatisfaction.</p><p>Large-scale software systems usually generate logs to record system runtime information (e.g., states and events). These logs are frequently utilized in the maintenance and diagnosis of systems. When a failure occurs, inspecting recorded logs has become a common practice. Particularly, logs play a crucial role in the diagnosis of modern cloud-based online service systems, where conventional debugging tools are hard to be applied.</p><p>Clearly, manual problem diagnosis is very time-consuming and error-prone due to the increasing scale and complexity of large-scale systems. Over the years, a stream of methods based on machine learning have been proposed for log-based problem identification and troubleshooting. Some use supervised methods, such as classification algorithms <ref type="bibr" target="#b43">[43]</ref>, to categorize system problems. However, they require a large number of labels and substantial manual labeling effort. Others use unsupervised methods, such as PCA <ref type="bibr" target="#b41">[41]</ref> and Invariants Mining <ref type="bibr" target="#b23">[23]</ref> to detect system anomalies. However, these approaches can only recognize whether there is a problem or not but cannot distinguish among different types of problem.</p><p>To identify different problem types, clustering is the most pervasive method <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b21">21]</ref>. However, it is hard to develop an effective and efficient log-based problem identification approach through clustering due to the following three challenges: 1) First, large-scale online service systems such as those of Microsoft and Amazon, often run on a 7 × 24 basis and support hundreds of millions of users, which yields an incredibly large quantity of logs. For instance, a service system of Microsoft that we studied can produce dozens of Terabytes of logs per day. Notoriously, conducting conventional clustering on data of such order-of-magnitude consumes a great deal of time, which is unacceptable in practice <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">18]</ref>.</p><p>2) Second, there are many types of problems associated with the logs and clustering alone cannot determine whether a cluster reflects a problem or not. In previous work on log clustering, developers are required to verify the problems manually during the clustering process <ref type="bibr" target="#b21">[21]</ref>, which is tedious and time-consuming.</p><p>3) Third, log data is highly imbalanced. In a production environment, a well-deployed online service system operates normally most of the time. That is, most of the logs record normal operations and only a small percentage of logs are problematic and indicate impactful problems. The imbalanced data distribution can severely impede the accuracy of the conventional clustering algorithm <ref type="bibr" target="#b42">[42]</ref>. Furthermore, it is intrinsic that some problems may arise less frequently than others; therefore, these rare problems emerge with fewer log messages. As a result, it is challenging to identify all problem types from the highly imbalanced log data.</p><p>To tackle the above challenges, we propose a novel problem identification framework, Log3C, using both log data and system KPI data. System KPIs (Key Performance Indicators such as service availability, average request latency, failure rate, etc.) are widely adopted in industry. They measure the health status of a system over a time period and are collected periodically.</p><p>To be specific, we propose a novel clustering algorithm, Cascading Clustering, which clusters a massive amount of log data by iteratively sampling, clustering, and matching log sequences (sequences of log events). Cascading clustering can significantly reduce the clustering time while keeping high accuracy. Further, we analyze the correlation between log clusters and system KPIs. By integrating the Cascading Clustering and Correlation analysis, Log3C can promptly and precisely identify impactful service problems.</p><p>We evaluate our approach on real-world log data collected from a deployed online service system at Microsoft. The results show that our method can accurately find impactful service problems from large log datasets with high time performance. Log3C can precisely find out problems with an average precision of 0.877 and an average recall of 0.883. We have also successfully applied Log3C to the maintenance of many actual online service systems at Microsoft. To summarize, our main contributions are threefold:</p><p>• We propose Cascading Clustering, a novel clustering algorithm that can greatly save the clustering time while keeping high accuracy. The implementation is available on Github 1 . • We propose Log3C, which is a novel framework that integrates cascading clustering and correlation analysis. Log3C can automatically identify impactful problems from a large amount of log and KPI data efficiently and accurately. • We evaluate our method using the real-world data from Microsoft.</p><p>Besides, we have also applied Log3C to the actual maintenance of online service systems at Microsoft. The results confirm the usefulness of Log3C in practice. The rest of this paper is organized as follows: In Section 2, we introduce the background and motivation. Section 3 presents the proposed framework and each procedure in detail. The evaluation of our approach is described in Section 4. Section 5 discusses the experiment results and Section 6 shares some success stories and https://github.com/logpai/Log3C  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND MOTIVATION</head><p>Cloud-based online service systems, such as Microsoft Azure, Google Cloud, and Amazon AWS, have been widely adopted in the industry. These systems provide a variety of services and support a myriad of users across the world every day. Therefore, one system problem could cause catastrophic consequences. Thus far, service providers have made tremendous efforts to maintain high service quality. For example, Amazon AWS <ref type="bibr" target="#b1">[2]</ref> and Microsoft Azure <ref type="bibr" target="#b25">[25]</ref> claim to have "five nines", which indicates the service availability of 99.999%. Although a lot of efforts have been devoted to quality assurance, in practice, online service systems still encounter many problems. To diagnose the problem, engineers often rely on system logs, which record system runtime information (e.g., states and events).</p><p>The top frame of <ref type="figure" target="#fig_0">Figure 1</ref> shows eight real-world log messages from Microsoft (some fields are omitted for simplicity of presentation). Each log message comprises two parts: a constant part and a variable part. The constant part consists of fixed text strings, which describe the semantic meaning of a program event. The variable part contains parameters (e.g., URL) that record important system attributes. A log event is the abstraction of a group of similar log messages. As depicted in <ref type="figure" target="#fig_0">Figure 1</ref>, the log event for log message 3,5,7 is E4: "HTTP request URL: * ", where the constant part is the common part of these log messages ("HTTP request URL:"), and the asterisk represents the parameter part. Log parsing is the procedure that extracts log events from log messages, and we defer details to Section 3.1. A log sequence is a sequence of log events that record a system operation in the same task. In <ref type="figure" target="#fig_0">Figure 1</ref>, log message 1,4,6,7,8 are sequentially generated to record a typical HTTP request. These log messages share the same task ID (t_41bx0), and thereby the corresponding log sequence is: [E1, E3, E5, E4, E2].</p><p>For a well-deployed online service system, it operates normally in most cases and exhibits problems occasionally. However, it does not imply that problems are easy to identify. On the contrary, problems are hidden among a vast number of logs while most logs record the system's normal operations. In addition, there are various types of service problems, which may manifest different patterns, occur at different frequencies, and affect the service system in different <ref type="formula">1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18</ref>Log sequence types As an example, <ref type="figure" target="#fig_1">Figure 2</ref> shows the long tail distribution of 18 types of log sequences (in logarithmic scale for easy plotting), which are labeled by engineers from product teams. The first two types of log sequences occupy more than 99.8% of the total occurrences ("head") and are generated by normal system operations. The remaining ones indicate different problems, but they all together only take up less than 0.2% of all occurrences ("long tail"). Besides, the occurrences of distinct problem types varies significantly. For example, the first type of problem (the 3rd bar in <ref type="figure" target="#fig_1">Figure 2</ref>) is a "SQL connection problem", which shows that the server cannot connect a SQL database. The most frequent problem occurs over 100 times more often than the least frequent one. The distribution is highly imbalanced and exhibits strong long-tail property, which poses challenges for log-based problem identification.</p><p>Among all the problems, some are impactful because they can lead to the degradation of system KPIs. As aforementioned, system KPIs delineate the system's health status. A lower KPI value indicates that some system problems may have occurred and the service quality deteriorates. In our work, we leverage both log and KPI data to guide the identification of impactful problems. In practice, systems continuously generate logs, but the KPI values are periodically collected.</p><p>We use time interval to denote the KPI collection frequency. The value of time interval is typically 1 hour or more, which is set by the production team. In our setting, we use failure rate as the KPI, which is the ratio of failed requests to all requests within a time interval. In each time interval, there could be many logs but only one KPI value (e.g., one failure rate).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LOG3C: THE PROPOSED APPROACH</head><p>In this paper, we aim at solving the following problems: Given system logs and KPIs, how to detect impactful service system problems automatically? How to identify different kinds of impactful service system problems precisely and promptly?</p><p>To this end, we propose Log3C, whose overall framework is depicted in <ref type="figure">Figure 3</ref>. Log3C consists of four steps: log parsing, sequence vectorization, cascading clustering, and correlation analysis. In short, at each time interval, logs are parsed into log events and vectorized into sequence vectors, which are then grouped into multiple clusters through cascading clustering. However, we still cannot extrapolate whether a cluster is an impactful problem, which necessitates the use of KPIs. Consequently, in step four, we correlate clusters and KPIs over different time intervals to find impactful problems. More details are presented in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Log Parsing</head><p>As aforementioned, log parsing extracts the log event for each raw log message since raw log messages contain some superfluous information (e.g., file name, IP address) that can hinder the automatic log analysis. The most straightforward way of log parsing is to write a regular expression for every logging statement in the source code, as adopted in <ref type="bibr" target="#b41">[41]</ref>. However, it is tedious and time-consuming because the source code updates very frequently and is not always available in practice (e.g., third-party libraries). Thus, automatic log parsing without source code is imperative.</p><p>In this paper, we use an automatic log parsing method proposed in <ref type="bibr" target="#b12">[13]</ref> to extract log events. Following this method, firstly, some common parameter fields (e.g., IP address), are removed using regular expressions. Then, log messages are clustered into coarsegrained groups based on weighted edit distance. These groups are further split into fine-grained groups of log messages. Finally, a log event is obtained by finding the longest common substrings for each group of raw log messages.</p><p>To form a log sequence, log messages that share the same task ID are linked together and parsed into log events. Moreover, we remove the duplicate events in the log sequence. Generally, repetition often indicates retrying operations or loops, such as continuously trying to connect to a remote server. Without removing duplicates, similar log sequences with different occurrences of the same event are identified as distinct sequences, although they essentially indicate the same system behavior/operation. Following the common practice <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b32">32]</ref> in log analysis, we remove the duplicate log events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sequence Vectorization</head><p>After obtaining log sequences from logs in all time intervals, we compute the vector representation for each log sequence. We believe that different log events have different discriminative power in problem identification. As delineated in Step 2 of <ref type="figure">Figure 3</ref>, to measure the importance of each event, we calculate the event weight by combining the following two techniques:</p><p>IDF Weighting: IDF (Inverse Document Frequency) is widely utilized in text mining to measure the importance of words in some documents, which lowers the weight of frequent words while increasing rare words' weight <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b31">31]</ref>. In our scenario, events that frequently appear in numerous log sequences cannot distinguish problems well because problems are relatively rare. Hence, the event and log sequence are analogous to word and document respectively. We aggregate log sequences in all time intervals together to calculate the IDF weight, which is defined in Equation 1, where N is the total number of all log sequences and n e is the number of log sequences that contain the event e. With IDF weighting, frequent events have low weights, while rare events are weighted high.   </p><formula xml:id="formula_0">w id f (e) = log N n e (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Cascading Clustering 4. Correlation Analysis</head><formula xml:id="formula_1">Figure 3: Overall Framework of Log3C w(e) = α * Norm(w id f (e)) + (1 − α) * w cor (e)<label>(2)</label></formula><p>Importance Weighting: In problem identification, it is intuitive that events strongly correlate with KPI degradation are more critical and should be weighted more. Therefore, we build a regression model between log events and KPI values to find the importance weight. To achieve so, as shown <ref type="figure">Figure 3</ref>, in each time interval, we sum the occurrence of each event in all log sequences (three in the example) as a summary sequence vector. After that, we get d summary sequence vectors, and d KPI values are also available as aforementioned. Then, a multivariate linear regression model is applied to evaluate the correlation between log events and KPIs. The weights w cor (e) obtained from the regression model serve as the importance weights for log events e. Note that the regression model only aims to find the importance weight for the log event.</p><p>As denoted in Equation 2, the final event weight is the weighted sum of IDF weight and importance weight. Besides, we use Sigmoid function <ref type="bibr" target="#b40">[40]</ref> to normalize the IDF weight into the range of [0, 1]. Since the importance weight is directly associated with KPIs and is thereby more effective in problem identification, we value the importance weight more, i.e., α &lt; 0.5. In our experiments, we empirically set α to 0.2. Given the final event weights, the weighted sequence vectors can be easily obtained. For simplicity, hereafter, we use "sequence vectors" to refer to "weighted sequence vectors". Note that each log sequence has a corresponding sequence vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cascading Clustering</head><p>Once all log sequences are vectorized, we group sequence vectors into clusters separately for each time interval. However, the conventional clustering methods are incredibly time-consuming when the data size is large <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">18]</ref> because distances between any pair of samples are required. As mentioned in Section 2, log sequences follow the long tail distribution and are highly imbalanced. Based on the observation, we propose a novel clustering algorithm, cascading clustering, to group sequence vectors into clusters (different log sequence types) promptly and precisely, where each cluster represents one kind of log sequence (system behavior). <ref type="figure">Figure 4</ref> depicts the procedure of cascading clustering, which leverages iterative processing, including sampling, clustering, matching and cascading. The input of cascading clustering is all the sequence vectors in a time interval, and the output is a number of clusters. To be more specific, we first sample a portion of sequence vectors, on which a conventional clustering method (e.g., hierarchical clustering) is applied to generate multiple clusters. Then, a pattern can be extracted from each cluster. In the matching step, we match all the original unsampled sequence vectors with the patterns to determine their cluster. Those unmatched sequence vectors are collected and fed into the next iteration. By iterating these processes, all sequence vectors can be clustered rapidly and accurately. The reason behind is that large clusters are separated from the remaining data at the first several iterations.</p><p>3.3.1 Sampling. Given numerous sequence vectors in each time interval, we first sample a portion of them through Simple Random Sampling (SRS). Each sequence vector has an equal probability p (e.g., 0.1%) to be selected. Suppose there are N sequence vectors in the input data, then the sampled data size is M = ⌈p * N ⌉. After sampling, log sequence types (clusters) that dominate in the original input data are still dominant in the sampled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Clustering.</head><p>After sampling M sequence vectors from the input data, we group these sequence vectors into multiple clusters and extract a representative vector (pattern) from every cluster. To do so, we calculate the distance between every two sequence vectors and apply an ordinary clustering algorithm.</p><p>Distance Metric: During clustering, we use Euclidean distance as the distance metric, which is defined in Equation 3: u and v are two sequence vectors, and n is the vector length, which is the number of log events. u i and v i are the i-th value in vector u and v, respectively.</p><formula xml:id="formula_2">d(u, v) = ∥u − v ∥ = n i=1 (u i − v i ) 2 (3) D(A, B) = max {d(a, b), ∀a ∈ A, ∀b ∈ B} (4) µ = min{d(x, P j ), ∀j ∈ {1, 2, ..., k}}<label>(5)</label></formula><p>Clustering Technique: We utilize Hierarchical Agglomerative Clustering (HAC) to conduct clustering. At first, each sequence vector itself forms a cluster, and the closest two clusters are merged into a new one. To find the closest clusters, we use the complete linkage <ref type="bibr" target="#b38">[38]</ref> to measure the cluster distance. As shown in Equation 4, D is the cluster distance between two clusters A and B, which is defined as the longest distance between any two elements (one in each cluster) in the clusters. The merging process continues until reaching a distance threshold of θ . That is, the clustering stops when all the distances between clusters are larger than θ . In Section 4.4, we also study the effect of different thresholds. After clustering, similar sequence vectors are grouped into the same cluster, while dissimilar sequence vectors are separated into different clusters.</p><p>Pattern Extraction: After clustering, a representative vector is extracted for each cluster, which serves as the pattern of a group of similar log sequences. To achieve so, we compute the mean vector <ref type="bibr" target="#b2">[3]</ref> of all sequence vectors in a cluster. Assume that there are k clusters, then k mean vectors (patterns) can be extracted to represent those clusters respectively. <ref type="figure">Figure 4</ref>, we match each sequence vector in the original unsampled input data (of size N ) to one of the k patterns, which are obtained by clustering M sampled sequence vectors. To this end, for each sequence vector x, we calculate the distance between it and every pattern. Furthermore, we compute the minimum distance µ as denoted in Equation 5, where P is a set of all patterns. If the minimum distance µ is smaller than the threshold θ defined in the clustering step, the sequence vector x is matched with a pattern successfully and thereby can be assigned to the corresponding cluster. Otherwise, this sequence vector is classified as mismatched. Note that those mismatched sequence vectors would proceed to the next iteration.  <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b18">[18]</ref><ref type="bibr" target="#b19">[19]</ref> to store the distances between a sequence vector and every cluster pattern. The sequence vector is allocated to the closest cluster if the distance is smaller than the threshold θ . The remaining mismatched data is updated (lines 24) and processed in the next cascading round.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Matching. As illustrated in</head><p>We now analyze the time complexity of the proposed algorithm. Note that only the core parts of the cascading clustering algorithm are considered, i.e., distance calculation and matching, because they consume most of the time. We set the data size to N , which is a large number (e.g., larger than 10 6 ). The sample rate p is usually a userdefined small number (e.g., less than 1%). For standard hierarchical agglomerative clustering, the distance calculation takes O(N 2 ) time complexity, and no matching is involved. For cascading clustering, suppose that pN data instances are selected and clustered into k 1 groups firstly, and further N 1 instances are mismatched. Therefore, the time complexity of the first round is T 1 = p 2 N 2 + k 1 N . After t iterations, the total number of clusters is K = t i=1 k i . Therefore, the overall time complexity T (cc) is calculated as:</p><formula xml:id="formula_3">T (cc) = p 2 N 2 + k 1 N + p 2 N 2 1 + k 2 N 1 + ... + p 2 N 2 t + k t N t −1 = p 2 N 2 + t i=1 p 2 N 2 i + k 1 N + t −1 i=1 k i+1 N i &lt; p 2 N 2 + tp 2 N 2 1 + KN &lt; (pN + p √ tN 1 + √ KN ) 2</formula><p>Since N is a large number and K is the total number of clusters, we have K ≪ N and √ KN ≪ N . Because the data follows the long tail distribution and the "head" occupies most of the data (e.g., more than 80%). After several iterations, most data can be successfully clustered and matched. Recall that p ≪ 1, we then have p √ t N 1 ≪ N and pN ≪ N . Therefore, the inequality pN + p √ tN 1 + √ KN &lt; N holds and the left-hand side is much smaller. Given that f (X ) = X 2 is a monotonic increasing function (X ≥ 0), where f (X ) decreases with the decreasing of X . We then have (pN +p √ tN 1 + √ KN ) 2 ≪ N 2 satisfied, which indicates that cascading clustering consumes much less time than standard clustering in terms of distance calculation and matching. In our experiments, we empirically evaluate the time performance of cascading clustering, and the results support our theoretical analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Correlation Analysis</head><p>As described in <ref type="figure">Figure 3</ref>, log sequence vectors are grouped into multiple clusters separately in each time interval. These clusters only represent different types of log sequences (system behaviors) but may not necessarily be problems. From the clusters, we identify the impactful problems that lead to the degradation of KPI. Intuitively, KPI degrades more if impact problems occur more frequently. Hence, we aim to identify those clusters that highly correlate with KPI's changes. To do so, we model the correlation between cluster sizes and KPI values over multiple time intervals. Unlike the importance weighting in Section 3.2 that discriminates the importance of different log events, this step attempts to identify impactful problems from clusters of sequence vectors.</p><p>More specifically, we utilize a multivariate linear regression (MLR) model (Equation 6), which correlates independent variables (cluster sizes) with the dependent variable (KPI). Among all independent variables, those have statistical significance make notable contributions to the dependent variable. Moreover, the corresponding clusters indicate impactful problems, whose occurrences contribute to the change of KPI. Statistical significance is widely utilized in the identification of important variables <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b34">34]</ref>.</p><formula xml:id="formula_4">         c 11 c 12 c 13 . . . c 1n c 21 c 22 c 23 . . . c 2n . . . . . . . . . . . . . . . c d 1 c d 2 c d 3 . . . c dn                   β 1 β 2 . . . β n          +          ε 1 ε 2 . . . ε d          =          KPI 1 KPI 2 . . . KPI d         <label>(6)</label></formula><p>In Equation 6, suppose there are n clusters generated during d time intervals, c i j represents the cluster size (the number of sequence vectors) of the j-th cluster at time interval i. KPI i is the system KPI value at time interval i. β i and ε i are coefficients and error terms that would be learned from data.</p><p>To find out which clusters are highly correlated with the KPI values, we adopt the t-statistic, which is a widely used statistical hypothesis test. In our MLR model, important clusters (indicating impactful problems) make major contributions to the change of KPIs, and their coefficients should not be zero. Therefore, we make a null hypothesis for each independent variable that its coefficient is zero. Then, a two-tailed t-test is applied to measure the significant difference of each coefficient, i.e., the probability p that the null hypothesis is true. A lower p-value is preferred since it represents a higher probability of the null hypothesis being rejected. If p-value is less than or equal to a given threshold α (significance level), the corresponding cluster implies an impactful problem that affects the KPI. In this paper, we set α to 0.05, which is a common setting in hypothesis test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we evaluate our approach using real-world data from industry. We aim at answering the following research questions:</p><p>RQ1: How effective is the proposed Log3C approach in detecting impactful problems?</p><p>RQ2: How effective is the proposed Log3C approach in identifying different types of problems?</p><p>RQ3: How does cascading clustering perform under different configurations?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Datasets: We collect the real-world data from an online service system X of Microsoft. Service X is a large scale online service system, which serves hundreds of millions of users globally on a 24/7 basis. Service X has been running over the years and has achieved high service availability. The system is operating in multiple data centers with a large number of machines, each of which produces a vast quantity of logs every hour. Service X utilizes the load balancing strategies, and end user requests are accepted and dispatched to different back-ends. There are many components at the application level, and each component has its specific functionalities. Most user requests involve multiple components on various servers. Each component generates logs and all the logs are uploaded to a distributed HDFS-like data storage automatically. Each machine or component has a probability to fail, leading to various problem types. We use failure rate as the KPI, which shows the percentage of failed requests in a time interval. Service X produces a large quantity of log data consisting of billions of log messages. However, it is unrealistic to evaluate Log3C on all the data due to the lack of labels. The labeling difficulties origin from two aspects: first, the log sequences are of huge size. Second, various problem types can exist, and human labeling is very time-consuming and error-prone. Therefore, we extract logs that were generated during a specified period 2 on three different days. In this way, three real-world datasets (i.e., Data 1, 2, 3) are obtained, as shown in <ref type="table" target="#tab_3">Table 1</ref>. Besides the log data, we also collect the corresponding KPI values. During labeling, product team engineers utilize their domain knowledge to identify the normal log sequences. Then, they manually inspect the rest log sequences from two aspects: 1) Does the log sequence indicate a problem? 2) What is the problem type? <ref type="table" target="#tab_3">Table 1</ref> shows the number of problem types identified in the evaluation datasets. Note that the manual labels are only used for evaluating the effectiveness of Log3C in our experiments. Log3C is an unsupervised method, which only requires log and KPI data to identify problems.</p><p>Implementation and Environments: We use Python to implement our approach for easy comparison, and run the experiments on a Windows Server 2012 (Intel(R) Xeon(R) CPU E5-4657L v2 @ 2.40GHz 2.40 with 1.00TB Memory).</p><p>The actual period is anonymous due to data sensitivity. Evaluation Metrics: To measure the effectiveness of Log3C in problem detection, we use the Precision, Recall, and F1-measure. Given the labels from engineers, we calculate these metrics as follows:</p><p>Precision: the percentage of log sequences that are correctly identified as problems over all the log sequences that are identified as problems: Precision = T P T P +F P . Recall: the percentage of log sequences that are correctly identified as problems over all problematic log sequences: Recall =</p><formula xml:id="formula_5">T P T P +F N .</formula><p>F1-measure: the harmonic mean of precision and recall. TP is the number of problematic log sequences that correctly detected by Log3C, FP is the number of non-problematic log sequences that are wrongly identified as problems by Log3C. FN is the number of problematic log sequences that are not detected by Log3C, TN is the number of log sequences that are identified as non-problematic by both engineers and Log3C.</p><p>To measure the effectiveness of clustering, we use the Normalized Mutual Information (NMI), which is a widely used metric for evaluating clustering quality <ref type="bibr" target="#b35">[35]</ref>. The value of NMI ranges from 0 to 1. The closer to 1, the better the clustering results. To measure the efficiency of cascading clustering, we record the total time (in seconds) spent on clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">RQ1: Effectiveness of Log3C in Detecting</head><p>Impactful Problems</p><p>To answer RQ1, we apply Log3C to the three datasets collected from Service X and evaluate the precision, recall, and F1-measure. The results are shown in <ref type="table" target="#tab_5">Table 2</ref>. Log3C achieves satisfactory accuracy, with recall ranging from 0.826 to 0.92 and precision ranging from 0.834 to 0.9. The F1-measures on the three datasets are 0.91, 0.86, and 0.868, respectively. Furthermore, we compare our method with two typical methods: PCA <ref type="bibr" target="#b41">[41]</ref> and Invariants Mining <ref type="bibr" target="#b23">[23]</ref>. All these three methods are unsupervised, log-based problem identification methods. PCA projects the log sequence vectors into a subspace. If the projected vector is far from the majority, it is considered as a problem. Invariants Mining extracts the linear relations (invariants) between log event occurrences, which hypothesizes that log events are often pairwise generated. For example, when processing files, "File A is opened" and "File A is closed" should be printed as a pair. Log sequences that violate the invariants are regarded as problematic.</p><p>Log3C achieves good recalls (similar to those achieved by two comparative methods) and surpasses the comparative methods concerning precision and F1-measure. The absolute improvement in F1-measure ranges from 15.7% to 61.8% on the three datasets. The two comparative methods all achieve low precision (less than 0.61), while the precisions achieved by Log3C are greater than 0.83. We also explore the reasons for the low precision of the competing methods. In principle, PCA and Invariants Mining aim at finding the abnormal log sequences from the entire data. However, some rare user/system behaviors can be wrongly identified as problems. Thus, many false positives are generated, which result in high recall and low precision. More details are described in Section 6.2.1.</p><p>Regarding the time usage of problem detection, on average, it takes Log3C 223.93 seconds to produce the results for each dataset, while PCA takes around 911.97 seconds and invariants mining consumes 1830.78 seconds. The time performance of Log3C is satisfactory considering the large amount of log sequence data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">RQ2: Effectiveness of Log3C in Identifying Different Types of Problems</head><p>In Log3C, we propose a novel cascading clustering algorithm to group the log sequences into clusters that represent different types of problems. For the ease of evaluation, clusters that represent normal system behaviors are considered as special "non-problem" types. In this section, we use NMI to evaluate the effectiveness of Log3C in identifying different types of problems. We also compare the performance of cascading clustering (denoted as CC) with the standard clustering method hierarchical agglomerative clustering (denoted as SC). To compare fairly, we implement a variant of Log3C that replaces CC with SC, denoted as Log3C-SC. All the other settings (e.g., distance threshold, event weight) remain the same.  <ref type="table" target="#tab_6">Table 3</ref> presents the NMI results, in which data size refers to the number of log sequences. We sample four subsets of each dataset with size ranging from 10k to 200k (for Data 3, 180k is used instead of 200k as its total size is around 180k). From the table, we can conclude that Log3C (with cascading clustering) is effective in grouping numerous log sequences into different clusters and outperforms Log3C-SC on all three datasets. Besides, with the increase of data size, clustering accuracy increases. This is because more accurate event weights can be obtained with more data during sequence vectorization. For instance, when 200k data is used, the NMI values achieved by Log3C range from 0.715 to 0.91 (180k for Data 3).</p><p>We also evaluate the time performance of cascading clustering. <ref type="table" target="#tab_7">Table 4</ref> shows that our cascading clustering (CC) dramatically save the time in contrast to the standard HAC clustering (SC), and the comparison is more noticeable when the data size grows. For example, our approach is around 1800x faster than standard clustering on dataset 1 with a size of 200k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">RQ3: Cascading Clustering under Different Configurations</head><p>In Section 3.3, we introduced two important hyper-parameters that are used in cascading clustering: the sample rate p and the distance threshold θ . In this section, we evaluate clustering accuracy and time performance under different configurations of parameters. We conduct the experiments on Data 1, but the results are also applicable to other datasets.</p><p>0.01% 0.1% 0.2% 1% 3% 5% 10% Sample rate Distance threshold θ : We first fix the sample rate (1%) and vary the distance threshold θ for cascading clustering. The clustering accuracy (NMI) is given in <ref type="table" target="#tab_8">Table 5</ref>. When θ is 0.30, the highest NMI value (0.928) is achieved. However, we also observe that NMI changes slightly when the threshold changes within a reasonable range. The results show that our proposed cascading clustering algorithm is insensitive to the distance threshold to some degree.</p><p>Sample rate p: It is straightforward that sample rate can affect the time performance of cascading clustering because it takes more time to do clustering on a larger dataset. To verify it, we change the sample rate while fixing the distance threshold. <ref type="figure" target="#fig_3">Figure 5</ref> depicts the results. We conduct the experiments with different sample rates under three distance thresholds (0.15, 0.25, and 0.3). The left subfigure shows that a higher sample rate generally causes more time usage. However, when the sample rate is very small, e.g., 0.01%, a little more time is required. This is because, in cascading clustering, a small sample rate leads to more iterations of clustering, which hampers the efficiency of cascading clustering. Besides, we also  <ref type="figure" target="#fig_3">Figure 5</ref>, clustering accuracy (NMI) is relatively stable when the sample rate changes. It shows that the NMI value floats slightly with a small standard deviation of 0.0071. In summary, we can conclude that generally, a small sample rate does not affect clustering accuracy and cost much less time. This finding can guide the setting of the sample rate in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSIONS 5.1 Discussions of Results</head><p>5.1.1 Performance of Cascading Clustering with Different Numbers of Clusters. In Section 4, we explored the efficiency and effectiveness of cascading clustering on real-world datasets. In this section, we evaluate our cascading clustering algorithm on some synthetic datasets. More specifically, we generate some synthetic datasets with different number of clusters.</p><p>To simulate a scenario that is similar to problem identification, we synthesize several synthetic datasets consisting of multiple clusters, where the cluster sizes follow the long tail distribution. In more detail, 1) we firstly synthesize a dataset of multiple clusters, and the data sample dimension is fixed at 200. The data samples in each cluster follow the multivariate normal distribution <ref type="bibr" target="#b39">[39]</ref>. 2) Then, we use the pow law function (i.e., f (x) = αx −k ) to determine the size of each cluster with some Gaussian noises added, as noises always exist in real data. In this way, we can generate multiple datasets with different data sizes (from 20k to 600k) and various numbers of clusters (from 20 to 200).  In <ref type="table" target="#tab_9">Table 6</ref>, we measure the clustering accuracy (in terms of NMI) under different data sizes and cluster numbers. We can conclude from the table that, overall, cascading clustering leads to equal or slightly better accuracy when compared with the standard clustering. The main reason is that our cascading clustering algorithm is specially designed for long-tailed data. The small clusters can be precisely clustered. Moreover, the evaluation results of standard clustering on 600k data are not available due to the out-of-memory (more than 1TB) computation. From <ref type="table" target="#tab_9">Table 6</ref>, we can also observe that clustering accuracy increases with the increase of cluster number and decreases when the data size increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Impact of Log Data</head><p>Quality. The quality of log data is crucial to log-based problem identification. For a large-scale service system, logs are usually generated on local machines, which are then collected and uploaded to a data center separately. During the process, some logs may be missed or duplicated. For duplicated logs, they do not affect the accuracy of Log3C as duplicates are removed from log sequences as described in Section 3.2. To evaluate the impact of missing log data, we randomly remove a certain percentage (missing rate) of logs from Data 1 and then evaluate the accuracy of Log3C. We use three different missing rates 0.1%, 0.5%, and 1%. The resulting F1-measures are 0.877, 0.834, 0.600, respectively. It can be concluded that a higher missing rate could lead to a lower problem identification accuracy. Therefore, we suggest ensuring the log data quality before applying Log3C in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Threats to Validity</head><p>We have identified the following threats to validities:</p><p>Subject Systems: In our experiment, we only collect log data from one online service system (Service X). This system is a typical, large-scale online system, from which sufficient data can be collected. Furthermore, we have applied our approach to the maintenance of actual online service systems of Microsoft. In the future, we will evaluate Log3C on more subject systems and report the evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Selection of KPI:</head><p>In our experiments, we use failure rate as the KPI for problem identification. failure rate is an important KPI for evaluating system service availability. There are also other KPIs such as mean time between failures, average request latency, throughput, etc. In our future work, we will experiment with problem identification concerning different KPI metrics.</p><p>Noises in labeling: Our experiments are based on three datasets that are collected as a period of logs on three different days. The engineers manually inspected and labeled the log sequences. Noises (false positives/negatives) may be introduced during the manual labeling process. However, as the engineers are experienced professionals of the product team who maintain the service system, we believe the amount of noise is small (if it exists).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SUCCESS STORY AND LESSONS LEARNED 6.1 Success Story</head><p>Log3C is successfully applied to Microsoft's Service X system for log analysis. Service X provides online services to hundreds of millions of global end users on 7 * 24 basis. For online service systems like Service X, inspecting logs is the only feasible way for fault diagnosis. In Service X, more than one Terabyte of logs (around billions) are generated in a few hours, and it is a great challenge to process the great volume of logs. A distributed version of Log3C is developed and employed in Service X. Billions of logs can be handled within hours using our method, which helps the service team in identifying different log sequence types and detecting system problems. For example, in April 2015, a severe problem occurred to one component of Service X on some servers. The problem was caused by an incompatibility issue between a patch and a previous product version during a system upgrade. The service team received lots of user complains regarding this problem. Our Log3C successfully detected the problem and reported it to the service team. The service team also utilized Log3C to investigate the logs and precisely identified the type of the problem. With the help of Log3C, the team quickly resolved this critical issue and redeployed the system.</p><p>Log3C is also integrated into Microsoft's Product B, an integrated environment for analyzing the root causes of service issues. Tens of billions of logs are collected and processed by Product B every day, in which Log3C is the log analysis engine. Using Log3C, Product B divides the log sequences into different clusters and identifies many service problems automatically. Log3C greatly reduces engineers' efforts on manually inspecting the logs and pinpointing root causes of failures. Furthermore, fault patterns are also extracted and maintained for analyzing similar problems in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Lessons Learned</head><p>6.2.1 Problems != Outliers. Recent research <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b41">41]</ref> proposed many approaches to detect system anomalies using data mining and machine learning techniques. These approaches work well for relatively small systems. Their ideas are mainly based on the following hypothesis: systems are regular most of the time and problems are "outliers". Many current approaches try to detect the "outliers" from a huge volume of log data. For example, PCA <ref type="bibr" target="#b41">[41]</ref> attempts to map all data to a normal subspace, and those cannot be projected to the normal space are considered as anomalies.</p><p>However, the outliers are not always real problems. Some outliers are caused by certain infrequent user behaviors, e.g., rarely-used system features. Our experiences with the production system reveal that there are indeed many rare user behaviors, which are not real problems. A lot of effort could be wasted by examining these false positives. In our work, we utilize system KPI to guide the identification of real system problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.2.2</head><p>The Trend of Problem Reports Is Important. In production, engineers not only care about the occurrence of a problem but also about the number of problem reports (i.e., the instances of problems) over time (which reflects the number of users that are affected by the problem over time). Through our communication with a principal architect of a widely-used service in Microsoft, we conclude three types of important trends: 1) Increasing. When the size of one certain problem continuously increases for a period, the production team should be notified. This is because the number of problem reports may accumulate and cause even serious consequences.</p><p>2) The appearance of new problems: when a previously unknown problem appears, it is often a sign of new bugs, which may be introduced by software updates or a newly launched product feature.</p><p>3) The disappearance of problems: The disappearing trend is very interesting. In production, after fixing a problem, the scale of the problem is expected to decrease. However, sometimes the disappearing trend may stop at a certain point (the service team continues to receive reports for the same problem), which often indicates an incomplete bug-fix or a partial solution. More debugging and diagnosis work are needed to identify the root cause of the problem and propose a complete bug-fixing solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK 7.1 Log-based Problem Identification</head><p>Logs have been widely used for the maintenance and diagnosis of various software systems with the abundant information they provide. Log-based problem identification has become a very popular area <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b43">43]</ref> in recent years. Typically, based on information extracted from logs, these work employ machine learning and data mining techniques to analyze logs for anomaly detection and problem diagnosis <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b41">41]</ref>.</p><p>The target of anomaly detection is to find system's abnormal behaviors and give feedback to engineers for further diagnosis. Lou et al. <ref type="bibr" target="#b23">[23]</ref> mined the invariants (linear relationships) among log events to detect anomalies. Liang et al. <ref type="bibr" target="#b20">[20]</ref> trained a SVM classifier to detect failures. However, anomaly detection can only determine whether a log sequence is abnormal or not; it cannot determine if there is a real problem. Our Log3C can not only detect system problems but also cluster them into various types.</p><p>Problem identification aims at categorizing different types of problems by grouping similar log sequences together. Lin et al. <ref type="bibr" target="#b21">[21]</ref> proposed a clustering-based approach for problem identification. Based on testing environment logs, a knowledge base is built firstly and updated in production environment. However, it requires manual examination when new problems appear. Yuan et al. <ref type="bibr" target="#b43">[43]</ref> employed a classification method to categorize system traces by calculating the similarity with traces of existing and known problems. Beschastnikh et al. <ref type="bibr" target="#b4">[5]</ref> inferred system behaviors by utilizing logs, which can support anomaly detection and bug finding. Ding et al. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> correlated logs with system problems and mitigation solutions when similar logs appear. Shang et al. <ref type="bibr" target="#b32">[32]</ref> identified problems by grouping the same log sequences after removing repetition and permutations. However, they ignored different importance of log events and the similarity between two log sequences. In our work, we use cascading clustering to quickly and precisely cluster log sequences into different groups, and correlate clusters with the KPIs to identify problems. Our approach does not require manual examination, nor a knowledge base of known problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Log Parsing and Logging Practice</head><p>Logs cannot be utilized towards automatic analysis before being parsed into log events. Many log parser (e.g. LogSig <ref type="bibr" target="#b36">[36]</ref>, SLCT <ref type="bibr" target="#b37">[37]</ref>, IPLoM <ref type="bibr" target="#b24">[24]</ref>) have been proposed in recent years, and the parsing accuracy can significantly affect the downstream log analysis tasks <ref type="bibr" target="#b15">[16]</ref>. Xu et al. <ref type="bibr" target="#b41">[41]</ref> extracted log events from console logs using the source code. Fu et al. <ref type="bibr" target="#b12">[13]</ref> parsed logs by clustering with weighted edit distance. Makanju et al. <ref type="bibr" target="#b24">[24]</ref> proposed a lightweight log parsing method by iteratively partitioning logs into subgroups and extracting log event.</p><p>Recently, there are also research on logging practice <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b45">45]</ref>. For example, Fu et al. <ref type="bibr" target="#b13">[14]</ref>, Yuan et al. <ref type="bibr" target="#b44">[44]</ref>, and Shang et al. <ref type="bibr" target="#b33">[33]</ref> provide suggestions to developers by exploring the logging practice on some open-source systems and industry products. Zhu et al. <ref type="bibr" target="#b45">[45]</ref> proposed a method to guide developers on whether to write logging statements. Kabinna1 et al. <ref type="bibr" target="#b19">[19]</ref> examined the stability of logging statements and suggested to developers the unstable ones. The above research improves the quality of logs, which could in turn help with log-based problem identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>Large-scale online service systems generate a huge number of logs, which can be used for troubleshooting purpose. In this paper, we propose Log3C, a novel framework for automated problem identification via log analysis. At the heart of Log3C is cascading clustering, a novel clustering algorithm for clustering a large number of highly imbalanced log sequences. The clustered log sequences are correlated with system KPI through a regression model, from which the clusters that represent impactful problems are identified. We evaluate Log3C using the real-world log data. Besides, we also apply our approach to the maintenance of actual online service systems. The results confirm the effectiveness and efficiency of Log3C in practice.</p><p>In the future, we will apply Log3C to a variety of software systems to further evaluate its effectiveness and efficiency. Also, the proposed Cascading Clustering algorithm is a general algorithm, which can be applied to a wide range of problems as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An Example of Log Messages and Log Events experiences obtained from industrial practice. The related work and conclusion are presented in Section 7 and Section 8, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Long Tail Distribution of Log Sequences manners. As a result, it is challenging to precisely and promptly identify the service problems from the logs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Cascading Clustering on Service X Data under Different Configurations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :Figure 6</head><label>66</label><figDesc>Time Performance of Clustering Methods on Synthetic Data with 50 Cluster (Left) and 200 Clusters (Right) shows the time performance (in logarithmic scale for easy plotting) of standard clustering and cascading clustering where the number of clusters is 50 and 200. We also vary the synthetic data size from 20k to 600k. It is clear that cascading clustering requires much less time than standard clustering (hierarchical agglomerative clustering), with different cluster numbers. For example, standard clustering takes 11512.2 seconds (around 3.19 hours) on 200k data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>02</head><label></label><figDesc>Leaving Monitored Scope (EnsureListItemsData) Execution Time=52.9013 07 HTTP request URL: http://AAA:1000/BBBB/sitedata.html 05 HTTP request URL: /55/RST/UVX/ADEG/Lists/Files/docXX.doc 03 HTTP request URL: /14/Emails/MrX(MrX@mail.com)/1c-48f0-b29.eml 01 Name=Request (GET:http://AAA:1000/BBBB/sitedata.html)</figDesc><table><row><cell>04 HTTP Request method: GET</cell><cell></cell></row><row><cell>06 Overridden HTTP request method: GET</cell><cell></cell></row><row><cell cols="2">08 Leaving Monitored Scope (Request (POST:http://AAA:100/BBBB/</cell></row><row><cell>sitedata.html)) Execution Time=334.319268903038</cell><cell></cell></row><row><cell>E1 Name=Request (*)</cell><cell></cell></row><row><cell>E3 HTTP Request method: *</cell><cell>Log Parsing</cell></row><row><cell>E4 HTTP request URL: *</cell><cell></cell></row><row><cell>E5 Overridden HTTP request method: *</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Algorithm 1 :</head><label>1</label><figDesc>Cascading Clustering Input : Sequence vector data D, Sample rate p, Clustering threshold θ Output : Sequence clusters дlobalClusters, Pattern set дloablPatList Overview of Cascading Clustering Algorithm unmatched data by repeating the abovementioned procedures. That is, during each iteration, new clusters are grouped based on current mismatched data, new patterns are extracted, and new mismatched data are produced. In our experiments, we cascade these repetitions until all the sequence vectors are successfully clustered.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Matched</cell><cell>Mismatched</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>data</cell><cell>data</cell></row><row><cell></cell><cell></cell><cell>Log Sequences</cell><cell>Sampling</cell><cell>Clustering &amp; Pattern extraction</cell><cell>Matching</cell></row><row><cell></cell><cell></cell><cell cols="2">Figure 4:</cell></row><row><cell>5</cell><cell>/* Sampling sequence vectors</cell><cell>*/</cell><cell></cell></row><row><cell>6</cell><cell>foreach seqV ec ∈ D do</cell><cell></cell><cell></cell></row><row><cell>7</cell><cell>if random(0, 1) &lt;= p then</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell>SampleData.append(seqV ec);</cell><cell></cell><cell></cell></row><row><cell>9</cell><cell>end</cell><cell></cell><cell></cell></row><row><cell>10</cell><cell>end</cell><cell></cell><cell></cell></row><row><cell>11</cell><cell>/* Hierarchical clustering</cell><cell>*/</cell><cell></cell></row><row><cell>12</cell><cell>localClusters = HAC(SampledData, θ );</cell><cell></cell><cell></cell></row><row><cell>13</cell><cell>localPatList = patternExtraction(clusters);</cell><cell></cell><cell></cell></row><row><cell>14</cell><cell>/* Matching and finding mismatched data</cell><cell>*/</cell><cell></cell></row><row><cell>15</cell><cell>newMismatchData = ∅;</cell><cell></cell><cell></cell></row><row><cell>19</cell><cell>end</cell><cell></cell><cell></cell></row><row><cell>20</cell><cell>if min(distList) &gt; θ then</cell><cell></cell><cell></cell></row><row><cell></cell><cell>newMismatchData.append(seqV ec);</cell><cell></cell><cell></cell></row><row><cell>22</cell><cell>end</cell><cell></cell><cell></cell></row><row><cell>23</cell><cell>end</cell><cell></cell><cell></cell></row><row><cell>24</cell><cell>misMatchData = newMismatchData;</cell><cell></cell><cell></cell></row><row><cell>25</cell><cell>дlobalPatList .extend(localPatList);</cell><cell></cell><cell></cell></row><row><cell>26</cell><cell>дlobalClusters.extend(localClusters);</cell><cell></cell><cell></cell></row><row><cell cols="2">27 end</cell><cell></cell><cell></cell></row><row><cell cols="2">28 Return дlobalClusters, дlobalPatList</cell><cell></cell><cell></cell></row></table><note>1 misMatchData = D;2 дlobalPatList = ∅; дlobalClusters = ∅;3 while mismatchData! = ∅ do4 SampleData = ∅;16 foreach seqV ec ∈ misMatchData do foreach pat ∈ localPatList do distList .append(dist(seqV ec, pat));3.3.4 Cascading. After going through the above three processes (i.e., sampling, clustering, and matching), the majority of the data in a time interval can be grouped into clusters, while some sequence vectors may remain unmatched. Hence, we further process the3.3.5 Algorithm and Time Complexity Analysis. The pseudo code of Cascading Clustering is detailed in Algorithm 1. The algorithm takes sequence vectors in a time interval as input data, with sample rate and clustering distance threshold as hyper-parameters. After cascading clustering, the algorithm outputs all sequence vector clusters and a set of patterns. To initialize, we assign all sequence vectors D to the mismatched data. Besides, we define two global variables (lines 1-2) to store the clusters and patterns. Then, the sampled data is obtained with a sampling rate of p (lines 3-10). In lines 12 and 13, we perform the hierarchical agglomerative cluster- ing (HAC) on sampled data with threshold θ and extract the cluster patterns. In fact, other clustering methods (e.g., K-Means) are also applicable here. During the matching process (line 16-23), we use distList (line</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Summary of Service X Log Data</figDesc><table><row><cell>Data</cell><cell cols="2">Snapshot starts #Log Seq (Size) #Events #Types</cell></row><row><cell cols="3">Data 1 Sept 5th 10:50 359,843 (722MB)</cell></row><row><cell>Data 2</cell><cell>Oct 5th 04:30</cell><cell>472,399 (996MB)</cell></row><row><cell cols="3">Data 3 Nov 5th 18:50 184,751 (407MB)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of Problem Detection on Service X Data</figDesc><table><row><cell>Data</cell><cell></cell><cell>Data 1</cell><cell></cell><cell></cell><cell>Data 2</cell><cell></cell><cell></cell><cell>Data 3</cell><cell></cell></row><row><cell>Metrics</cell><cell cols="9">Precision Recall F1-measure Precision Recall F1-measure Precision Recall F1-measure</cell></row><row><cell>PCA</cell><cell>0.465</cell><cell>0.946</cell><cell>0.623</cell><cell>0.142</cell><cell>0.834</cell><cell>0.242</cell><cell>0.207</cell><cell>0.922</cell><cell>0.338</cell></row><row><cell>Invariants Mining</cell><cell>0.604</cell><cell></cell><cell>0.753</cell><cell>0.160</cell><cell>0.847</cell><cell>0.269</cell><cell>0.168</cell><cell>0.704</cell><cell>0.271</cell></row><row><cell>Log3C</cell><cell>0.900</cell><cell>0.920</cell><cell>0.910</cell><cell>0.897</cell><cell>0.826</cell><cell>0.860</cell><cell>0.834</cell><cell>0.903</cell><cell>0.868</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>NMI of Clustering on Service X Data</figDesc><table><row><cell></cell><cell>Size</cell><cell>10k</cell><cell>50k</cell><cell>100k</cell><cell>200k</cell></row><row><cell>Data 1</cell><cell cols="2">Log3C-SC 0.659</cell><cell>0.706</cell><cell cols="2">0.781 0.822</cell></row><row><cell></cell><cell>Log3C</cell><cell cols="2">0.720 0.740</cell><cell cols="2">0.798 0.834</cell></row><row><cell></cell><cell>Size</cell><cell>10k</cell><cell>50k</cell><cell>100k</cell><cell>200k</cell></row><row><cell>Data 2</cell><cell cols="2">Log3C-SC 0.610</cell><cell>0.549</cell><cell cols="2">0.600 0.650</cell></row><row><cell></cell><cell>Log3C</cell><cell cols="2">0.624 0.514</cell><cell cols="2">0.663 0.715</cell></row><row><cell></cell><cell>Size</cell><cell>10k</cell><cell>50k</cell><cell>100k</cell><cell>180k</cell></row><row><cell>Data 3</cell><cell cols="2">Log3C-SC 0.601</cell><cell>0.404</cell><cell cols="2">0.792 0.828</cell></row><row><cell></cell><cell>Log3C</cell><cell cols="4">0.680 0.453 0.837 0.910</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Time Performance (in Seconds) of Clustering</figDesc><table><row><cell></cell><cell>Size</cell><cell>10k</cell><cell>50k</cell><cell>100k</cell><cell>200k</cell></row><row><cell>Data 1</cell><cell cols="5">SC 127.6 2319.2 9662.3 38415.5</cell></row><row><cell></cell><cell>CC</cell><cell>1.0</cell><cell>4.3</cell><cell>9.2</cell><cell>20.7</cell></row><row><cell></cell><cell>Size</cell><cell>10k</cell><cell>50k</cell><cell>100k</cell><cell>200k</cell></row><row><cell>Data 2</cell><cell>SC</cell><cell cols="4">80.6 2469.1 8641.2 38614.0</cell></row><row><cell></cell><cell>CC</cell><cell>0.7</cell><cell>3.8</cell><cell>9.5</cell><cell>18.9</cell></row><row><cell></cell><cell>Size</cell><cell>10k</cell><cell>50k</cell><cell>100k</cell><cell>180k</cell></row><row><cell>Data 3</cell><cell>SC</cell><cell cols="4">81.5 2417.2 8761.2 33728.3</cell></row><row><cell></cell><cell>CC</cell><cell>0.8</cell><cell>4.0</cell><cell>8.8</cell><cell>18.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>NMIs of Cascading Clustering under Different Distance Thresholds θ .848 0.867 0.912 0.916 0.928 0.898 0.898 0.887 evaluate the clustering accuracy under different sample rates. As shown in the right sub-figure of</figDesc><table><row><cell>θ</cell><cell>0.10</cell><cell>0.15</cell><cell>0.20</cell><cell>0.25</cell><cell>0.30</cell><cell>0.35</cell><cell>0.40</cell><cell>0.45</cell></row><row><cell cols="2">NMI 0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>NMIs of Standard Clustering (SC) and Cascading Clustering (CC) on Synthetic Data</figDesc><table><row><cell>Size</cell><cell>20k</cell><cell></cell><cell>50k</cell><cell></cell><cell cols="2">100k</cell><cell></cell><cell>200k</cell><cell></cell><cell>300k</cell><cell></cell><cell>600k</cell></row><row><cell>#Clusters</cell><cell>SC</cell><cell>CC</cell><cell>SC</cell><cell>CC</cell><cell>SC</cell><cell>CC</cell><cell>SC</cell><cell>CC</cell><cell>SC</cell><cell>CC</cell><cell>SC</cell><cell>CC</cell></row><row><cell>20</cell><cell cols="10">0.958 0.947 0.885 0.918 0.837 0.850 0.786 0.791 0.758 0.774</cell><cell>-</cell><cell>0.725</cell></row><row><cell>50</cell><cell cols="10">0.971 0.961 0.937 0.960 0.906 0.916 0.864 0.883 0.837 0.854</cell><cell>-</cell><cell>0.811</cell></row><row><cell>100</cell><cell cols="10">0.976 0.995 0.956 0.979 0.927 0.939 0.903 0.911 0.889 0.892</cell><cell>-</cell><cell>0.859</cell></row><row><cell>200</cell><cell cols="10">0.988 0.990 0.973 0.973 0.955 0.953 0.929 0.937 0.914 0.925</cell><cell>-</cell><cell>0.896</cell></row><row><cell cols="6">with 50 clusters, while cascading clustering (sample rate is 1%) only</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">takes 10.3 seconds on the same dataset. Our cascading clustering is</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">more than 1000× faster than standard clustering.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We thank the principal architect Anthony Bloesch and the intern student Yanxia Xu from product teams for their valuable work. We also thank partners at Microsoft product teams for their collaboration and suggestions on the application of Log3C in practice.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparisons Between Data Clustering Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbas</forename><surname>Osama Abu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Arab Journal of Information Technology (IAJIT)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amazon</surname></persName>
		</author>
		<ptr target="https://aws.amazon.com/" />
	</analytic>
	<monogr>
		<title level="j">Amazon Web Service</title>
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">An introduction to multivariate statistical analysis</title>
		<editor>Theodore Wilbur Anderson, Theodore Wilbur Anderson, Theodore Wilbur Anderson, Theodore Wilbur Anderson, and Etats-Unis Mathématicien</editor>
		<imprint>
			<date type="published" when="1958" />
			<publisher>Wiley</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The bones of the system: a case study of logging and telemetry at microsoft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Titus</forename><surname>Barik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Deline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danyel</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Software Engineering Companion</title>
		<meeting>the 38th International Conference on Software Engineering Companion</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="92" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inferring models of concurrent systems from logs of their behavior with CSight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Beschastnikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuriy</forename><surname>Brun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Software Engineering</title>
		<meeting>the 36th International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="468" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">What logs should you look at when an application fails? insights from an industrial case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Cinque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Domenico</forename><surname>Cotroneo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaele</forename><surname>Della Corte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Pecchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">44th Annual IEEE/IFIP International Conference on. IEEE</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="690" to="695" />
		</imprint>
	</monogr>
	<note>Dependable Systems and Networks (DSN)</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ReBucket: a method for clustering duplicate crash reports based on call stack similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingnong</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Nobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Software Engineering</title>
		<meeting>the 34th International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1084" to="1093" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Finding failures by cluster analysis of execution profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Podgurski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Software engineering</title>
		<meeting>the 23rd international conference on Software engineering</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="339" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Software behavior and failure clustering: An empirical study of fault causality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Digiuseppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James A Jones</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Testing, Verification and Validation</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
	<note>2012 IEEE Fifth International Conference on</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Healing online service systems via mining historical issue repositories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Software Engineering (ASE), 2012 Proceedings of the 27th IEEE/ACM International Conference on. IEEE</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="318" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mining historical issue repositories to heal large-scale online service systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">44th Annual IEEE/IFIP International Conference on. IEEE</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="311" to="322" />
		</imprint>
	</monogr>
	<note>Dependable Systems and Networks (DSN)</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey of clustering algorithms for big data: Taxonomy and empirical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adil</forename><surname>Fahad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Najlaa</forename><surname>Alshatri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahir</forename><surname>Tari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdullah</forename><surname>Alamri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ibrahim</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebti</forename><surname>Zomaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelaziz</forename><surname>Foufou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on emerging topics in computing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="267" to="279" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Execution anomaly detection in distributed systems through unstructured log analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining, 2009. ICDM&apos;09. Ninth IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Where do developers log? an empirical study on logging practices in industry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenlu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the 36th International Conference on Software Engineering</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micheline</forename><surname>Kamber</surname></persName>
		</author>
		<title level="m">Data mining: concepts and techniques</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An evaluation study on log parsing and its use in log mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinjia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilin</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">46th Annual IEEE/IFIP International Conference on. IEEE</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="654" to="661" />
		</imprint>
	</monogr>
	<note>Dependable Systems and Networks (DSN)</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An Empirical Study of Speed and Communication in Globally Distributed Software Development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">D</forename><surname>Herbsleb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Audris</forename><surname>Mockus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Softw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eng</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2003.1205177</idno>
		<ptr target="https://doi.org/10.1109/TSE.2003.1205177" />
		<imprint>
			<date type="published" when="2003-06" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="481" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Data clustering: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anil K Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick J</forename><surname>Narasimha Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM computing surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="264" to="323" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Examining the stability of logging statements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhas</forename><surname>Kabinna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyi</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cor-Paul</forename><surname>Bezemer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Analysis, Evolution, and Reengineering (SANER)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="326" to="337" />
		</imprint>
	</monogr>
	<note>IEEE 23rd International Conference on</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Failure prediction in ibm bluegene/l event logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinglung</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramendra</forename><surname>Sahoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="583" to="588" />
		</imprint>
	</monogr>
	<note>Data Mining</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Log clustering based problem identification for online service systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingwei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuewei</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Software Engineering Companion</title>
		<meeting>the 38th International Conference on Software Engineering Companion</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="102" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Classification of software behaviors for failure detection: a discriminative pattern mining approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siau-Cheng</forename><surname>Khoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengnian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="557" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mining Invariants from Console Logs for System Problem Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conference</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A lightweight algorithm for message type extraction in system application logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adetokunbo</forename><surname>Makanju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><forename type="middle">E</forename><surname>Nur Zincir-Heywood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Milios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1921" to="1936" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Microsoft Azure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Microsoft</surname></persName>
		</author>
		<ptr target="https://azure.microsoft.com/en-us/" />
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Structured comparative analysis of systems logs to diagnose performance problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Nagaraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Killian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Neville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation. USENIX Association</title>
		<meeting>the 9th USENIX conference on Networked Systems Design and Implementation. USENIX Association</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="26" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Detection of early-stage enterprise infection by mining large-scale log data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alina</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">45th Annual IEEE/IFIP International Conference on. IEEE</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="45" to="56" />
		</imprint>
	</monogr>
	<note>Dependable Systems and Networks (DSN)</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automated derivation of application-specific error detectors using dynamic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Pattabiraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Giancinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Saggese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Dependable and Secure Computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="640" to="655" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Zbigniew Kalbarczyk, and Ravishankar Iyer</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Industry practices and event logging: Assessment of a critical software development process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Pecchia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Cinque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Carrozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Domenico</forename><surname>Cotroneo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE), 2015 IEEE/ACM 37th IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Term-weighting approaches in automatic text retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information processing &amp; management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Introduction to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international communication of association for computing machinery conference</title>
		<meeting>the international communication of association for computing machinery conference</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Assisting developers of big data analytics applications when deploying on hadoop clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyi</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bram</forename><surname>Hemmati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 International Conference on Software Engineering</title>
		<meeting>the 2013 International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="402" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Studying the relationship between logging characteristics and the code quality of platform software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyi</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meiyappan</forename><surname>Nagappan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">High-impact defects: a study of breakage and surprise defects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emad</forename><surname>Shihab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Audris</forename><surname>Mockus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Kamei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bram</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">E</forename><surname>Hassan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering</title>
		<meeting>the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="300" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Evaluation of Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stanford</surname></persName>
		</author>
		<ptr target="https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html" />
		<imprint>
			<date type="published" when="2008-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">LogSig: Generating system events from raw textual logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang-Shing</forename><surname>Perng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM international conference on information and knowledge management</title>
		<meeting>the 20th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A data clustering algorithm for mining patterns from event logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risto</forename><surname>Vaarandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPOM 2003). 3rd IEEE Workshop on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
	<note>IP Operations &amp; Management</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Complete linkage clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Complete-linkage_clustering" />
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Multivariate normal distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Multivariate_normal_distribution" />
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Sigmoid Function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Sigmoid_function" />
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Detecting large-scale system problems by mining console logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armando</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles</title>
		<meeting>the ACM SIGOPS 22nd symposium on Operating systems principles</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="117" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Exploring of clustering algorithm on class-imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhigang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 8th International Conference on Computer Science Education</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="89" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automated known problem diagnosis with event traces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Min</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="375" to="388" />
			<date type="published" when="2006" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Be Conservative: Enhancing Failure Diagnosis with Proactive Logging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soyeon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael Mihn-Jong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Savage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="293" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning to log: Helping developers make informed logging decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinjia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Michael R Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Software Engineering (ICSE), 2015 IEEE/ACM 37th IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="415" to="425" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
