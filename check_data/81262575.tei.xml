<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Workshop track -ICLR 2016 RESNET IN RESNET: GENERALIZING RESIDUAL ARCHITECTURES</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-03-25">25 Mar 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Targ</surname></persName>
							<email>sasha.targ@ucsf.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lyman</surname></persName>
						</author>
						<title level="a" type="main">Workshop track -ICLR 2016 RESNET IN RESNET: GENERALIZING RESIDUAL ARCHITECTURES</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-03-25">25 Mar 2016</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1603.08029v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Residual networks (ResNets) have recently achieved state-of-the-art on challenging computer vision tasks. We introduce Resnet in Resnet (RiR): a deep dualstream architecture that generalizes ResNets and standard CNNs and is easily implemented with no computational overhead. RiR consistently improves performance over ResNets, outperforms architectures with similar amounts of augmentation on CIFAR-10, and establishes a new state-of-the-art on CIFAR-100. * Equal contribution. Author ordering determined by coin flip.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Recently proposed residual networks (ResNets) get state-of-the-art performance on the ILSVRC classification task <ref type="bibr" target="#b1">(Deng et al., 2009)</ref> and allow training of extremely deep networks up to more than 1000 layers <ref type="bibr" target="#b5">(He et al., 2015b)</ref>. Similar to highway networks, residual networks make use of identity shortcut connections that enable flow of information across layers without attenuation that would be caused by multiple stacked non-linear transformations, resulting in improved optimization <ref type="bibr" target="#b14">(Srivastava et al., 2015)</ref>. In residual networks, shortcut connections are not gated and untransformed input is always transmitted. While the empirical performance of ResNets in <ref type="bibr" target="#b5">He et al. (2015b)</ref> is very impressive, current residual network architectures have several potential limitations: identity connections as implemented in the current ResNet leads to accumulation of a mix of levels of feature representations at each layer, even though in a deep network some features learned by earlier layers may no longer provide useful information in later layers <ref type="bibr" target="#b2">(Gers et al., 2000)</ref>.</p><p>A hypothesis of the ResNet architecture is that learning identity weights is difficult, but by the same argument, it is difficult to learn the additive inverse of identity weights needed to remove information from the representation at any given layer. The fixed size layer structure of the residual block modules also enforces that residuals must be learned by shallow subnetworks, despite evidence that deeper networks are more expressive <ref type="bibr" target="#b0">(Bianchini &amp; Scarselli, 2014)</ref>. We introduce a generalized residual architecture that combines residual networks and standard convolutional networks in parallel residual and non-residual streams. We show architectures using generalized residual blocks retain the optimization benefits of identity shortcut connections while improving expressivity and the ease of removing unneeded information. We then present a novel architecture, ResNet in ResNet (RiR), which incorporates these generalized residual blocks within the framework of a ResNet and demonstrate state-of-the-art performance of the RiR architecture on CIFAR-100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GENERALIZING RESIDUAL NETWORK ARCHITECTURES</head><p>The modular unit of the generalized residual network architecture is a generalized residual block consisting of parallel states for a residual stream, r, which contains identity shortcut connections and is similar to the structure of a residual block from the original ResNet with a single convolutional layer (parameters W l,r→r ), and a transient stream, t, which is a standard convolutional layer (W l,t→t ). Two additional sets of convolutional filters in each block (W l,r→t , W l,t→r ) also transfer information across streams.</p><formula xml:id="formula_0">r l+1 = σ(conv(r l , W l,r→r ) + conv(t l , W l,t→r ) + shortcut(r l )) (1) t l+1 = σ(conv(r l , W l,r→t ) + conv(t l , W l,t→r ))</formula><p>Same-stream and cross-stream activations are summed (along with the shortcut connection for the residual stream) before applying batch normalization and ReLU nonlinearities (together σ) to get the output states of the block (Equation 1) <ref type="bibr" target="#b7">(Ioffe &amp; Szegedy, 2015)</ref>. The function of the residual stream r resembles that of the original structure of the ResNet <ref type="bibr" target="#b5">(He et al., 2015b)</ref> with shortcut connections between each unit of processing, while the transient stream t adds the ability to process information from either stream in a nonlinear manner without shortcut connections, allowing information from earlier states to be discarded. The form of the shortcut connection can be an identity function with the appropriate padding or a projection as in <ref type="bibr" target="#b5">He et al. (2015b)</ref>. We implement the generalized residual block as a single convolutional layer with a modified initialization, which we call ResNet Init (see Appendix 6.1 for detail). The generalized residual block can act as either a standard CNN layer (by learning to zero the residual stream) or a single-layer ResNet block (by learning to zero the transient stream). By repeating the generalized residual block several times, the generalized residual architecture has the expressivity to learn anything in between, including the standard 2-layer ResNet block ( <ref type="figure" target="#fig_0">Figure 1c</ref>). This architecture allows the network to learn residuals with a variable effective number of processing steps before addition back into the residual stream, which we investigate by visualizations. The generalized residual block is not specific to CNNs, and can be applied to standard fully connected layers and other feedforward layers. Replacing each of the convolutional layers within a residual block from the original ResNet ( <ref type="figure" target="#fig_0">Figure 1a</ref>) with a generalized residual block ( <ref type="figure" target="#fig_0">Figure 1b</ref>) leads us to a new architecture we call ResNet in ResNet (RiR) ( <ref type="figure" target="#fig_0">Figure 1d</ref>). In <ref type="figure" target="#fig_1">Figure 2</ref>, we summarize the relationship between standard CNN, ResNet Init, ResNet, and RiR architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>We evaluate our architectures on CIFAR-10 and CIFAR-100 datasets <ref type="bibr" target="#b10">(Krizhevsky &amp; Hinton, 2009)</ref> and report the best results found after a grid search on hyperparameters including learning rate, L2 penalty, initialization among Xavier <ref type="bibr" target="#b3">(Glorot &amp; Bengio, 2010)</ref>, MSR <ref type="bibr" target="#b4">(He et al., 2015a)</ref>, and orthogonal (Saxe et al., 2013), optimizer among SGD with momentum, SGD with Nesterov momentum <ref type="bibr" target="#b15">(Sutskever et al., 2013)</ref>, Adam <ref type="bibr" target="#b9">(Kingma &amp; Ba, 2014)</ref>, and RMSProp <ref type="bibr" target="#b16">(Tieleman &amp; Hinton, 2012)</ref>, and the type of shortcut connections in the residual blocks. We optimize the hyperparameters for the original ResNet architecture and use SGD with momentum of 0.9, a minibatch size of 500, L2 penalty of 0.0001, and train for 82 epochs. The learning rate was scaled by 0.1 after epochs 42 and and MSR initialization was used for all weight tensors. Test time batch normalization statistics were approximated using an exponential moving average of training batch normalization statistics. A projection with a 3x3 convolution was used for residual blocks that increase dimensionality, and all other shortcut connections were identity. We use equal numbers of filters for the residual and transient streams of the generalized residual network, but optimizing this hyperparameter could lead to further potential improvements.  In our experiments, the ResNet Init architecture shows consistent improvement over standard CNN architectures, and the RiR architecture outperforms the original ResNet <ref type="table" target="#tab_2">(Table 3)</ref>. We find the RiR architecture performs well across a range of numbers of blocks and layers in each block and that ResNet Init applied to existing architectures, such as ALL-CNN-C (Springenberg et al., 2014), yields improvement over standard initialization <ref type="table" target="#tab_3">(Tables 4, 5</ref>). Because each stream uses only half the total filters, we investigate the effect of our architectures on a wider 18-layer network <ref type="table" target="#tab_0">(Tables 1,  2</ref>). We find this RiR architecture is remarkably effective, obtaining competitive results on CIFAR-10 with only standard augmentation by random crops and horizontal flips, and state-of-the-art results on CIFAR-100. We visualize the effect of zeroing learned connections of each stream in a trained ResNet Init model a single layer at a time, which shows both streams contribute to accuracy and relative use of residual and transient streams changes at different stages of processing <ref type="figure">(Figure 3)</ref>. In <ref type="figure">Figure 4</ref>, we show performance of the RiR architecture is robust to increasing depth of residual blocks and the RiR architecture allows training of deeper residuals compared to the original ResNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>Interacting transformation streams in which only one stream includes shortcut connections are also used in blocks of LSTM and Grid-LSTM networks <ref type="bibr" target="#b6">(Hochreiter &amp; Schmidhuber, 1997;</ref><ref type="bibr" target="#b8">Kalchbrenner et al., 2015)</ref>. However, in contrast to highway networks which control flow through shortcut connections via input-dependent carry and transform gates, and to memory and hidden states of LSTM and Grid-LSTM blocks, flow of information between the residual and transient states of the generalized residual block does not use gates and can thus be implemented with no additional parameters over a standard feedforward network <ref type="bibr" target="#b14">(Srivastava et al., 2015)</ref>. Another difference between previous architectures and the generalized residual block we present is that while memory (m) and hidden (h) states in an LSTM or Grid-LSTM block are calculated sequentially (with h l = o l tanh(m l )), transformation of residual and memory streams of the generalized residual block occurs in parallel and depends only on the learned convolutional filters at each layer without further constraints on their relation. The SCRN architecture of <ref type="bibr" target="#b11">Mikolov et al. (2014)</ref> also uses hidden and context units together within a single layer to learn longer term information, which behave similarly to the transient and residual streams, but SCRN only allows unidirectional flow from context to hidden units and connections between context units are fixed, in contrast to bidirectional flow between streams and learned connections for both transient and residual streams in our generalized residual architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We present a generalized residual architecture which be simply implemented by a modified initialization scheme, ResNet Init, and apply it to the original ResNet to create a novel RiR architecture which achieves state-of-the-art results. Future work includes additional study of RiR and related residual models to further determine the cause of their beneficial effects.    We implement the generalized residual block with a modified initialization of a standard convolutional or fully connected (FC) layer that combines the identity shortcut with the desired linear transformation (convolution or matrix multiplication), which we call ResNet Init, and concatenating tensors for the residual r and transient t streams to form a single tensor x. Because the identity shortcut and the results of the same-stream and cross-stream transformations are summed to give the output for each stream, linear operations on r and t can be composed into a single linear operation on x (see Equation 2 for an example of ResNet Init applied to an FC layer).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">APPENDIX</head><formula xml:id="formula_1">x l+l = σ(W l x l ) ⇔ r l+1 t l+1 = σ(( W l,r→r W l,t→r W l,r→t W l,t→t + I 0 0 0 ) × r l t l )<label>(2)</label></formula><p>To implement ResNet Init in a single FC layer, we concatenate weight matrices initialized by any existing scheme and then add a partial identity matrix (with 1s only on the first half of the diagonal) to the concatenated weight matrix.   as a standard layer with modified initialization (W l ) is exactly equivalent to the output if it were implemented as separate linear operations (W l,r→r , W l,t→r , W l,r→t , W l,t→t , and I).</p><p>The generalized residual block implemented using modified initialization will perform differently from one implemented as separate linear operations when weight regularization that pulls all weights towards zero is present, such as L2 regularization. To maintain equivalence of implementation, we subtract the partial identity from the weights prior to application of weight decay.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) 2-layer ResNet block. (b) 2 generalized residual blocks (ResNet Init). (c) 2-layer ResNet block from 2 generalized residual blocks (grayed out connections are 0). (d) 2-layer RiR block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Relationship between standard CNN, ResNet, ResNet Init, and RiR architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Effect of ablating each stream of the generalized residual network architecture ResNet and RiR with increased layers/block. All models have 15 blocks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of our architecture with state-of-the-art architectures on CIFAR-10.</figDesc><table><row><cell>Model</cell><cell>Accuracy (%)</cell></row><row><cell>Highway Network</cell><cell>92.40</cell></row><row><cell>ResNet (32 layers)</cell><cell>92.49</cell></row><row><cell>ResNet (110 layers)</cell><cell>93.57</cell></row><row><cell>Large ALL-CNN</cell><cell>95.59</cell></row><row><cell>Fractional Max-Pooling</cell><cell>96.53</cell></row><row><cell>18-layer + wide CNN</cell><cell>93.64</cell></row><row><cell>18-layer + wide ResNet</cell><cell>93.95</cell></row><row><cell cols="2">18-layer + wide ResNet Init 94.28</cell></row><row><cell>18-layer + wide RiR</cell><cell>94.99</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison of our architecture with state-of-the-art architectures on CIFAR-100.</figDesc><table><row><cell>Model</cell><cell>Accuracy (%)</cell></row><row><cell>Highway Network</cell><cell>67.76</cell></row><row><cell>ELU-Network</cell><cell>75.72</cell></row><row><cell>18-layer + wide CNN</cell><cell>75.17</cell></row><row><cell>18-layer + wide ResNet</cell><cell>76.58</cell></row><row><cell cols="2">18-layer + wide ResNet Init 75.99</cell></row><row><cell>18-layer + wide RiR</cell><cell>77.10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Test set accuracy of baseline 32-layer CNN<ref type="bibr" target="#b5">(He et al., 2015b)</ref> on CIFAR-10.</figDesc><table><row><cell>Model</cell><cell>Accuracy (%)</cell></row><row><cell cols="2">ResNet (He et al., 2015b) 92.49</cell></row><row><cell>CNN</cell><cell>89.03</cell></row><row><cell>ResNet</cell><cell>92.32</cell></row><row><cell>ResNet Init</cell><cell>89.62</cell></row><row><cell>RiR</cell><cell>92.97</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="2">: Performance of ALL-CNN-C from</cell></row><row><cell cols="2">Springenberg et al. (2014) with batch normaliza-</cell></row><row><cell cols="2">tion (Ioffe &amp; Szegedy, 2015). The original model</cell></row><row><cell cols="2">without batch normalization had 90.92% accu-</cell></row><row><cell>racy.</cell><cell></cell></row><row><cell>Model</cell><cell>Accuracy (%)</cell></row><row><cell cols="2">Standard initialization 93.22</cell></row><row><cell>ResNet Init</cell><cell>93.42</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>To implement ResNet Init in a single convolutional layer, we first concatenate convolutional kernels along the input dimension (W l,x→r = W l,r→r + W l,t→r and W l,x→t = W l,r→t + W l,t→t ) and the filter dimension (W l,x→x = W l,x→r + W l,x→t ), and then similarly add half of an identity kernel. The output of the generalized residual block implemented</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Accuracy of RiR with different numbers of blocks and layers per block on CIFAR-10.</figDesc><table><row><cell cols="3">Blocks Layers/Block Accuracy (%)</cell></row><row><cell>15</cell><cell>2</cell><cell>92.87</cell></row><row><cell>3</cell><cell>10</cell><cell>90.06</cell></row><row><cell>6</cell><cell>5</cell><cell>92.98</cell></row><row><cell>15</cell><cell>5</cell><cell>92.11</cell></row><row><cell>9</cell><cell>3</cell><cell>93.23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Accuracy of RiR and ResNet with different numbers of layers per block on CIFAR-10.</figDesc><table><row><cell cols="3">Layers/Block ResNet (%) RiR (%)</cell></row><row><cell>2</cell><cell>92.32</cell><cell>92.97</cell></row><row><cell>4</cell><cell>92.48</cell><cell>93.43</cell></row><row><cell>6</cell><cell>92.61</cell><cell>93.42</cell></row><row><cell>8</cell><cell>88.47</cell><cell>92.38</cell></row><row><cell>10</cell><cell>10.00</cell><cell>92.01</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the complexity of neural network classifiers: A comparison between shallow and deep architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Bianchini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1553" to="1565" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to forget: Continual prediction with lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Felix A Gers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2451" to="2471" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Grid long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.01526</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc'aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.7753</idno>
		<title level="m">Learning longer memory in recurrent neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">L</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ganguli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6120</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Striving for simplicity: The all convolutional net. CoRR, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6806" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6806</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Training very deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rupesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2368" to="2376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th international conference on machine learning (ICML-13)</title>
		<meeting>the 30th international conference on machine learning (ICML-13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Lecture 6.5-rmsprop. COURSERA: Neural networks for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">When not otherwise specified, convolutions are performed with stride 1. Baseline 32-layer CNN architecture (He et al., 2015b) 3x3 conv., 16 filters, BN, ReLU Residual block: 2x 3x3 conv., 16 filters, BN, ReLU Residual block: 2x 3x3 conv., 16 filters, BN, ReLU Residual block: 2x 3x3 conv., 16 filters, BN, ReLU Residual block: 2x 3x3 conv., 16 filters, BN, ReLU Residual block: 2x 3x3 conv., 16 filters, BN, ReLU Residual block: 2x 3x3 conv. (first with stride 2), 32 filters, BN, ReLU Residual block: 2x 3x3 conv., 32 filters, BN, ReLU Residual block: 2x 3x3 conv., 32 filters, BN, ReLU Residual block: 2x 3x3 conv., 32 filters, BN, ReLU Residual block: 2x 3x3 conv., 32 filters, BN, ReLU Residual block: 2x 3x3 conv. (first with stride 2), 64 filters, BN</title>
	</analytic>
	<monogr>
		<title level="m">Table 7: Description of network architectures used in experiments comparing performance of standard CNN, ResNet, ResNet Init, and RiR models. In standard CNN and ResNet Init models, identity connections of the residual blocks listed below are set to 0. For CIFAR-10 models, the output layer has 10 units and for CIFAR-100 models, the output layer has 100 units</title>
		<meeting><address><addrLine>BN, ReLU Residual block</addrLine></address></meeting>
		<imprint>
			<biblScope unit="volume">192</biblScope>
		</imprint>
	</monogr>
	<note>ResNet Init) / 0.49M (ResNet and RiR) 18-layer and wide CNN architecture 3x3 conv., 96 filters, BN, ReLU Residual block: 2x 3x3 conv., 96 filters, BN, ReLU Residual block: 2x 3x3 conv., 96 filters, BN, ReLU Residual block: 2x 3x3 conv. (first with stride 2). 2x 3x3 conv., 192 filters, BN, ReLU Residual block: 2x 3x3 conv., 192 filters, BN, ReLU Residual block: 2x 3x3 conv. (first with stride 2), 384 filters, BN, ReLU Residual block: 2x 3x3 conv., 384 filters, BN, ReLU Residual block: 2x 3x3 conv., 384 filters, BN, ReLU 1x1 conv., 10 or 100 filters Global mean pool Softmax Total number of parameters: 9.5M (CNN and ResNet Init) / 10.3M (ResNet and RiR</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
