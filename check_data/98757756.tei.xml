<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data Shapley: Equitable Valuation of Data for Machine Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirata</forename><surname>Ghorbani</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Zou</surname></persName>
							<email>&lt;jamesz@stanford.edu&gt;.</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Biomedical Data Science</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data Shapley: Equitable Valuation of Data for Machine Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>As data becomes the fuel driving technological and economic growth, a fundamental challenge is how to quantify the value of data in algorithmic predictions and decisions. For example, in healthcare and consumer markets, it has been suggested that individuals should be compensated for the data that they generate, but it is not clear what is an equitable valuation for individual data. In this work, we develop a principled framework to address data valuation in the context of supervised machine learning. Given a learning algorithm trained on n data points to produce a predictor, we propose data Shapley as a metric to quantify the value of each training datum to the predictor performance. Data Shapley uniquely satisfies several natural properties of equitable data valuation. We develop Monte Carlo and gradient-based methods to efficiently estimate data Shapley values in practical settings where complex learning algorithms, including neural networks, are trained on large datasets. In addition to being equitable, extensive experiments across biomedical, image and synthetic data demonstrate that data Shapley has several other benefits: 1) it is more powerful than the popular leave-one-out or leverage score in providing insight on what data is more valuable for a given learning task; 2) low Shapley value data effectively capture outliers and corruptions; 3) high Shapley value data inform what type of new data to acquire to improve the predictor.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Data is valuable and it is the fuel that powers artificial intelligence. Increasingly in sectors such as health care and advertising, data generated by individuals is a key compo-nent of the market place, similar to labor and capital <ref type="bibr" target="#b27">(Posner &amp; Weyl, 2018)</ref>. It has been suggested that certain data constitute individual property, and as such individuals should be compensated in exchange for these data <ref type="bibr" target="#b28">(Regulation, 2018)</ref>. Like labor and capital, a fundamental question is how to equitably value individual's data.</p><p>We focus on data valuation in the specific setting of supervised machine learning. In order to make sense of data value, we need three ingredients in our investigation: a fixed training data set, a learning algorithm, and a performance metric. The training data is a fixed set of n data points, {x i , y i } n 1 , where x i and y i are the features and the label of point i, respectively. For our purpose, a learning algorithm A is a procedure that takes an arbitrary training set and produces a predictor. For example, A could be the common empirical risk minimization where it solves θ * = arg min θ l(f (x i ; θ), y i ), where l is the loss, θ parametrizes a family of models and f ( ; θ * ) is the predictor. For any predictor f , we also need a performance metric of V (f ). We can think of V as the test performance of f on whatever metric of interest.</p><p>The two questions that we want to investigate are: 1) what is an equitable measure of the value of each (x i , y i ) to the learning algorithm A with respect to the performance metric V ; and 2) how do we efficiently compute this data value in practical settings. For example, suppose we have data from N = 1000 patients and we train a small neural network to build a heart disease classifier. We also have some independent metric to assess the performance of the trained classifier-e.g. its prediction accuracy on a test set. Then we would like to quantify the value of each patient's data to the classifier's performance on this task.</p><p>Note that we do not define a universal value for data. Instead, the value of each datum depend on the learning algorithm, the performance metric as well as on other data in the training set. This dependency is reasonable and desirable in machine learning. Certain data points could be more important if we are training a logistic regression instead of a neural network. Similarly, if the performance metric changes-e.g. regressing to the age of heart disease onset instead of heart disease incidence-then the value of certain patient's data should change. Moreover the performance metric could be computed on a different population/distribution than the training data; we make no assumptions about how it is done.</p><p>A common method to evaluate data importance is some form of leave-one-out (LOO) test: compare the difference in the predictor's performance when trained on the full dataset vs. the performance when trained on the full set minus one point <ref type="bibr" target="#b7">(Cook, 1977)</ref>. The drop in performance in one measure of the "value" of that point. LOO is often approximated by leverage or influence score, which measures how the predictor changes when the weight of one point changes slightly <ref type="bibr" target="#b8">(Cook &amp; Weisberg, 1982)</ref>. We will show below that leave-one-out does not satisfy natural properties we expect for equitable data valuation, and it performs poorly in experiments. For a simple intuition of why leave-one-out fails, suppose our predictor is a nearest-neighbor classifieri.e. for each test point we find its nearest neighbor in the training set and assign it that label. Moreover suppose every training point has two exact copies in the training set. Removing one point from training does not change the predictor at all, since its copy is still present. Therefore the leave-one-out approach would assign every training point zero value, regardless of how well the actual predictor performs. This simple example illustrates that leave-one-out does not capture potentially complex interactions between subsets of data. Our proposed data Shapley value provides more meaningful valuation by precisely accounting for such interactions.</p><p>Our contributions We provide a natural formulation of the important problem of equitable data valuation in machine learning. We propose data Shapley value, leveraging powerful results from game theory, to quantify the the contribution of individual data points to a learning task. Data Shapley uniquely satisfies three natural properties of equitable valuation. Moreover, our empirical studies demonstrate that data Shapley has several additional utilities: 1) it gives more insights into the importance of each data point than the common leave-one-out score; 2) it can identify outliers and corrupted data; 3) it can inform how to acquire future data to improve the predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Equitable Data Valuation for ML</head><formula xml:id="formula_0">Preliminaries Let D = {(x i , y i )} n</formula><p>1 be our fixed training set. We do not make any distributional assumptions about D and the data need not be independent. The y i 's can be categorical or real for classification and regression, respectively. Let A denote the learning algorithm. We view A as a black-box that takes as input a training data set of size between 0 and ∞, and returns a predictor. We are particularly interested in the predictor trained on subsets S ⊆ D. The performance score V is another black-box oracle that takes as input any predictor and returns a score. We write V (S, A), or just V (S) for short, to denote the performance score of the predictor trained on data S. Our goal is to compute a data value φ i (D, A, V ) ∈ R, as a function of D, A and V , to quantify the value of the i-th datum. We will often write it as φ i (V ) or just φ i to simplify notation. For convenience, we will sometimes overload the notation for S and D so that it can also indicate the set of indices-i.e. i ∈ S if (x i , y i ) is in that subset and D = {1, ..., n}.</p><p>Example Suppose y i 's are binary and A corresponds to a logistic regression learner-i.e. A takes any dataset and returns a logistic regression fitted to it. The score V here could be the 0/1 accuracy on a separate test set. Then V (S) is the 0/1 test accuracy when the logistic regression is trained on a subset S ⊆ D. If S = ∅, then V (S) is the performance of a randomly initialized classifier. In general, the test data used to compute V could be from a different distribution than that of D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Equitable properties of data valuation</head><p>We believe that φ should satisfy the following properties in order to be equitable: </p><formula xml:id="formula_1">1. If (x i , y i ) does</formula><formula xml:id="formula_2">S ⊆ D − {i}, V (S) = V (S ∪ {i}), then φ i = 0.</formula><p>2. If for data i and j and any subset S</p><formula xml:id="formula_3">⊆ D − {i, j}, we have V (S ∪ {i}) = V (S ∪ {j}), then φ i = φ j .</formula><p>In other words, if i and j, when added to any subset of our training data, always produce exactly the same change in the predictor's score, then i and j should be given the same value by symmetry.</p><p>3. In most ML settings, V = − k∈test set l k where l k is the loss of the predictor on the k-th test point (we took a minus so that lower loss is higher score). We can define V k = −l k to be the predictor's performance on the k-th test point. Similarly φ i (V k ) quantifies the value of the i-th training point to the k-th test point.</p><formula xml:id="formula_4">If datum i contributes values φ i (V 1 ) and φ i (V 2 )</formula><p>to the predictions of test points 1 and 2, respectively, then we expect the value of i in predicting both test pointsi.e. when</p><formula xml:id="formula_5">V = V 1 + V 2 -to be φ i (V 1 ) + φ i (V 2 ).</formula><p>In words: when the overall prediction score is the sum of K separate predictions, the value of a datum should be the sum of its value for each prediction. Formally:</p><formula xml:id="formula_6">φ i (V + W ) = φ i (V ) + φ i (W ) for performance scores V and W .</formula><p>While there are other desirable properties of data valuation worth discussing, these three properties listed above actually pin down the form of φ i up to a proportionality constant.</p><p>Proposition 2.1. Any data valuation φ(D, A, V ) that satisfies properties 1-3 above must have the form</p><formula xml:id="formula_7">φ i = C S⊆D−{i} V (S ∪ {i}) − V (S) n−1 |S| (1)</formula><p>where the sum is over all subsets of D not containing i and C is an arbitrary constant. We call φ i the data Shapley value of point i.</p><p>Proof. The expression of φ i in Eqn. 1 is the same as the Shapley value defined in game theory, up to the constant C <ref type="bibr" target="#b30">(Shapley, 1953;</ref><ref type="bibr" target="#b31">Shapley et al., 1988</ref>). This motivates calling φ i the data Shapley value. The proof also follows directly from the uniqueness of the game theoretic Shapley value, by reducing our problem to a cooperative game <ref type="bibr" target="#b10">(Dubey, 1975)</ref>. In cooperative game theory, there are n players and there is a score function v :</p><formula xml:id="formula_8">2 [n] → R. Basically v(S)</formula><p>is the reward if the players in subset S work together. Shapley proposed a way to divide the score among the n players so that each player receives his/her fair payment, where fairness is codified by properties that are mathematically equivalent to the three properties that we listed. We can view data valuation as a cooperative game: each training datum is a player, and the training data work together through the learner A to achieve prediction score v = V . The data Shapley value is analogous to the payment that each player receives.</p><p>The choice of C is an arbitrary scaling and does not affect any of our experiments and analysis.</p><p>Interpretation of data Shapley Eqn. 1 could be interpreted as a weighted sum of all possible "marginal contributions" of i; where the weight is inverse the number of subsets of size |S| in D − {i}. This formulation is close to that of leave-one-out where instead of considering the last marginal contribution</p><formula xml:id="formula_9">V (D) − V (D − {i})</formula><p>, we consider each point's marginal contribution assuming that instead of the whole training set, a random subset of it is given. In other words, we can assume the scenario where instead of the train data, we were given a random subset of it; Shapley formula outputs an equitable value by capturing all these possible subset scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approximating Data Shapley</head><p>As discussed in the previous section, the Shapley formula in Eqn. 1 uniquely provides an equitable assignment of values to data points. Computing data Shapley, however, requires computing all the possible marginal contributions which is exponentially large in the train data size. In addition, for each S ⊆ D, computing V (S) involves learning a predictor on S using the learning algorithm A. As a consequence, calculating the exact Shapley value is not tractable for real world data sets. In this section, we discuss approximation methods to estimate the data Shapley value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Approximating Shapley Value</head><p>As mentioned, computing the Shapley value has exponential complexity in number of data points n. Here, we discuss two methods for circumventing this problem:</p><p>Monte-Carlo method: We can rewrite Eqn. into an equivalent formulation by setting C = 1/n!. Let Π be the uniform distribution over all n! permutations of data points, we have:</p><formula xml:id="formula_10">φ i = E π∼Π [V (S i π ∪ {i}) − V (S i π )]<label>(2)</label></formula><p>where S i π is the set of data points coming before datum i in permutation π (S i π = ∅ if i is the first element). As described in Eqn. 2, calculating the Shapley value can be represented as an expectation calculation problem. Therefore, Monte-Carlo method have been developed and analyzed to estimate the Shapley value <ref type="bibr" target="#b23">(Mann &amp; Shapley, 1962;</ref><ref type="bibr" target="#b4">Castro et al., 2009b;</ref><ref type="bibr" target="#b22">Maleki et al., 2013)</ref>. First, we sample a random permutations of data points. Then, we scan the permutation from the first element to the last element and calculate the marginal contribution of every new data point. Repeating the same procedure over multiple Monte Carlo permutations, the final estimation of the data Shapley is simply the average of all the calculated marginal contributions. This Monte Carlo sampling gives an unbiased estimate of the data Shapley. In practice, we generate Monte Carlo estimates until the average has empirically converged. Previous work has analyzed error bounds of Monte-carlo approximation of Shapley value <ref type="bibr" target="#b22">(Maleki et al., 2013)</ref>. Truncation: In the machine learning setting, V (S) for S ⊆ N is usually the predictive performance of the model learned using S on a separate test set. Because the test set is finite, V (S) is itself an approximation to the true performance of the trained model on the test distribution, which we do not know. In practice, it is sufficient to estimate the data Shapley value up to the intrinsic noise in V (S), which can be quantified by measuring variation in the performance of the same predictor across bootstrap samples of the test set <ref type="bibr" target="#b13">(Friedman et al., 2001</ref>). On the other hand, as the size of S increases, the change in performance by adding only one more training point becomes smaller and smaller <ref type="bibr" target="#b21">(Mahajan et al., 2018;</ref><ref type="bibr" target="#b2">Beleites et al., 2013)</ref>. Combining these two observations lead to a natural truncation approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Truncated Monte Carlo Shapley</head><p>Input: Train data D = {1, . . . , n}, learning algorithm A, performance score V Output: Shapley value of training points: φ 1 , . . . , φ n Initialize φ i = 0 for i = 1, . . . , n and t = 0 while Convergence criteria not met do</p><formula xml:id="formula_11">t ← t + 1 π t : Random permutation of train data points v t 0 ← V (∅, A) for j ∈ {1, . . . , n} do if |V (D) − v t j−1 | &lt; Performance Tolerance then v t j = v t j−1 else v t j ← V ({π t [1], . . . , π t [j]}, A) end if φ π t [j] ← t−1 t φ π t−1 [j] + 1 t (v t j − v t j−1 ) end for end for</formula><p>We can define a "performance tolerance" based on the bootstrap variation in V . As we scan through a sampled permutation and calculate marginal contributions, we truncate the calculation of marginal contributions in a sampled permutation whenever V (S) is within the performance tolerance of V (D) and set the marginal contribution to be zero for the rest of data points in this permutation. Appendix B shows that truncation leads to substantial computational savings without introducing significant estimation bias. In the rest of the paper, we refer to the combination of truncation with Monte-Carlo as the "Trunctated Monte Carlo Shapley"(TMC-Shapley); described with more details in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Approximating Performance Metric V</head><p>For every S ⊆ D, calculating V (S) requires A to learn a new model. For a small D and a fast A-e.g. logistic regression, LASSO-it is possible to use the TMC-Shapley method as stated. However, in settings where the number of data points is large or the predictive model requires high computational power (e.g. deep neural networks), applying TMC-Shapley can be quite expensive. We propose two strategies to further reduce the computational cost of data Shapley for large data settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gradient Shapley</head><p>For a wide family of predictive models, A involves a variation of stochastic gradient descent where randomly selected batches of D update the model parameters iteratively. One simple approximation of a completely trained model in these settings is to consider training the model with only one pass through the training data; in other words, we train the model for one "epoch" of D. This Initialize φ i = 0 for i = 1, . . . , n and t = 0 while Convergence criteria not met do</p><formula xml:id="formula_12">t ← t + 1 π t : Random permutation of train data points θ t 0 ← Random parameters v t 0 ← V (θ t 0 ) for j ∈ {1, . . . , n} do θ t j ← θ t j−1 − α∇ θ L (π t [j]; θ j−1 ) v t j ← V (θ t j ) φ π t [j] ← t−1 t φ π t−1 [j] + 1 t (v t j − v t j−1 ) end for end for</formula><p>approximation fits nicely within the framework of Algorithm 1: for a sampled permutation of data points, update the model by performing gradient descent on one data point at a time; the marginal contribution is the change in model's performance. Details are described in Algorithm 2, which we call Gradient Shapley or G-Shapley for short. In order to have the best approximation, we perform hyper-parameter search for the learning algorithm to find the one resulting best performance for a model trained on only one pass of the data which, in our experiments, result in learning rates bigger than ones used for multi-epoch model training. Appendix D discusses numerical examples of how good of an approximation G-Shapley method yields in this work's experimental results.</p><p>Value of groups of data points In many settings, in order to have more robust interpretations or because the training set is very large, we prefer to compute the data Shapley for groups of data points rather than for individual data. For example, in a heart disease prediction setting, we could group the patients into discrete bins based on age, gender, ethnicity and other features, and then quantify the data Shapley of each bin. In these settings, we can calculate the Shapley value of a group using the same procedure as Algorithm 1, replacing the data point i by group i. As a consequence, even for a very large data set, we can calculate the group Shapley value if the number of groups is reasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments &amp; Applications</head><p>In this section, we demonstrate the estimation and applications of data Shapley across systematic experiments on real and synthetic data. We show that points with high Shapley value are critical for model's performance and vice versa. We then discuss the effect of acquiring new data points similar to highly valued training points compared to acquiring new data randomly. Moreover we conduct two experiments showing that data points that are noisy or have label corruption will be assigned low Shapley value. Lastly we demonstrate that Shapley values can also give informative scores for groups of individuals. Taken together, these experiments suggest that, in addition to its equitable properties, data Shapley provides meaningful values to quantify the importance of data and can inform downstream analysis. Given that leverage and influence scores seek to approximate leave-one-out score , throughout the experiments, we focus on comparing the performance of the Shapley methods to that of the leave-one-out (LOO) method. LOO is computed as the difference in the model performance V between the model trained on the full dataset with and without the point of interest.</p><p>In all of the following experiments, we have a train set, a separate test set used for calculating V , and a held-out set used for reporting the final results of each figure. Our convergence criteria for TMC-Shapley and G-Shapley is n n i=1</p><formula xml:id="formula_13">|φ t i −φ t−100 i | |φ t i |</formula><p>&lt; 0.05. For all the experiments, calculating data Shapley values took less than 24 hours on four machines running in parallel (each with 4 cpus) except for one of the experiments where the model is a Conv-Net for which 4 GPUs were utilized in parallel for 120 hours. It should be mentioned that both data Shapley algorithms are parallelizable up to the number of iterations and therefore, the computations can become faster using more machines in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Shapley for Disease Prediction</head><p>In this experiment, we use the UK Biobank data set <ref type="bibr" target="#b34">(Sudlow et al., 2015)</ref>; the task is predicting whether an individual will be diagnosed with Malignant neoplasm of breast and skin (ICD10 codes C50 and C44, binary classification) using 285 features. Balanced binary data sets for each task are created and we use 1000 individuals for the task of training. Logistic regression yields a test accuracy of 68.7% and 56.4% for breast and skin cancer prediction, respectively. Performance is computed as the accuracy of trained model on 1000 separate patients. The varying accuracies for the two tasks allow us to investigate data Shapley for classifiers that are more or less accurate. We first compute the TMC-Shapley, G-Shapley, and leave-one-out values. The TMC-Shapley converges in 4000 Monte Carlo iterations for both tasks while G-Shapley is already converged at iteration 1500. Appendix A shows examples of convergence for randomly selected data points in the train sets.</p><p>Importance of valuable datum After calculating data values, we remove data points from the training set starting from the most valuable datum to the least valuable and train a new model each time. <ref type="figure" target="#fig_2">Fig. 1(a)</ref> shows the change in the performance as valuable data points are thrown away; points that data Shapley considers valuable are crucially important for the model performance while leave-one-out valuation is only slightly better than random valuation (i.e. removing random points). <ref type="figure" target="#fig_2">Fig. 1(b)</ref> depicts the results for the opposite setting; we remove data points starting from the least valuable. Interestingly points with low Shapley value in these training set actually harm the model's performance and removing them will improve accuracy.</p><p>Acquiring new data Looking at which type of train data have high Shapley value and inform us how to collect new data-by recruiting similar individuals-in order to improve the model performance. Let's consider the following practical scenario: we want to add a number of new patients to the training data to improve our model. Adding an individual carries a cost, so we have to choose among a pool of candidates. We run two experiments: first we try to add points that are similar to high value training points and then we repeat the same experiment by adding low value points. To this end, we fit a Random Forest regression model to the calculated data Shapley values. The regression model learns to predict a data point's value given its observables. Using the trained regression model, we estimate the value of patients in the patient pool. <ref type="figure" target="#fig_2">Fig. 1(c)</ref> depicts how the model performance changes as we add patients with high estimated value to our training set; the model's performance increases more effectively than adding new patients randomly. Considering the opposite case, <ref type="figure" target="#fig_2">Fig. 1(d)</ref> shows that by choosing the wrong patients to add, we can actually hurt the current model's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Synthetic Data</head><p>We use synthetic data to further analyze Shapley values. The data generating process is as follows. First, features are sampled from a 50-dimensional Gaussian distribution N (0, I) . Each sample i 's label is then assigned a binary label y i where P (y i = 1) = f () for a function f (.). We create to sets of data sets: 20 data sets were feature-label relationship is linear (linear f (.)) , and 20 data sets where f (.) is a third order polynomial. For the first sets of data set we us a logistic regression model and for the second set we use both a logistic regression and a neural network with one hidden layer. We then start removing training points from the most valuable to the least valuable and track the change in model performance. <ref type="figure">Fig. 2</ref> shows the results for using train data size of 100 and 1000; for all of the settings, the Shapley valuation methods do a better job than the leaveone-out in determining datum with the most positive effect on model performance. Note here that Shapley value is always dependent on the chosen model: in a dataset with non-linear feature-label relationship, data points that will improve a non-linear model's performance, can be harmful to a linear model and therefore valueless.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Label Noise</head><p>Labeling data sets using crowd-sourcing is susceptible to mistakes <ref type="bibr" target="#b12">(Frénay &amp; Verleysen, 2014)</ref> and mislabeling the data can be used as a simple data poisoning method <ref type="bibr" target="#b32">(Steinhardt et al., 2017)</ref>. In this experiment, given a train data with noisy labels, we check and correct the mislabeled examples by inspecting the data points from the least valuable to the most valuable as we expect the mislabeled examples to be among the lowest valuable points (some have negative Shapley value). <ref type="figure">Fig. 3</ref> shows the effectiveness of this method using TMC-Shapley, Gradient-Shapley (If applicable), and leave-one-out methods compared to the random inspection benchmark. We run the experiment for three different data sets and three different predictive models. In the first experiment, we use the spam classification data set <ref type="bibr" target="#b24">(Metsis et al., 2006)</ref>. 3000 data points are used for training a Multinomial Naive Bayes model that takes the bag of words representation of emails as input. We randomly flip the label for 20% of training points. TMC-Shapley converges in 5000 iterations.In the next experiment, we use the flower image classification data set 1 with 5 different classes. We pass the flower images through Inception-V3 model and train a multinomial logistic regression model on the learned network's representation of 1000 images where 10% of the images are mislabeled. Both Shapley algorithms converge in 2000 iterations. At last, we train a convolutional neural network with one convolutional and two feed-forward layers on 1000 images from the Fashion MNIST data set <ref type="bibr" target="#b36">(Xiao et al., 2017)</ref> to </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Data Quality and Value</head><p>In this experiment, we used the Dog vs. Fish data set introduced in . For each class, 1200 images are extracted from Imagenet <ref type="bibr" target="#b29">(Russakovsky et al., 2015)</ref>. We adapted from https://goo.gl/Xgr1a1</p><p>Train data size 100</p><p>Train data size 1000</p><p>(a) (b) (c) <ref type="figure">Figure 2</ref>. Synthetic experiments Average results are displayed for three different settings. Vertical axis if relative accuracy which stands for accuracy divided by the accuracy of the model trained on the whole train data without any removal. For each figure, 20 data sets are used. In all data sets, the generative prorcess is as follows: for input features , the label is generated such that p(y|x) = f (x) where in (a) f (.) is linear and in (b) f (.) is a third order polynomial and (c) uses the same data sets as (b). In (a) and (b) the model is logistic regression and in (c) it's a neural network. Both Shapley methods do a better job at assigning high value to data points with highest positive effect on model performance. Colored shaded areas stand for standard deviation over results of 20 data sets.</p><p>use a state of the art Inception-v3 network <ref type="bibr" target="#b35">(Szegedy et al., 2016)</ref> with all layers but the top layer frozen. 100 images are randomly sampled as the training set and 1000 images are used to compute the value function. We corrupt 10% of train data by adding white noise and compute the average TMC-Shapley value of clean and noisy images and repeat the same experiment with different levels of noise. As it is shown in <ref type="figure">Fig. 5(a)</ref>, as the noise level increases (the data quality drops), the data Shapley value of the noisy images decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Group Shapley Value</head><p>In this experiment, we use a balanced subset of the hospital readmission data set <ref type="bibr" target="#b33">(Strack et al., 2014)</ref> for binary prediction of a patient's readmission. We group patients into 146 groups by intersections of demographic features of gender, race, and age. A gradient boosting classifier trained on a train set of size 60000 yields and accuracy of 58.4%. We then calculate the TMC-Shapey values of groups. <ref type="figure">Fig 5(b)</ref> shows that the most valuable groups are also the most important ones for model's performance. In addition to computational efficiency, an important advantage of group Shapley is its easy interpretations. For instance, in this data set, groups of older patients have higher value than younger ones, racial minorities get less value, and groups of females tend to be more valuable than males with respect to data Shapley, and so forth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related Works</head><p>Shapley value was proposed in a classic paper in game theory <ref type="bibr" target="#b30">(Shapley, 1953)</ref> and has been widely influential in economics <ref type="bibr" target="#b31">(Shapley et al., 1988)</ref>. It has been applied to analyze and model diverse problems including voting, resource allocation and bargaining <ref type="bibr" target="#b26">(Milnor &amp; Shapley, 1978;</ref><ref type="bibr" target="#b15">Gul, 1989)</ref>. To the best of our knowledge, Shapley value has not been used to quantify data value in a machine learning context like ours. Shapley value has been recently proposed as a feature importance score for the purpose of interpreting black-box predictive models <ref type="bibr" target="#b18">(Kononenko et al., 2010;</ref><ref type="bibr" target="#b9">Datta et al., 2016;</ref><ref type="bibr" target="#b19">Lundberg &amp; Lee, 2017;</ref><ref type="bibr" target="#b6">Cohen et al., 2007;</ref><ref type="bibr" target="#b5">Chen et al., 2018;</ref><ref type="bibr" target="#b20">Lundberg et al., 2018)</ref>. Their goal is to quantify, for a given prediction, which features are the most influential for the model output. Our goal is very different in that we aim to quantify the value of individual data points (not features). There is also a literature in estimating Shapley value using Monte Carlo methods, network approximations, as well as analytically solving Shapley value in specialized settings <ref type="bibr" target="#b11">(Fatima et al., 2008;</ref><ref type="bibr" target="#b25">Michalak et al., 2013;</ref><ref type="bibr" target="#b3">Castro et al., 2009a;</ref><ref type="bibr" target="#b22">Maleki et al., 2013;</ref><ref type="bibr" target="#b16">Hamers et al., 2016)</ref> In linear regression, Cook's Distance measures the effect of deleting one point on the regression model <ref type="bibr" target="#b7">(Cook, 1977)</ref>. Leverage and influence are related notions that measures how perturbing each point affects the model parameters and model predictions on other data <ref type="bibr" target="#b8">(Cook &amp; Weisberg, 1982;</ref>  satisfy any equitability conditions, and also have been shown to have robustness issues <ref type="bibr" target="#b14">(Ghorbani et al., 2017)</ref>. In the broad discourse, value of data and how individuals should be compensated has been intensely discussed by economists and policy makers along with the discussion of incentivizing participants to generate useful data. <ref type="bibr" target="#b0">(Arrieta Ibarra et al., 2017;</ref><ref type="bibr" target="#b27">Posner &amp; Weyl, 2018)</ref> 6. Discussion</p><p>We proposed data Shapley as an equitable framework to quantify the value of individual training datum for the learning algorithm. Data Shapley uniquely satisfies three natural properties of equitable data valuation. There are ML settings where these properties may not be desirable and perhaps other properties need to be added. It is a very important direction of future work to clearly understand these different scenarios and study the appropriate notions of data value. Drawing on the connections from economics, we believe the three properties we listed is a reasonable starting point. While our experiments demonstrate several desirable features of data Shapley, we should interpret it with care. Due to the space limit, we have skipped over many important  <ref type="figure">Figure 5</ref>. (a) Value and data quality: White noise is added to 10% of training points. As the noise level increases, the average TMC-Shapley value of noisy images becomes decreases compared to that of clean images. (b) Group Shapley: Removing the valuable groups degrades the performance more than removing groups with the highest leave-one-out score.</p><p>considerations about the intrinsic value of personal data, and we focused on valuation in the very specific context of training set for supervised learning algorithms. We acknowledge that there are nuances in the value of data-e.g. privacy, personal association-not captured by our framework. Moreover we do not propose that people should be exactly compensated by their data Shapley value; we believe data Shapley is more useful for the quantitative insight it provides.</p><p>In the data Shapley framework, the value of individual datum depends on the learning algorithm, evaluation metric as well as other data points in the training set. Therefore when we discuss data with high (or low) Shapley value, all of this context is assumed to be given. A datum that is not valuable for one context could be very valuable if the context changes. Understanding how data Shapley behaves for different learning functions and metrics is an interesting direction of follow up work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig 6in Appendix A depicts examples of convergence of data Shapley. In practice, convergence is reached with number of samples on the order n; usually 3n Monte Carlo samples is sufficient for convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Parametrized and differentiable loss function L (.; θ), train data D = {1, . . . , n} , performance score function V (θ) Output: Shapley value of training points: φ 1 , . . . , φ n</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 .</head><label>1</label><figDesc>Disease Prediction For breast and skin cancer prediction tasks, we calculate the value of every point in the train set using TMC-Shapley, G-Shapley and leave-one-out (LOO). (a) We remove the most valuable data from the train set, as ranked by the three methods plus uniform sampling. The Shapley methods identifies important data points, and removing the most TMC-Shapley or G-Shapley valuable points results in performance worse than randomly removing data. This is not true for LOO. (b) Removing the low TMC-Shapley or G-Shapley value data from the train set improves the predictor performance. (c) We acquired new patients who are similar to the high TMC-Shapley or G-Shapley value patients in the training data. This resulted in greater performance gains compared to adding random patients. (d) Acquiring new patients who are similar to low TMC-Shapley or G-Shapley value patients do not help.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>classify T-Shirts and Tops against Shirts. 10% of data points have flipped labels. TMC-Shapley and G-Shapley both converge in 2000 iterations. The value is computed on separate sets of size 1000. Fig. 3 displays the results. Fig 4 shows the 5 least TMC-Shapley valued images for Flowers and Fashion MNIST data sets where all are mislabeled examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .Figure 4 .</head><label>34</label><figDesc>Correcting Flipped Labels We inspect train data points from the least valuable to the most valuable and fix the mislabeled examples. As it is shown, Shapley value methods result in the earliest detection of mislabeled examples. While leave-one-out works reasonably well on the Logistic Regression model, it's performance on the two other models is similar to random inspection. Label noise and Shapley value Images with the least TMC-Shapley value. All of them are mislabeled.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>). These methods, however, do not</figDesc><table><row><cell>Spam Classification Naïve Bayes Classifier 20% mislabeled</cell><cell>Flower Classification Multinomial Logistic Regression 10% mislabeled</cell><cell>T-Shirt/Top vs Shirt Classification ConvNet Classifier 10% mislabeled</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arrieta</forename><surname>Ibarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiménez Hernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lanier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weyl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename></persName>
		</author>
		<title level="m">Should we treat data as labor? moving beyond&apos;free&apos;. Moving Beyond&apos;Free&apos;</title>
		<imprint>
			<date type="published" when="2017-12-27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">American Economic Association Papers &amp; Proceedings</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sample size planning for classification models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beleites</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neugebauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bocklitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Krafft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Popp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analytica chimica acta</title>
		<imprint>
			<biblScope unit="volume">760</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Polynomial calculation of the shapley value based on sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tejada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Operations Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1726" to="1730" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Polynomial calculation of the shapley value based on sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tejada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Operations Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1726" to="1730" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Lshapley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.02610</idno>
		<title level="m">Efficient model interpretation for structured data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Feature selection via coalitional game theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1939" to="1961" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Detection of influential observation in linear regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="18" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Residuals and influence in regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weisberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>Chapman and Hall</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy (SP), 2016 IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="598" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the uniqueness of the shapley value</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dubey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Game Theory</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="131" to="139" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A linear approximation method for the shapley value</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Fatima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wooldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennings</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1673" to="1699" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frénay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="845" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The elements of statistical learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer series in statistics</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10547</idno>
		<title level="m">Interpretation of neural networks is fragile</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bargaining foundations of shapley value. Econometrica</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="81" to="95" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A new approximation method for the shapley value applied to the wtc 9/11 terrorist attack</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hamers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Husslage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lindelauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Campen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Understanding black-box predictions via influence functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04730</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An efficient explanation of individual classifications using game theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kononenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2010-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-I</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Erion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-I</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03888</idno>
		<title level="m">Consistent individualized feature attribution for tree ensembles</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bharambe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00932</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Bounding the estimation error of samplingbased shapley value approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tran-Thanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rahwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogers</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1306.4265</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Evaluating the electoral college exactly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Shapley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Santa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ca</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Values of large games</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spam filtering with naive bayes-which naive bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Metsis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CEAS</title>
		<meeting><address><addrLine>Mountain View, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="28" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficient computation of the shapley value for game-theoretic network centrality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Michalak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Aadithya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Szczepanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennings</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="607" to="650" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Milnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Shapley</surname></persName>
		</author>
		<title level="m">Values of large games ii: Oceanic games. Mathematics of operations research</title>
		<imprint>
			<date type="published" when="1978" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="290" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Radical Markets: Uprooting Capitalism and Democracy for a Just Society</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Posner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Weyl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">General data protection regulation. IN-TOUCH</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Regulation</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A value for n-person games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Shapley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contributions to the Theory of Games</title>
		<imprint>
			<date type="published" when="1953" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="307" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The Shapley value: essays in honor of Lloyd S. Shapley</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Shapley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Certified defenses for data poisoning attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3517" to="3529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Impact of hba1c measurement on hospital readmission rates: analysis of 70,000 clinical database patient records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Strack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Deshazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gennings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Olmo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ventura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Cios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Clore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMed research international</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Uk biobank: an open access resource for identifying the causes of a wide range of complex diseases of middle and old age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sudlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gallacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Beral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Danesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Landray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS medicine</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1001779</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
