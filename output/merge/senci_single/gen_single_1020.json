{"1020": "this paper presents a tts system that can synthesize speech with close to natural quality while running times faster than real-time on a standard cpu. the modular setup of the system allows for simple adaptation to new voices with a small amount of data. we first demonstrate the ability of the system to produce high quality speech when trained on large, high quality datasets. following that, we demonstrate its adaptability by mimicking unseen voices using to minutes long datasets with lower recording quality. large scale mean opinion score quality and similarity tests are presented, showing that the system can adapt to unseen voices with quality gap of and similarity gap of compared to natural speech for male voices and quality gap of and similarity of for female voices. lpcnet is a wavernn variant that uses a nn model to generate speech samples from the utterance-intime input of cepstrum, pitch and pitch correlation parameters. the lpcnet decoder is a wavernn variant that uses a nn model to predict the lpc residual ( the vocal source signal) and then apply the lpcnet residual. in this paper we propose a new method to train a tts system on multispeaker datasets . the method is based on the idea that the tts system can be considered as a multispeaker same gender network (lpcnet) . the lpcnet is used to train a tts system in a speaker independent setting. in this article we present a new tts system that produces high quality speech while operating at faster than real-time rate without an expensive gpu support. the system is built around three nn models for generating the prosody, acoustic features and the final speech signal. we tested this system using two proprietary tts voice datasets and demonstrated that our system produces high quality speech that is comparable to larger and much slower tacotron2 wavenet systems. the task of creating a high-quality tts system out of a smaller set of audio data is even more challenging. we demonstrated that when we reduce the size of the training data, there is some graceful degradation to the quality, but we are still able to maintain good similarity to the original speaker. the system is composed of three separate neural network blocks prosody prediction, acoustic feature prediction and linear prediction coding net as a neural vocoder. the lpcnet uses its nn to predict the lpc residual ( the vocal source signal) and then apply to it an lpc filter calculated from the cepstrum. this has the advantages of better control over the output of the spectral shape since it depends directly on the lpc filter shape. the system is modular and provides easy control, flexibility and adaptability at the component level. the tests were performed using the amazon mechanical turk ( amt) platform with 50- anonymous and untrained subjects participating in several evaluation sessions, constructed so that each sentence is evaluated by distinct subjects. this paper describes the design and implementation of a new tts system that produces high quality speech while operating at faster than real-time rate without an expensive gpu support. for future work, we plan to allow voice modifications by adding control over voice parameters such as pitch, breathiness and vocal tract.", "1000": "###", "1001": "###", "1002": "###", "1003": "###", "1004": "###", "1005": "###", "1006": "###", "1007": "###", "1008": "###", "1009": "###", "1010": "###", "1011": "###", "1012": "###", "1013": "###", "1014": "###", "1015": "###", "1016": "###", "1017": "###", "1018": "###", "1019": "###", "1021": "###"}