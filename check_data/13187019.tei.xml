<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Matejka</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Autodesk Research</orgName>
								<orgName type="institution" key="instit2">Toronto Ontario</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Fitzmaurice</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Autodesk Research</orgName>
								<orgName type="institution" key="instit2">Toronto Ontario</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3025453.3025912</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Figure 1. A collection of data sets produced by our technique. While different in appearance, each has the same summary statistics (mean, std. deviation, and Pearson&apos;s corr.) to 2 decimal places. (x ͞ =54.02, y</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Anscome's Quartet <ref type="bibr" target="#b0">[1]</ref> is a set of four distinct datasets each consisting of 11 (x,y) pairs where each dataset produces the same summary statistics (mean, standard deviation, and correlation) while producing vastly different plots ( <ref type="figure" target="#fig_0">Figure  2A</ref>). This dataset is frequently used to illustrate the importance of graphical representations when exploring data. The effectiveness of Anscombe's Quartet is not due to simply having four different data sets which generate the same statistical properties, it is that four clearly different and identifiably distinct datasets are producing the same statistical properties. Dataset I appears to follow a somewhat noisy linear model, while Dataset II is following a parabolic distribution. Dataset III appears to be strongly linear, except for a single outlier, while Dataset IV forms a vertical line with the regression thrown off by a single outlier. In contrast, <ref type="figure" target="#fig_0">Figure 2B</ref> shows a series of datasets also sharing the same summary statistics as Anscombe's Quartet, however without any obvious underlying structure to the individual datasets, this quartet is not nearly as effective at demonstrating the importance of graphical representations.</p><p>While very popular and effective for illustrating the importance of visualizations, it is not known how Anscombe came up with his datasets <ref type="bibr" target="#b4">[5]</ref>. Our work presents a novel method for creating datasets which are identical over a range of statistical properties, yet produce dissimilar graphics. Our method differs from previous by being agnostic to the particular statistical properties that are to remain constant between the datasets, while allowing for control over the graphical appearance of resulting output.</p><p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org. CHI 2017, May 06 -11, 2017, Denver, CO, USA Copyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-4655-9/17/05…$15.00 DOI: http://dx.doi.org/10.1145/3025453.3025912 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head><p>As alluded to above, producing multiple datasets with similar statistics and dissimilar graphics was introduced by Anscombe in 1973 <ref type="bibr" target="#b0">[1]</ref>. "Graphs in Statistical Analysis" starts by listing three notions prevalent about graphs at the time: While one cannot argue that there is currently as much resistance towards graphical methods as when Anscombe's paper was originally published, the datasets described in the work ( <ref type="figure">Figure 1A</ref>) are still effective and frequently used for introducing or reinforcing the importance of visual methods. Unfortunately, Anscombe does not report how the datasets were created, nor suggest any method to create new ones.</p><formula xml:id="formula_0">(1) Numerical</formula><p>The first attempt at producing a generalized method for creating such datasets was published in 2007 by Chatterjee and Firat <ref type="bibr" target="#b4">[5]</ref>. They proposed a genetic algorithm based approach where 1,000 random datasets were created with identical summary statistics, then combined and mutated with an objective function to maximize the "graphical dissimilarity" between the initial and final scatter plots. While the datasets produced were graphically dissimilar to the input datasets, they did not have any discernable structure in their composition. Our technique differs by providing a mechanism to direct the solutions towards a specific shape, as well as allowing for variety in the statistical measures which are to remain constant between the solutions.</p><p>Govindaraju and Haslett developed a method for regressing datasets towards their sample means while maintaining the same linear regression formula <ref type="bibr" target="#b6">[7]</ref>. In 2009, the same authors extended their procedure to creating "cloned" datasets <ref type="bibr" target="#b7">[8]</ref>. In addition to maintaining the same linear regression as the seed dataset, their cloned datasets also maintained the same means (but not the same standard deviations). While Chatterjee and Firat <ref type="bibr" target="#b4">[5]</ref> wanted to create datasets as graphically dissimilar as possible, Govindaraju and Haslett's cloned datasets were designed to be visually similar, with a proposed application of confidentializing sensitive data for publication purposes. While our technique is primarily aimed at creating visually distinct datasets, by choosing appropriate statistical tests to remain constant through the iterations (such as a Kolmogorov-Smirnov test) our technique can produce datasets with similar graphical characteristics as well.</p><p>In the area of generating synthetic datasets, GraphCuisine <ref type="bibr" target="#b1">[2]</ref> allows users to direct an evolutionary algorithm to create network graphs matching user-specified parameters. While this work looks at a similar problem, it differs in that it is focused on network graphs, is an interactive system, and allows for directly specifying characteristics of the output, while our technique looks at 1D or 2D distributions of data, is non-interactive, and perturbs the data such that the initial statistical properties are maintained throughout the process.</p><p>Finally, on the topic of using scatter plots to encode graphics, Residual Sur(Realism) <ref type="bibr" target="#b10">[11]</ref> produces datasets with hidden images which are only revealed when appropriate statistical measures are performed. Conversely, our technique encodes graphical appearance into the data directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHOD</head><p>The key insight behind our approach is that while generating a dataset from scratch to have particular statistical properties is relatively difficult, it is relatively easy to take an existing dataset, modify it slightly, and maintain (nearly) the same statistical properties. With repetition, this process creates a dataset with a different visual appearance from the original, while maintaining the same statistical properties. Further, if the modifications to the dataset are biased to move the points towards a particular goal, the resulting graph can be directed towards a particular visual appearance.</p><p>The pseudocode for the high-level algorithm is listed below:</p><p>INITIAL_DS is the seed dataset from which the statistical values we wish to maintain are calculated. The PERTURB function is called at each iteration of the algorithm to modify the latest version of the dataset (CURRENT_DS) by moving one or more points by a small amount, in a random direction. The "small amount" is chosen from a normal distribution and is calibrated such that &gt;95% of movements result in the statistical properties of the overall dataset remaining unchanged (to two decimal places).</p><p>Once the individual points have been moved, the FIT function is used to check if perturbing the points has increased the overall fitness of the dataset. The fitness can be calculated in a variety of ways, but for conditions where we want to coerce the dataset to into a shape, fitness is calculated as the average distance of all points to the nearest point on the target shape.</p><p>The naïve approach of accepting only datasets with an improved fitness value results in possibly getting stuck in locally-optimal solutions where other, more globally-optimal solutions are possible. To mitigate this possibility, we employ a simulated annealing technique <ref type="bibr" target="#b8">[9]</ref>. With the possible solutions generated in each iteration, simulated annealing works by always accepting solutions which return test improve the fitness, but also, if the fitness is not improved, the solution may be accepted based on the "temperature" of the simulated annealing algorithm. If the current temperature is less than a random number between 0 and 1, the solution is accepted even if it the fitness is worsened. We found that using a quadratically-smoothed monotonic cooling schedule starting with a temperature of 0.4 and finishing with a temperature of 0.01 worked well for the sample datasets.</p><p>Once the perturbed dataset has been accepted, either through an improved fitness value or from the simulated annealing process, the perturbed dataset is compared to the initial dataset for statistical equivalence. For the examples in this paper we consider properties to be "the same" if they are equal to two decimal places. The ISERROROK function compares the statistics between the datasets, and if they are equal (to the specified number of decimal places), the result from the current iteration becomes the new current state.</p><p>Example Generated Datasets</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 1: Coercion Towards Target Shapes</head><p>In this first example <ref type="figure">(Figure 1</ref>), each dataset contains 182 points and are equal (to two decimal places) for the "standard" summary statistics (x/y mean, x/y standard deviation, and Pearson's correlation). Each dataset was seeded with the plot in the top left. The target shapes are specified as a series of line segments, and the shapes used in this example are shown in <ref type="figure" target="#fig_1">Figure 3</ref>. With this example dataset, the algorithm ran for 200,000 iterations to achieve the final results. On a laptop computer this process took ~10 minutes. <ref type="figure" target="#fig_2">Figure 4</ref> shows the progression of one of the datasets towards the target shape. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 2: Alternate Statistical Measures</head><p>One benefit of our approach over previous methods is that the iterative process is agnostic to the particular statistical properties which remain constant between the datasets. In this example ( <ref type="figure" target="#fig_3">Figure 5</ref>) the datasets are derived from the same initial dataset as in Example 1, but rather than being equal on the parametric properties, the datasets are equal in the non-parametric measures of x/y median, x/y interquartile range (IQR), and Spearman's rank correlation coefficient. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 3: Specific Initial Dataset</head><p>The previous two examples used a rather "generic" dataset of a slightly positively correlated point cloud as the starting point of the optimization. Alternately, it is possible to begin with a very specific dataset to seed the optimization. Alberto Cairo produced a dataset called the "Datasaurus" <ref type="bibr" target="#b3">[4]</ref>. Like Anscombe's Quartet, this serves as a reminder to the importance of visualizing your data, since, although the dataset produces "normal" summary statistics, the resulting plot is a picture of a dinosaur. In this example we use the "datasaurus" as the initial dataset, and create other datasets with the same summary statistics ( <ref type="figure" target="#fig_4">Figure 6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 4: Simpson's Paradox</head><p>Another instrument for demonstrating the importance of visualizing your data is Simpson's Paradox <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10]</ref>. This paradox occurs with data sets where a trend appears when looking at individual groups in the data, but disappears or reverses when the groups are combined.</p><p>To create a dataset exhibiting Simpson's Paradox, we start with a strongly positively correlated dataset ( <ref type="figure" target="#fig_5">Figure 7A</ref>), and then perturb and direct that dataset towards a series of negatively sloping lines ( <ref type="figure" target="#fig_5">Figure 7B</ref>). The resulting dataset ( <ref type="figure" target="#fig_5">Figure 7C</ref>) has the same positive correlation as the initial dataset when looked at as a whole, while the individual groups each have a strong negative correlation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 5: Cloned Dataset with Similar Appearance</head><p>As discussed by Govindaraju and Haslett <ref type="bibr" target="#b7">[8]</ref> another use for datasets with the same statistical properties is the creation of "cloned" datasets to anonymize sensitive data <ref type="bibr" target="#b5">[6]</ref>. In this case, it is important that individual data points are changed while the overall structure of the data remains similar. This can be accomplished by performing a Kolmogorov-Smirnov test within the ISERROROK function for both x and y. By only accepting solutions where both the x and y K-S statistic is &lt;0.05 we ensure that the result will have a similar shape to the original <ref type="figure" target="#fig_6">(Figure 8</ref>). This approach has the benefit of maintaining the x/y means and correlation as accomplished in previous work <ref type="bibr" target="#b7">[8]</ref>, and additionally the x/y standard deviations as well. This could also be useful for "graphical inference" <ref type="bibr" target="#b11">[12]</ref> to create a collection of variant plots following the same null hypothesis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 6: 1D Boxplots</head><p>To demonstrate the applicability of our approach to non 2Dscatterplot data, this example uses a 1D distribution of data as represented by a boxplot. The most common variety of boxplot, the "Tukey Boxplot", presents the 1 st quartile, median, and 3 rd quartile values on the "box", with the "whiskers" showing the location of the furthest datapoints within 1.5 interquartile ranges (IQR) from the 1 st and 3 rd quartiles. Starting with the data in a normal distribution ( <ref type="figure" target="#fig_7">Figure 9A</ref>) and perturbing the data to the left (B), right (C), edges (D, E), and arbitrary points along the range (F) while ensuring that the boxplot statistics remain constant produces the results shown in <ref type="figure" target="#fig_7">Figure 9</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LIMITATIONS AND FUTURE WORK</head><p>When the source dataset and the target shape are vastly different, the produced output might not be desirable. An example is show <ref type="figure" target="#fig_8">Figure 10</ref>, where the data set from <ref type="figure" target="#fig_5">Figure  7A</ref> is coerced into a star ( <ref type="figure" target="#fig_8">Figure 10</ref>). This problem can be mitigated by coercing the data towards "simpler" patterns with more coverage of the coordinate space -such as lines spanning the grid, or pre-scaling and positioning the target shape to better align with the initial dataset. The currently implemented fitness function looks only at the position of individual points in relation to the target shape, which can result in "clumping" of data points and sparse areas on the target shape. A future improvement could consider an additional goal to "separate" the points to encourage better coverage of the target shape in the output.</p><p>The parameters chosen for the algorithm (95% success rate, quadratic cooling scheme, start/end temperatures, etc.) were found to work well, but should not be considered "optimal". Such optimization is left as future work.</p><p>The code and datasets presented in this work are available at www.autodeskresearch.com/publications/samestats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>We presented a technique for creating visually dissimilar datasets which are equal over a range of statistical properties. The outputs from our method can be used to demonstrate the importance of visualizing your data, and may serve as a starting point for new data anonymization techniques. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>(A) Anscombe's Quartet, with each dataset having the same mean, standard deviation, and correlation. (B) Four unstructured datasets, each also having the same statistical properties as those in Anscombe's Quartet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>The initial data set (top-left), and line segment collections used for directing the output towards specific shapes. The results are seen in Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Progression of the algorithm towards a target shape over the course of the cooling schedule.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Example datasets are equal in the non-parametric statistics of x/y median (53.73, 46.21), x/y IQR (19.17, 37.92), and Spearman's rank correlation coefficient (+0.31).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Creating a collection of datasets based on the "dinosaurus" dataset. Each dataset has the same summary statistics to two decimal places: (x ͞ =54.26, y ͞ = 47.83, sdx = 16.76, sdy = 26.93, Pearson's r = -0.06).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Demonstration of Simpson's Paradox. Both datasets (A and C) have the same overall Pearson's correlation of +0.81, however after coercing the data towards the pattern of sloping lines (B), each subset of data in (C) has an individually negative correlation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Example of creating a "mirror" dataset as in<ref type="bibr" target="#b7">[8]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Six data distributions, each with the same 1 st quartile, median, and 3 rd quartile values, as well as equal locations for points 1.5 IQR from the 1 st and 3 rd quartiles. Each dataset produces an identical boxplot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>Undesirable outcome (C) when coercing a strongly positively correlated dataset (A) into a star (B).</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graphs in Statistical Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Anscombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="17" to="21" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Interactive Random Graph Generation with Evolutionary Algorithms. SpringerLink</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Spritzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="541" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On Simpson&apos;s Paradox and the Sure-Thing Principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Blyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="364" to="366" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Download the Datasaurus: Never trust summary statistics alone; always visualize your data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cairo</surname></persName>
		</author>
		<ptr target="http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating Data with Identical Statistics but Dissimilar Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Firat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="248" to="254" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Privacy-preserving Data Publishing: A Survey of Recent Developments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C M</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">53</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Illustration of regression towards the means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Haslett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Mathematical Education in Science and Technology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="544" to="550" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cloning Data: Generating Datasets with Exactly the Same Multiple Linear Regression Fit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Haslett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Govindaraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australian &amp; New Zealand Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="499" to="503" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simulated annealing: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-R</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Applicandae Mathematica</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="108" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Interpretation of Interaction in Contingency Tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Simpson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="238" to="241" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Residual (Sur)Realism. The American Statistician</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Stefanski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Graphical inference for infovis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="973" to="979" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
