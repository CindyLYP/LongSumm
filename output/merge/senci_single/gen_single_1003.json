{"1003": "emotion detection from text has become a popular task due to the key role of emotions in human-machine interaction. current approaches represent text as a sparse bag-of-words vector, where each vector entry corresponds to the presence of a speci c feature ( such as n-grams, punctuation and other) as reported recently by 11, deep learning is a promising approach for solving nlp tasks including text classi cation. while the aforementioned approach utilizes bow representation and linear classi ers, neural network methods are based on dense vector representations of text samples ( word embedding) and are nonlinear. such word embedding representation captures syntactic and semantic knowledge, which can improve the emotion detection task. generating high quality word vectors requires large-scale data and computing power. when generation is not an option, one can utilize pre-trained representations; the most popular pre-trained representations are based on word2vec and glove algorithms, and were trained on large corpora. classi ers ( a binary classi er for each emotion), typically svm 19 or logistic regression 32, using textual features such as n-grams, lexicon based, and pos features. forgues used pretrained word vectors and a linear classi er to classify user intents in dialog systems, however their task and methodology is di erent than ours. we propose a novel classi er that is based on di erent document representation for each emotion. word ( and hence its weight ai) is di erent for each emotion. this is a novel embedded document representation method, and as detailed in section 5, it is superior in comparison to the other representation methods we experimented with. we experimented with the following ve emotion detection datasets from di erent domains: isear contains labeled sentences where participants who have di erent cultural backgrounds reported experiences and reactions for seven emotions. semeval contains newspaper headlines labeled with the six ekman emotions by six annotators. for our experiments, we considered the most dominant emotion as the headline label as in fairy tales, labeled with ve emotions by six annotators. blog posts consists of emotion-rich sentences collected from blogs labeled with emotions by four annotators. isear contains labeled sentences where participants who have di erent cultural backgrounds reported experiences and reactions for seven emotions. this work studied the use of pretrained word vectors for emotion detection. we presented a novel method for representing document as a dense vector based on the importance of the document s terms and the importance of the document s terms in respect to classi cation. our results show that an ensemble that combines bow embedded representations using our class method, outperforms previous approaches for domain-speci c datasets. in comparison to other deep learning methods, our approach ts a small number of model parameters and requires little computing power. for future work we plan to investigate the use of deep learning models trained on domain adapted pseudo-labeled largescale datasets. current approaches represent text as a sparse bag-of-words vector. in this work, we propose a new approach that utilizes pre-trained, dense word embedding representations. we introduce an ensemble approach combining both sparse and dense representations. for example, cbow representation for glove source showed a improvement in f1-score relative to word2vec. also, the class method we 2url/ 3url/ 4url 5url/ proposed outperformed the other embedded document representation methods.", "1000": "###", "1001": "###", "1002": "###", "1004": "###", "1005": "###", "1006": "###", "1007": "###", "1008": "###", "1009": "###", "1010": "###", "1011": "###", "1012": "###", "1013": "###", "1014": "###", "1015": "###", "1016": "###", "1017": "###", "1018": "###", "1019": "###", "1020": "###", "1021": "###"}