{
  "name" : "84480736.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Protecting User Privacy: An Approach for Untraceable Web Browsing History and Unambiguous User Profiles",
    "authors" : [ "Ghazaleh Beigi", "Ruocheng Guo", "Alexander Nou", "Yanchao Zhang", "Huan Liu" ],
    "emails" : [ "gbeigi@asu.edu", "rguo12@asu.edu", "asnou@asu.edu", "yczhang@asu.edu", "huan.liu@asu.edu", "permissions@acm.org." ],
    "sections" : [ {
      "heading" : null,
      "text" : "CCS CONCEPTS • Security and Privacy→ Data Anonymization and Sanitization; • Security and privacy→ Privacy protections;\nKEYWORDS Web Browsing History Anonymization, Privacy, Utility, Trade-off ACM Reference Format: Ghazaleh Beigi, Ruocheng Guo, Alexander Nou, Yanchao Zhang, Huan Liu. 2019. Protecting User Privacy: An Approach for Untraceable Web Browsing History and Unambiguous User Profiles. In The Twelfth ACM International Conference on Web Search and Data Mining (WSDM ’19), February 11–15, 2019, Melbourne, VIC, Australia. ACM, New York, NY, USA, 9 pages. https: //doi.org/10.1145/3289600.3291026"
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "The web browsing history is the list of web pages a user has visited in past browsing sessions and includes the name of the web pages as well as their corresponding URLs. Online users usually\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WSDM ’19, February 11–15, 2019, Melbourne, VIC, Australia © 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5940-5/19/02. . . $15.00 https://doi.org/10.1145/3289600.3291026\nexpect a secure environment when surfing the Web wherein their personally identifiable information (a.k.a. PII) could be kept hidden from prying eyes. However, the web browsing history log is stored by the web browser on the device’s local hard drive. In addition to the web browser, users’ browsing histories are recorded via thirdparty trackers embedded on the web pages to help improve online advertising and web surfing experience. Moreover, Internet Service Providers (ISPs) such as AT&T and Verizon, have full access to individuals’ web browsing histories. ISPs can infer different types of personal information such as users’ political views, sexual orientations and financial information based on the sites they visit. Some countries have policies for protecting individuals’ privacy. For example, European Union (EU) has regulated a new data protection and privacy policy for all individuals within the European Union and the European Economic Area (a.k.a. General Data Protection Regulation (GDPR)).1United States government also had Federal Communications Commission’s (FCC) landmark Internet privacy protections for users such that ISPs could have been punished by the Federal Trade Commission (FTC) for violating their customers’ privacy. However, not all countries have such policies. FCC’s Internet privacy protection has been also removed in late March of 2017. This new legislation allows ISPs to monitor, collect, share and sell their customer’s behavior online such as detailed Web browsing histories without their consent and any anonymization.2\nAssuming that ISPs and online trackers make browsing history data pseudonymous before sharing, a recent study has shown the fingerprintability of such data by introducing an attack which maps a given browsing history to a social media profile such as Twitter, Facebook, or Reddit accounts [36]. Although linking browsing history to social media profiles may not always lead to figuring out one’s real identity, it is a stepping stone for attackers to infer real identities. This identity exposure may result in harms ranging from persecution by governments to targeted frauds [6, 10].\nThe onus is now on the users to protect their browsing history from any kind of adversaries like ISPs and online trackers. There are approaches to help users shield their web browsing history such as browser add-ons or extensions (e.g., ‘Ghostery’, ‘Privacy Badger’ and ‘HTTPS everywhere’), Virtual Private Networks (VPN) services, Tor, and HTTPS. However, none of the above solutions can prevent ISPs from collecting users’ web browsing history and protect users’ identities when such information is revealed because de-anonymization attacks will still work [36]. Moreover, using these solutions could result in a severe decrease in the quality of online personalization services due to the lack of customer’s information. This information is critical for online vendors to profile users’ preferences from their online activities to predict their future needs. So\n1https://bit.ly/1lmrNJz 2http://wapo.st/2mvYKGa\nar X\niv :1\n81 1.\n09 34\n0v 1\n[ cs\n.C R\n] 2\n3 N\nov 2\n01 8\nusers face a dilemma between user privacy and service satisfaction. Hereafter, we refer to a user’s satisfaction of online personalization services, as online service utility, or simply, utility. The aforementioned challenges highlight the need to have a web browsing history anonymizer framework, which can help users strike a good balance between their privacy and utility. Traditional privacy preserving web search techniques such as [38, 40, 41] are designed for different purposes and are thus ineffective in accomplishing our goals.\nIntuitively, the more links we add to a web browsing history, the more privacy we can preserve. An extreme case is when the added links completely change a user’s browsing history to perfectly obfuscate the user’s fingerprints. Some existing methods include ISPPolluter,3 Noiszy,4 and RuinMyHistory5 which pollute a web browsing history by adding links randomly. However, such methods largely disturb user profiles and thus results in the loss of utility of online services. Similarly, the maximum service utility can only be achieved at the complete sacrifice of user privacy. It is challenging to design an effective browsing history anonymizer that retains high utility. In this paper, we aim to study the following problem: howmany links andwhat links should be added to a user’s browsing history to boost user privacy while retaining high utility. Note that links cannot be removed from the browsing history as all of user’s activities have been already recorded by ISPs. The research requires quantifying the privacy of users and the utility of their services. We address these challenges within a novel framework, called PBooster. This framework exploits publicly available information in social media networks as an auxiliary source of information to help anonymizing web browsing history while preserving utility. Our contributions can be summarized as follows. • We address the problem of anonymizing web browsing histories while retaining high service utility. We show that this problem cannot be solved in polynomial time. • We propose an efficient framework, PBooster, with measures for quantifying the trade-off between user privacy and the quality of online services. • We conduct experiments and evaluate the proposed approach in terms of privacy and utility. Results demonstrate the efficiency of PBooster in terms of privacy-utility trade-off."
    }, {
      "heading" : "2 RELATEDWORK",
      "text" : "Explosive growth of the Web has not only drastically changed the way people conduct activities and acquire information, but also has raised security [1, 2] and privacy [4, 6, 27] issues for them. Identifying andmitigating user privacy issues has been studied from different aspects on the Web and social media (for a comprehensive survey see [4]). Our work is related to a number of research which we discuss below while highlighting the differences between our work and them. Tracking and Profiling. In the area of user tracking and profiling, there have been efforts to study how and to what degree that web browser tracking [12, 21, 26] and cross-device tracking [42] can be done by third parties. This line of work mainly studied the mechanisms of the user tracking techniques. To go one step further, for\n3https://github.com/essandess/isp-data-pollution 4https://noiszy.com/ 5https://github.com/FascinatedBox/RuinMyHistory\nthe protection of users from tracking and profiling, strategies such as limiting the access to sampled user profiles [34] and distorting the user profile [9] are proposed to minimize privacy risk. Privacy Preserving Web Search.Web search has become a regular activity where a user composes a query formed by one or more keywords and sends it to the search engine. The engine returns a list of web pages according to the user query. These search queries are a rich source of information for user profiling. Privacy preserving web search approaches focus on anonymizing users search queries. One group of works focused on the protection of post-hoc logs [11, 15, 40]. Another group of approaches including client-side ones focuses on search query obfuscation [3, 14, 17, 39]. These approaches are user-centric and automatically generate fake search queries on behalf of user. Web browsing history anonymization problem is different from privacy preserving web search problem. The former consists of a set of URLs a user has visited in past browsing sessions, while the latter includes a set of queries and relevant pages returned by search engine for each given query. Moreover, in web browsing history anonymization, URLs cannot be removed from a user’s history (all activities have been already recorded by ISPs) while a data publisher is allowed to remove a portion of queries and pages in privacy preserving web search problem. This makes the web browsing history anonymization more challenging. Privacy Preserving Recommendation. Recommendation systems help individuals find relevant information, however, these systems can also raise privacy concerns for users [5]. Differential privacy based approaches [23, 25, 32] add noise to recommendation results so that the distribution of results is insensitive to the records of any specific user. Secure computation approaches have been also designed to take care of the computation procedure in recommender systems. Privacy-preserving matrix factorization schemes [18] are designed to avoid exposure of user information during the recommender’s computation. Matrix factorization has been used in many applications such as recommendation systems and trust/distrust prediction [7]. Another work [19] studies sharing user attributes to recommenders while handling the trade-off between privacy and quality of received service. Recent work [33] also studied utilityprivacy trade-off.\nThe problem of anonymizing web browsing history is unique in this work. First, in our problem web browsing URLs cannot be removed and the original format of data will be published rather than its statistics. This also makes differential privacy based techniques ineffective for this task. Second, the user is not aware of the tasks that use his data and thus securing computation approaches is impractical for this new problem. Third, the proposed solution should be efficient and results in minimal loss in utility. All of these make this problem even more challenging."
    }, {
      "heading" : "3 THREAT MODEL AND PROBLEM STATEMENT",
      "text" : "Before discussing the details of the proposed solution, we first formally define browsing history, then review the web browsing history de-anonymization and finally introduce the problem of web browsing history anonymization. For each user, web browsing history is defined as the list of web pages a user has visited in his past browsing sessions and includes the corresponding URLs of the\nvisited web pages. This log is recorded by the browser, third-party trackers and ISPs. In addition to his browsing history, other private data components such as cache, cookies and saved passwords are also saved during a browsing session which are sometimes referred to under the browsing history umbrella. However, in this work, we separate these pieces of information from web browsing history. Given a user u, we assume his web browsing historyHu is generated by a sequence of n linksHu = {l1, ...ln } where li corresponds to the i-th URL visited by the user u."
    }, {
      "heading" : "3.1 Threat Model",
      "text" : "De-anonymizing browsing histories is a type of linkage attack which is introduced by Su et al. [36]. This de-anonymization attack links web browsing histories to social media profiles. The main idea behind this threat model is that people tend to click on the links in their social media feed. These links are mainly provided by the set of user’s friends. Since each user has a distinctive set of friends on social media and he is more likely to click on a link posted by any of his friends rather than a random user, these distinctive web browsing patterns remain in his browsing history. Assuming that the attacker knows which links in the history have resulted from clicks on social media feeds, a maximum likelihood based framework is developed as a de-anonymization attack which identifies the feed in the system that has more probably generated the browsing history. This attack can be formally defined as:\nProblem 1. Given user u’s web browsing historyHu = {l1, ...ln } which is consisted of n links, map u to a social media profile whose feed has most probably generated the browsing history [36].\nLet’s assume that each user u has a personalized set of recommender links. For example, this recommendation set could be a set of links appeared in the user’s social media Feed (e.g., Twitter) which includes links posted by the user’s friends on the network. Su et. al. [36] assume that each user visits links in his recommendation set. Given a browsing historyHu , the attacker finds the most likely recommendation set that corresponds to the given user u: the recommendation set which contains many of the URLs in the browsing history and is not too big. This de-identifies the browsing history. For the detailed proof and implementation of this attack please refer to [36]. Twitter is selected as a mapping platform for evaluation of this attack. This work shows that users’ activities in social media can be used to re-identify them. We next introduce the problem of web browsing history anonymization."
    }, {
      "heading" : "3.2 Problem Statement",
      "text" : "In this work, we define a privacy preserving framework which protects user’s privacy by combating the de-anonymizing web browsing history threat model we discussed in Section 3.1. In addition, utility here is also defined as user’s satisfaction of online personalized services. This could also be measured by comparing the quality of manipulated web browsing history after anonymization with the original one. Given user u’s browsing history Hu , the goal is to anonymize u’s browsing history by adding new links to Hu in an efficient manner, such that both the user’s privacy and utility are preserved, i.e., web browsing history is robust against de-identification attack and maintains its utility.\nWe first need to convert links to a structured dataset. One straightforward solution is to leverage the content of each web page and then map it to a category or a topic selected from a predefined set. This way, each user will be represented by a set of categories extracted from all of the web pages he has visited. One typical way for extracting topics is to manually define them (e.g., sports, fashion, knowledge, etc.) and then map each web page to the corresponding category. This method requires a set of keywords related to each topic and then inferring the web page’s topic by calculating the similarity of its textual content to the given keywords. This solution is not feasible in practice since it needs frequent updates of keywords for each category due to the fast growth of the Internet. Moreover, this only provides a coarse-grained categorization of web pages’ contents. In order to have a finer level of granularity we follow the same approach as in [29] and adopt Latent Dirichlet Allocation (LDA) topic modeling technique [8]. We use the following procedure to assign topics for each web page: (1) We retrieve a set of web pages to construct a corpus and then\nuse LDA to learn topic structures from the corpus. (2) For each web page, the learned topic model in the previous step\nis used to infer the topic proportion and topic assignment based on the textual content of the page. (3) The topic with highest probability from the topic distribution is selected as the representative topic of the page. We use T = {t1, ..., tm } to denote the set of learned topics. Then each link in the browsing historyHu is mapped to a topic in the topic set, tl ∈ T . Matrix Tu ∈ Rn×m is then used to represent the link-topic relationship for all the links in Hu where Tui j = 1 indicates that i-th link of user u is correlated to the topic tj . The problem of anonymizing browsing history of useru is then formally defined as:\nProblem 2. Given user u’s browsing historyHu , and link-topic matrix Tu , we seek to learn an anonymizer f to create a manipulated browsing history H̃u by adding links to Hu to preserve the privacy of user u while keeping the utility of H̃u for future applications.\nf : {Hu ,Tu } → {H̃u } (1)\nWe stress that links cannot be removed from the browsing history as all of user’s activities have been already recorded by ISPs."
    }, {
      "heading" : "4 A FRAMEWORK FOR PRIVACY BOOSTING",
      "text" : "The goal of the web browsing history anonymizer is to manipulate the user’s browsing history by adding links in a way that: 1) user privacy is preserved even when the adversary publishes the data with the weakest level of anonymization (i.e., just removing PIIs) and 2) browsing history still demonstrates user’s preferences so that the quality of personalized online services is preserved.\nAn immediate solution that may come to mind is to add links from popular web sites. This approach cannot preserve privacy as the adversary can easily remove popular links from the history and then deploy the attack. Another solution could be adding links from the browsing history of users who are very similar to u, i.e., his friends in social media. This approach can preserve the utility of browsing history but fail to make the user robust to the adversary attack. This is also observed in [36] where it was shown that the\nmore a user’s history contains links from his friends’ browsing activities in social media, the more fingerprints he leaves behind. All these emphasize the need for an effective solution which can handle the utility-privacy trade-off.\nIn this section we will discuss how our proposed algorithm PBooster, can handle utility-privacy trade-off. To better guide the PBooster and to assess the quality of the altered history, we need measures for quantifying the effect of adding links on user privacy and utility. We first present these measures and then detail the PBooster."
    }, {
      "heading" : "4.1 Measuring User Privacy",
      "text" : "The best case for user privacy is when a user’s visited links (i.e., interests) are distributed uniformly over different topics. This improves the user privacy by increasing ambiguity of his interests distribution. This makes it harder for the adversary to infer the real characteristic of the user’s preferences and then re-identify him by mapping his anonymized information to a real profile. Entropy is a metric which measures the degree of ambiguity. We leverage the entropy of the user’s browsing history distribution over a set of predefined topics as a measure of privacy.\nWe first introduce the topic-frequency vector cu ∈ Rm×1 as ⟨cu1, cu2, ..., cum⟩ for each user u, where cuj is the number of links in u’s history related to the topic tj . Note that ∑m j=1 cuj = |Hu | where |.| denotes the size of a set. The topic probability distribution for each user can be then defined as pu = J (cu ) = ⟨pu1,pu2, ...,pum⟩ where J is the normalization function of input vector cu where puj = cuj |Hu | and ∑m j=1 puj = 1. The privacy of user u, which is the degree of ambiguity of his browsing history, can be captured by the entropy of the topic probability distribution pu . This measures the spread of the user’s interests across different topics. Given topic probability distribution, privacy is measured as:\nPrivacy(pu ) = − m∑ j=1 puj logpuj (2)\nThe higher this metric is, the greater the user privacy. The optimal value of this measure is thus achieved when the user’s browsing links topics are distributed uniformly across the set of topics."
    }, {
      "heading" : "4.2 Measuring Utility Loss",
      "text" : "Utility or quality of online services is a measurement of a user’s satisfaction from the online personalized services he receives based on his online activities. Thismeasurement should be able to estimate the loss of quality of services after manipulating the user’s browsing history by the PBooster. We quantify utility loss as the difference between a user’s topic distribution before and after browsing history manipulation. Finding the difference between topic distributions has been exploited in other applications such as recommender systems [22]. We use the same notion used in [22] and quantify the utility loss between pu and p̂u as:\nutilityloss (pu , p̂u ) = 0.5 × (1 − sim(pu , p̂u )) (3)\nwhere p̂u denotes the new topic probability after manipulating history. One typical choice for the sim is cosine similarity [22]:\nsim(pu , p̂u ) = pu .p̂u ∥pu ∥.∥p̂u ∥\n(4)\nSince sim ∈ [−1, 1], the output of utilityloss function will be in [0, 1]. According to this measure, the minimum value for utility loss is when pu = p̂u and the maximum is reached when p̂u does not have any non-zero value in common with pu .\n4.3 PBooster Algorithm We have discussed so far how to quantify a user’s utility and privacy according to his browsing history. The goal is now to find a set of new links A to add to the browsing history such that, 1) privacy(p̂u ) is as large as possible, and 2) utilityloss (pu , p̂u ) is as small as possible. However, as we discussed earlier, the optimal value for privacy is reached when the user’s interests are spread uniformly across different topics, while the utility loss is minimized when no changes have been done to the topic distribution pu . This raises a trade-off issue between user’s privacy and utility loss. Simply put, maximizing privacy results in the loss of utility and vice versa. In order to optimize the trade-off between utility loss and privacy for each user u, we define a new scalar objective function:\nG(J (cu ), J (ĉu ), λ) = λ ∗ privacy(J (ĉu )) − utilityloss (J (cu ), J (ĉu )) (5)\nwhere ĉu is the topic-frequency vector after manipulating browsing history and λ controls the contribution of privacy in G. We aim to find a set of linksA by solving the following optimization problem:\nA∗ = argmax A G(J (cu ), J (ĉu ), λ) (6)\nwhere ĉu could be made from H̃u = Hu ∪ A. Topic distribution p̂u is constructed from ĉu accordingly. It’s notable to say that the value of λ has impact on the inferred set of linksA∗ in a sense that larger values of λ will lead to a browsing history H̃u with higher privacy while lower λ values result in lower utility loss.\nIt is worthwhile to mention that the search space for this problem (Eq.6) is exponential to N (O(m × 2N )), where N is the maximum of the number of links w.r.t. a topic. Considering this fact, it can be expensive and even infeasible to search for the optimal solution. We thus decide to approach this problem in an alternative way. We divide the optimization problem in Eq.6 into two subproblems : (1) Topic Selection: Selecting a subset of topics and calculating\nthe number of links which should be added to each topic in order to maximize the function G as follows:\na∗ = argmax a G(J (cu ), J (ĉu ), λ) (7)\nwhere a = ⟨a1, ..,am⟩ ∈ Rm×1 such that each non-zero element ai indicates the number of to-be added new links which are related to the topic ti . Zero value means that none of the new links are associatedwith the topic ti . Consequently, ĉu is defined as ĉu = ⟨cu1 +a1, .., cum +am⟩. This step indicates the number of links which should be added to each topic to maximize G. (2) Link Selection: Selecting a proper set of links which corresponds to the identified topics and their numbers found in the previous step.\nTo recap, the PBooster algorithm anonymizes a user’s browsing history by first selecting a subset of topics with the proper number of links for each topic (topic selection phase) and then finding corresponding links for each of them (link selection phase). Next, we will discuss the possible solutions for each step."
    }, {
      "heading" : "4.4 Topic Selection",
      "text" : "One brute-force solution to the optimization problem in Eq.7, is to evaluate all possible combinations of a set of topics with different sizes to find the best a∗. The exponential computational complexity of this algorithm makes it unacceptable and even impractical when quick results are required. We thus need a more efficient solution.\nAccording to a recent study [16], having more information in the browsing history will not necessarily increase either the utility or the privacy. In other words, with large information available on user’s preferences, observing a new link would have little to no impact on enhancing utility and privacy of the user. Simply put, adding more data to the history, could make the user less secured, with no specific improvement observed in the utility. The submodularity concept formally captures this intuition. A real valued function f is submodular if for a finite set E and two of its subsets X, Y where X ⊆ Y ⊆ E, and e ∈ E\\Y , the following property holds:\nf (X ∪ {e}) − f (X) ≥ f (Y ∪ {e}) − f (Y) (8) This means that adding one element {e} to the set X increases f more than adding {e} to the setY which is superset of X [28]. This intuitive diminishing return property exists in different areas such as social media networks and recommender systems. Recall from Eq. 5 that the function G is consisted of two components, namely privacy and utility loss. Given λ ∈ [0, 1] and topic-frequency vector cu , we can rewrite the optimization problem in Eq.7 as:\nargmax a − λ( ∑ j p̂uj logp̂uj ) − 0.5 × (1 − ∑ j puj p̂uj√∑\nj p 2 uj √∑ j p̂ 2 uj )\nsubject to − ĉuj ≤ −cuj , ĉuj ∈ N0\n(9)\nwhere p̂uj = ĉuj | H̃u |\nis the topic probability distribution after applying PBooster. Privacy is calculated using the entropy function which is submodular in the set of random variables [20]. The defined utility loss is also naturally submodular [22]. Since nonnegative linear combinations of submodular functions are submodular as well, the objective functionG is submodular.G is also non-monotone and thus the problem in Eq.9 is equal to maximizing a non-monotone nonnegative submodular function. This problem has been shown to be NP-hard [13] and there is no optimal solution for it in an efficient amount of time.\nHowever, the problem ofmaximizing non-monotone non-negative submodular function has been solved earlier [13]. A greedy local search algorithm, LS, has been introduced for solving this problem which was proved to guarantee a near-optimal solution. The greedy LS achieved a value of at least 13 of the optimal solution [13]. Formally speaking, if we assume solution aG is provided by the greedy LS algorithm, and ˆcG = cu + aG , and the optimal solution is aOPT, and OPT(cu ) = cu + aOPT, the following theorem holds:\nTheorem 4.1. If G(., .) is a nonnegative non-monotone submodular function, the set of topics aG found by the greedy algorithm has\nAlgorithm 1 Greedy local search for topic selection Input: topic-frequency vector cu , λ, ϵ Output: a = ⟨a1,a2, ...,am⟩ 1: Initialize a = ⟨0, 0, ..., 0⟩, ĉu = cu + a and val ←− 0 2: while there is increase in in value of G(J (cu ), J (ĉu ), λ) do 3: Select tj , j ∈ {1, ...,m} such that by updating aj ←− aj + 1\nand ĉu = cu + a, then G(J (cu ), J (ĉu ), λ) is maximazed 4: Update val ←− G(J (cu ), J (ĉu ), λ) 5: if ∃ tj such that updating aj ←− aj + 1 and ĉu = cu + a\nresults in G(J (cu ), J (ĉu ), λ) > (1 + ϵn2 ). val then 6: Update aj ←− aj + 1 , val ←− G(J (cu ), J (ĉu ), λ) 7: Repeat from step 5 8: end if 9: if ∃ tj such that aj ≥ 1 and updating aj ←− aj − 1 and\nĉu = cu + a results in G(J (cu ), J (ĉu ), λ) > (1 + ϵn2 ). val then 10: Update aj ←− aj − 1 , val ←− G(J (cu ), J (ĉu ), λ) 11: Repeat from step 5 12: end if 13: end while\nthe following lower bound [13]:\nG(J (cu ), J (ĉu ), λ) ≥ ( 1 3 − ϵ n )G(J (cu ), J (OPT(cu )), λ) (10)\nHere, ϵ > 0 is a small number. Local search algorithm iteratively adds an element to the final set or removes one from it to increase the value of G until no further improvement can be achieved. Algorithm 1 shows the topic selection algorithm which deploys the greedy local search. Elements of a = ⟨a1, ..,am⟩ will be increased or decreased iteratively to increase value of G until it cannot be improved anymore.\nWe emphasize that according to [13], there is no efficient algorithm which could select the best set of links to maximize aggregation of both privacy and utility in polynomial time. Following the Theorem 4.1, the proposed greedy algorithm can select a set with a lower bound of 13 of the optimal solution, providing the maximum user privacy and utility in polynomial time."
    }, {
      "heading" : "4.5 Link Selection",
      "text" : "Previously, we discussed the solution for selecting a subset of topics and the proper number of links for each topic to preserve user privacy while keeping the new topic distribution as close as possible to the original one. The second step in PBooster is to select links which correspond to the selected set of topics. Let us assume that user u has at least one active6 account on a social media site and PBooster has access to the list of user’s friends Fu , ∅.\nWe propose the following solution for the link selection problem. For each single update ω in the vector a, we randomly select a user v with a public social media profile from outside of the list of u’s friends, v < Fu . We then simulate v’s browsing historyH ′v , with the size of |H ′v | = q. The detail of this simulation is discussed in the next section. Link-topic relation matrix Tv will be constructed from the historyH ′v . If there is no link inH ′v which corresponds to the topic of ω, then the process will be repeated for another 6Here, user activity does not refer to posting contents. In this work, we assume a user as active if he visits his feed and have non-empty list of friends.\nAlgorithm 2 Link selection\nInput: Fu , q, a = ⟨a1,a2, ...,am⟩ Output: Set of links A 1: A = ∅ 2: for each update ω in a do 3: Let tj be the corresponding topic of update ω 4: Select a user v randomly such that v < Fu 5: Simulate a browsing historyH ′v for v with the size of q.\nMake cv and link-topic matrix Tu fromH ′v 6: if cv j = 0 then : Go to line 4 and repeat, else 7: Select a non-zero row r randomly from Tv [:, j] 8: Select corresponling link l to row r 9: A = A ∪ {l} 10: end if 11: end for\nrandom user, otherwise, a random related link will be chosen. The pseudocode of this algorithm is shown in Algorithm 2.\nTo recap, PBooster uses the greedy local search algorithm for submodular maximization to first find the topics which need to be updated and then infer the number of links which should be added to those topics in a way that user privacy and utility is maximized."
    }, {
      "heading" : "5 EXPERIMENTAL EVALUATION",
      "text" : "In this section we conduct experiments to evaluate the effectiveness of PBooster in terms of both privacy and utility. In particular, we seek to answer the following questions: (1) how successful is the proposed defense in protecting users’ privacy? (2) how does PBooster affect the quality of online services? (3) how successful is PBooster in handling privacy-utility trade-off?"
    }, {
      "heading" : "5.1 Dataset",
      "text" : "Su et al. [36] evaluate their de-anonymization strategy by examining it on a set of synthetically generated histories as well as real, usercontributed web browsing histories. Synthetic history is generated for a set of users based on their activities in social media. These users are selected semi-randomly from social media real-time streaming API– the more active a user is, the more likely he is to be chosen. The histories are simulated in a way that mimic users’ real online behaviors–they mostly click on links posted to their news feed, and sometimes click on links posted by their friends-of-friends [36]. These friends-of-friends links may be clicked due to the organic exploration behavior of people or the Social media’s algorithmic recommendation system that tries to get users visit their friendsof-friends links [35]. Their results on real user generated browsing history is consistent with the results of synthetic histories. This confirms the procedure of simulating synthetic browsing history as well as the efficiency of the generated data [36].\nSimilar to Su et al [36], we examine the performance of PBooster on a set of synthetically generated browsing history. We follow the same procedure as in [36] to simulate the browsing history dataset. To generate the synthetic history for each user u, friend’s links and friends-of-friends’ links are generated accordingly [36]. Friends’ links are generated by pulling links from a randomly selected friend of u. Friends-of-friends’ links are also generated by first picking\none of u’s friends, say v , uniformly at random, and then pulling a link from one ofv’s friends. Following [36], we select Twitter as the source of users’ activities to simulate data because of two reasons. First, many users activities on Twitter are public, and second Twitter has real-time API which helps avoid the need for large-scale web crawling. We select a total number of 1200 users and following [36], we generate histories of various sizes including {30, 50, 100} for each user. For each history, 16% of links are from friends-of-friends and the rest are from friends. Note that we only select links that are related to web pages in English to make the textual analysis easier."
    }, {
      "heading" : "5.2 Experiment Setting",
      "text" : "To simulate the real-world browsing situation, we divide the browsing history into |H\nu | h batches of links with size of h. These batches\nwill be added to the history incrementally and PBooster will anonymize the updated history after taking each batch. We set the values h = 25, q = 20 (used in link selection algorithm) and trade-off coefficient λ = {0, 0.1, 0.5, 1, 10, 20, 50, 70, 100}. We use LDA topic modeling from Python package gensim [30] and set the number of topicsm = 20 and LDA parameters α = 0.05, β = 0.05. We compare PBooster with the following baselines: • Random: Assuming x new links are added by PBooster, this approach selects x links randomly from the browsing history of users who are not fromu’s friends. Note that this method does not consider the topics of the links. We compare our model against this method to investigate whether the topics of the chosen links will have effect on the privacy of the users, or in other words, how well topic selection technique in Algorithm 1 performs? • JustFriends: This approach is quite similar to PBooster except that in the link selection phase, it adds links from a user’s friends’ simulated browsing history. We use this method to see how well our link selection technique in Algorithm 2 performs. • ISPPolluter7: The goal of this method is to eliminate the mutual information between actual browsing history and the manipulated one. According to [39] mutual information vanishes if:\nnNoise ≥ (nCalls − 1) × nPossibleCall (11) where nPossibleCall is the number of domains that a user might visit per day, and nCalls is the number of visited domains. For instance, if a user visits 100 domains and requests 200 calls per day, then ISPPolluter adds 20,000 links randomly to the history. We choose this method to see if eliminating mutual information can preserve privacy in practice."
    }, {
      "heading" : "5.3 Privacy Analysis",
      "text" : "To answer the first question, we first compare each user’s privacy before and after anonymization for browsing histories with size 100 (|Hu | = 100). Fig. 1 depicts box plots of the distributions of users’ privacy measured using Eq.2. The privacy-utility trade-off coefficient λ is also fixed to λ = 10. Results demonstrate how privacy increases after deploying PBooster in comparison to JustFriends approach and original history. This shows that adding links from friends cannot make significant change in privacy. This is because of Homophily effect [24]. The Random technique leads to the most uniform topics distribution and thus highest privacy among others. 7https://github.com/essandess/isp-data-pollution\nWe now evaluate the efficiency of PBooster against the deanonymization attack introduced in [36]. We measure the attack success rate by the metricX% = ncN ×100where nc is the total number of users that have been successfully mapped to their Twitter accounts, and N indicates the total number of users in the dataset. We consider the attack as successful if the user is among the top 10 results returned by the attack. Lower values of this measure translates to the higher privacy and stronger defense. We evaluate all methods on histories with different sizes. The results for browsing histories with different λ are demonstrated in Fig. 2. Note due to the lack of space, we have removed the similar trend that we observed for |Hu | = 30. We observe the following: • ISPPolluter does not work properly in practice and is not robust to the attack which leverages traces of users’ activities in social media. This confirms the idea of selecting links from non-friend users which inhibits the adversary to find the targeted user.\n• Random is more robust to the attack than PBooster and JustFriends. This demonstrates that adding random links from nonfriends could perform better in terms of privacy. • JustFriends decreases the privacy in comparison to the original history. This aligns well with the observations of [36] suggesting that adding links from friends can even decrease the privacy. • Attack success rate decreases to 15% after applying PBooster. We conclude that the generated history from PBooster is more robust to the attacks in comparison to original history and those generated from JustFriends and ISPPOlluter. This confirms the effectiveness of PBooster for preserving privacy. • PBooster performs better when |Hu | = 100. This means larger history can help PBooster to model user’s interests better and manipulate the history accordingly. • PBooster is much more robust than JustFriends. This clearly shows the efficiency of the link selection approach. • In PBooster,the attack success rate first decreases with the increase of λ and then it gets almost stable (for λ ≥ 10). This makes the selection of λ easier and suggests that the privacy will not increase significantly after some point, confirming that adding more links does not always necessarily lead to more privacy. • By deploying PBooster, the attack success rate decreases even when λ slightly changes from 0 to 0.1, which confirms the effectiveness of PBooster in anonymizing browsing histories. To study the effect of h (size of batches of links in browsing history), we repeat the attack with different values of h for |Hu | = 100 with λ = 10 which was empirically found to work well in our problem. Results are demonstrated in Table 1 suggesting that increasingh can help to model users’ preferences more accurately and PBooster can further decrease the traceability of users by making\nthe profiles more ambiguous. Although this increases the privacy, it increases the anonymization waiting time which could result in sudden publishing of history without proper anonymization."
    }, {
      "heading" : "5.4 Utility Analysis",
      "text" : "To answer the second question, we investigate the utility of the manipulated histories to estimate the change in quality of services. We evaluate the utility of manipulated history via a well-known machine learning task, i.e. clustering. Prior works [31, 37] have indicated the benefits of applying clustering in personalization which can help to offer similar services to same cluster of people.\nWe use k-means to cluster users into k = 5 groups based on their topic preferences distribution p̂u . We evaluate the utility of browsing histories according to the quality of generated clusters via Silhouette coefficient. Silhouette coefficient ranges from [−1, 1], where a higher value indicates better clusters while a negative value indicate that a sample has been assigned to the wrong cluster. Values near zero indicate overlapping clusters (i.e., all users are similar to each other). The results are demonstrated in Fig.3. The same trend was observed for |Hu | = 30 but we remove it due to space limitations. We make the following observations: • Clusters by ISPPolluter has the lowest Silhouette coefficient close to 0 (i.e., clusters are almost overlapping). This shows that adding a large number of random links results in making all users similar to each other and thus severe utility degradation. • The quality of clusters formed by Random decreases by increasing λ. This confirms that adding links randomly decreases the utility of browsing history and thus shows the importance of the topic and link selection phases. • JustFriends can even increase the utility of the manipulated browsing history. This is not surprising and the reason is that friends havemore similar tastes to each other than random people (Homophily effect [24]). Therefore, adding links from a friends’ history will not change the preferences distributions significantly. Utility also improves slightly with increase in value of λ. • Generated history by PBooster has better quality when |Hu | = 100 in comparison to |Hu | = 50. This shows that PBooster works better when more user’s information is fed to it. • The quality of clusters by PBooster decreases with increase in value of λ. The change is even sensible when λ ≥ 20. • The quality of data generated by PBooster is comparable to the original data when λ ≤ 10. Moreover, PBooster reaches the optimal point in privacy-utility trade-off by fixing λ = 10.\nWe repeat k-means with different values of h for |Hu | = 100 with λ = 10. Results are demonstrated in Table 2 and suggest that increasing h will lead to more accurate representation of users and thus improvement in the utility of data. However, as discussed earlier, the main drawback with increasing value of h is increasing the risk of sudden history publishing without proper anonymization."
    }, {
      "heading" : "5.5 Privacy-Utility Trade-off",
      "text" : "To answer the third question, we plot the privacy and utility gain values for each user after applying different approaches over histories with size 100. We measure the privacy by Eq.2 and utility gain as 1 − utilityloss using the Eq.3. Different colors and markers represent different approaches. Each marker represents a user, with measures over his manipulated history with h = 25 and λ = 10. • The original history gains the utility of 1 and the privacy to some extent. Random reaches the highest privacy but loses utility. JustFriends results in higher data utility gain in comparison to other methods but reaches a lower level of privacy. The result of PBooster varies for different users, achieving different levels of privacy and utility according to their original browsing behavior, whereas all users gain similar level of privacy by Random. • Users achieve higher privacy with PBooster than the original data comparing with other approaches. The achieved utility by PBooster is more than the utility by Random but less than the utility by JustFriends. The reason lies at the intrinsic trade-off between utility and privacy–higher privacy results in less utility. We compare the privacy and utility of browsing history manipulated by different techniques demonstrated in Fig.2 and Fig.3: • JustFriends achieves the highest utility among all approaches while it is the most vulnerable method. Random approach is the most robust technique against de-anonymization attack, however has the most utility lost. PBooster provides high privacy but can sacrifice utility for high values of λ (λ ≥ 20). • PBooster is the most efficient approach in terms of both privacy and utility. Setting λ = 10, it returns the highest possible privacy while maintaining comparable utility with the original data."
    }, {
      "heading" : "6 CONCLUSION AND FUTUREWORK",
      "text" : "The need arises for users to protect their sensitive information such as browsing history from potential adversaries. Some users resort to Tor, VPN and HTTPS to remove their traces from browsing history to assure their privacy. However, these solutions may hinder personalized online services by degrading the utility of browsing\nhistory. In this study, we first quantified the trade-off between user privacy and utility and then proposed an efficient framework PBooster to address the problem of anonymizing web browsing histories while retaining the utility. Our experiments demonstrate the efficiency of the proposed model by increasing the user privacy and preserving utility of browsing history for future applications. In future, we would like to investigate personalized utility-privacy trade-off, by tweaking framework parameters to fit specific needs of each user. We also plan to replicate the work by exploring other mechanisms for anonymizing web browsing histories. Last but not least, we would also like to collect real-world data and investigate the efficiency of PBooster in terms of both privacy and utility in practice."
    }, {
      "heading" : "ACKNOWLEDGMENTS",
      "text" : "This material is based upon the work supported, in part, by NSF #1614576, ARO W911NF-15-1-0328 and ONR N00014-17-1-2605."
    } ],
    "references" : [ {
      "title" : "Early Identification of Pathogenic Social Media Accounts",
      "author" : [ "Hamidreza Alvari", "Elham Shaabani", "Paulo Shakarian" ],
      "venue" : "In IEEE Intelligence and Security Informatics (ISI). IEEE",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2018
    }, {
      "title" : "Semi-supervised learning for detecting human trafficking",
      "author" : [ "Hamidreza Alvari", "Paulo Shakarian", "JE Kelly Snyder" ],
      "venue" : "Security Informatics",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2017
    }, {
      "title" : "OB-PWS: Obfuscationbased private web search",
      "author" : [ "Ero Balsa", "Carmela Troncoso", "Claudia Diaz" ],
      "venue" : "In Security and Privacy (SP),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Privacy in Social Media: Identification, Mitigation and Applications",
      "author" : [ "Ghazaleh Beigi", "Huan Liu" ],
      "venue" : "arXiv preprint arXiv:1808.02191",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2018
    }, {
      "title" : "Similar but Different: Exploiting Users’ Congruity for Recommendation Systems",
      "author" : [ "Ghazaleh Beigi", "Huan Liu" ],
      "venue" : "In International Conference on Social Computing,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2018
    }, {
      "title" : "Securing Social Media User Data: AnAdversarial Approach",
      "author" : [ "Ghazaleh Beigi", "Kai Shu", "Yanchao Zhang", "Huan Liu" ],
      "venue" : "In Proceedings of the 29th on Hypertext and Social Media",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2018
    }, {
      "title" : "Exploiting emotional information for trust/distrust prediction",
      "author" : [ "Ghazaleh Beigi", "Jiliang Tang", "Suhang Wang", "Huan Liu" ],
      "venue" : "In Proceedings of the 2016 SIAM international conference on data mining",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2016
    }, {
      "title" : "Latent dirichlet allocation",
      "author" : [ "DavidMBlei", "Andrew YNg", "andMichael I Jordan" ],
      "venue" : "Journal of machine Learning research",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2003
    }, {
      "title" : "Preserving userâĂŹs privacy in web search engines",
      "author" : [ "Jordi Castellà-Roca", "Alexandre Viejo", "Jordi Herrera-Joancomartí" ],
      "venue" : "Computer Communications 32,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2009
    }, {
      "title" : "Dissecting one click frauds",
      "author" : [ "Nicolas Christin", "Sally S Yanagihara", "Keisuke Kamataki" ],
      "venue" : "In Proceedings of ACM conference on Computer and communications security",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "A survey of query log privacy-enhancing techniques from a policy perspective",
      "author" : [ "Alissa Cooper" ],
      "venue" : "ACM Transactions on the Web (TWEB)",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    }, {
      "title" : "Online tracking: A 1-millionsite measurement and analysis",
      "author" : [ "Steven Englehardt", "Arvind Narayanan" ],
      "venue" : "In ACM SIGSAC Conference on Computer and Communications Security",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2016
    }, {
      "title" : "Maximizing non-monotone submodular functions",
      "author" : [ "Uriel Feige", "Vahab S Mirrokni", "Jan Vondrak" ],
      "venue" : "SIAM J. Comput. 40,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "Quantifying web-search privacy",
      "author" : [ "Arthur Gervais", "Reza Shokri", "Adish Singla", "Srdjan Capkun", "Vincent Lenders" ],
      "venue" : "In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "Publishing search logsâĂŤa comparative study of privacy guarantees",
      "author" : [ "Michaela Gotz", "Ashwin Machanavajjhala", "Guozhang Wang", "Xiaokui Xiao", "Johannes Gehrke" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering 24,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2012
    }, {
      "title" : "The Utility and Privacy Effects of a Click",
      "author" : [ "Rachid Guerraoui", "Anne-Marie Kermarrec", "Mahsa Taziki" ],
      "venue" : "In Proceedings of ACM",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2017
    }, {
      "title" : "TrackMeNot: Resisting surveillance in web search. Lessons from the Identity trail: Anonymity, privacy, and identity in a networked society",
      "author" : [ "Daniel C Howe", "Helen Nissenbaum" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "Differentially Private Matrix Factorization",
      "author" : [ "Jingyu Hua", "Chang Xia", "Sheng Zhong" ],
      "venue" : "In IJCAI",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2015
    }, {
      "title" : "A utility-theoretic approach to privacy in online services",
      "author" : [ "Andreas Krause", "Eric Horvitz" ],
      "venue" : "Journal of Artificial Intelligence Research",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2010
    }, {
      "title" : "Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies",
      "author" : [ "Andreas Krause", "Ajit Singh", "Carlos Guestrin" ],
      "venue" : "Journal of Machine Learning Research",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    }, {
      "title" : "Internet Jones and the Raiders of the Lost Trackers: An Archaeological Study of Web Tracking",
      "author" : [ "Adam Lerner", "Anna Kornfeld Simpson", "Tadayoshi Kohno", "Franziska Roesner" ],
      "venue" : "In USENIX Security Symposium",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2016
    }, {
      "title" : "SCENE: a scalable two-stage personalized news recommendation system",
      "author" : [ "Lei Li", "Dingding Wang", "Tao Li", "Daniel Knox", "Balaji Padmanabhan" ],
      "venue" : "In Proceedings ACM SIGIR",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2011
    }, {
      "title" : "Personalized social recommendations: accurate or private",
      "author" : [ "Ashwin Machanavajjhala", "Aleksandra Korolova", "Atish Das Sarma" ],
      "venue" : "Proceedings of the VLDB Endowment",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2011
    }, {
      "title" : "Birds of a feather: Homophily in social networks",
      "author" : [ "Miller McPherson", "Lynn Smith-Lovin", "James M Cook" ],
      "venue" : "Annual review of sociology 27,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2001
    }, {
      "title" : "Differentially private recommender systems: building privacy into the net",
      "author" : [ "Frank McSherry", "Ilya Mironov" ],
      "venue" : "In Proceedings of SIGKDD",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2009
    }, {
      "title" : "TrackMeOrNot: Enabling Flexible Control on Web Tracking",
      "author" : [ "Wei Meng", "Byoungyoung Lee", "Xinyu Xing", "Wenke Lee" ],
      "venue" : "In Proceedings of the 25th WWW",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2016
    }, {
      "title" : "De-anonymizing social networks",
      "author" : [ "Arvind Narayanan", "Vitaly Shmatikov" ],
      "venue" : "In Security and Privacy,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2009
    }, {
      "title" : "An analysis of approximations for maximizing submodular set functionsâĂŤI",
      "author" : [ "George LNemhauser", "Laurence AWolsey", "andMarshall L Fisher" ],
      "venue" : "Mathematical Programming 14,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1978
    }, {
      "title" : "Gender prediction using browsing history",
      "author" : [ "Tu Minh Phuong" ],
      "venue" : "In Knowledge and Systems Engineering",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2014
    }, {
      "title" : "Software framework for topic modelling with large corpora",
      "author" : [ "Radim Rehurek", "Petr Sojka" ],
      "venue" : "Proceedings of the LREC 2010Workshop on New Challenges for NLP Frameworks. Citeseer",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2010
    }, {
      "title" : "Recommender systems for large-scale e-commerce: Scalable neighborhood formation using clustering",
      "author" : [ "Badrul M Sarwar", "George Karypis", "Joseph Konstan", "John Riedl" ],
      "venue" : "In International conference on computer and information technology",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2002
    }, {
      "title" : "Privacy-preserving personalized recommendation: An instance-based approach via differential privacy",
      "author" : [ "Yilin Shen", "Hongxia Jin" ],
      "venue" : "In Proceedings of ICDM. IEEE",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2014
    }, {
      "title" : "EpicRec: towards practical differentially private framework for personalized recommendation",
      "author" : [ "Yilin Shen", "Hongxia Jin" ],
      "venue" : "In Proceedings of ACM SIGSAC. ACM",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2016
    }, {
      "title" : "Stochastic privacy",
      "author" : [ "Adish Singla", "Eric Horvitz", "Ece Kamar", "Ryen White" ],
      "venue" : "In AAAI",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2014
    }, {
      "title" : "The effect of recommendations on network structure",
      "author" : [ "Jessica Su", "Aneesh Sharma", "Sharad Goel" ],
      "venue" : "In Proceedings of WWW",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2016
    }, {
      "title" : "Deanonymizing web browsing data with social networks",
      "author" : [ "Jessica Su", "Ansh Shukla", "Sharad Goel", "Arvind Narayanan" ],
      "venue" : "In Proceedings of the 26th International Conference on World Wide Web",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2017
    }, {
      "title" : "Clustering methods for collaborative filtering",
      "author" : [ "Lyle H Ungar", "Dean P Foster" ],
      "venue" : "In AAAI workshop on recommendation systems,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1998
    }, {
      "title" : "Privacy-Preserving IR 2016: Differential Privacy, Search, and Social Media",
      "author" : [ "Hui Yang", "Ian Soboroff", "Li Xiong", "Charles LA Clarke", "Simson L Garfinkel" ],
      "venue" : "In ACM SIGIR",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2016
    }, {
      "title" : "Noise injection for search privacy protection",
      "author" : [ "Shaozhi Ye", "Felix Wu", "Raju Pandey", "Hao Chen" ],
      "venue" : "In Computational Science and Engineering,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2009
    }, {
      "title" : "Anonymizing query logs by differential privacy",
      "author" : [ "Sicong Zhang", "Hui Yang", "Lisa Singh" ],
      "venue" : "In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2016
    }, {
      "title" : "Anonymizing user profiles for personalized web search",
      "author" : [ "Yun Zhu", "Li Xiong", "Christopher Verdery" ],
      "venue" : "In WWW. ACM",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2010
    }, {
      "title" : "A privacy analysis of cross-device tracking",
      "author" : [ "Sebastian Zimmeck", "Jie S Li", "Hyungtae Kim", "Steven M Bellovin", "Tony Jebara" ],
      "venue" : "In 26th Security Symposium",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 35,
      "context" : "2 Assuming that ISPs and online trackers make browsing history data pseudonymous before sharing, a recent study has shown the fingerprintability of such data by introducing an attack which maps a given browsing history to a social media profile such as Twitter, Facebook, or Reddit accounts [36].",
      "startOffset" : 291,
      "endOffset" : 295
    }, {
      "referenceID" : 5,
      "context" : "This identity exposure may result in harms ranging from persecution by governments to targeted frauds [6, 10].",
      "startOffset" : 102,
      "endOffset" : 109
    }, {
      "referenceID" : 9,
      "context" : "This identity exposure may result in harms ranging from persecution by governments to targeted frauds [6, 10].",
      "startOffset" : 102,
      "endOffset" : 109
    }, {
      "referenceID" : 35,
      "context" : "protect users’ identities when such information is revealed because de-anonymization attacks will still work [36].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 37,
      "context" : "Traditional privacy preserving web search techniques such as [38, 40, 41] are designed for different",
      "startOffset" : 61,
      "endOffset" : 73
    }, {
      "referenceID" : 39,
      "context" : "Traditional privacy preserving web search techniques such as [38, 40, 41] are designed for different",
      "startOffset" : 61,
      "endOffset" : 73
    }, {
      "referenceID" : 40,
      "context" : "Traditional privacy preserving web search techniques such as [38, 40, 41] are designed for different",
      "startOffset" : 61,
      "endOffset" : 73
    }, {
      "referenceID" : 0,
      "context" : "Explosive growth of the Web has not only drastically changed the way people conduct activities and acquire information, but also has raised security [1, 2] and privacy [4, 6, 27] issues for them.",
      "startOffset" : 149,
      "endOffset" : 155
    }, {
      "referenceID" : 1,
      "context" : "Explosive growth of the Web has not only drastically changed the way people conduct activities and acquire information, but also has raised security [1, 2] and privacy [4, 6, 27] issues for them.",
      "startOffset" : 149,
      "endOffset" : 155
    }, {
      "referenceID" : 3,
      "context" : "Explosive growth of the Web has not only drastically changed the way people conduct activities and acquire information, but also has raised security [1, 2] and privacy [4, 6, 27] issues for them.",
      "startOffset" : 168,
      "endOffset" : 178
    }, {
      "referenceID" : 5,
      "context" : "Explosive growth of the Web has not only drastically changed the way people conduct activities and acquire information, but also has raised security [1, 2] and privacy [4, 6, 27] issues for them.",
      "startOffset" : 168,
      "endOffset" : 178
    }, {
      "referenceID" : 26,
      "context" : "Explosive growth of the Web has not only drastically changed the way people conduct activities and acquire information, but also has raised security [1, 2] and privacy [4, 6, 27] issues for them.",
      "startOffset" : 168,
      "endOffset" : 178
    }, {
      "referenceID" : 11,
      "context" : "In the area of user tracking and profiling, there have been efforts to study how and to what degree that web browser tracking [12, 21, 26] and cross-device tracking [42] can be done by third parties.",
      "startOffset" : 126,
      "endOffset" : 138
    }, {
      "referenceID" : 20,
      "context" : "In the area of user tracking and profiling, there have been efforts to study how and to what degree that web browser tracking [12, 21, 26] and cross-device tracking [42] can be done by third parties.",
      "startOffset" : 126,
      "endOffset" : 138
    }, {
      "referenceID" : 25,
      "context" : "In the area of user tracking and profiling, there have been efforts to study how and to what degree that web browser tracking [12, 21, 26] and cross-device tracking [42] can be done by third parties.",
      "startOffset" : 126,
      "endOffset" : 138
    }, {
      "referenceID" : 41,
      "context" : "In the area of user tracking and profiling, there have been efforts to study how and to what degree that web browser tracking [12, 21, 26] and cross-device tracking [42] can be done by third parties.",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 33,
      "context" : "com/FascinatedBox/RuinMyHistory the protection of users from tracking and profiling, strategies such as limiting the access to sampled user profiles [34] and distorting",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 8,
      "context" : "the user profile [9] are proposed to minimize privacy risk.",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 10,
      "context" : "One group of works focused on the protection of post-hoc logs [11, 15, 40].",
      "startOffset" : 62,
      "endOffset" : 74
    }, {
      "referenceID" : 14,
      "context" : "One group of works focused on the protection of post-hoc logs [11, 15, 40].",
      "startOffset" : 62,
      "endOffset" : 74
    }, {
      "referenceID" : 39,
      "context" : "One group of works focused on the protection of post-hoc logs [11, 15, 40].",
      "startOffset" : 62,
      "endOffset" : 74
    }, {
      "referenceID" : 2,
      "context" : "ones focuses on search query obfuscation [3, 14, 17, 39].",
      "startOffset" : 41,
      "endOffset" : 56
    }, {
      "referenceID" : 13,
      "context" : "ones focuses on search query obfuscation [3, 14, 17, 39].",
      "startOffset" : 41,
      "endOffset" : 56
    }, {
      "referenceID" : 16,
      "context" : "ones focuses on search query obfuscation [3, 14, 17, 39].",
      "startOffset" : 41,
      "endOffset" : 56
    }, {
      "referenceID" : 38,
      "context" : "ones focuses on search query obfuscation [3, 14, 17, 39].",
      "startOffset" : 41,
      "endOffset" : 56
    }, {
      "referenceID" : 4,
      "context" : "Recommendation systems help individuals find relevant information, however, these systems can also raise privacy concerns for users [5].",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 22,
      "context" : "Differential privacy based approaches [23, 25, 32] add noise to recommendation results so that the distribution of results is insensitive to the records of any specific user.",
      "startOffset" : 38,
      "endOffset" : 50
    }, {
      "referenceID" : 24,
      "context" : "Differential privacy based approaches [23, 25, 32] add noise to recommendation results so that the distribution of results is insensitive to the records of any specific user.",
      "startOffset" : 38,
      "endOffset" : 50
    }, {
      "referenceID" : 31,
      "context" : "Differential privacy based approaches [23, 25, 32] add noise to recommendation results so that the distribution of results is insensitive to the records of any specific user.",
      "startOffset" : 38,
      "endOffset" : 50
    }, {
      "referenceID" : 17,
      "context" : "Privacy-preserving matrix factorization schemes [18] are designed to avoid exposure of user information during the recommender’s computation.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 6,
      "context" : "Matrix factorization has been used in many applications such as recommendation systems and trust/distrust prediction [7].",
      "startOffset" : 117,
      "endOffset" : 120
    }, {
      "referenceID" : 18,
      "context" : "Another work [19] studies sharing user attributes to recommenders while handling the trade-off between privacy and quality of received service.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 32,
      "context" : "Recent work [33] also studied utilityprivacy trade-off.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 35,
      "context" : "feed has most probably generated the browsing history [36].",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 35,
      "context" : "[36] assume that each user visits links in his recommendation set.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 35,
      "context" : "For the detailed proof and implementation of this attack please refer to [36].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 28,
      "context" : "In order to have a finer level of granularity we follow the same approach as in [29] and adopt Latent Dirichlet Allocation (LDA) topic modeling technique [8].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 7,
      "context" : "In order to have a finer level of granularity we follow the same approach as in [29] and adopt Latent Dirichlet Allocation (LDA) topic modeling technique [8].",
      "startOffset" : 154,
      "endOffset" : 157
    }, {
      "referenceID" : 35,
      "context" : "This is also observed in [36] where it was shown that the",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 21,
      "context" : "We use the same notion used in [22] and quantify the utility loss between pu and p̂u as:",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 21,
      "context" : "One typical choice for the sim is cosine similarity [22]:",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 15,
      "context" : "According to a recent study [16], having more information in the browsing history will not necessarily increase either the utility or the privacy.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 27,
      "context" : "This means that adding one element {e} to the set X increases f more than adding {e} to the setY which is superset of X [28].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 19,
      "context" : "Privacy is calculated using the entropy function which is submodular in the set of random variables [20].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 21,
      "context" : "The defined utility loss is also naturally submodular [22].",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 12,
      "context" : "This problem has been shown to be NP-hard [13] and there is no optimal solution for it in an efficient amount of time.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 12,
      "context" : "However, the problem ofmaximizing non-monotone non-negative submodular function has been solved earlier [13].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 12,
      "context" : "LS achieved a value of at least (1)3 of the optimal solution [13].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 12,
      "context" : "We emphasize that according to [13], there is no efficient algorithm which could select the best set of links to maximize aggregation of both privacy and utility in polynomial time.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 35,
      "context" : "[36] evaluate their de-anonymization strategy by examining it on a set of synthetically generated histories as well as real, usercontributed web browsing histories.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 35,
      "context" : "and sometimes click on links posted by their friends-of-friends [36].",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 34,
      "context" : "These friends-of-friends links may be clicked due to the organic exploration behavior of people or the Social media’s algorithmic recommendation system that tries to get users visit their friendsof-friends links [35].",
      "startOffset" : 212,
      "endOffset" : 216
    }, {
      "referenceID" : 35,
      "context" : "This confirms the procedure of simulating synthetic browsing history as well as the efficiency of the generated data [36].",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 35,
      "context" : "Similar to Su et al [36], we examine the performance of PBooster on a set of synthetically generated browsing history.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 35,
      "context" : "same procedure as in [36] to simulate the browsing history dataset.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 35,
      "context" : "To generate the synthetic history for each user u, friend’s links and friends-of-friends’ links are generated accordingly [36].",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 35,
      "context" : "Following [36], we select Twitter as the",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 35,
      "context" : "We select a total number of 1200 users and following [36], we generate histories of various sizes including {30, 50, 100} for",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 29,
      "context" : "We use LDA topic modeling from Python package gensim [30] and set the number of topicsm = 20 and LDA parameters α = 0.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 38,
      "context" : "According to [39] mutual information vanishes if:",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 23,
      "context" : "This is because of Homophily effect [24].",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 35,
      "context" : "We now evaluate the efficiency of PBooster against the deanonymization attack introduced in [36].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 35,
      "context" : "This aligns well with the observations of [36] suggesting that adding links from friends can even decrease the privacy.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 30,
      "context" : "Prior works [31, 37] have indicated the benefits of applying clustering in personalization which can help to offer similar services to same cluster of people.",
      "startOffset" : 12,
      "endOffset" : 20
    }, {
      "referenceID" : 36,
      "context" : "Prior works [31, 37] have indicated the benefits of applying clustering in personalization which can help to offer similar services to same cluster of people.",
      "startOffset" : 12,
      "endOffset" : 20
    }, {
      "referenceID" : 23,
      "context" : "This is not surprising and the reason is that friends havemore similar tastes to each other than random people (Homophily effect [24]).",
      "startOffset" : 129,
      "endOffset" : 133
    } ],
    "year" : 2018,
    "abstractText" : "The overturning of the Internet Privacy Rules by the Federal Communications Commissions (FCC) in late March 2017 allows Internet Service Providers (ISPs) to collect, share and sell their customers’ Web browsing data without their consent. With third-party trackers embedded on Web pages, this new rule has put user privacy under more risk. The need arises for users on their own to protect their Web browsing history from any potential adversaries. Although some available solutions such as Tor, VPN, and HTTPS can help users conceal their online activities, their use can also significantly hamper personalized online services, i.e., degraded utility. In this paper, we design an effective Web browsing history anonymization scheme, PBooster, aiming to protect users’ privacy while retaining the utility of their Web browsing history. The proposed model pollutes users’ Web browsing history by automatically inferring how many and what links should be added to the history while addressing the utility-privacy trade-off challenge. We conduct experiments to validate the quality of the manipulated Web browsing history and examine the robustness of the proposed approach for user privacy protection.",
    "creator" : "LaTeX with acmart 2018/02/07 v1.50 Typesetting articles for the Association for Computing Machinery and hyperref 2016/06/24 v6.83q Hypertext links for LaTeX"
  }
}