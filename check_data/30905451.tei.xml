<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learned Optimizers that Scale and Generalize</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Wichrowska</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niru</forename><surname>Maheswaranathan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>GÃ³mez Colmenarejo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Denil</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
						</author>
						<title level="a" type="main">Learned Optimizers that Scale and Generalize</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Learning to learn has emerged as an important direction for achieving artificial intelligence. Two of the primary barriers to its adoption are an inability to scale to larger problems and a limited ability to generalize to new tasks. We introduce a learned gradient descent optimizer that generalizes well to new tasks, and which has significantly reduced memory and computation overhead. We achieve this by introducing a novel hierarchical RNN architecture, with minimal perparameter overhead, augmented with additional architectural features that mirror the known structure of optimization tasks. We also develop a meta-training ensemble of small, diverse optimization tasks capturing common properties of loss landscapes. The optimizer learns to outperform RMSProp/ADAM on problems in this corpus. More importantly, it performs comparably or better when applied to small convolutional neural networks, despite seeing no neural networks in its meta-training set. Finally, it generalizes to train Inception V3 and ResNet V2 architectures on the ImageNet dataset for thousands of steps, optimization problems that are of a vastly different scale than those it was trained on. We release an open source implementation of the meta-training algorithm.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Optimization is a bottleneck for almost all tasks in machine learning, as well as in many other fields, including engineering, design, operations research, and statistics. Advances in optimization therefore have broad impact. Historically, optimization has been performed using hand-designed algorithms. Recent results in machine learning show that, given sufficient data, well-trained neural networks often outperform hand-tuned approaches on supervised tasks. This raises the tantalizing possibility that neural networks may be able to outperform hand-designed optimizers.</p><p>Despite the promise in this approach, previous work on learned RNN optimizers for gradient descent has failed to produce neural network optimizers that generalize to new problems, or that continue to make progress on the problems for which they were meta-trained when run for large numbers of steps (see <ref type="figure">Figure 2</ref>). Current neural network optimizers are additionally too costly in both memory and computation to scale to larger problems.</p><p>We address both of these issues. Specifically, we improve upon existing learned optimizers by:</p><p>1. Developing a meta-training set that consists of an ensemble of small tasks with diverse loss landscapes 2. Introducing a hierarchical RNN architecture with lower memory and compute overhead, and which is capable of capturing inter-parameter dependencies.</p><p>3. Incorporating features motivated by successful handdesigned optimizers into the RNN, so that it can build on existing techniques. These include dynamically adapted input and output scaling, momentum at multiple time scales, and a cross between Nesterov momentum and RNN attention mechanisms.</p><p>4. Improving the meta-optimization pipeline, for instance by introducing a meta-objective that better encourages exact convergence of the optimizer, and by drawing the number of optimization steps during training from a heavy tailed distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Learning to learn has a long history in psychology <ref type="bibr" target="#b33">(Ward, 1937;</ref><ref type="bibr" target="#b10">Harlow, 1949;</ref><ref type="bibr" target="#b13">Kehoe, 1988;</ref><ref type="bibr" target="#b16">Lake et al., 2016)</ref>. Inspired by it, machine learning researchers have proposed meta-learning techniques for optimizing the process of learning itself. <ref type="bibr" target="#b24">Schmidhuber (1987)</ref>, for example, considers networks that are able to modify their own weights. arXiv:1703.04813v4 <ref type="bibr">[cs.LG]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Sep 2017</head><p>This leads to end-to-end differentiable systems which allow, in principle, for extremely general update strategies to be learned. There are many works related to this idea, including <ref type="bibr" target="#b27">(Sutton, 1992;</ref><ref type="bibr" target="#b18">Naik &amp; Mammone, 1992;</ref><ref type="bibr" target="#b29">Thrun &amp; Pratt, 1998;</ref><ref type="bibr" target="#b12">Hochreiter et al., 2001;</ref><ref type="bibr" target="#b23">Santoro et al., 2016)</ref>.</p><p>A series of papers from <ref type="bibr">Bengio et al. (1990;</ref><ref type="bibr" target="#b27">1992;</ref><ref type="bibr" target="#b2">1995)</ref> presents methods for learning parameterized local neural network update rules that avoid back-propagation. <ref type="bibr" target="#b22">Runarsson &amp; Jonsson (2000)</ref> extend this to more complex update models. The result of meta learning in these cases is an algorithm, i.e. a local update rule. <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref> learn to learn by gradient descent by gradient descent. Rather than trying to distill a global objective into a local rule, their work focuses on learning how to integrate gradient observations over time in order to achieve fast learning of the model. The component-wise structure of the algorithm allows a single learned algorithm to be applied to new problems of different dimensionality. While <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref> consider the issue of transfer to different datasets and model structures, they focus on transferring to problems of the same class. In fact, they report negative results when transferring optimizers, meta-trained to optimize neural networks with logistic functions, to networks with ReLU functions. <ref type="bibr" target="#b17">Li &amp; Malik (2017)</ref> proposed an approach similar to <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref>, around the same time, but they rely on policy search to compute the meta-parameters of the optimizer. That is, they learn to learn by gradient descent by reinforcement learning.</p><p>Zoph &amp; Le (2017) also meta-train a controller RNN, but this time to produce a string in a custom domain specific language (DSL) for describing neural network architectures. An architecture matching the produced configuration (the "child" network) is instantiated and trained in the ordinary way. In this case the meta-learning happens only at the network architecture level.</p><p>Ravi &amp; Larochelle (2017) modify the optimizer of <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref> for 1 and 5-shot learning tasks. They use test error to optimize the meta learner. These tasks have the nice property that the recurrent neural networks only need to be unrolled for a small number of steps. <ref type="bibr" target="#b32">Wang et al. (2016)</ref> show that it is possible to learn to solve reinforcement learning tasks by reinforcement learning. They demonstrate their approach on several examples from the bandits and cognitive science literature. A related approach was proposed by <ref type="bibr" target="#b8">Duan et al. (2016)</ref>.</p><p>Finally, <ref type="bibr" target="#b6">Chen et al. (2016)</ref> also learn reinforcement learning, but by supervised meta-training of the meta-learner. They apply their methods to black-box function optimiza-tion tasks, such as Gaussian process bandits, simple lowdimensional controllers, and hyper-parameter tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Architecture</head><p>At a high level, a hierarchical RNN is constructed to act as a learned optimizer, with its architecture matched to the parameters in the target problem. The hierarchical RNN's parameters (called meta-parameters) are shared across all target problems, so despite having an architecture that adapts to the target problem, it can be applied to new problems. At each optimization step, the learned optimizer receives the gradients for every parameter along with some additional quantities derived from the gradients, and outputs an update to the parameters. <ref type="figure">Figure 1</ref> gives an overview.  <ref type="figure">Figure 1</ref>. Hierarchical RNN architecture. At the lowest level, a small Parameter RNN processes the inputs and outputs (Section 3.3) for every parameter (Î¸ij) in the target problem. At the intermediate level, a medium-sized Tensor RNN exists for every parameter tensor (denoted by Î¸i) in the target problem. It takes as input the average latent state across all Parameter RNNs belonging to the same tensor. Its output enters those same Parameter RNNs as a bias term. At the top level, a single Global RNN receives as input the average hidden state of all Parameter RNNs, and its output enters the Tensor RNNs as a bias term and is added to the Parameter RNN bias term. This architecture has low perparameter overhead, while the Tensor RNNs are able to capture inter-parameter dependencies, and the Global RNN is able to capture inter-tensor dependencies.</p><formula xml:id="formula_0">[â 1 ] 1 [â 1 ] 2 [â 1 ] [â 2 ] 1 [â 2 ] 2 [â i ] j E[â¢] E[â¢] E[â¢]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Hierarchical architecture</head><p>In order to effectively scale to large problems, the optimizer RNN must stay quite small while maintaining enough flexibility to capture inter-parameter dependencies that shape the geometry of the loss surface. Optimizers that account for this second order information are often particularly effective (e.g. quasi-Newton approaches). We propose a novel hierarchical architecture to enable both low per-parameter computational cost, and aggregation of gradient information and coordination of update steps across parameters <ref type="figure">(Figure 1)</ref>. At the lowest level of the hierarchy, we have a small Parameter RNN that receives direct perparameter (scalar) gradient inputs. One level up, we have an intermediate Tensor RNN that incorporates information from a subset of the Parameter RNNs (where the subsets are problem specific). For example, consider a feedforward fully-connected neural network. There would be a Tensor RNN for each layer of the network, where each layer contains an (nÃm) weight matrix and therefore nm Parameter RNNs.</p><p>At the highest level of the hierarchy is a Global RNN which receives output from every Tensor RNN. This allows the Parameter RNN to have very few hidden units with larger Tensor and Global RNNs keeping track of problem-level information. The Tensor and Global RNNs can also serve as communication channels between Parameter and Tensor RNNs respectively. The Tensor RNN outputs are fed as biases to the Parameter RNN, and the new parameter state is averaged and fed as input to the Tensor RNN. Similarly, the Global RNN state is fed as a bias to each Tensor RNN, and the output of the Tensor RNNs is averaged and fed as input to the Global RNN ( <ref type="figure">Figure 1</ref>).</p><p>The architecture used in the experimental results has a Parameter RNN hidden state size of 10, and a Tensor and Global RNN state size of 20 (the architecture used by <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref> had a two layer RNN for each parameter, with 20 units per layer). These sizes showed the best generalization to ConvNets and other complex test problems. Experimentally, we found that we could make the Parameter RNN as small as 5, and the Tensor RNN as small as 10 and still see good performance on most problems. We also found that the performance decreased slightly even on simple test problems if we removed the Global RNN entirely. We used a GRU architecture <ref type="bibr" target="#b7">(Cho et al., 2014)</ref> for all three of the RNN levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Features inspired by optimization literature</head><p>The best performing neural networks often have knowledge about task structure baked into their design. Examples of this include convolutional models for image processing <ref type="bibr" target="#b15">(Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b11">He et al., 2016)</ref>, causal models (RNNs) for modeling causal time series data, and the merging of neural value functions with Monte Carlo tree search in AlphaGo <ref type="bibr" target="#b25">(Silver et al., 2016)</ref>.</p><p>We similarly incorporate knowledge of effective strategies for optimization into our network architecture. We emphasize that these are not arbitrary design choices. The features below are motivated by results in optimization and recurrent network literature. They are also individually important to the ability of the learned optimizer to generalize to new problems, as is illustrated by the ablation study in Section 5.5 and <ref type="figure">Figure 6</ref>.</p><p>Let L (Î¸) be the loss of the target problem, where Î¸ = {Î¸ 1 , ..., Î¸ N T } is the set of all parameter tensors Î¸ t (e.g. all weight matrices and bias vectors in a neural network). At each training iteration n, each parameter tensor t is updated as Î¸ n+1 t = Î¸ n t + âÎ¸ n t , where the update step âÎ¸ n t is set by the learned optimizer (Equation 5 below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">ATTENTION AND NESTEROV MOMENTUM</head><p>Nesterov momentum <ref type="bibr" target="#b19">(Nesterov, 1983a</ref>) is a powerful optimization approach, where parameter updates are based not on the gradient evaluated at the current iterate Î¸ n , but rather at a location Ï n which is extrapolated ahead of the current iterate. Similarly, attention mechanisms have proven extremely powerful in recurrent translation models <ref type="bibr" target="#b1">(Bahdanau et al., 2015)</ref>, decoupling the iteration n of RNN dynamics from the observed portion of the input sequence. Motivated by these successes, we incorporate an attention mechanism that allows the optimizer to explore new regions of the loss surface by computing gradients away (or ahead) from the current parameter position. At each training step n the attended location is set as Ï n+1 t = Î¸ n t +âÏ n t , where the offset âÏ n t is further described by Equation 6 below. Note that the attended location is an offset from the previous parameter location Î¸ n rather than the previous attended location Ï n .</p><p>The gradient g n of the loss L (Î¸) with respect to the attended parameter values Ï n will provide the only input to the learned optimizer, though it will be further transformed before being passed to the hierarchical RNN. For every parameter tensor t, g n t = âL âÏ n t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">MOMENTUM ON MULTIPLE TIMESCALES</head><p>Momentum with an exponential moving average is typically motivated in terms of averaging away minibatch noise or high frequency oscillations, and is often a very effective feature <ref type="bibr" target="#b20">(Nesterov, 1983b;</ref><ref type="bibr" target="#b31">Tseng, 1998)</ref>. We provide the learned optimizer with exponential moving averagesá¸¡ ts of the gradients on several timescales, where s indexes the timescale of the average. The update equation for the moving average is</p><formula xml:id="formula_1">g n+1 ts =á¸¡ n ts Ï Î² n gt 2 âs + g n t 1 â Ï Î² n gt 2 âs ,<label>(1)</label></formula><p>where the Ï indicates the sigmoid function, and where the momentum logit Î² n gt for the shortest s = 0 timescale is output by the RNN, and the remaining timescales each increase by a factor of two from that baseline.</p><p>By comparing the moving averages at multiple timescales, the learned optimizer has access to information about how rapidly the gradient is changing with training time (a mea-sure of loss surface curvature), and about the degree of noise in the gradient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">DYNAMIC INPUT SCALING</head><p>We would like our optimizer to be invariant to parameter scale. Additionally, RNNs are most easily trained when their inputs are well conditioned, and have a similar scale as their latent state. In order to aid each of these goals, we rescale the average gradients in a fashion similar to what is done in RMSProp <ref type="bibr" target="#b30">(Tieleman &amp; Hinton, 2012)</ref>, ADAM <ref type="bibr" target="#b14">(Kingma &amp; Ba, 2015)</ref>, and SMORMS3 <ref type="bibr" target="#b9">(Funk, 2015)</ref>,</p><formula xml:id="formula_2">Î» n+1 ts = Î» n ts Ï (Î² n Î»t ) 2 âs + (á¸¡ n ts ) 2 1 â Ï (Î² n Î»t ) 2 âs (2) m n ts =á¸¡ n ts Î» n ts ,<label>(3)</label></formula><p>where Î» n ts is a running average of the square average gradient, m n ts is the scaled averaged gradient, and the momentum logit Î² n Î»t for the shortest s = 0 timescale will be output by the RNN, similar to how the timescales for momentum are computed in the previous section.</p><p>It may be useful for the learned optimizer to have access to how gradient magnitudes are changing with training time. We therefore provide as further input a measure of relative gradient magnitudes at each averaging scale s. Specifically, we provide the relative log gradient magnitudes,</p><formula xml:id="formula_3">Î³ n ts = log Î» n ts â E s [log Î» n ts ] .<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4.">DECOMPOSITION OF OUTPUT INTO DIRECTION AND STEP LENGTH</head><p>Another aspect of RMSProp and ADAM is that the learning rate corresponds directly to the characteristic step length. This is true because the gradient is scaled by a running estimate of its standard deviation, and after scaling has a characteristic magnitude of 1. The length of update steps therefore scales linearly with the learning rate, but is invariant to any scaling of the gradients.</p><p>We enforce a similar decomposition of the parameter updates into update directions d n Î¸ and d n Ï for parameters and attended parameters, with corresponding step lengths exp (Î· n Î¸ ) and exp Î· n Ï ,</p><formula xml:id="formula_4">âÎ¸ n t = exp (Î· n Î¸t ) d n Î¸t ||d n Î¸t || /N t ,<label>(5)</label></formula><formula xml:id="formula_5">âÏ n t = exp Î· n Ï d n Ït d n Ït /N t ,<label>(6)</label></formula><p>where N t is the number of elements in the parameter tensor Î¸ t . The directions d n Î¸t and d n Ït are read directly out of the RNN (though see B.1 for subtleties).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relative learning rate</head><p>We want the performance of the optimizer to be invariant to parameter scale. This requires that the optimizer judge the correct step length from the history of gradients, rather than memorizing the range of step lengths that were useful in its meta-training ensemble. The RNN therefore controls step length by outputing a multiplicative (additive after taking a logarithm) change, rather than by outputing the step length directly, step length Î· n Î¸ is related to Î· n Î¸ by a meta-learned constant offset c,</p><formula xml:id="formula_6">Î· n Ï = Î· n Î¸ + c.<label>(9)</label></formula><p>To further force the optimizer to dynamically adapt the learning rate rather than memorizing a learning rate trajectory, the learning rate is initialized from a log uniform distribution from 10 â6 to 10 â2 . We emphasize that the RNN has no direct access to the learning rate, so it must adjust it based purely on its observations of the statistics of the gradients.</p><p>In order to aid in coordination across parameters, we do provide the RNN as an input the relative log learning rate of each parameter, compared to the remaining parameters,</p><formula xml:id="formula_7">Î· n rel = Î· n Î¸ â E ti [Î· n Î¸ti ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimizer inputs and outputs</head><p>As described in the preceding sections, the full set of Parameter RNN inputs for each tensor t are x n t = {m n t , Î³ n t , Î· n rel }, corresponding to the scaled averaged gradients, the relative log gradient magnitudes, and the relative log learning rate.</p><p>The full set of Parameter RNN outputs for each tensor t are</p><formula xml:id="formula_8">y n t = d n Î¸t , d n Ït , âÎ· n Î¸t , Î² n gt , Î² n</formula><p>Î»t , corresponding to the parameter and attention update directions, the change in step length, and the momentum logits. Each of the outputs in y n t is read out via a learned affine transformation of the Parameter RNN hidden state. The readout biases are clamped to 0 for d n Î¸ and d n Ï . The RNN update equations are then:</p><formula xml:id="formula_9">h n+1 Param = ParamRNN(x n , h n Param , h n Tensor , h n Global ) (10) h n+1 Tensor = TensorRNN(x n , h n+1 Param , h n Tensor , h n Global ) (11) h n+1 Global = GlobalRNN(x n , h n+1 Param , h n+1 Tensor , h n Global ) (12) y n = Wh n Param + b,<label>(13)</label></formula><p>where h n is the hidden state for each level of the RNN, as described in Section 3.1, and W and b are learned weights of the affine transformation from the lowest level hidden state to output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Compute and memory cost</head><p>The computational cost of the learned optimizer is</p><formula xml:id="formula_10">O N P B + N P K 2 P + N T K 2 T + K 2 G ,</formula><p>where B is the minibatch size, N P is the total number of parameters, N T is the number of parameter tensors, and K P , K T , and K G are the latent sizes for Parameter, Tensor, and Global RNNs respectively. Typically, we are in the regime where</p><formula xml:id="formula_11">N P K 2 P N T K 2 T &gt; K 2</formula><p>G , in which case the computational cost simplifies to O N P B + N P K 2 P . Note that as the minibatch size B is increased, the computational cost of the learned optimizer approaches that of vanilla SGD, as the cost of computing the gradient dominates the cost of computing the parameter update.</p><p>The memory cost of the learned optimizer is O (N P + N P K P + N T K T + K G ), which similarly to computational cost typically reduces to O (N P + N P K P ). So long as the latent size K P of the Parameter RNN can be kept small, the memory overhead will also remain small.</p><p>We show experimental results for computation time in Section 5.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Meta-training</head><p>The RNN optimizer is meta-trained by a standard optimizer on an ensemble of target optimization tasks. We call this process meta-training, and the parameters of the RNN optimizer the meta-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Meta-training set</head><p>Previous learned optimizers have failed to generalize beyond the problem on which they were meta-trained. In order to address this, we meta-train the optimizer on an ensemble of small problems, which have been chosen to capture many commonly encountered properties of loss landscapes and stochastic gradients. By meta-training on small toy problems, we also avoid memory issues we would encounter by meta-training on very large, real-world problems.</p><p>Except where otherwise indicated, all target problems were designed to have a global minimum of zero (in some cases a constant offset was added to make the minimum zero). The code defining each of these problems is included in the open source release. See A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">EXEMPLAR PROBLEMS FROM LITERATURE</head><p>We included a set of 2-dimensional problems which have appeared in optimization literature <ref type="bibr" target="#b26">(Surjanovic &amp; Bingham, 2013)</ref> as toy examples of various loss landscape pathologies.</p><p>These consisted of Rosenbrock, Ackley, Beale, Booth, Styblinski-Tang, Matyas, Branin, Michalewicz, and log-sum-exp functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">WELL BEHAVED PROBLEMS</head><p>We included a number of well-behaved convex loss functions, consisting of quadratic bowls of varying dimension with randomly generated coupling matrices, and logistic regression on randomly generated, generally linearly separable data. For the logistic regression problem, when the data is not fully linearly separable, the global minimum is greater than 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">NOISY GRADIENTS AND MINIBATCH PROBLEMS</head><p>For problems with randomly generated data, such as logistic regression, we fed in minibatches of various sizes, from 10 to 200. We also used a minibatch quadratic task, where the minibatch loss consisted of the square inner product of the parameters with random input vectors.</p><p>For full-batch problems, we sometimes added normally distributed noise with standard deviations from 0.1 to 2.0 in order to simulate noisy minibatch loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4.">SLOW CONVERGENCE PROBLEMS</head><p>We included several tasks where optimization could proceed only very slowly, despite the small problem size. This included a many-dimensional oscillating valley whose global minimum lies at infinity, and a problem with a loss consisting of a very strong coupling terms between parameters in a sequence. We additionally included a task where the loss only depends on the minimum and maximum valued parameter, so that gradients are extremely sparse and the loss has discontinuous gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.5.">TRANSFORMED PROBLEMS</head><p>We also included a set of problems which transform the previously defined target problems in ways which map to common situations in optimization.</p><p>To simulate problems with sparse gradients, one transformation sets a large fraction of the gradient entries to 0 at each training step. To simulate problems with different scaling across parameters, we added a transformation which performs a linear change of variables so as to change the relative scale of parameters. To simulate problems with different steepness-profiles over the course of learning, we added a transformation which applied monotonic transformations (such as raising to a power) to the final loss. Finally, to simulate complex tasks with diverse parts, we added a multi-task transformation, which summed the loss and concatenated the parameters from a diverse set of prob-lems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Meta-objective</head><p>For the meta-training loss, used to train the metaparameters of the optimizer, we used the average log loss across all training problems,</p><formula xml:id="formula_12">L (Ï) = 1 N N n=1 log ( (Î¸ n (Ï)) + ) â log (Î¸ 0 ) + ,<label>(14)</label></formula><p>where the second term is a constant, and where Ï is the full set of meta-parameters for the learned optimizer, consisting of</p><formula xml:id="formula_13">Ï = {Ï P-RNN , Ï T-RNN , Ï G-RNN , Î³, c}, where Ï â¢-RNN</formula><p>indicates the GRU weights and biases for the Parameter, Tensor, or Global RNN, Î³ is the learning rate momentum and c is the attended step offset (Section 3.2.4).</p><p>Minimizing the average log function value, rather than the average function value, better encourages exact convergence to minima and precise dynamic adjustment of learning rate based on gradient history ( <ref type="figure">Figure 6</ref>). The average logarithm also more closely resembles minimizing the final function value, while still providing a meta-learning signal at every training step, since very small values of (Î¸ n ) make an outsized contribution to the average after taking the logarithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Partial unrolling</head><p>Meta-learning gradients were computed via backpropagation through partial unrolling of optimization of the target problem, similarly to <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref>. Note that <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref> dropped second derivative terms from their backpropagation, due to limitations of Torch. We compute the full gradient in TensorFlow, including second derivatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Heavy-tailed distribution over training steps</head><p>In order to encourage the learned optimizer to generalize to long training runs, both the number of partial unrollings, and the number of optimization steps within each partial unroll, was drawn from a heavy tailed exponential distribution. The resulting distribution is shown in Appendix C.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Meta-optimization</head><p>The optimizers were meta-trained for at least 40M metaiterations (each meta-iteration consists of loading a random problem from the meta-training set, running the learned optimizer on that target problem, computing the metagradient, and then updating the meta-parameters). The meta-objective was minimized with asynchronous RM-SProp across 1000 workers, with a learning rate of 10 â6 . <ref type="figure">Figure 2</ref>. Training loss versus number of optimization steps on MNIST for the Learned optimizer in this paper compared to the L2L optimizer from <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref>, ADAM (learning rate 2e-3), and RMSProp (learning rate 1e-2). The L2L optimizer from previous work was meta-trained on a 2-layer, fullyconnected network with sigmoidal nonlinearities. The test problems were a 2-layer fully-connected network and a 2-layer convolutional network. In both cases, ReLU activations and minibatches of size 64 was used. <ref type="figure">Figure 3</ref>. Three sample problems from the meta-training corpus on which the learned optimizer outperforms RMSProp and ADAM. The learning rates for RMSProp (1e-2) and ADAM (2e-3) were chosen for good average performance across all problem types in the training and test set. The learned optimizer generally beats the other optimizers on problems in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Failures of existing learned optimizers</head><p>Previous learned optimizer architectures like <ref type="bibr" target="#b0">Andrychowicz et al. (2016)</ref> perform well on the problems on which they are meta-trained. However, they do not generalize well to new architectures or scale well to longer timescales. <ref type="figure">Figure 2</ref> shows the performance of an optimizer metatrained on a 2-layer perceptron with sigmoid activations on (a) Learned optimizer matches performance of ADAM, RM-SProp, and SGD with momentum on four problems never seen in the meta-training set. For the non-learned optimizer, the optimal learning rate for each problem was chosen from a sweep over learning rates from 10 â9 to 0.1. Actual learning rates used are shown in the inset legend. (b) Training loss on ImageNet data in early training as a function of number of training examples seen (accounting for varying minibatch sizes). While other optimizer performance is highly dependent on hyperparameters, learned optimizer performance is similar to the best tuned optimizers (though in late training, the learned optimizer loss increases again). In both cases the learned optimizer was used for distributed, synchronized learning with an effective minibatch size of 800. The Inception V3 plot was generated from a newer version of the codebase, with small improvements described in Appendix D. On Inception V3, other optimizers used a learning rate of 0.045 and an effective minibatch size of 1600 (the optimal hyperparameters for the RMSProp optimizer from the original paper). On Resnet, other optimizers used a learning rate of 0.1 and an effective minibatch size of (the optimal hyperparameters for the SGD + momentum optimizer from the original paper). the same problem type with ReLU activations and a new problem type (a 2-layer convolutional network). In both cases, the same dataset (MNIST) and minibatch size (64) was used. In contrast, our optimizer, which has not been meta-trained on this dataset or any neural network problems, shows performance comparable with ADAM and RMSProp, even for numbers of iterations not seen during meta-training (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Performance on training set problems</head><p>The learned optimizer matches or outperforms ADAM and RMSProp on problem types from the meta-training set <ref type="figure">(Figure 3</ref>). The exact setup for each problem type can be seen in the python code in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Generalization to new problem types</head><p>The meta-training problem set did not include any convolutional or fully-connected layers. Despite this, we see comparable performance to ADAM, RMSProp, and SGD with momentum on simple convolutional multi-layer networks and multi-layer fully connected networks both in terms of final loss and number of iterations to convergence ( <ref type="figure" target="#fig_0">Figure  4a</ref> and <ref type="figure">Figure 2</ref>).</p><p>We also tested the learned optimizer on Inception V3 <ref type="bibr" target="#b28">(Szegedy et al., 2016)</ref> and on ResNet V2 <ref type="bibr" target="#b11">(He et al., 2016)</ref>. <ref type="figure" target="#fig_0">Figure 4b</ref> shows the learned optimizer is able to stably train these networks for the first 10K to 20K steps, with performance similar to traditional optimizers tuned for the spe-cific problem. Unfortunately, we find that later in training the learned optimizer stops making effective progress, and the loss approaches a constant (approximately 6.5 for Inception V3). Addressing this issue would be a goal of future work.</p><p>5.4. Performance is robust to choice of learning rate <ref type="figure">Figure 5</ref>. Learned optimizer performance is robust to learning rate hyperparameter. Training curves on a randomly generated quadratic loss problem with different learning rate initializations.</p><p>One time-consuming aspect of training neural networks with current optimizers is choosing the right learning rate for the problem. While the learned optimizer is also sensitive to initial learning rate, it is much more robust. <ref type="figure">Figure  shows</ref> the learned optimizer's training loss curve on a quadratic problem with different initial learning rates com-pared to those same learning rates on other optimizers. <ref type="figure">Figure 6</ref>. Ablation study demonstrating importance of design choices on a small ConvNet on MNIST data. DEFAULT is the optimizer with all features included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Ablation experiments</head><p>The design choices described in Section 3 matter for the performance of the optimizer. We ran experiments in which we removed different features and re-meta-trained the optimizer from scratch. We kept the features which, on average, made performance better on a variety of test problems. Specifically, we kept all of the features described in 3.2 such as attention (3.2.1), momentum on multiple timescales (gradient scl) (3.2.2), dynamic input scaling (variable scl decay) (3.2.3), and a relative learning rate (relative lr) (3.2.4). We found it was important to take the logarithm of the meta-objective (log obj) as described in 4.2. In addition, we found it helpful to let the RNN learn its own initial weights (trainable weight init) and an accumulation decay for multiple gradient timescales (inp decay). Though all features had an effect, some features were more crucial than others in terms of consistently improved performance. <ref type="figure">Figure 6</ref> shows one test problem (a 2-layer convolutional network) on which all final features of the learned optimizer matter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Wall clock comparison</head><p>In experiments, for small minibatches, we significantly underperform ADAM and RMSProp in terms of wall clock time. However, consistent with the prediction in 3.4, since our overhead is constant in terms of minibatch we see that the overhead can be made small by increasing the minibatch size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have shown that RNN-based optimizers meta-trained on small problems can scale and generalize to early train-  <ref type="figure">Figure 7</ref>. Wall clock time in seconds to run a single gradient and update step for a 6-layer ConvNet architecture on an HPz440 workstation with an NVIDIA Titan X GPU. As batch size increases, the total computation time for the Learned optimizer approaches ADAM.</p><p>ing on large problems like ResNet and Inception on the Im-ageNet dataset. To achieve these results, we introduced a novel hierarchical architecture that reduces memory overhead and allows communication across parameters, and augmented it with additional features shown to be useful in previous optimization and recurrent neural network literature. We also developed an ensemble of small optimization problems that capture common and diverse properties of loss landscapes. Although the wall clock time for optimizing new problems lags behind simpler optimizers, we see the difference decrease with increasing batch size. Having shown the ability of RNN-based optimizers to generalize to new problems, we look forward to future work on optimizing the optimizers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 .</head><label>4</label><figDesc>The learned optimizer generalizes to new problem types unlike any in the meta-training set, and with many more parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Google Brain 2 Work done during an internship at Google Brain. 3 Stanford University 4 Deepmind. Correspondence to: Olga Wichrowska &lt;olganw@google.com&gt;. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Code</head><p>The code for the meta-training procedure and meta-train problem set is available at https://git.io/v5oq5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Additional details of RNN architecture B.1. Shortcut connection</head><p>Since we expect m n ts to be the primary driver of update step direction, and in order to further reduce the information which must be stored in the Parameter RNN hidden state, we included a meta-trainable linear projection from the average rescaled gradients m n ts and the update directions âÎ¸ n t and âÏ n t .</p><p>C. Additional details of meta-training process C.1. Heavy-tailed distribution over training steps </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Architecture updates</head><p>The Inception V3 experiment in <ref type="figure">Figure 4b</ref> used a slightly newer version of the learned optimizer codebase. The changes were:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Parameter noise during training</head><p>Due to the use of small meta-training problems in Section 4.1, during meta-training the learned optimizer is often able to optimize the problem almost exactly early in the unrolled optimization, after which the meta-loss s becomes relatively uninformative. In order to better simulate tasks which take many steps to optimize, small Gaussian noise is added to the parameters during each optimization step.</p><p>This effectively moves the loss landscape underneath the optimizer, providing a more informative learning signal after many unrolls, and forcing the learned optimizer to be robust to a new type of noise. Specifically, the parameter update becomes</p><p>where the noise scale Î± is drawn from a log uniform distribution between 10 â10 and 10 â2 for each problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Momentum from previous timescale</head><p>In Equation 3 we scale the average gradientsá¸¡ n ts by a running estimate Î» n ts of the root-mean-square magnitude of g n ts . This is a mismatch with Adam, where the average gradient is scaled by a running estimate of the root-meansquare magnitude of the non-averaged gradients. In order to be consistent with this, and in order to encourage better use of the dynamic range of m n ts (as defined in the text body, it spends much of its time with values near or â1), we modify Equation 3 to normalize the average gradient g n ts by Î» n ts from the immediately faster timescale,</p><p>and where we define the average gradient at the fastest time scale to be the raw gradient,á¸¡ n t(â1) = g n t</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. No normalization of step length</head><p>In order to simplify interactions between parameters, we no longer force a normalization of the parameter and attention update directions d n Î¸t and d n Ït . We do still decompose the update into the product of a learning rate and a step. Since the attended update direction is now able to take on a different magnitude, the separate attention log learning rate Î· n Ï is no longer required, and is eliminated. Equations 5 and 6 thus become</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4. More stable meta-training hyper-parameters</head><p>The distribution over meta-loss gradients is observed to be assymmetrical and heavy tailed. This combination is known to cause biased parameter updates in RMSProp and Adam, since both optimizers underweight the contribution from extremely rare extremely large gradients. In order to reduce this tendency, we updated the mean-quare-gradient momentum term Î³ to be 0.999, rather than 0.9 in the metaoptimizer RMSProp (Section 4.5).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Misha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sergio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate. iclr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the search for new learning rules for ANNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cloutier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="26" to="30" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning a synaptic learning rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jocelyn</forename><surname>Cloutier</surname></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>UniversitÃ© de</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">DÃ©partement d&apos;informatique et de recherche opÃ©rationnelle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>MontrÃ©al</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the optimization of a synaptic learning rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Samy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jocelyn</forename><surname>Cloutier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gecsei</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Optimality in Biological and Artificial Networks</title>
		<imprint>
			<date type="published" when="1992-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Learning to learn for global optimization of black box functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Misha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
		</author>
		<idno>1611.03824</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv Report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Van</forename><surname>MerriÃ«nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1259</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Encoder-decoder approaches. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Rl : Fast reinforcement learning via slow reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>UC Berkeley and OpenAI</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">RMSprop loses to SMORMS3 -beware the epsilon!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Funk</surname></persName>
		</author>
		<ptr target="URLsifter.org/$\sim$simon/journal/20150420.html" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The formation of learning sets. Psychological review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><forename type="middle">F</forename><surname>Harlow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949" />
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page">51</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to learn using gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sepp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Younger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Conwell</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A layered network model of associative learning: learning to learn and configuration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kehoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">411</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization. iclr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brenden</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Joshua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gershman</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<idno>1604.00289</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to optimize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ske</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Meta-neural networks that learn by learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devang</forename><forename type="middle">K</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mammone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1992" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="437" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A method of solving a convex programming problem with convergence rate o (1/k2)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurii</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Soviet Mathematics Doklady</title>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="372" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A method of solving a convex programming problem with convergence rate o (1/k2)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurii</forename><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Soviet Mathematics Doklady</title>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="372" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evolution and design of distributed learning rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Runarsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Combinations of Evolutionary Computation and Neural Networks</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="59" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sergey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Principles in Self-Referential Learning. On Learning how to Learn</title>
		<editor>The Meta-Meta-Meta...-Hook</editor>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Institut f. Informatik, Tech. Univ. Munich</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aja</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Julian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Veda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Optimization test functions and datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonja</forename><surname>Surjanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Bingham</surname></persName>
		</author>
		<ptr target="http://www.sfu.ca/Ëssurjano/optimization.html" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adapting bias by gradient descent: An incremental version of delta-bar-delta</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="171" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sergey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorien</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer Science and Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COURSERA: Neural Networks for Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An incremental gradient (-projection) method with momentum term and adaptive stepsize rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tseng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="506" to="531" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeb</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tirumala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhruva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>RÃ©mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharshan</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Botvinick</surname></persName>
		</author>
		<idno>1611.05763</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv Report</note>
	<note>Learning to reinforcement learn</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reminiscence and rote learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename><forename type="middle">B</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Monographs</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
