<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">One-shot Learning with Memory-Augmented Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
							<email>adamsantoro@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">National Research University Higher School of Economics (HSE)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Deepmind</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Research University Higher School of Economics (HSE)</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">National Research University Higher School of Economics (HSE)</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">National Research University Higher School of Economics (HSE)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
							<email>botvinick@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">National Research University Higher School of Economics (HSE)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
							<email>wierstra@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">National Research University Higher School of Economics (HSE)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Research University Higher School of Economics (HSE)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">One-shot Learning with Memory-Augmented Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of &quot;one-shot learning.&quot; Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory locationbased focusing mechanisms.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The current success of deep learning hinges on the ability to apply gradient-based optimization to high-capacity models. This approach has achieved impressive results on many large-scale supervised tasks with raw sensory input, such as image classification <ref type="bibr" target="#b6">(He et al., 2015)</ref>, speech recognition <ref type="bibr" target="#b20">(Yu &amp; Deng, 2012)</ref>, and games <ref type="bibr" target="#b11">(Mnih et al., 2015;</ref><ref type="bibr" target="#b15">Silver et al., 2016)</ref>. Notably, performance in such tasks is typically evaluated after extensive, incremental training on large data sets. In contrast, many problems of interest re-quire rapid inference from small quantities of data. In the limit of "one-shot learning," single observations should result in abrupt shifts in behavior.</p><p>This kind of flexible adaptation is a celebrated aspect of human learning <ref type="bibr" target="#b9">(Jankowski et al., 2011)</ref>, manifesting in settings ranging from motor control <ref type="bibr" target="#b0">(Braun et al., 2009)</ref> to the acquisition of abstract concepts <ref type="bibr" target="#b10">(Lake et al., 2015)</ref>. Generating novel behavior based on inference from a few scraps of information -e.g., inferring the full range of applicability for a new word, heard in only one or two contexts -is something that has remained stubbornly beyond the reach of contemporary machine intelligence. It appears to present a particularly daunting challenge for deep learning. In situations when only a few training examples are presented one-by-one, a straightforward gradient-based solution is to completely re-learn the parameters from the data available at the moment. Such a strategy is prone to poor learning, and/or catastrophic interference. In view of these hazards, non-parametric methods are often considered to be better suited.</p><p>However, previous work does suggest one potential strategy for attaining rapid learning from sparse data, and hinges on the notion of meta-learning <ref type="bibr" target="#b16">(Thrun, 1998;</ref><ref type="bibr" target="#b18">Vilalta &amp; Drissi, 2002)</ref>. Although the term has been used in numerous senses <ref type="bibr" target="#b13">(Schmidhuber et al., 1997;</ref><ref type="bibr" target="#b2">Caruana, 1997;</ref><ref type="bibr" target="#b14">Schweighofer &amp; Doya, 2003;</ref><ref type="bibr" target="#b1">Brazdil et al., 2003)</ref>, meta-learning generally refers to a scenario in which an agent learns at two levels, each associated with different time scales. Rapid learning occurs within a task, for example, when learning to accurately classify within a particular dataset. This learning is guided by knowledge accrued more gradually across tasks, which captures the way in which task structure varies across target domains <ref type="bibr" target="#b4">(Giraud-Carrier et al., 2004;</ref><ref type="bibr" target="#b12">Rendell et al., 1987;</ref><ref type="bibr" target="#b16">Thrun, 1998)</ref>. Given its two-tiered organization, this form of meta-arXiv:1605.06065v1 <ref type="bibr">[cs.LG]</ref> 19 May 2016 learning is often described as "learning to learn." It has been proposed that neural networks with memory capacities could prove quite capable of meta-learning <ref type="bibr" target="#b8">(Hochreiter et al., 2001)</ref>. These networks shift their bias through weight updates, but also modulate their output by learning to rapidly cache representations in memory stores <ref type="bibr" target="#b7">(Hochreiter &amp; Schmidhuber, 1997)</ref>. For example, LSTMs trained to meta-learn can quickly learn never-before-seen quadratic functions with a low number of data samples <ref type="bibr" target="#b8">(Hochreiter et al., 2001)</ref>.</p><p>Neural networks with a memory capacity provide a promising approach to meta-learning in deep networks. However, the specific strategy of using the memory inherent in unstructured recurrent architectures is unlikely to extend to settings where each new task requires significant amounts of new information to be rapidly encoded. A scalable solution has a few necessary requirements: First, information must be stored in memory in a representation that is both stable (so that it can be reliably accessed when needed) and element-wise addressable (so that relevant pieces of information can be accessed selectively). Second, the number of parameters should not be tied to the size of the memory. These two characteristics do not arise naturally within standard memory architectures, such as LSTMs. However, recent architectures, such as Neural Turing Machines (NTMs) <ref type="bibr" target="#b5">(Graves et al., 2014)</ref> and memory networks <ref type="bibr" target="#b19">(Weston et al., 2014)</ref>, meet the requisite criteria. And so, in this paper we revisit the meta-learning problem and setup from the perspective of a highly capable memory-augmented neural network (MANN) (note: here on, the term MANN will refer to the class of external-memory equipped networks, and not other "internal" memory-based architectures, such as LSTMs).</p><p>We demonstrate that MANNs are capable of meta-learning in tasks that carry significant short-and long-term memory demands. This manifests as successful classification of never-before-seen Omniglot classes at human-like accuracy after only a few presentations, and principled function estimation based on a small number of samples. Additionally, we outline a memory access module that emphasizes memory access by content, and not additionally on memory location, as in original implementations of the NTM <ref type="bibr" target="#b5">(Graves et al., 2014)</ref>. Our approach combines the best of two worlds: the ability to slowly learn an abstract method for obtaining useful representations of raw data, via gradient descent, and the ability to rapidly bind never-beforeseen information after a single presentation, via an external memory module. The combination supports robust metalearning, extending the range of problems to which deep learning can be effectively applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Meta-Learning Task Methodology</head><p>Usually, we try to choose parameters θ to minimize a learning cost L across some dataset D. However, for metalearning, we choose parameters to reduce the expected learning cost across a distribution of datasets p(D):</p><formula xml:id="formula_0">θ * = argmin θ E D∼p(D) [L(D; θ)].</formula><p>(1)</p><p>To accomplish this, proper task setup is critical <ref type="bibr" target="#b8">(Hochreiter et al., 2001)</ref>. In our setup, a task, or episode, involves the presentation of some dataset</p><formula xml:id="formula_1">D = {d t } T t=1 = {(x t , y t )} T</formula><p>t=1 . For classification, y t is the class label for an image x t , and for regression, y t is the value of a hidden function for a vector with real-valued elements x t , or simply a real-valued number x t (here on, for consistency, x t will be used). In this setup, y t is both a target, and is presented as input along with x t , in a temporally offset manner; that is, the network sees the input sequence (</p><p>). And so, at time t the correct label for the previous data sample (y t−1 ) is provided as input along with a new query x t (see <ref type="figure" target="#fig_0">Figure 1</ref> (a)). The network is tasked to output the appropriate label for x t (i.e., y t ) at the given timestep. Importantly, labels are shuffled from dataset-to-dataset. This prevents the network from slowly learning sample-class bindings in its weights. Instead, it must learn to hold data samples in memory until the appropriate labels are presented at the next timestep, after which sample-class information can be bound and stored for later use (see <ref type="figure" target="#fig_0">Figure 1</ref> (b)). Thus, for a given episode, ideal performance involves a random guess for the first presentation of a class (since the appropriate label can not be inferred from previous episodes, due to label shuffling), and the use of memory to achieve perfect accuracy thereafter. Ultimately, the system aims at modelling the predictive distribution p(y t |x t , D 1:t−1 ; θ), inducing a corresponding loss at each time step. This task structure incorporates exploitable metaknowledge: a model that meta-learns would learn to bind data representations to their appropriate labels regardless of the actual content of the data representation or label, and would employ a general scheme to map these bound representations to appropriate classes or function values for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Memory-Augmented Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Neural Turing Machines</head><p>The Neural Turing Machine is a fully differentiable implementation of a MANN. It consists of a controller, such as a feed-forward network or LSTM, which interacts with an external memory module using a number of read and write heads <ref type="bibr" target="#b5">(Graves et al., 2014)</ref>. Memory encoding and retrieval in a NTM external memory module is rapid, with vector , yt−1, to prevent the network from simply mapping the class labels to the output. From episode to episode, the classes to be presented in the episode, their associated labels, and the specific samples are all shuffled. (b) A successful strategy would involve the use of an external memory to store bound sample representation-class label information, which can then be retrieved at a later point for successful classification when a sample from an already-seen class is presented. Specifically, sample data xt from a particular time step should be bound to the appropriate class label yt, which is presented in the subsequent time step. Later, when a sample from this same class is seen, it should retrieve this bound information from the external memory to make a prediction. Backpropagated error signals from this prediction step will then shape the weight updates from the earlier steps in order to promote this binding strategy.</p><p>representations being placed into or taken out of memory potentially every time-step. This ability makes the NTM a perfect candidate for meta-learning and low-shot prediction, as it is capable of both long-term storage via slow updates of its weights, and short-term storage via its external memory module. Thus, if a NTM can learn a general strategy for the types of representations it should place into memory and how it should later use these representations for predictions, then it may be able use its speed to make accurate predictions of data that it has only seen once.</p><p>The controllers employed in our model are are either LSTMs, or feed-forward networks. The controller interacts with an external memory module using read and write heads, which act to retrieve representations from memory or place them into memory, respectively. Given some input, x t , the controller produces a key, k t , which is then either stored in a row of a memory matrix M t , or used to retrieve a particular memory, i, from a row; i.e., M t (i).</p><p>When retrieving a memory, M t is addressed using the cosine similarity measure,</p><formula xml:id="formula_2">K k t , M t (i) = k t • M t (i) k t M t (i) ,<label>(2)</label></formula><p>which is used to produce a read-weight vector, w r t , with elements computed according to a softmax:</p><formula xml:id="formula_3">w r t (i) ← exp K k t , M t (i) j exp K k t , M t (j) .<label>(3)</label></formula><p>A memory, r t , is retrieved using this weight vector:</p><formula xml:id="formula_4">r t ← i w r t (i)M t (i).<label>(4)</label></formula><p>This memory is used by the controller as the input to a classifier, such as a softmax output layer, and as an additional input for the next controller state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Least Recently Used Access</head><p>In previous instantiations of the NTM <ref type="bibr" target="#b5">(Graves et al., 2014)</ref>, memories were addressed by both content and location. Location-based addressing was used to promote iterative steps, akin to running along a tape, as well as long-distance jumps across memory. This method was advantageous for sequence-based prediction tasks. However, this type of access is not optimal for tasks that emphasize a conjunctive coding of information independent of sequence. As such, writing to memory in our model involves the use of a newly designed access module called the Least Recently Used Access (LRUA) module.</p><p>The LRUA module is a pure content-based memory writer that writes memories to either the least used memory location or the most recently used memory location. This module emphasizes accurate encoding of relevant (i.e., recent) information, and pure content-based retrieval. New information is written into rarely-used locations, preserving recently encoded information, or it is written to the last used location, which can function as an update of the memory with newer, possibly more relevant information. The distinction between these two options is accomplished with an interpolation between the previous read weights and weights scaled according to usage weights w u t . These usage weights are updated at each time-step by decaying the previous usage weights and adding the current read and write weights:</p><formula xml:id="formula_5">w u t ← γw u t−1 + w r t + w w t . (5)</formula><p>Here, γ is a decay parameter and w r t is computed as in (3). The least-used weights, w lu t , for a given time-step can then be computed using w u t . First, we introduce the notation m(v, n) to denote the n th smallest element of the vector v. Elements of w lu t are set accordingly:</p><formula xml:id="formula_6">w lu t (i) = 0 if w u t (i) &gt; m(w u t , n) 1 if w u t (i) ≤ m(w u t , n) ,<label>(6)</label></formula><p>where n is set to equal the number of reads to memory.</p><p>To obtain the write weights w w t , a learnable sigmoid gate parameter is used to compute a convex combination of the previous read weights and previous least-used weights:</p><formula xml:id="formula_7">w w t ← σ(α)w r t−1 + (1 − σ(α))w lu t−1 .<label>(7)</label></formula><p>Here, σ(•) is a sigmoid function, 1 1+e −x , and α is a scalar gate parameter to interpolate between the weights. Prior to writing to memory, the least used memory location is computed from w u t−1 and is set to zero. Writing to memory then occurs in accordance with the computed vector of write weights:</p><formula xml:id="formula_8">M t (i) ← M t−1 (i) + w w t (i)k t , ∀i<label>(8)</label></formula><p>Thus, memories can be written into the zeroed memory slot or the previously used slot; if it is the latter, then the least used memories simply get erased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data</head><p>Two sources of data were used: Omniglot, for classification, and sampled functions from a Gaussian process (GP) with fixed hyperparameters, for regression. The Omniglot dataset consists of over 1600 separate classes with only a few examples per class, aptly lending to it being called the transpose of MNIST <ref type="bibr" target="#b10">(Lake et al., 2015)</ref>. To reduce the risk of overfitting, we performed data augmentation by randomly translating and rotating character images. We also created new classes through 90 • , 180 • and 270 • rotations of existing data. The training of all models was performed on the data of 1200 original classes (plus augmentations), with the rest of the 423 classes (plus augmentations) being used for test experiments. In order to reduce the computational time of our experiments we downscaled the images to 20 × 20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Omniglot Classification</head><p>We performed a number of iterations of the basic task described in Section 2. First, our MANN was trained using one-hot vector representations as class labels ( <ref type="figure" target="#fig_1">Figure 2</ref>). After training on 100,000 episodes with five randomly chosen classes with randomly chosen labels, the network was given a series of test episodes. In these episodes, no further learning occurred, and the network was to predict the class labels for never-before-seen classes pulled from a disjoint test set from within Omniglot. The network exhibited high classification accuracy on just the second presentation of a sample from a class within an episode (82.8%), reaching up to 94.9% accuracy by the fifth instance and 98.1% accuracy by the tenth.</p><p>For classification using one-hot vector representations, one relevant baseline is human performance. Participants were first given instructions detailing the task: an image would appear, and they must choose an appropriate digit label from the integers 1 through 5. Next, the image was presented and they were to make an un-timed prediction as to its class label. The image then disappeared, and they were given visual feedback as to their correctness, along with the correct label. The correct label was presented regardless of the accuracy of their prediction, allowing them to further reinforce correct decisions. After a short delay of two seconds, a new image appeared and they repeated the prediction process. The participants were not permitted to view previous images, or to use a scratch pad for externalization of memory. Performance of the MANN surpassed that of a human on each instance. Interestingly, the MANN displayed better than random guessing on the first instance within a class. Seemingly, it employed a strategy of educated guessing; if a particular sample produced a key that was a poor match to any of the bindings stored in external memory, then the network was less likely to choose the class labels associated with these stored bindings, and hence increased its probability of correctly guessing this new class on the first instance. A similar strategy was reported qualitatively by the human participants. We were unable to accumulate an appreciable amount of data from participants on the fifteen class case, as it proved much too difficult and highly demotivating. For all intents and purposes, as the number of classes scale to fifteen and beyond, this type of binding surpasses human working memory capacity, which is limited to storing only a handful of arbitrary bindings <ref type="bibr" target="#b3">(Cowan, 2010)</ref>.</p><p>Since learning the weights of a classifier using large onehot vectors becomes increasingly difficult with scale, a different approach for labeling classes was employed so that the number of classes presented in a given episode could be arbitrarily increased. These new labels consisted of strings of five characters, with each character assuming one of five possible values. Characters for each label were uniformly sampled from the set {'a', 'b', 'c', 'd', 'e'}, producing random strings such as 'ecdba'. Strings were represented as concatenated one-hot vectors, and hence were of length 25 , first instance accuracy is above chance, indicating that the MANN is performing "educated guesses" for new classes based on the classes it has already seen and stored in memory. In (c-d), first instance accuracy is poor, as is expected, since it must make a guess from 3125 random strings. Second instance accuracy, however, approaches 80% during training for the <ref type="bibr">MANN (d)</ref>. At the 100,000 episode mark the network was tested, without further learning, on distinct classes withheld from the training set, and exhibited comparable performance. with five elements assuming a value of 1, and the rest 0. This combinatorial approach allows for 3125 possible labels, which is nearly twice the number of classes in the dataset. Therefore, the probability that a given class assumed the same label in any two episodes throughout training was greatly reduced. This also meant, however, that the guessing strategy exhibited by the network for the first instance of a particular class within an episode would prob-ably be abolished. Nonetheless, this method allowed for episodes containing a large number of unique classes.</p><p>To confirm that the network was able to learn using these class representations, the previously described experiment was repeated (See <ref type="table" target="#tab_1">Table 2</ref>). Notably, a MANN with a standard NTM access module was unable to reach comparable performance to a MANN with LRU Access. Given this success, the experiment was scaled to up to fifteen unique classes presented in episodes of length 100, with the network exhibiting similar performance.</p><p>We considered a set of baselines, such as a feed-forward RNN, LSTM, and a nonparametric nearest neighbours classifier that used either raw-pixel input or features extracted by an autoencoder. The autoencoder consisted of an encoder and decoder each with two 200-unit layers with leaky ReLU activations, and an output bottleneck layer of 32 units. The resultant architecture contained significantly more parameters than the MANN and, additionally, was allowed to train on three times as much augmented data. The highest accuracies from our experiments are reported, which were achieved using a single nearest neighbour for prediction and features from the output bottleneck layer of the autoencoder. Importantly, the nearest neighbour classifier had an unlimited amount of memory, and could automatically store and retrieve all previously seen examples. This provided the kNN with an distinct advantage, even when raw pixels were used as input representations. Although using rich features extracted by the autoencoder further improved performance, the kNN baseline was clearly outperformed by the MANN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">PERSISTENT MEMORY INTERFERENCE</head><p>A good strategy to employ in this classification task, and the strategy that was artificially imposed thus-far, is to wipe the external memory from episode to episode. Since each episode contains unique classes, with unique labels, any information persisting in memory across episodes inevitably acts as interference for the episode at hand. To test the effects of memory interference, we performed the classification task without wiping the external memory between episodes.</p><p>This task proved predictably difficult, and the network was less robust in its ability to achieve accurate classification ( <ref type="figure" target="#fig_3">Figure 3</ref>). For example, in the case of learning one-hot vector labels in an episode that contained five unique classes, learning progressed much slower than in the memory-wipe condition, and did not produce the characteristic fast spike in accuracy seen in the memory-wipe condition <ref type="figure" target="#fig_1">(Figure 2</ref>). Interestingly, there were conditions in which learning was not compromised appreciably. In the case of learning ten unique classes in episodes of length 75, for example, classification accuracy reached comparable levels. Exploring the requirements for robust performance is a topic of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">CURRICULUM TRAINING</head><p>Given the successful one-shot classification in episodes with fifteen classes, we employed a curriculum training regime to further scale the classification capabilities of the model. The network was first tasked to classify fifteen classes per episode, and every 10,000 episodes of training thereafter, the maximum number of classes presented per episode incremented by one <ref type="figure">(Figure 4)</ref>. The network maintained a high level of accuracy even as the number of classes incremented higher throughout training. After training, at the 100,000 episode mark, the network was tested on episodes with 50 classes. Similar tests continued, increasing the maximum number of classes to 100. The network generally exhibited gradually decaying performance as the number of classes increased towards 100.  The training limit of the network seemed to have not been reached, as its performance continued to rise throughout up until the 100,000 episode mark. Assessing the maximum capacity of the network offers an interesting opportunity for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Regression</head><p>Since our MANN architecture generated a broad strategy for meta-learning, we reasoned that it would be able to adequately perform regression tasks on never-before-seen functions. To test this, we generated functions using from a GP prior with a fixed set of hyper-parameters and trained our network using unique functions in each episode. Each episode involved the presentation of x-values (either 1, 2, or 3-dimensional) along with time-offset function values (i.e., f (x t−1 )). A successful strategy involves the binding of x-values with the appropriate function values and storage of these bindings in the external memory. Since individual x-values were only presented once per episode, successful function prediction involved an accurate content-(a) One additional class per 10,000 episodes <ref type="figure">Figure 4</ref>. Curriculum classification. The network started with episodes that included up to 15 unique classes, and every 10,000 episodes this maximum was raised by one. Episode lengths were scaled to a value ten times the max number of classes. At the 100,000 episode mark (when the number of classes reached 25) the network was tested on episodes with up to 50 unique classes, which incremented to 100 in steps of five.</p><p>based look-up of proximal information in memory. Thus, unlike in the image-classification scenario, this task demands a broader read from memory: the network must learn to interpolate from previously seen points, which most likely involves a strategy to have a more blended readout from memory. Such an interpolation strategy in the image classification scenario is less obvious, and probably not necessary.</p><p>Network performance was compared to true GP predictions of samples presented in the same order as was seen by the network. Importantly, a GP is able to perform complex queries over all data points (such as covariance matrix inversion) in one step. In contrast, a MANN can only make local updates to its memory, and hence can only approximate such functionality. In our experiments, the GP was initiated with the correct hyper-parameters for the sampled function, giving it an advantage in function prediction. As seen in <ref type="figure">Figure 5</ref>, the MANN predictions track the underlying function, with its output variance increasing as it predicts function values that are distance from the values it has already received.</p><p>These results were extended to 2-dimensional and 3dimensional cases <ref type="figure" target="#fig_6">(Fig 6)</ref>, with the GP again having access to the correct hyper-parameters for the sampled functions. In both the 2-dimensional and 3-dimensional cases, the log-likelihood predictions of the MANN tracks appreciably well versus the GP, with predictions becoming more accurate as samples are stored in the memory. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion &amp; Future Work</head><p>Many important learning problems demand an ability to draw valid inferences from small amounts of data, rapidly and knowledgeably adjusting to new information. Such problems pose a particular challenge for deep learning, which typically relies on slow, incremental parameter changes. We investigated an approach to this problem based on the idea of meta-learning. Here, gradual, incremental learning encodes background knowledge that spans tasks, while a more flexible memory resource binds information particular to newly encountered tasks. Our central contribution is to demonstrate the special utility of a particular class of MANNs for meta-learning. These are deeplearning architectures containing a dedicated, addressable memory resource that is structurally independent from the mechanisms that implement process control. The MANN examined here was found to display performance superior to a LSTM in two meta-learning tasks, performing well in classification and regression tasks when only sparse training data was available.</p><p>A critical aspect of the tasks studied is that they cannot be performed based solely on rote memory. New information must be flexibly stored and accessed, with correct performance demanding more than just accurate retrieval. Specifically, it requires that inferences be drawn from new data based on longer-term experience, a faculty sometimes referred as "inductive transfer." MANNs are well-suited to meet these dual challenges, given their combination of flexible memory storage with the rich capacity of deep archi- tectures for representation learning.</p><p>Meta-learning is recognized as a core ingredient of human intelligence, and an essential test domain for evaluating models of human cognition. Given recent successes in modeling human skills with deep networks, it seems worthwhile to ask whether MANNs embody a promising hypothesis concerning the mechanisms underlying human metalearning. In informal comparisons against human subjects, the MANN employed in this paper displayed superior performance, even at set-sizes that would not be expected to overtax human working memory capacity. However, when memory is not cleared between tasks, the MANN suffers from proactive interference, as seen in many studies of human memory and inference <ref type="bibr" target="#b17">(Underwood, 1957)</ref>. These preliminary observations suggest that MANNs may provide a useful heuristic model for further investigation into the computational basis of human meta-learning.</p><p>The work we presented leaves several clear openings for next-stage development. First, our experiments employed a new procedure for writing to memory that was prima facie well suited to the tasks studied. It would be interesting to consider whether meta-learning can itself discover optimal memory-addressing procedures. Second, although we tested MANNs in settings where task parameters changed across episodes, the tasks studied contained a high degree of shared high-level structure. Training on a wider range of tasks would seem likely to reintroduce standard challenges associated with continual learning, including the risk of catastrophic interference. Finally, it may be of interest to examine MANN performance in meta-learning tasks requiring active learning, where observations must be actively selected.  To obtain the write weights w w t , a learnable sigmoid gate parameter is used to compute a convex combination of the previous read weights and previous least-used weights:</p><formula xml:id="formula_9">w w t ← σ(α)w r t−1 + (1 − σ(α))w lu t−1 ,<label>(22)</label></formula><p>where α is a dynamic scalar gate parameter to interpolate between the weights. Prior to writing to memory, the least used memory location is computed from w u t−1 and is set to zero. Writing to memory then occurs in accordance with the computed vector of write weights:</p><formula xml:id="formula_10">M t (i) ← M t−1 (i) + w w t (i)k t , ∀i<label>(23)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Output distribution</head><p>The controller's output, o t , is propagated to an output distribution. For classification tasks using one-hot labels, the controller output is first passed through a linear layer with an output size equal to the number of classes to be classified per episode. This linear layer output is then passed as input to the output distribution. For one-hot classification, the output distribution is a categorical distribution, implemented as a softmax function. The categorical distribution produces a vector of class probabilities, p t , with elements:</p><formula xml:id="formula_11">p t (i) = exp(W op (i)o t ) j exp(W on (j)o t ) ,<label>(24)</label></formula><p>where W op are the weights from the controller output to the linear layer output.</p><p>For classification using string labels, the linear output size is kept at 25. This allows for the output to be split into five equal parts each of size five. Each of these parts is then sent to an independent categorical distribution that computes probabilities across its five inputs. Thus, each of these categorical distributions independently predicts a 'letter,' and these letters are then concatenated to produce the five-character-long string label that serves as the network's class prediction (see <ref type="figure" target="#fig_7">figure 8)</ref>.</p><p>A similar implementation is used for regression tasks. The linear output from the controller outputs two values: µ and σ, which are passed to a Gaussian distribution sampler as predicted mean and variance values. The Gaussian sampling distribution then computes probabilities for the target value y t using these values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Learning</head><p>For one-hot label classification, given the probabilities output by the network, p t , the network minimizes the episode loss of the input sequence:</p><formula xml:id="formula_12">L(θ) = − t y T t log p t ,<label>(25)</label></formula><p>where y t is the target one-hot or string label at time t (note: for a given one-hot class-label vector y t , only one element assumes the value 1, and for a string-label vector, five elements assume the value 1, one per five-element 'chunk').</p><p>For string label classification, the loss is similar:</p><formula xml:id="formula_13">L(θ) = − t c y T t (c) log p t (c).<label>(26)</label></formula><p>Here, the (c) indexes a five-element long 'chunk' of the vector label, of which there are a total of five.</p><p>For regression, the network's output distribution is a Gaussian, and as such receives two-values from the controller output's linear layer at each time-step: predictive µ and σ values, which parameterize the output distribution. Thus, the network minimizes the negative log-probabilities as determined by the Gaussian output distribution given these parameters and the true target y t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Classification input data</head><p>Input sequences consist of flattened, pixel-level representations of images x t and time-offset labels y t−1 (see <ref type="figure" target="#fig_7">figure  8</ref> for an example sequence of images and class identities for an episode of length 50, with five unique classes). First, N unique classes are sampled from the Omniglot dataset, where N is the maximum number of unique classes per episode. N assumes a value of either 5, 10, or 15, which is indicated in the experiment description or table of results in the main text. Samples from the Omniglot source set are pulled, and are kept if they are members of the set of n unique classes for that given episode, and discarded otherwise. 10N samples are kept, and constitute the image data for the episode. And so, in this setup, the number of samples per unique class are not necessarily equal, and some classes may not have any representative samples. Omniglot images are augmented by applying a random rotation uniformly sampled between − π and π , and by applying a random translation in the x-and y-dimensions uniformly sampled between -10 and 10 pixels. The images are then downscaled to 20x20. A larger class-dependent rotation is then applied, wherein each sample from a particular class is rotated by either 0, π , π, or 3π (note: this class-specific rotation is randomized each episode, so a given class may experience different rotations from episode-to-episode). The image is then flattened into a vector, concatenated with a randomly chosen, episode-specific label, and fed as input to the network controller.</p><p>Class labels are randomly chosen for each class from episode-to-episode. For one-hot label experiments, labels are of size N , where N is the maximum number of unique classes that can appear in a given episode. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Task</head><p>Either 5, 10, or 15 unique classes are chosen per episode. Episode lengths are ten times the number of unique classes (i.e., 50, 100, or 150 respectively), unless explicitly mentioned otherwise. Training occurs for 100 000 episodes. At the 100 000 episode mark, the task continues; however, data are pulled from a disjoint test set (i.e., samples from classes 1201-1623 in the omniglot dataset), and weight updates are ceased. This is deemed the "test phase." For curriculum training, the maximum number of unique classes per episode increments by 1 every 10 000 training episodes. Accordingly, the episode length increases to 10 times this new maximum. 9. Parameters 9.0.1. OPTIMIZATION Rmsprop was used with a learning rate of 1e −4 and max learning rate of 5e −1 , decay of 0.95 and momentum 0.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.0.2.">FREE PARAMETER GRID SEARCH</head><p>A grid search was performed over number of parameters, with the values used shown in parentheses: memory slots (128), memory size (40), controller size (200 hidden units for a LSTM), learning rate (1e −4 ), and number of reads from memory (4). Other free parameters were left constant: usage decay of the write weights (0.99), minibatch size (16), 9.1. Comparisons and controls evaluation metrics 9.1.1. HUMAN COMPARISON For the human comparison task, participants perform the exact same experiment as the network: they observe sequences of images and time-offset labels (sequence length = 50, number of unique classes = 5), and are challenged to predict the class identity for the current input image by inputting a single digit on a keypad. However, participants view class labels the integers 1 through 5, rather than one-hot vectors or strings. There is no time limit for their choice. Participants are made aware of the goals of the task prior to starting, and they perform a single, non-scored trial run prior to their scored trials. Nine participants each performed two scored trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.2.">KNN</head><p>When no data is available (i.e., at the start of training), the kNN classifier randomly returns a single class as its prediction. So, for the first data point, the probability that the prediction is correct is 1 N where N is number of unique classes in a given episode. Thereafter, it predicts a class from classes that it has observed. So, all instances of samples that are not members of the first observed class cannot be correctly classified until at least one instance is passed to the classifier. Since statistics are averaged across classes, first instance accuracy becomes 1 N ( 1 N + 0) = 1 N 2 , which is 4% and 0.4% for 5 and 15 classes per episode, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Task structure. (a) Omniglot images (or x-values for regression), xt, are presented with time-offset labels (or function values)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>(a) LSTM, five random classes/episode, one-hot vector labels (b) MANN, five random classes/episode, one-hot vector labels (c) LSTM, fifteen classes/episode, five-character string labels (d) MANN, fifteen classes/episode, five-character string labels Omniglot classification. The network was given either five (a-b) or up to fifteen (c-d) random classes per episode, which were of length 50 or 100 respectively. Labels were one-hot vectors in (a-b), and five-character strings in (c-d). In (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Persistent memory. To test the effects of interference, we did not wipe the external memory store from episode-toepisode. The network indeed struggled in this task (a), but nonetheless was able to perform comparably under certain setups, such as when episodes included ten classes and were of length 75 (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) MANN predictions along all x-inputs after 20 samples (b) GP predictions along all x-inputs after 20 samplesFigure 5. Regression. The network received data samples that were x-values for a function sampled from a GP with fixed hyperparameters, and the labels were the associated function values. (a) shows the MANN's predictions for all x-values after observing 20 samples, and (b) shows the same for a GP with access to the same hyper-parameters used to generate the function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) 2D regression log-likelihoods within an episode (b) 3D regression log-likelihoods within an episode</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Multi-Dimensional Regression. (a)  shows the negative log likelihoods for 2D samples within a single episode, averaged across 100 episodes, while (b) shows the same for 3D samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Example string label and input sequence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Test-set classification accuracies for humans compared to machine algorithms trained on the Omniglot dataset, using onehot encodings of labels and five classes presented per episode.</figDesc><table><row><cell></cell><cell></cell><cell cols="4">INSTANCE (% CORRECT)</cell><cell></cell></row><row><cell>MODEL</cell><cell>ST</cell><cell>2 ND</cell><cell>3 RD</cell><cell>4 TH</cell><cell>5 TH</cell><cell>10 TH</cell></row><row><cell>HUMAN</cell><cell cols="6">34.5 57.3 70.1 71.8 81.4 92.4</cell></row><row><cell cols="7">FEEDFORWARD 24.4 19.6 21.1 19.9 22.8 19.5</cell></row><row><cell>LSTM</cell><cell cols="6">24.4 49.5 55.3 61.0 63.6 62.5</cell></row><row><cell>MANN</cell><cell cols="6">36.4 82.8 91.0 92.6 94.9 98.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Test-set classification accuracies for various architectures on the Omniglot dataset after 100000 episodes of training, using fivecharacter-long strings as labels. See the supplemental information for an explanation of 1st instance accuracies for the kNN classifier.</figDesc><table><row><cell>INSTANCE (% CORRECT)</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head><p>The authors would like to thank Ivo Danihelka and Greg Wayne for helpful discussions and prior work on the NTM and LRU Access architectures, as well as Yori Zwols, and many others at Google DeepMind for reviewing the manuscript.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Additional model details</head><p>Our model is a variant of a Neural Turing Machine (NTM) from <ref type="bibr">Graves et al.</ref> It consists of a number of differentiable components: a controller, read and write heads, an external memory, and an output distribution. The controller receives input data (see section 7) directly, and also provides an input to the output distribution. Each of these components will be addressed in turn. The controllers in our experiments are feed-forward networks or Long Short-Term Memories (LSTMs). For the best performing networks, the controller is a LSTM with 200 hidden units. The controller receives some concatenated input (x t , y t−1 ) (see section 7 for details) and updates its state according to:</p><p>whereĝ f ,ĝ o , andĝ i are the forget gates, output gates, and input gates, respectively, b h are the hidden state biases, c t is the cell state, h t is the hidden state, r t is the vector read from memory, o t is the concatenated output of the controller, represents element-wise multiplication, and (•, •) represents vector concatenation. W xh are the weights from the input (x t , y t−1 ) to the hidden state, and W hh are the weights between hidden states connected through time. The read vector r t is computed using content-based addressing using a cosine distance measure, as described in the main text, and is repeated below for self completion.</p><p>The network has an external memory module, M t , that is both read from and written to. The rows of M t serve as memory 'slots', with the row vectors themselves constituting individual memories. For reading, the controller cell state serves as a query for M t . First, a cosine distance measure is computed for the query key vector (here notated as k t ) and each individual row in memory:</p><p>Next, these similarity measures are used to produce a readweight vector w r t , with elements computed according to a softmax:</p><p>A memory, r t , is then retrieved using these read-weights:</p><p>Finally, r t is concatenated with the controller hidden state, h t , to produce the network's output o t (see equation <ref type="formula">16</ref>). The number of reads from memory is a free parameter, and both one and four reads were experimented with. Four reads was ultimately chosen for the reported experimental results. Multiple reads is implemented as additional concatenation to the output vector, rather than any sort of combination or interpolation.</p><p>To write to memory, we implemented a new content-based access module called Least Recently Used Access (LRUA). LRUA writes to either the most recently read location, or the least recently used location, so as to preserve recent, and hence potentially useful memories, or to update recently encoded information. Usage weights w u t are computed each time-step to keep track of the locations most recently read or written to:</p><p>where γ is a decay parameter. The least-used weights, w lu t , for a given time-step can then be computed using w u t . First, we introduce the notation m(v, n) to denote the n th smallest element of the vector v. Elements of w lu t are set accordingly:</p><p>where n is set to equal the number of reads to memory.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Motor task variation induces structural learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aertsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Mehring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="352" to="357" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ranking learning algorithms: Using ibl and meta-learning on accuracy and time results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><forename type="middle">B</forename><surname>Brazdil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquim</forename><surname>Pinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="251" to="277" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Multitask learning. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The magical mystery four how is working memory capacity limited, and why?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><surname>Cowan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="57" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Introduction to the special issue on meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Giraud-Carrier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Vilalta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Brazdil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="193" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ivo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.01852</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to learn using gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sepp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Younger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Conwell</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural NetworksICANN</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Meta-learning in computational intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norbert</forename><surname>Jankowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Włodzisław</forename><surname>Duch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Grabczewski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">358</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brenden</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Volodymyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Layered concept-learning and dynamically variable bias management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">A</forename><surname>Rendell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><surname>Sheshu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Tcheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="308" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Shifting inductive bias with success-story algorithm, adaptive levin search, and incremental selfimprovement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Wiering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="105" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Meta-learning in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Schweighofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Doya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="9" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aja</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Julian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Veda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lifelong learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning to learn</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="181" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Interference and forgetting. Psychological review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benton</forename><forename type="middle">J</forename><surname>Underwood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A perspective view and survey of meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Vilalta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youssef</forename><surname>Drissi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="95" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Memory networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Automatic Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
