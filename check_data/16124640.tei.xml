<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discovering Causal Signals in Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-10-31">31 Oct 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paz</forename><surname>Facebook</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Nishihara</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">C</forename><surname>Berkeley</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">LÃ©on</forename><surname>Bottou</surname></persName>
						</author>
						<title level="a" type="main">Discovering Causal Signals in Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-10-31">31 Oct 2017</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1605.08179v2[stat.ML]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>This paper establishes the existence of observable footprints that reveal the &quot;causal dispositions&quot; of the object categories appearing in collections of images. We achieve this goal in two steps. First, we take a learning approach to observational causal discovery, and build a classifier that achieves state-of-the-art performance on finding the causal direction between pairs of random variables, given samples from their joint distribution. Second, we use our causal direction classifier to effectively distinguish between features of objects and features of their contexts in collections of static images. Our experiments demonstrate the existence of a relation between the direction of causality and the difference between objects and their contexts, and by the same token, the existence of observable signals that reveal the causal dispositions of objects.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Imagine an image representing a bridge over a river. On top of the bridge, a car is speeding through the right lane.</p><p>Modern computer vision algorithms excel at answering questions about the observable properties of the scene, such as such as "Is there a car in this image?". This is achieved by leveraging correlations between pixels and image features across large datasets of images. However, a more nuanced understanding of images arguably requires the ability to reason about how the scene depicted in the image would change in response to interventions. Since the list of possible interventions is long and complex, we can, as a first step, reason about the intervention of removing an object.</p><p>To this end, consider the two counterfactual questions "What would the scene look like if we were to remove the car?" and "What would the scene look like if we were to remove the bridge?" On the one hand, the first intervention seems rather benign. After removing the car, we could argue Our goal is to reveal causal relationships between pairs of real entities composing scenes in the world (e.g. "the presence of cars cause the presence of wheels", solid blue arrow). To this end, we apply a novel observational causal discovery technique, NCC, to the joint distribution of a pair of related proxy variables that are computed by applying CNNs to the image pixels. Since these variables are expected to be highly correlated with the presence of the corresponding real entities, the appearance of causation between the proxy variables (dashed blue arrow) suggests that there is a causal link between the real world entities themselves (e.g. the appearance of causation between score(car) and score(wheel) suggests that the presence of cars causes the presence of wheels in the real world.)</p><p>that the rest of the scene depicted in the image (the river, the bridge) would remain invariant. On the other hand, the second intervention seems more severe. If the bridge had been removed from the scene, it would, in general, make little sense to observe the car floating weightlessly above the river. Thus, we understand that the presence of the bridge has an effect on the presence of the car. Reasoning about these and similar counterfactuals allows to begin asking "Why is there a car in this image?" This question is of course poorly defined, but the answer is linked to the causal relationship between the bridge and the car. In our example, the presence of the bridge causes the presence of the car, in the sense that if the bridge were not there, then the car would not be either (needless to say, it is not the only cause for the car). Such interventional semantics of what is meant by causation align with current approaches in the literature <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b21">22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Causal dispositions</head><p>We have so far discussed causal relations between two objects present in a single image, representing a particular scene. In order to deploy statistical techniques, we must work with a large collection of images representing a variety of scenes. Similar objects may have different causal relationships in different scenes. For instance, an image may show a car passing under the bridge, instead of over the bridge.</p><p>The dispositional semantics of causation <ref type="bibr" target="#b19">[20]</ref> provide a way to address this difficulty. In this framework, causal relations are established when objects exercise some of their causal dispositions, which are sometimes informally called the powers of objects. For instance a bridge has the power to provide support for a car, and a car has the power to cross a bridge. Although the objects present in a scene do not necessarily exercise all of their powers, the foundation of the dispositional theory of causation is that all causal relationships are manifestations of the powers of objects. <ref type="bibr" target="#b0">1</ref> Since the list of potential causal dispositions is as long and complex as the list of possible interventions, we again restrict our attention to interventions that affect the presence of certain objects in the scene. In particular we can count the number C(A, B) of images in which the causal dispositions of objects of categories A and B are exercised in a manner that the objects of category B would disappear if one were to remove objects of category A. We then say that the objects of category A cause the presence of objects of category B when C(A, B) is (sufficiently) greater than the converse C(B, A). This definition induces a network of asymmetric causal relationships between object categories that represents, on average, how real-world scenes would be modified when one were to make certain objects disappear.</p><p>The fundamental question addressed in this paper is to determine whether such an asymmetric causal relationship can be inferred from statistics observed in image datasets. Hypothesis 1. Image datasets carry an observable statistical signal revealing the asymmetric relationship between object categories that results from their causal dispositions.</p><p>To our knowledge, no prior work has established or even considered the existence of such a signal. If such a signal were found, it would imply that it is in principle possible for Causal dispositions are more primitive concepts than the causal graphs of Pearl's approach <ref type="bibr" target="#b21">[22]</ref>. Therefore, in our case, causal dispositions are responsible for the shape of causal graphs. statistical computer vision algorithms to reason about the causal structure of the world. This is not small feat, given that it is being debated in statistics until this day whether one can at all infer causality from purely statistical information, without performing interventions. The focus of this contribution is to establish the existence of such causal signals using a newly proposed method. We do not, in contrast, make any engineering contribution advancing the state-of-the-art in standard computer vision tasks using these signals -this is beyond the scope of the present paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Object features and context features</head><p>Since image datasets do not provide labels describing the causal dispositions of objects, we cannot resort to supervised learning techniques to find the causal signal put forward by Hypothesis 1. Instead, we take an indirect approach described below.</p><p>The features computed by the final layers of a convolutional neural network (CNN) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b7">8]</ref> often indicate the presence of a well localized object-like feature in the scene depicted by the image under study. <ref type="bibr" target="#b1">2</ref> Various techniques have been developed to investigate where these object-like features appear in the scene and what they look like in the image <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b30">31]</ref>. We can therefore examine large collections of images representing different objects of interest such as cats, dogs, trains, buses, cars, and people. The locations of these objects in the images are given to us in the form of bounding boxes. For each object of interest, we can distinguish between object features and context features. By definition, the object features are those that are mostly activated inside the bounding box of the object of interest, and the context features are those that are mostly activated outside the bounding box of the object of interest. Independently and in parallel, we also distinguish between causal features and anticausal features <ref type="bibr" target="#b26">[27]</ref>. Causal features are those that cause the presence 3 of the object in the scene, whereas anticausal features are those caused by the presence of the object in the scene.</p><p>Having made a distinction between object and context features, our indirect approach relies on a second hypothesis: Hypothesis 2. There exists an observable statistical dependence between object features and anticausal features. The statistical dependence between context features and causal features is nonexistent or much weaker.</p><p>We expect Hypothesis 2 to be true, because many of the features caused by the presence of an object of interest are in fact parts of the object itself, and hence are likely to be contained inside its bounding box. For instance, the presence of a car often causes the presence of wheels. In contrast, the context of an object of interest may either cause or be The word feature in this work describes a property of the scene whose presence is flagged by feature activations computed by the CNN.</p><p>caused by the presence of the object. For instance, asphaltlike features cause the presence of a car, but the car's shadow is caused by the presence of the car. Importantly, empirical support in favour of Hypothesis 2 translates into support in favour of Hypothesis 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Our contribution</head><p>Our plan is to use a large collection of images to provide empirical evidence in favour of Hypothesis 2. In order to do so, we must effectively determine, for each object category, which features are causal or anti-causal. In this manner we would support Hypothesis 2, and consequently, Hypothesis 1.</p><p>Our exposition is organized as follows. After a discussing related literature, Section 2 introduces the basics of causal inference from observational data. Section 3 proposes a new algorithm, the Neural Causation Coefficient (NCC), able to learn causation from a corpus of labeled data. NCC is shown to outperform the previous state-of-the-art in causeeffect inference. Section 4 makes use of NCC to distinguish between causal and anticausal features in collections of images. As hypothesized, we show a consistent relationship between anticausal features and object features. Finally, Section 5 closes our exposition by offering some conclusions and directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">Related work</head><p>The experiments described in this paper depend crucially on the properties of the features computed by the convolutional layers of a CNN <ref type="bibr" target="#b13">[14]</ref>. Zeiler et al. <ref type="bibr" target="#b30">[31]</ref> show that the final convolutional layers can often be interpreted as objectlike features. Work on weak supervision <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b31">32]</ref> suggests that such features can be accurately localized.</p><p>We also build on the growing literature discussing the discovery of causal relationships from observational data <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b0">1]</ref>. In particular, the Neural Causation Coefficient (Section 3) is related to <ref type="bibr" target="#b16">[17]</ref> but offers superior performance, and is learned end-to-end from data. The notion of causal and anticausal features was inspired by <ref type="bibr" target="#b26">[27]</ref>. We believe that our work is the first observational causal discovery technique that targets the causal dispositions of objects.</p><p>Causation in computer vision has been the object of at least four recent works. Pickup et al. <ref type="bibr" target="#b23">[24]</ref> use observational causal discovery techniques to determine the direction of time in video playback. Lebeda et al. <ref type="bibr" target="#b12">[13]</ref> use transfer entropy to study the causal relationship between object and camera motions in video data. Fire and Zhu <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> use video data annotated with object status and actions to infer perceptual causality. The work of Chalupka et al. <ref type="bibr" target="#b1">[2]</ref> is closer to our work because it addresses causation issues in images. However, their work deploys interventional experiments to target causal relationships in the labelling process, that is, which pixel manipulations can result in different labels, whereas</p><formula xml:id="formula_0">f â¼ P f for j = 1, . . . , m do x j â¼ P c (X) e j â¼ P e (E) y j â f (x j ) + e j end for return S = {(x j , y j )} m j=1 Figure 2: Additive Noise Model, where X â Y .</formula><p>we target causal relationships in scenes from a purely observational perspective. This critical difference leads to very different conceptual and technological challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Observational causal discovery</head><p>Randomized experiments are the gold standard for causal inference <ref type="bibr" target="#b21">[22]</ref>. Like a child may drop a toy to probe the nature of gravity, these experiments rely on interacting with the world to reveal causal relations between variables of interest. When such experiments are expensive, unethical, or impossible to conduct, we must discern cause from effect using observational data only, and without the ability to intervene <ref type="bibr" target="#b29">[30]</ref>. This is the domain of observational causal discovery.</p><p>In the absence of any assumptions, the determination of causal relations between random variables given samples from their joint distribution is fundamentally impossible <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. However, it may still be possible to determine a plausible causal structure in practice. For joint distributions that occur in the real world, the different causal interpretations may not be equally likely. That is, the causal direction between typical variables of interest may leave a detectable signature in their joint distribution. We shall exploit this insight to build a classifier for determining the cause-effect relation between two random variables from samples of their joint distribution.</p><p>In its simplest form, observational causal discovery <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b17">18]</ref> considers the observational sample</p><formula xml:id="formula_1">S = {(x j , y j )} m j=1 â¼ P m (X, Y ),<label>(1)</label></formula><p>and aims to infer whether X â Y or Y â X. In particular, S is assumed to be drawn from one of two models: from a causal model where X â Y , or from an anticausal model where X â Y . <ref type="figure">Figure 2</ref> exemplifies a family of such models, the Additive Noise Model (ANM) <ref type="bibr" target="#b9">[10]</ref>, where the effect variable Y is a nonlinear function f of the cause variable X, plus some independent random noise E. If we make no assumptions about the distributions P f , P c , and P e appearing in <ref type="figure">Figure 2</ref>, the problem of observational causal discovery is nonidentifiable <ref type="bibr" target="#b22">[23]</ref>. To address this issue, we assume that whenever X â Y , the cause, noise, and mechanism distributions are "independent". This should be interpreted as an informal statement that includes two types of independences. One is the independence between the cause and the mechanism (ICM) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b26">27]</ref>, which is formalized not as an independence between the input variable x and the mechanism f , but as an independence between the data source (that is, the distribution P (X)) and the mechanism P (Y |X) mapping cause to effect. This can be formalized either probabilistically <ref type="bibr" target="#b2">[3]</ref> or in terms of algorithmic complexity <ref type="bibr" target="#b11">[12]</ref>. The ICM is one incarnation of uniformitarianism: processes f in nature are fixed and agnostic to the distributions P c of their causal inputs. The second independence is between the cause and the noise. This is a standard assumption in structural equation modeling, and it can be related to causal sufficiency. Essentially, if this assumption is violated, our causal model is too small and we should include additional variables <ref type="bibr" target="#b21">[22]</ref>. In lay terms, believing these assumptions amounts to not believing in spurious correlations.</p><formula xml:id="formula_2">â1 0 1 X â1 0 1 Y (a) ANM X â Y . â1 0 1 Y â1 0 1 X (b) ANM Y â X 0.0 0.5 1.0 X â3 â2 â1 0 1 2 3 Y P (Y ) P (X) (c) Monotonic X â Y .</formula><p>For most choices of (P c , P e , P f ), the ICM will be violated in the anticausal direction X â Y . This violation will often leave an observable statistical footprint, rendering cause and effect distinguishable from observational data alone <ref type="bibr" target="#b22">[23]</ref>. But, what exactly are these causal footprints, and how can we develop statistical tests to find them?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Examples of observable causal footprints</head><p>Let us illustrate two types of observable causal footprints. First, consider a linear additive noise model Y â f (X) + E, where the cause X and the noise E are two independent uniform random variables with bounded range, and the mechanism f is a linear function <ref type="figure" target="#fig_1">(Figure 3a)</ref>. Crucially, it is impossible to construct a linear additive noise model X âf (Y )+áº¼ where the new cause Y and the new noiseáº¼ are two independent random variables (except in degenerate cases). This is illustrated in <ref type="figure" target="#fig_1">Figure 3b</ref>, where the variance of the new noise variableáº¼ varies (as depicted in red bars) across different locations of the new cause variable Y . Therefore, the ICM assumption is satisfied for the correct causal direction X â Y but violated for the wrong causal direction Y â X. This asymmetry makes cause distinguishable from effect <ref type="bibr" target="#b9">[10]</ref>. Here, the relevant footprint is the independence between X and E.</p><p>Second, consider a new observational sample where X â Y , Y = f (X), and f is a monotone function. The causal relationship X â Y is deterministic, so the noisebased footprints from the previous paragraphs are rendered useless. Let us assume that P (X) is a uniform distribution. Then, the probability density function of the effect Y increases whenever the derivative f decreases, as depicted by <ref type="figure" target="#fig_1">Figure 3c</ref>. Loosely speaking, the shape of the effect distribution P (Y ) is thus not independent of the mechanism f . In this example, ICM is satisfied under the correct causal direction X â Y , but violated under the wrong causal direction Y â X <ref type="bibr" target="#b2">[3]</ref>. Again, this asymmetry renders the cause distinguishable from the effect <ref type="bibr" target="#b2">[3]</ref>. Here, the relevant footprint is a form of independence between the density of X and f .</p><p>It may be possible to continue in this manner, considering more classes of models and adding new footprints to detect causation in each case. However, engineering and maintaining a catalog of causal footprints is a tedious task, and any such catalog will most likely be incomplete. The next section thus proposes to use neural networks to learn causal footprints directly from data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The neural causation coefficient</head><p>To learn causal footprints from data, we follow <ref type="bibr" target="#b17">[18]</ref> and pose cause-effect inference as a binary classification task. Our input patterns S i are effectively scatterplots similar to those shown in <ref type="figure" target="#fig_1">Figures 3a and 3b</ref>. That is, each data point is a bag of samples (x ij , y ij ) â R 2 drawn iid from a distribution P (X i , Y i ). The class label l i indicates the causal direction between X i and Y i .</p><formula xml:id="formula_3">D = {(S i , l i )} n i=1 , S i = {(x ij , y ij )} mi j=1 â¼ P mi (X i , Y i ), l i = 0 if X i â Y i 1 if X i â Y i .<label>(2)</label></formula><p>Using data of this form, we will train a neural network to classify samples from probability distributions as causal or anticausal. Since the input patterns S i are not fixed-dimensional vectors, but bags of points, we borrow inspiration from the literature on kernel mean embedding classifiers <ref type="bibr" target="#b27">[28]</ref> and construct a feedforward neural network of the form</p><formula xml:id="formula_4">NCC({(x ij , y ij )} mi j=1 ) = Ï ï£« ï£­ 1 m i mi j=1 Ï(x ij , y ij ) ï£¶ ï£¸ .</formula><p>In the previous, Ï is a feature map, and the average over all Ï(x ij , y ij ) is the mean embedding of the empirical distribu-</p><formula xml:id="formula_5">tion 1 mi mi i=1 Î´ (xij ,yij ) .</formula><p>The function Ï is a binary classifier that takes a fixed-length mean embedding as input <ref type="bibr" target="#b17">[18]</ref>. In kernel methods, Ï is fixed a priori and defined with respect to a nonlinear kernel <ref type="bibr" target="#b27">[28]</ref>. In contrast, our feature map Ï : R 2 â R h and our classifier Ï : R h â {0, 1} are both multilayer perceptrons, which are learned jointly from data. <ref type="figure" target="#fig_2">Figure 4</ref> illustrates the proposed architecture, which we term the Neural Causation Coefficient (NCC). In short, to classify a sample S i as causal or anticausal, NCC maps each point (x ij , y ij ) in the sample S i to the representation Ï(x ij , y ij ) â R h , computes the embedding vector Ï Si := 1 mi mi j=1 Ï(x ij , y ij ) across all points (x ij , y ij ) â S i , and classifies the embedding vector Ï Si â R h as causal or anticausal using the neural network classifier Ï. Importantly, the proposed neural architecture is not restricted to causeeffect inference, and can be used to represent and learn from general distributions.</p><formula xml:id="formula_6">{(x ij , y ij )} mi j=1 (x i1 , y i1 ) (x imi , y imi ) 1 mi mi j=1 (â¢)P (X i â Y i )</formula><p>NCC has some attractive properties. First, predicting the cause-effect relation for a new set of samples at test time can be done efficiently with a single forward pass through the aggregate network. The complexity of this operation is linear in the number of samples. In contrast, the computational complexity of the state-of-the-art (kernel-based additive noise models) is cubic in the number of samples. Second, NCC can be trained using mixtures of different causal and anticausal generative models, such as linear, non-linear, noisy, and deterministic mechanisms linking causes to their effects. This rich training allows NCC to learn a diversity of causal footprints simultaneously. Third, for differentiable activation functions, NCC is a differentiable function. This allows us to embed NCC into larger neural architectures or to use it as a regularization term to encourage the learning of causal or anticausal patterns.</p><p>The flexibility of NCC comes at a cost. In practice, labeled cause-effect data as in Equation <ref type="formula" target="#formula_3">2</ref>is scarce and laborious to collect. Because of this, we follow <ref type="bibr" target="#b17">[18]</ref> and train NCC on artificially generated data. This turns out to be advantageous as it gives us easy access to unlimited data. In the following, we describe the process to generate synthetic cause-effect data along with the training procedure for NCC, and demonstrate the performance of NCC on real-world cause-effect data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Synthesis of training data</head><p>Causal signals differ significantly from the correlation structures exploited by modern computer vision algorithms. In particular, since the first and second moments are always symmetrical, causal signals can only be found in high-order moments.</p><p>More specifically, we will construct n synthetic observational samples S i (see <ref type="figure">Figure 2)</ref>, where the ith observational sample contains m i points. The points comprising the observational sample S i = {(x ij , y ij )} mi j=1 are drawn from an heteroscedastic additive noise model y ij â f i (x ij ) + v ij e ij , for all j = 1, . . . , m i . In this manner, we generalize the homoscedastic noise assumption ubiquitous in previous literature <ref type="bibr" target="#b18">[19]</ref>.</p><p>The cause terms x ij are drawn from a mixture of k i Gaussians distributions. We construct each Gaussian by sampling its mean from Gaussian(0, r i ), its standard deviation from Gaussian(0, s i ) followed by an absolute value, and its unnormalized mixture weight from Gaussian(0, 1) followed by an absolute value. We sample k i â¼ RandomInteger <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref> and r i , s i â¼ Uniform <ref type="bibr">[0,</ref><ref type="bibr" target="#b4">5]</ref>. We normalize the mixture weights to sum to one. We normalize {x ij } mi j=1 to zero mean and unit variance.</p><p>The mechanism f i is a cubic Hermite spline with support</p><formula xml:id="formula_7">min({x ij } mi j=1 ) â std({x ij } mi j=1 ) , max({x ij } mi j=1 ) + std({x ij } mi j=1 )<label>(3)</label></formula><p>and d i knots drawn from Gaussian(0, 1), where d i â¼ RandomInteger <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b4">5)</ref>. The noiseless effect terms {f (x ij )} mi j=1 are normalized to have zero mean and unit variance.</p><p>The noise terms e ij are sampled from Gaussian(0</p><formula xml:id="formula_8">, v i ), where v i â¼ Uniform[0, 5].</formula><p>To generalize the ICM, we allow for heteroscedastic noise: we multiply each e ij by v ij , where v ij is the value of a smoothing spline with support defined as in Equation <ref type="formula" target="#formula_7">3</ref> This sampling process produces a training set of 2n labeled observational samples</p><formula xml:id="formula_9">D = ({(x ij , y ij )} mi j=1 , 0) n i=1 âª ({(y ij , x ij )} mi j=1 , 1) n i=1 .<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training NCC</head><p>We train NCC with two embedding layers and two classification layers followed by a softmax output layer. Each hidden layer is a composition of batch normalization <ref type="bibr" target="#b10">[11]</ref>, 100 hidden neurons, a rectified linear unit, and 25% dropout <ref type="bibr" target="#b28">[29]</ref>. We train for 10000 iterations using RMSProp <ref type="bibr" target="#b8">[9]</ref> with the default parameters, where each minibatch is of the form given in Equation <ref type="formula" target="#formula_9">4</ref>and has size 2n = 32. Lastly, we further enforce the symmetry P(X â Y ) = 1 â P(Y â X), by training the composite classifier</p><formula xml:id="formula_10">1 1 â NCC({(x ij , y ij )} mi j=1 ) + NCC({(y ij , x ij )} mi j=1 ) ,<label>(5)</label></formula><p>where NCC({(x ij , y ij )} mi j=1 ) tends to zero if the classifier believes in X i â Y i , and tends to one if the classifier believes in X i â Y i . We chose our parameters by monitoring the validation error of NCC on a held-out set of 10000 synthetic observational samples. Using this held-out set, we cross-validated the dropout rate over {0.1, 0.25, 0.3}, the number of hidden layers over {2, 3}, and the number of hidden units in each of the layers over {50, 100, 500}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Testing NCC</head><p>We test the performance of NCC on the TÃ¼bingen datasets, version 1.0 <ref type="bibr" target="#b18">[19]</ref>. This is a collection of one hundred heterogeneous, hand-collected, real-world cause-effect observational samples that are widely used as a benchmark in the causal inference literature <ref type="bibr" target="#b17">[18]</ref>. The NCC model with the highest synthetic held-out validation accuracy correctly classifies the cause-effect direction of 79% of the TÃ¼bingen datasets observational samples. This result outperforms the previous state-of-the-art on observational cause-effect discovery, which achieves 75% accuracy on this dataset <ref type="bibr" target="#b17">[18]</ref>. <ref type="bibr" target="#b3">4</ref> The accuracies reported in <ref type="bibr" target="#b17">[18]</ref> are for version 0.8 of the dataset, so we reran the algorithm from <ref type="bibr" target="#b17">[18]</ref> on version 1.0 of the dataset. This validation highlights a crucial fact: even when trained on abstract data, NCC discovers the correct causeeffect relationship in a wide variety of real-world datasets. But: Do these abstract, domain-independent, causal footprints hide in complex image data?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Causal signals in sets of static images</head><p>We now have at our disposal all the necessary tools to verify our hypotheses. In the following, we chose to work with the twenty object categories of the Pascal VOC 2012 dataset <ref type="bibr" target="#b3">[4]</ref>. We first explain how we use NCC to select the most plausible causal or anticausal features for each object category. We then we show that the selected anticausal features are more likely to be object features, that is, located within the object bounding box, than the selected causal features. This establishes that Hypothesis 2 is true, and, as a consequence, also establish that Hypothesis 1 is true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>Our experiments use a feature extraction network trained on the ImageNet <ref type="bibr" target="#b25">[26]</ref> dataset and a classifier network trained on the Pascal VOC 2012 dataset <ref type="bibr" target="#b3">[4]</ref>. We then use these networks to identify causal relationships on the subset of the 99,309 MSCOCO images <ref type="bibr" target="#b15">[16]</ref> representing objects belonging to the twenty Pascal categories: aeroplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow, dining table, dog, horse, motorbike, person, potted plant, sheep, sofa, train, and television. These datasets feature heterogeneous images that possibly contain multiple objects from different categories. The objects may appear at different scales and angles, and be partially visible or occluded. In addition to these challenges, we have no control about the confounding and selection bias effects polluting these datasets of images. All images are rescaled to ensure that their shorter side is 224 pixels long, then cropped to the central 224Ã224 square.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Selecting causal and anticausal features</head><p>Our first task is to determine which of the features scores computed by the feature extraction neural network represent real world entities that cause the presence of the object of interest (causal features), or are caused by the presence of the object of interest (anticausal features).</p><p>To that effect, we consider the feature scores computed by a 18-layer ResNet <ref type="bibr" target="#b7">[8]</ref> trained on the ImageNet dataset using a proven implementation <ref type="bibr" target="#b6">[7]</ref>. Building on top of these features, we use the Pascal VOC2012 dataset to train an independent network with two 512-unit hidden layers to recognize the 20 Pascal VOC2012 categories, For each of the MSCOCO images containing at least one instance of the twenty Pascal VOC 2012 object categories, x j â R 3Ã224Ã224 , let f j = f (x j ) â R 512 denote the vector of feature scores (before the ReLU nonlinearity) obtained using the feature extraction network and let c j = c(x j ) â R 20  <ref type="figure">Figure 5</ref>: Blacking out image pixels to distinguish objectfeatures from context-features. We show the original image x j , and the corresponding object-only image x o j and context-only image x c j for the category "dog". The pixels are blacked out after normalizing the image in order to obtain true zero pixels. denote the vector of log-odds (that is, the output unit activations before the sigmoid nonlinearity) obtained using the classifier network. We use features before their nonlinearity and log odds instead of the class probabilities because NCC is trained on continuous data with full support on R.</p><p>As depicted in <ref type="figure">Figure 1</ref>, for each category k â {1 . . . 20} and each feature l â {1 . . . 512}, we apply NCC to the scatterplot {(f jl , c jk )} m j=1 representing the joint distribution of the scores of feature j and the score of category k. Since these scores are computed by running our neural networks on the image pixels, they are not related by a direct causal relationship. However we know that these scores are highly correlated with the presence of objects and features in the real scene. Therefore, the appearance of a causal relationship between these scores suggests that there is a causal relationship between the real world entities they represent.</p><p>Because we analyze one feature at a time, the values taken by all other features appear as an additional source of noise, and the observed statistical dependencies are then be much weaker than in the synthetic NCC training data. To avoid detecting causation between independent random variables, we use a variant of NCC trained with an augmented training set: in addition to presenting each scatterplot in both causal directions as in (4), we pick a random permutation Ï to generate an additional uncorrelated example {x i,Ï(j) , y ij } mi j=1 with label <ref type="bibr" target="#b0">1</ref> . We use our best model of this kind which, for validation purposes, achieves 79% accuracy in the TÃ¼bingen pair benchmark.</p><p>For each category k â 1 . . . 20, we then record the indices of the top 1% causal and the top 1% anticausal features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Verifying Hypothesis 2</head><p>In order to verify Hypothesis 2, it is sufficient to show that the top anticausal features are more likely to be object features than the top causal features. For each category k and each feature j, we must therefore determine whether feature j is likely to be an object feature or a context feature. This is relatively easy because we have access to the object bounding boxes and we simply need to determine how much of each feature score j is imputable to the bounding boxes of the objects of category k.</p><p>To that effect, we prepare two alternate versions of each MSCOCO image x j by blacking out (with zeroes) the pixels located outside the bounding boxes of the category k objects, yielding the object-only image x o j , or by blacking out the pixels located inside the bounding boxes of the category k objects, yielding the context-only image x c j . This process is illustrated in <ref type="figure">Figure 5c</ref>. We then compute the corresponding vectors of feature scores f o j = f (x o j ) and f c j = f (x c j ). For each category k and each feature f we heuristically define the object-feature ratio s o l and the context-feature ratio s c l as follows:</p><formula xml:id="formula_11">s o l = m j=1 f c jl â f jl m j=1 |f jl | , s c l = m j=1 f o jl â f jl m j=1 |f jl | .</formula><p>Intuitively, features with high object-feature ratio (resp. high context-feature ratio) are those features that react violently when the object (resp. the context) is erased.</p><p>Note that blacking out pixels does not constitute an intervention on the scene represented by the image. This is merely a procedure to impute the contribution of the object bounding boxes to each feature score. <ref type="figure">Figure 6</ref> shows the means and the standard deviations of the object-context ratios (top plot) and the context-feature ratios (bottom plot) estimated on the top 1% anticausal features (blue bars) and the top 1% causal features (green bars) for each of the twenty object categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results</head><p>As predicted by Hypothesis 2, object features are related to anticausal features: the top 1% anticausal features exhibit a higher object-feature ratio than the top 1% causal features. Since this effect can be observed on all 20 classes of interest, the probability of obtaining such a result by chance would be 2 â20 â10 â6 . When we select the top 20% causal and anticausal features, this effect remains consistent across 16 out of 20 classes of interest.</p><p>This result indicates that anticausal features may be useful for detecting objects locations in a robust manner, regardless of their context. As stated in Hypothesis 2, we could not find a consistent relationship between context features and causal features. Remarkably, we remind the reader that the NCC classifier does not depend on the object categories and was trained using synthetic data unrelated to images. As a sanity check, we did not obtain any such results when replacing the NCC scores with the correlation coefficient or the absolute value of the correlation coefficient. <ref type="bibr" target="#b4">5</ref> We also ran preliminary experiments to find causal relationships be- context-feature ratio <ref type="figure">Figure 6</ref>: Average and standard deviation of the object/context feature scores associated to the top 1% causal/anticausal feature scores, for all the twenty studied categories. The average object feature score associated to the top 1% anticausal feature scores is always higher than the average object feature score associated to the top 1% causal features. Such separation does not occur for context feature scores. These results are strong empirical evidence in favour of Hypoteheses 1 and 2: the probability of obtaining these results by chance is 2 â20 â 10 â6 .</p><p>Therefore we believe that this result establishes that Hypothesis 2 is true with high certainty. As explained in Section 1.3, verifying Hypothesis 2 in this manner also implies confirms Hypothesis 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Using a carefully designed experiment, we have established that the high order statistical properties of image datasets contain information about the causal dispositions of objects and, more generally, about causal structure of the real world.</p><p>Our experiment relies on three main components. First, we use synthetic scatterplots to train a binary classifier that identifies plausible causal (XâY ) and anticausal (XâY ) relations. Second we hypothesise that the distinction between object features and context features in natural scenes tween objects of interest, by computing the NCC scores between the log odds of different objects of interest. The strongest causal relationships that we found were "bus causes car," "chair causes plant," "chair causes sofa," "dining table causes bottle," "dining table causes chair," "dining table causes plant," "television causes chair," and "television causes sofa." is related to the distinction between features that cause the presence of the object and features that are caused by the presence of the object. Finally, we construct an experiment that leverages static image datasets to establish that this latter hypothesis is true. Thus, we conclude that we must therefore have been able to effectively distinguish which features were causal or anticausal.</p><p>Because we now know that such a signal exist, we can envision in a reasonable future that computer vision algorithms will be able to perceive the causal structure of the real world and reason about scenes. There is no question that significant algorithmic advances will be necessary to achieve this goal. In particular, we stress the importance of (1) building large, real-world datasets to aid research in causal inference, (2) extending data-driven techniques like NCC to causal inference of more than two variables, and (3) exploring data with explicit causal signals, such as the arrow of time in videos (e.g. <ref type="bibr" target="#b23">[24]</ref>.)</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Our goal is to reveal causal relationships between pairs of real entities composing scenes in the world (e.g. "the presence of cars cause the presence of wheels", solid blue arrow). To this end, we apply a novel observational causal discovery technique, NCC, to the joint distribution of a pair of related proxy variables that are computed by applying CNNs to the image pixels. Since these variables are expected to be highly correlated with the presence of the corresponding real entities, the appearance of causation between the proxy variables (dashed blue arrow) suggests that there is a causal link between the real world entities themselves (e.g. the appearance of causation between score(car) and score(wheel) suggests that the presence of cars causes the presence of wheels in the real world.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Examples of causal footprints.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Scheme of the Neural Causation Coefficient (NCC) architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>and d i random knots drawn from Uniform[0, 5]. The noisy effect terms {y ij } mi j=1 are normalized to have zero mean and unit variance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>r b i k e p e r s o n p o t t e d p l a n t s h e e p s o f a t r a i n t</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">In the sense defined in Section 1.1.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Estimating causal direction and confounding of two discrete variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chalupka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visual causal feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chalupka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eberhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Inferring deterministic causal relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>DaniuÅ¡is</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zscheischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<title level="m">The PASCAL Visual Object Classes Challenge 2012 (VOC2012)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using causal induction in humans to learn and infer causality from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Cognitive Science Society</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning perceptual causality from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TIST</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ResNet training in Torch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Lecture 6a: Overview of mini-batch gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nonlinear causal discovery with additive noise models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Causal inference using the algorithmic Markov condition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploring causal relationships in visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lebeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hadfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bowden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Causal models as minimal descriptions of multivariate systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lemeire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dirkx</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Microsoft COCO: common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>DollÃ¡r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 13th European Conference on Computer Vision (ECCV 2014), Part V</title>
		<meeting>13th European Conference on Computer Vision (ECCV 2014), Part V</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The randomized causation coefficient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards a learning theory of cause-effect inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">O</forename><surname>Tolstikhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML 2015)</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML 2015)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distinguishing cause from effect using observational data: methods and benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zscheischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Getting Causes from Powers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Anjum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Is object localization for free? -weakly-supervised learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning, and Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Causal discovery with continuous additive noise models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Seeing the arrow of time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Pickup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Which ifs have causal answers. Discussion of Holland&apos;s &quot;Statistics and Causal Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Americal Statistical Association</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-04" />
		</imprint>
		<respStmt>
			<orgName>ImageNet Large Scale Visual Recognition Challenge. IJCV</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On causal and anticausal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Machine Learning</title>
		<meeting>the 29th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note>ICML 2012</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Hilbert space embedding for distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ALT</title>
		<meeting>ALT</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Inferring causal networks from observations and interventions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Blum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<title level="m">Visualizing and understanding convolutional networks</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Object detectors emerge in deep scene CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
