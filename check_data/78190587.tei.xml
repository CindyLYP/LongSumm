<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Texture Synthesis Through Convolutional Neural Networks and Spectrum Constraints</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Liu</surname></persName>
							<email>gang.liu@telecom-paristech.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Telecom-ParisTech</orgName>
								<orgName type="institution" key="instit2">LTCI CNRS</orgName>
								<address>
									<addrLine>46 Rue Barrault</addrLine>
									<postCode>75013</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Gousseau</surname></persName>
							<email>gousseau@telecom-paristech.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Telecom-ParisTech</orgName>
								<orgName type="institution" key="instit2">LTCI CNRS</orgName>
								<address>
									<addrLine>46 Rue Barrault</addrLine>
									<postCode>75013</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
							<email>guisong.xia@whu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Lab. LIESMARS</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<addrLine>129 Luoyu Road</addrLine>
									<postCode>430079</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Texture Synthesis Through Convolutional Neural Networks and Spectrum Constraints</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a significant improvement for the synthesis of texture images using convolutional neural networks (CNNs), making use of constraints on the Fourier spectrum of the results. More precisely, the texture synthesis is regarded as a constrained optimization problem, with constraints conditioning both the Fourier spectrum and statistical features learned by CNNs. In contrast with existing methods, the presented method inherits from previous CNN approaches the ability to depict local structures and fine scale details, and at the same time yields coherent large scale structures, even in the case of quasi-periodic images. This is done at no extra computational cost. Synthesis experiments on various images show a clear improvement compared to a recent state-of-the art method relying on CNN constraints only.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>A large body of works has been dedicated over the last 30 years to the task of texture synthesis and more precisely to the task of generating new but perceptually similar images from a given exemplar. Parametric Markov models were among the first to be investigated for such tasks <ref type="bibr" target="#b0">[1]</ref>. Then, many methods were developed relying on the idea, inspired by the works of Julesz <ref type="bibr" target="#b1">[2]</ref>, that realistic textures could be obtained by constraining a well chosen set of image statistics: wavelet marginals <ref type="bibr" target="#b2">[3]</ref>, joint statistics of wavelet coefficients <ref type="bibr" target="#b3">[4]</ref>, Fourier spectrum <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> or the distribution of sparse representation coefficients <ref type="bibr" target="#b6">[7]</ref>. A completely different approach is provided by patch-based, non-parametric methods that have been largely studied after the initial works of <ref type="bibr" target="#b7">[8]</ref> and <ref type="bibr" target="#b8">[9]</ref>. Here, the basic idea is to generate a new texture by iteratively sampling patches from the exemplar, see e.g. <ref type="bibr" target="#b9">[10]</ref> for a review. These methods enable realistic results even on highly structured textures, at the price of very limited innovation capacity, see e.g. <ref type="bibr" target="#b10">[11]</ref>. Recently, the work from <ref type="bibr" target="#b11">[12]</ref> renewed this type of methods by promoting the use of parametric distributions for patches.</p><p>Recently, several synthesis methods based on convolutional neural networks (CNNs) have been proposed and shown to yield state-of-the art results <ref type="bibr" target="#b12">[13]</ref>- <ref type="bibr" target="#b15">[16]</ref>. Indeed, these methods are able to generate perceptually satisfying results on complex textures without producing piecewise recopy of the exemplar. The idea, in order to generate new textures, is to constrain some statistics of convolutional networks initially introduced for image classification. In <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, a non-parametric approach is proposed through the correlation matrices of filter responses (named feature maps), as we will see in more details later. In <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b14">[15]</ref>, a MRF model is learned from the feature <ref type="figure">Fig. 1</ref>. Illustration of the set of constraints used in this work. We impose both the correlations between filter responses in a CNN (in red) and the power spectrum (in green) of the solution. Observe that the synthesis results using only CNN constraints have good local structure and appearance but may lose large scale regularity, whose reproduction is allowed by constraining the spectrum. maps. One limitation of these approaches, however, is the difficulty to efficiently account for large scale regularity, see e.g. <ref type="figure">Fig. 1</ref> for an illustration.</p><p>In this work, we propose to incorporate some low frequency constraints into the CNN approach, in order to allow the synthesis of textures having large scale regularity. In particular, this will allow the synthesis of quasi-periodic textures such as brick wall or object alignments. In order to do this, we draw on previous works on texture synthesis <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b16">[17]</ref> that have shown the interest and easiness of using spectrum constraints for synthesizing textures. We therefore combine spectrum and feature maps constraint through the definition of a new loss function, allowing the reproduction of both fine scale details and large scale regular structures. The combination of these two types of constraints is illustrated in <ref type="figure">Fig. 1</ref>.</p><p>The remainder of the paper is organized as follows. In Sec.II we briefly recall how to use CNNs to synthesize textures. We then explain how to incorporate frequency control arXiv:1605.01141v3 [cs.CV] 19 May 2016</p><p>into this framework in Sec.III. Eventually, we experimentally show the interest of the approach in Sec.IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. TEXTURE SYNTHESIS BY CNNS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Convolution neural network</head><p>A convolution neural network (CNN) is a feed-forward artificial neural network whose neurons process overlapping regions of the input, generally an image. Parameters of such networks are usually learned using a back-propagated algorithm from a large number of annotated inputs. The network VGG-19, proposed in <ref type="bibr" target="#b17">[18]</ref>, is one of the CNN trained with the ImageNet dataset and has proven to be efficient in describing texture images with only convolution layers <ref type="bibr" target="#b18">[19]</ref>. Neglecting the latter fully connected layers, the network contains linearly rectified convolution layers and 5 pooling layers. Notice that for the task of texture synthesis, according to <ref type="bibr" target="#b13">[14]</ref>, the max-pooling strategy may be replaced by average-pooling for improving the gradient flow and obtaining slightly cleaner results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Texture model</head><p>In order to use CNNs for texture synthesis, it was first proposed in <ref type="bibr" target="#b13">[14]</ref> to constrain the statistics of feature maps. Inspired by Portilla and Simoncelli <ref type="bibr" target="#b3">[4]</ref>, important statistics are provided by correlations between the feature maps corresponding to different filters.</p><p>Given a texture exemplar I ∈ R N , where N is the number of pixels in the image, we first input I to the CNN to calculate the feature maps at each convolution layer. Suppose there are m l neurons at l-th convolution layer, the extracted feature map is denoted by f l ∈ R m l ×N l , with N l as the number of stimuli. Note that at the first convolution layer, N l = N .</p><p>After obtaining the feature map f l at the l-th layer, the correlation matrix</p><formula xml:id="formula_0">G l ∈ R m l ×m l [14] is computed as G l p,q = N l i=1 f l p (i) • f l q (i),<label>(1)</label></formula><p>where p, q denote the index of feature map corresponding to the filter p, q ∈ {1,</p><formula xml:id="formula_1">• • • , m l }.</formula><p>The set of correlation matrices</p><formula xml:id="formula_2">{G 1 , G 2 , • • • , G L</formula><p>} from the different layers are used to model the texture <ref type="bibr" target="#b13">[14]</ref> and to constrain the synthesis of new texture images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Texture generation</head><p>As proposed in <ref type="bibr" target="#b13">[14]</ref>, new texture samples are generated by starting from a white noise image and by iteratively imposing the previously defined correlation matrices, using gradient descent. <ref type="figure">Fig. 2</ref> shows the flowchart of this algorithm.</p><p>Given an imageÎ initialized by white noise, its feature mapsf l are computed at each layer of the CNN, as well as the correlation matrixĜ l . A loss function at layer l is then defined as the difference between the correlation matrices of the generated image and the reference one:</p><formula xml:id="formula_3">E l = 1 4N 2 l m 2 l m l p=1 m l q=1 G l p,q −Ĝ l p,q 2 .<label>(2)</label></formula><p>The derivative of this loss function is computed as</p><formula xml:id="formula_4">∂E l ∂f l p (i) = 1 N 2 l m 2 l m l q=1 f l q (i) • (G l p,q −Ĝ l p,q ).<label>(3)</label></formula><p>Note that this equation does not include a positive part as in <ref type="bibr" target="#b13">[14]</ref>, because the feature maps are always positive after the rectified linear transform. Combining these layers, a total loss function is defined as</p><formula xml:id="formula_5">L cnn (I,Î) = L l=0 w l E l ,<label>(4)</label></formula><p>where w l denotes the weight of loss at layer l. With the derivative given by Eq. <ref type="formula" target="#formula_4">3</ref>, a back-propagation (BP) algorithm can be applied to propagate the error from layer l to layer l − 1, which is illustrated in red line in <ref type="figure">Fig.2</ref>. Then, at each layer, the loss (or error) includes two aspects: the derivative of the current layer by Eq. 3 and the propagated error from the later layer. At any given layer in the network, we can obtain the propagated data error, denoted here by ∆ cnn . A solution is then computed using the L-BFGS algorithm <ref type="bibr" target="#b19">[20]</ref>, from the initialized imageÎ and the back-propagated error ∆ cnn .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. TEXTURE SYNTHESIS BY CNNS WITH SPECTRUM CONSTRAINT</head><p>Even though texture synthesis using CNN yields impressive results in many cases, it still suffers from several shortcomings. One of them is the difficulty to accurately reproduce regularity at large scales, typically low-frequency structures. This is illustrated in <ref type="figure">Fig.3</ref>. In this figure, the left column shows the original images and the right column displays the synthesized images, where large scales are not correctly handled. One possible reason for this is that the size of the convolutional filters in VGG-19 are 3 × 3 × N l , which are too small to depict the large structures. Another possible reason is that the number of layers of this network does not allow the handling of very large scale. Nevertheless in our experiments, neither increasing the filter size (this was tested using VGG-m <ref type="bibr" target="#b20">[21]</ref> and 7 × 7 filters) or increasing the number of layers did solve this issue. In this contribution, we show that enriching the loss function of the CNN with a term constraining the Fourier spectrum of the image solves this issue in many cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Spectrum constraint</head><p>It was shows in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b16">[17]</ref> that a large set of textures (the so-called micro-textures) may be reproduced simply by imposing the Fourier spectrum of the outputs and letting their Fourier phases be chosen at random. In a different direction, this constraint was used for enabling low frequency structures in sparsity-based texture synthesis <ref type="bibr" target="#b6">[7]</ref>, in a variational framework. We here follow a similar path by constraining the loss function in the CNN-based approach. In what follows, we write F(I) for the Discrete Fourier Transform (DFT) of an image I and F −1 for the inverse DFT.</p><p>In order to illustrate the Fourier representation of low frequency, quasi-periodic structures, <ref type="figure">Fig.4</ref> shows the amplitude of the DFT of two images, from which strong peaks can be observed. <ref type="figure">Fig. 2</ref>. The exemplar-based texture synthesis algorithm with CNN model <ref type="bibr" target="#b13">[14]</ref>. At each layer of the convolution neural network, the feature maps f l ,f l are extracted for both the reference image and the generated image. Then the errors E l between the correlation matrix G l andĜ l are calculated, where G l ,Ĝ l are the correlations of f l ,f l respectively. Through a back propagation algorithm (red line), the errors are propagated and the L-BFGS algorithm is used to compute the final result. <ref type="figure">Fig. 3</ref>.</p><p>Texture synthesis using CNNs according to <ref type="bibr" target="#b13">[14]</ref>. Left: a given exemplar texture. Right: synthesized result using the CNN model. Given an image I, we write E I for the set of images having the same spectrum (modulus of the Fourier transform) as I. Simple computations show that the projection of any given imageÎ on E I (that is, the image from E I being closest toÎ) is given byĨ</p><formula xml:id="formula_6">= F −1 F(Î) • F(I) * |F(Î) • F(I) * | • F(I) ,<label>(5)</label></formula><p>where F(I) * denotes the conjugate of F(I). For color images, the phase of the gray level image is first computed, and then imposed to each color channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Texture synthesis by CNNs with spectrum constraint</head><p>In order to constrain both the statistics of the feature maps and the spectrum of the results, we add in the loss function of the CNN an additional term, obtained from the distance of the current imageÎ to the space E I corresponding to some reference texture I. We write d(Î, E I ) for this term, then its gradient is simply computed asÎ −Ĩ, whereĨ is computed <ref type="figure">Fig. 4</ref>. The DFT of (the gray channel of) quasi-periodic images.</p><p>following Eq.(5). Therefore, the gradient term of the CNN is written as</p><formula xml:id="formula_7">∆ spe =Î −Ĩ,<label>(6)</label></formula><p>corresponding to the loss function</p><formula xml:id="formula_8">L spe = 1 d(Î, E I ) 2 ,<label>(7)</label></formula><p>where as before I is the reference texture.</p><p>The final loss function and gradient of the CNN are simply obtained as</p><formula xml:id="formula_9">L = L CN N + βL spe ,<label>(8)</label></formula><formula xml:id="formula_10">∆ = ∆ CN N + β∆ spe .<label>(9)</label></formula><p>The L-BFGS algorithm is then applied to synthesize a new texture image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS AND ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental setup</head><p>Following <ref type="bibr" target="#b13">[14]</ref>, the following layers of the convolution neural network are used: 'Conv1 1', 'Pooling1', 'Pooling2', 'Pooling3', 'Pooling4'. The corresponding weights are set to be w = w 2 = w 3 = w 4 = w 5 = 10 9 . For the spectrum constraint, we use β = 10 5 . For the experiments of this paper, we use CG texture samples 1 as input. All the images are rescaled first, as in <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Texture synthesis results</head><p>We illustrate the proposed approach by comparing it with the original CNN-based approach from <ref type="bibr" target="#b13">[14]</ref>. This last approach is one of the state-of-the art approaches among methods that produce truly new images. In particular, and contrarily to most patch-based methods derived from <ref type="bibr" target="#b7">[8]</ref> (see e.g. <ref type="bibr" target="#b10">[11]</ref>), these methods (the one from <ref type="bibr" target="#b13">[14]</ref>, as well as the proposed one) do not produce results containing parts that are verbatim copied from the exemplars.</p><p>In <ref type="figure">Fig. 5, 6</ref>, 7, the left column displays the given texture exemplars, the middle shows the synthesized results using the CNN-based algorithm <ref type="bibr" target="#b13">[14]</ref> and the right illustrates our results by combining the CNN model with a spectrum constraint.</p><p>In <ref type="figure">Fig. 5</ref>, from top to bottom are images of a checker board, two brick wall and a building with windows. All these have the particularity to present quasi-periodic structures. In the three first examples, we can see that the algorithm from <ref type="bibr" target="#b13">[14]</ref> fail to preserve the large scale organization, which is correctly reconstructed when adding the spectrum constraint. The last example is more difficult. Although not totally satisfying, the proposed method increases the regularity of the result. <ref type="figure">Fig. 6</ref> shows synthesis results from Zellige tiles, made of complex decorative patterns. Although some defaults may appear in the global organization of the synthesized images, the combined use of Fourier spectrum constraints and CNN permits the reproduction of both the global patterns and the small scale details. <ref type="figure">Fig. 7</ref> shows an example of failure, where the global structures are too complex to be reproduced by the proposed approach.</p><p>Although we do not illustrate it here, it is also worth mentioning that in the cases where the original approach from <ref type="bibr" target="#b13">[14]</ref> is sufficient, results are not degraded by adding the spectrum constraint.</p><p>The proposed approach has roughly the same complexity as the one from <ref type="bibr" target="#b13">[14]</ref>, the computation of the FFT being neglectable compared to CNN computations. Each experiment displayed in this paper took approximately 15 minutes using a 4 kernel CPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>This paper presents an effective improvement for the synthesis of textures using convolutional neural networks (CNNs), by incorporating a spectrum constraint in the loss function of the CNN. The generated texture images not only preserve local structures and fine scale details, but also preserve large http://www.textures.com quasi-periodic structures. The experimental results prove that the spectrum constraint is a necessary complement for texture synthesis, especially for structured textures, at no additional computational cost. <ref type="figure">Fig. 5</ref>. Left: given texture exemplars; Middle: results obtained by using CNNs as in <ref type="bibr" target="#b13">[14]</ref>; Right: our results, obtained by combining the CNN model with spectrum constraints. <ref type="figure">Fig. 6</ref>. Left: given texture exemplars; Middle: results obtained by using CNNs as in <ref type="bibr" target="#b13">[14]</ref>; Right: our results, obtained by combining the CNN model with spectrum constraints. <ref type="figure">Fig. 7</ref>. A failure example. Same layout as the previous figures. Observe that though our algorithm (right) can not reproduce the small elements in the exemplar, it still generates a relatively structured result.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Markov random field texture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="39" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visual pattern discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IRE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="84" to="92" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pyramid-based texture analysis/synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 22nd annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="229" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Aparametric texture model based on joint statistics of complex wavelet coefficients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="71" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Random phase textures: Theory and synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Galerne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="257" to="267" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Synthesizing and mixing stationary gaussian texture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ferradans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peyré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aujol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="476" to="508" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Variational Texture Synthesis with Sparsity and Spectrum Constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tartavel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peyré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="124" to="144" />
			<date type="published" when="2015-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Texture synthesis by non-parametric sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Proceedings of the Seventh IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="1999-09" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1033" to="1038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast texture synthesis using tree-structured vector quantization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th annual conference on Computer graphics and interactive techniques</title>
		<meeting>the 27th annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="479" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parallel controllable texture synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">777</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exemplar-based texture synthesis: the efros-leung algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aguerrebere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tartavel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing On Line</title>
		<imprint>
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page" from="223" to="241" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Conditional gaussian models for texture synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Raad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desolneux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scale Space and Variational Methods in Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="474" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Generative Modeling of Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-N</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
	<note type="report_type">arxiv</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Texture synthesis using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="262" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Exploring Generative Perspective of Convolutional Neural Networks by Learning Random Field Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Texture Networks: Feed-forward Synthesis of Textures and Stylized Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lebedev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
	<note>tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Micro-texture synthesis by phase randomization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Galerne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing On Line</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep filter banks for texture recognition and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3828" to="3836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">L-bfgs-b: Fortran subroutines for large scale bound constrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
		<respStmt>
			<orgName>EECS Department, Northwestern University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
