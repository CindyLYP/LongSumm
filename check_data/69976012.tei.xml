<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-05-26">26 May 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Lee</surname></persName>
							<email>&lt;juho.lee@stats.ox.ac.uk&gt;.</email>
							<affiliation key="aff1">
								<orgName type="institution">AITRICS</orgName>
								<address>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonho</forename><surname>Lee</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Kakao Corporation</orgName>
								<address>
									<settlement>Repub</settlement>
									<country>lic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungtaek</forename><surname>Kim</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<address>
									<postBox>POSTECH</postBox>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">R</forename><surname>Kosiorek</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">Oxford Robotics Institute</orgName>
								<orgName type="institution" key="instit2">Univer-sity of Oxford</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjin</forename><surname>Choi</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<address>
									<postBox>POSTECH</postBox>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Whye Teh</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country>United King-dom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-05-26">26 May 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1810.00825v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Many machine learning tasks such as multiple instance learning, 3D shape recognition and fewshot image classification are defined on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, specifically designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating increased performance compared to recent methods for set-structured data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Learning representations has proven to be an essential problem for deep learning and its many success stories. The majority of problems tackled by deep learning are instancebased and take the form of mapping a fixed-dimensional input tensor to its corresponding target value <ref type="bibr" target="#b12">(Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b9">Graves et al., 2013)</ref>.</p><p>For some applications, we are required to process setstructured data. Multiple instance learning <ref type="bibr" target="#b4">(Dietterich et al., 1997;</ref><ref type="bibr" target="#b17">Maron &amp; Lozano-Pérez, 1998)</ref> is an example of such a set-input problem, where a set of instances is given as an input and the corresponding target is a label for the entire set. Other problems such as 3D shape recognition <ref type="bibr" target="#b33">(Wu et al., 2015;</ref><ref type="bibr" target="#b24">Shi et al., 2015;</ref><ref type="bibr" target="#b28">Su et al., 2015;</ref><ref type="bibr" target="#b3">Charles et al., 2017)</ref>, sequence ordering <ref type="bibr" target="#b31">(Vinyals et al., 2016)</ref>, and various set operations <ref type="bibr" target="#b19">(Muandet et al., 2012;</ref><ref type="bibr" target="#b20">Oliva et al., 2013;</ref><ref type="bibr" target="#b5">Edwards &amp; Storkey, 2017;</ref><ref type="bibr" target="#b35">Zaheer et al., 2017)</ref> can also be viewed as the set-input problems. Moreover, many meta-learning <ref type="bibr" target="#b29">(Thrun &amp; Pratt, 1998;</ref><ref type="bibr" target="#b23">Schmidhuber, 1987)</ref> problems which learn using different, but related tasks may also be treated as setinput tasks where an input set corresponds to the training dataset of a single task. For example, few-shot image classification <ref type="bibr" target="#b6">(Finn et al., 2017;</ref><ref type="bibr" target="#b26">Snell et al., 2017;</ref><ref type="bibr" target="#b14">Lee &amp; Choi, 2018)</ref> operates by building a classifier using a support set of images, which is evaluated with query images.</p><p>A model for set-input problems should satisfy two critical requirements. First, it should be permutation invariantthe output of the model should not change under any permutation of the elements in the input set. Second, such a model should be able to process input sets of any size. While these requirements stem from the definition of a set, they are not easily satisfied in neural-network-based models: classical feed-forward neural networks violate both requirements, and RNNs are sensitive to input order. complex mappings well using only instance-based feature extractors and simple pooling operations. Since every element in a set is processed independently in a set pooling operation, some information regarding interactions between elements has to be necessarily discarded. This can make some problems unnecessarily difficult to solve.</p><p>Consider the problem of amortized clustering, where we would like to learn a parametric mapping from an input set of points to the centers of clusters of points inside the set. Even for a toy dataset in 2D space, this is not an easy problem. The main difficulty is that the parametric mapping must assign each point to its corresponding cluster while modelling the explaining away pattern such that the resulting clusters do not attempt to explain overlapping subsets of the input set. Due to this innate difficulty, clustering is typically solved via iterative algorithms that refine randomly initialized clusters until convergence. Even though a neural network with a set poling operation can approximate such an amortized mapping by learning to quantize space, a crucial shortcoming is that this quantization cannot depend on the contents of the set. This limits the quality of the solution and also may make optimization of such a model more difficult; we show empirically in Section 5 that such pooling architectures suffer from under-fitting.</p><p>In this paper, we propose a novel set-input deep neural network architecture called the Set Transformer, (cf. Transformer, <ref type="bibr" target="#b30">(Vaswani et al., 2017)</ref>). The novelty of the Set Transformer is in three important design choices: 1. We use a self-attention mechanism to process every element in an input set, which allows our approach to naturally encode pairwise-or higher-order interactions between elements in the set.</p><p>2. We propose a method to reduce the O(n 2 ) computation time of full self-attention (e.g. the Transformer) to O(nm) where m is a fixed hyperparameter, allowing our method to scale to large input sets.</p><p>3. We use a self-attention mechanism to aggregate features, which is especially beneficial when the problem requires multiple outputs which depend on each other, such as the problem of meta-clustering, where the meaning of each cluster center heavily depends its location relative to the other clusters.</p><p>We apply the Set Transformer to several set-input problems and empirically demonstrate the importance and effectiveness of these design choices, and show that we can achieve the state-of-the-art performances for the most of the tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Pooling Architecture for Sets</head><p>Problems involving a set of objects have the permutation invariance property: the target value for a given set is the same regardless of the order of objects in the set. A simple example of a permutation invariant model is a network that performs pooling over embeddings extracted from the elements of a set. More formally,</p><formula xml:id="formula_0">net({x 1 , . . . , x n }) = ρ(pool({φ(x 1 ), . . . , φ(x n )})). (1)</formula><p>Zaheer et al. <ref type="formula">2017</ref>have proven that all permutation invariant functions can be represented as (1) when pool is the sum operator and ρ, φ any continuous functions, thus justifying the use of this architecture for set-input problems.</p><p>Note that we can deconstruct (1) into two parts: an encoder (φ) which independently acts on each element of a set of n items, and a decoder (ρ(pool(•))) which aggregates these encoded features and produces our desired output. Most network architectures for set-structured data follow this encoder-decoder structure. <ref type="bibr" target="#b35">Zaheer et al. (2017)</ref> additionally observed that the model remains permutation invariant even if the encoder is a stack of permutation-equivariant layers: Definition 1. Let S n be the set of all permutations of indices {1, . . . , n}. A function f : X n → Y n is permutation equivariant iff for any permutation π ∈ S n , f (πx) = πf (x).</p><p>An example of a permutation-equivariant layer is</p><formula xml:id="formula_1">f i (x; {x 1 , . . . , x n }) = σ i (λx + γpool({x 1 , . . . , x n }))<label>(2)</label></formula><p>where pool is the pooling operation, λ, γ are learnable scalar variables, and σ(•) is a nonlinear activation function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Attention</head><p>Assume we have n query vectors (corresponding to a set with n elements) each with dimension</p><formula xml:id="formula_2">d q : Q ∈ R n×dq . An attention function Att(Q, K, V</formula><p>) is a function that maps queries Q to outputs using</p><formula xml:id="formula_3">n v key-value pairs K ∈ R nv×dq , V ∈ R nv×dv . Att(Q, K, V ; ω) = ω QK V.<label>(3)</label></formula><p>The pairwise dot product QK ∈ R n×nv measures how similar each pair of query and key vectors is, with weights computed with an activation function ω. The output ω(QK )V is a weighted sum of V where a value gets more weight if its corresponding key has larger dot product with the query.</p><p>Multi-head attention, originally introduced in <ref type="bibr" target="#b30">Vaswani et al. (2017)</ref>, is an extension of the previous attention scheme. Instead of computing a single attention function, this method first projects Q, K, V onto h different</p><formula xml:id="formula_4">d M q , d M q , d M v -dimensional vectors,</formula><p>respectively. An attention function (Att(•; ω j )) is applied to each of these h projections. The output is a linear transformation of the concatenation of all attention outputs:</p><formula xml:id="formula_5">Multihead(Q, K, V ; λ, ω) = concat(O 1 , • • • , O h )W O ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_6">O j = Att(QW Q j , KW K j , V W V j ; ω j )<label>(5)</label></formula><p>Note that Multihead(•, •, •; λ) has learnable parameters </p><formula xml:id="formula_7">λ = {W Q j , W K j , W V j } h j=1 , where W Q j , W K j ∈ R dq×d M q , W V j ∈ R dv×d M v , W O ∈ R hd M v ×d . A typical choice for the dimension hyperparameters is d M q = d q /h, d M v = d v /h, d = d q . For brevity, we set d q = d v = d, d M q = d M v = d/h throughout</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Set Transformer</head><p>In this section, we motivate and describe the Set Transformer: an attention-based neural network that is designed to process sets of data. Similar to other architectures, a Set Transformer consists of an encoder followed by a decoder (cf. Section 2.1), but a distinguishing feature is that each layer in the encoder and decoder attends to their inputs to produce activations. Additionally, instead of a fixed pooling operation such as mean, our aggregating function pool(•) is parameterized and can thus adapt to the problem at hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Permutation Equivariant (Induced) Set Attention Blocks</head><p>We begin by defining our attention-based set operations, which we call SAB and ISAB. While existing pooling methods for sets obtain instance features independently of other instances, we use self-attention to concurrently encode the whole set. This gives the Set Transformer the ability to compute pairwise as well as higher-order interactions among instances during the encoding process. For this purpose, we adapt the multihead attention mechanism used in Transformer. We emphasize that all blocks introduced here are neural network blocks with their own parameters, and not fixed functions.</p><p>Given matrices X, Y ∈ R n×d which represent two sets of d-dimensional vectors, we define the Multihead Attention Block (MAB) with parameters ω as follows:</p><formula xml:id="formula_8">MAB(X, Y ) = LayerNorm(H + rFF(H)),<label>(6)</label></formula><p>where</p><formula xml:id="formula_9">H = LayerNorm(X + Multihead(X, Y, Y ; ω)),<label>(7)</label></formula><p>rFF is any row-wise feedforward layer (i.e., it processes each instance independently and identically), and LayerNorm is layer normalization <ref type="bibr" target="#b0">(Ba et al., 2016)</ref>. The MAB is an adaptation of the encoder block of the Transformer <ref type="bibr" target="#b30">(Vaswani et al., 2017)</ref> without positional encoding and dropout. Using the MAB, we define the Set Attention Block (SAB) as</p><formula xml:id="formula_10">SAB(X) := MAB(X, X).<label>(8)</label></formula><p>In other words, an SAB takes a set and performs selfattention between the elements in the set, resulting in a set of equal size. Since the output of SAB contains information about pairwise interactions among the elements in the input set X, we can stack multiple SABs to encode higher order interactions. Note that while the SAB (8) involves a multihead attention operation <ref type="formula" target="#formula_9">7</ref>, where Q = K = V = X, it could reduce to applying a residual block on X. In practice, it learns more complicated functions due to linear projections of X inside attention heads, (3) and (5).</p><p>A potential problem with using SABs for set-structured data is the quadratic time complexity O(n 2 ), which may be too expensive for large sets (n 1). We thus introduce the Induced Set Attention Block (ISAB), which bypasses this problem. Along with the set X ∈ R n×d , additionally define m d-dimensional vectors I ∈ R m×d , which we call inducing points. Inducing points I are part of the ISAB itself, and they are trainable parameters which we train along with other parameters of the network. An ISAB with m inducing points I is defined as:</p><formula xml:id="formula_11">ISAB m (X) = MAB(X, H) ∈ R n×d ,<label>(9)</label></formula><p>where</p><formula xml:id="formula_12">H = MAB(I, X) ∈ R m×d .<label>(10)</label></formula><p>The ISAB first transforms I into H by attending to the input set. The set of transformed inducing points H, which contains information about the input set X, is again attended to by the input set X to finally produce a set of n elements. This is analogous to low-rank projection or autoencoder models, where inputs (X) are first projected onto a lowdimensional object (H) and then reconstructed to produce outputs. The difference is that the goal of these methods is reconstruction whereas ISAB aims to obtain good features for the final task. We expect the learned inducing points to encode some global structure which helps explain the inputs X. For example, in the amortized clustering problem on a 2D plane, the inducing points could be appropriately distributed points on the 2D plane so that the encoder can compare elements in the query dataset indirectly through their proximity to these grid points.</p><p>Note that in (9) and (10), attention was computed between a set of size m and a set of size n. Therefore, the time complexity of ISAB m (X; λ) is O(nm) where m is a (typically small) hyperparameter -an improvement over the quadratic complexity of the SAB. We also emphasize that both of our set operations (SAB and ISAB) are permutation equivariant (definition in Section 2.1): Property 1. Both SAB(X) and ISAB m (X) are permutation equivariant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pooling by Multihead Attention</head><p>A common aggregation scheme in permutation invariant networks is a dimension-wise average or maximum of the feature vectors (cf. Section 1). We instead propose to aggregate features by applying multihead attention on a learnable set of k seed vectors S ∈ R k×d . Let Z ∈ R n×d be the set of features constructed from an encoder. Pooling by Multihead Attention (PMA) with k seed vectors is defined as</p><formula xml:id="formula_13">PMA k (Z) = MAB(S, rFF(Z)).<label>(11)</label></formula><p>Note that the output of PMA k is a set of k items. We use one seed vector (k = 1) in most cases, but for problems such as amortized clustering which requires k correlated outputs, the natural thing to do is to use k seed vectors. To further model the interactions among the k outputs, we apply an SAB afterwards:</p><formula xml:id="formula_14">H = SAB(PMA k (Z)).<label>(12)</label></formula><p>We later empirically show that such self-attention after pooling helps in modeling explaining-away (e.g., among clusters in an amortized clustering problem).</p><p>Intuitively, feature aggregation using attention should be beneficial because the influence of each instance on the target is not necessarily equal. For example, consider a problem where the target value is the maximum value of a set of real numbers. Since the target can be recovered using only a single instance (the largest), finding and attending to that instance during aggregation will be advantageous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Overall Architecture</head><p>Using the ingredients explained above, we describe how we would construct a set transformer consists of an encoder and a decoder. The encoder Encoder : X → Z ∈ R n×d is a stack of SABs or ISABs, for example:</p><formula xml:id="formula_15">Encoder(X) = SAB(SAB(X)) (13) Encoder(X) = ISAB m (ISAB m (X)).<label>(14)</label></formula><p>We point out again that the time complexity for stacks of SABs and ISABs are O( n 2 ) and O( nm), respectively. This can result in much lower processing times when using ISAB (as compared to SAB), while still maintaining high representational power. After the encoder transforms data X ∈ R n×dx into features Z ∈ R n×d , the decoder aggregates them into a single or a set of vectors which is fed into a feed-forward network to get final outputs. Note that PMA with k &gt; 1 seed vectors should be followed by SABs to model the correlation between k outputs.</p><formula xml:id="formula_16">Decoder(Z; λ) = rFF(SAB(PMA k (Z))) ∈ R k×d (15) where PMA k (Z) = MAB(S, rFF(Z)) ∈ R k×d ,<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Analysis</head><p>Since the blocks used to construct the encoder (i.e., SAB, ISAB) are permutation equivariant, the mapping of the encoder X → Z is permutation equivariant as well. Combined with the fact that the PMA in the decoder is a permutation invariant transformation, we have the following:</p><p>Proposition 1. The Set Transformer is permutation invariant.</p><p>Being able to approximate any function is a desirable property, especially for black-box models such as deep neural networks. Building on previous results about the universal approximation of permutation invariant functions, we prove the universality of Set Transformers:</p><p>Proposition 2. The Set Transformer is a universal approximator of permutation invariant functions.</p><p>Proof. See supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Works</head><p>Pooling architectures for permutation invariant mappings Pooling architectures for sets have been used in various problems such as 3D shape recognition <ref type="bibr" target="#b24">(Shi et al., 2015;</ref><ref type="bibr" target="#b28">Su et al., 2015)</ref>, discovering causality (Lopez-Paz et al., 2017), learning the statistics of a set <ref type="bibr" target="#b5">(Edwards &amp; Storkey, 2017)</ref>, few-shot image classification <ref type="bibr" target="#b26">(Snell et al., 2017)</ref>, and conditional regression and classification <ref type="bibr" target="#b8">(Garnelo et al., 2018)</ref>. <ref type="bibr" target="#b35">Zaheer et al. (2017)</ref> discuss the structure in general and provides a partial proof of the universality of the pooling architecture, and Wagstaff et al. (2019) further discuss the limitation of pooling architectures. Bloem-Reddy &amp; Teh (2019) provides a link between probabilistic exchangeability and pooling architectures.</p><p>Attention-based approaches for sets Several recent works have highlighted the competency of attention mechanisms in modeling sets. <ref type="bibr" target="#b31">Vinyals et al. (2016)</ref> pool elements in a set by a weighted average with weights computed using an attention mechanism. <ref type="bibr" target="#b34">Yang et al. (2018)</ref> propose AttSets for multi-view 3D reconstruction, where dot-product attention is applied to compute the weights used to pool the encoded features via weighted sums. Similarly, <ref type="bibr" target="#b10">Ilse et al. (2018)</ref> use attention-based weighted sum-pooling for multiple instance learning. Compared to these approaches, ours use multihead attention in aggregation, and more importantly, we propose to apply self-attention after pooling to model correlation among multiple outputs. PMA with k = 1 seed vector and single-head attention roughly corresponds to these previous approaches. Although not permutation invariant, <ref type="bibr" target="#b18">Mishra et al. (2018)</ref> has attention as one of its core components to meta-learn to solve various tasks using sequences of inputs. <ref type="bibr" target="#b11">Kim et al. (2019)</ref> proposed attentionbased conditional regression, where self-attention is applied to the query sets.</p><p>Modeling interactions between elements in sets An important reason to use the Transformer is to explicitly model higher-order interactions among the elements in a set. <ref type="bibr" target="#b22">Santoro et al. (2017)</ref> propose the relational network, a simple architecture that sum-pools all pairwise interactions of elements in a given set, but not higher-order interactions. Similarly to our work, <ref type="bibr" target="#b16">Ma et al. (2018)</ref> use the Transformer to model interactions between the objects in a video. They use mean-pooling to obtain aggregated features which they fed into an LSTM.</p><p>Inducing point methods The idea of letting trainable vectors I directly interact with data points is loosely based on the inducing point methods used in sparse Gaussian processes <ref type="bibr" target="#b27">(Snelson &amp; Ghahramani, 2005)</ref> and the Nyström method for matrix decomposition <ref type="bibr" target="#b7">(Fowlkes et al., 2004)</ref>. m trainable inducing points can also be seen as m independent memory cells accessed with an attention mechanism. The differential neural dictionary <ref type="bibr" target="#b21">(Pritzel et al., 2017)</ref> stores previous experience as key-value pairs and uses this to process queries. One can view the ISAB is the inversion of this idea, where queries I are stored and the input features are used as key-value pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>To evaluate the Set Transformer, we apply it to a suite of tasks involving sets of data points. We repeat all experi- • rFF + Pooling <ref type="bibr" target="#b35">(Zaheer et al., 2017)</ref>: rFF layers in encoder and simple pooling + rFF layers in decoder.</p><p>• rFFp-mean/rFFp-max + Pooling <ref type="bibr" target="#b35">(Zaheer et al., 2017)</ref>: rFF layers with permutation equivariant variants in encoder <ref type="bibr">(Zaheer et al., 2017, (4)</ref>) and simple pooling + rFF layers in decoder.</p><p>• rFF + Dotprod <ref type="bibr" target="#b34">(Yang et al., 2018;</ref><ref type="bibr" target="#b10">Ilse et al., 2018)</ref>: rFF layers in encoder and dot product attention based weighted sum pooling + rFF layers in decoder.</p><p>• SAB (ISAB) + Pooling (ours): Stack of SABs (ISABs) in encoder and simple pooling + rFF layers in decoder.</p><p>• rFF + PMA (ours): rFF layers in encoder and PMA (followed by stack of SABs) in decoder.</p><p>• SAB (ISAB) + PMA (ours): Stack of SABs (ISABs) in encoder and PMA (followed by stack of SABs) in decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Toy Problem: Maximum Value Regression</head><p>To demonstrate the advantage of attention-based set aggregation over simple pooling operations, we consider a toy problem: regression to the maximum value of a given set. Given a set of real numbers {x 1 , . . . , x n }, the goal is to return</p><formula xml:id="formula_17">max(x 1 , • • • , x n ).</formula><p>Given prediction p, we use the mean absolute error |p − max(x 1 , • • • , x n )| as the loss function. We constructed simple pooling architectures with three different pooling operations: max, mean, and sum. We report loss values after training in <ref type="table" target="#tab_0">Table 1</ref>. Mean-and sumpooling architectures result in a high mean absolute error (MAE). The model with max-pooling can predict the output perfectly by learning its encoder to be an identity function, and thus achieves the highest performance. Notably, the Set Transformer achieves performance comparable to the max-pooling model, which underlines the importance of additional flexibility granted by attention mechanisms -it can learn to find and attend to the maximum element.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Counting Unique Characters</head><p>In order to test the ability of modelling interactions between objects in a set, we introduce a new task of counting unique elements in an input set. We use the Omniglot (Lake et al., 2015) dataset, which consists of 1,623 different handwritten characters from various alphabets, where each character is represented by 20 different images.</p><p>We split all characters (and corresponding images) into train, validation, and test sets and only train using images from the train character classes. We generate input sets by sampling between 6 and 10 images and we train the model to predict the number of different characters inside the set. We used a Poisson regression model to predict this number, with the rate λ given as the output of a neural network. We maximized the log likelihood of this model using stochastic gradient ascent.</p><p>We evaluated model performance using sets of images sampled from the test set of characters. <ref type="table" target="#tab_1">Table 2</ref> reports accuracy, measured as the frequency at which the mode of the Poisson distribution chosen by the network is equal to the number of characters inside the input set.</p><p>We additionally performed experiments to see how the number of incuding points affects performance. We trained ISAB n + PMA on this task while varying the number of inducing points (n). Accuracies are shown in <ref type="figure">Figure 3</ref>, where other architectures are shown as horizontal lines for comparison. Note first that even the accuracy of ISAB 1 + PMA surpasses that of both rFF + Pooling and rFF + PMA, and that performance tends to increase as we increase n.  <ref type="figure">Figure 3</ref>. Accuracy of ISABn + PMA on the unique character counting task. x-axis is n and y-axis is accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Amortized Clustering with Mixture of Gaussians</head><p>We applied the set-input networks to the task of maximum likelihood of mixture of Gaussians (MoGs). The log-likelihood of a dataset X = {x 1 , . . . , x n } generated from an MoG with k components is</p><formula xml:id="formula_18">log p(X; θ) = n i=1 log k j=1 π j N (x i ; µ j , diag(σ 2 j )). (17)</formula><p>The goal is to learn the optimal parameters θ * (X) = arg max θ log p(X; θ). The typical approach to this problem is to run an iterative algorithm such as Expectation-Maximisation (EM) until convergence. Instead, we aim to learn a generic meta-algorithm that directly maps the input set X to θ * (X). One can also view this as amortized maximum likelihood learning. Specifically, given a dataset X, we train a neural network to output parameters f (X; λ) = {π(X), {µ</p><formula xml:id="formula_19">j (X), σ j (X)} k j=1 } which maximize EX   |X| i=1 log k j=1 πj(X)N (xi; µj(X), diag(σ 2 j (X)))   . (18)</formula><p>We structured f (•; λ) as a set-input neural network and learned its parameters λ using stochastic gradient ascent, where we approximate gradients using minibatches of datasets.</p><p>We tested Set Transformers along with other set-input networks on two datasets. We used four seed vectors for the PMA (S ∈ R 4×d ) so that each seed vector generates the parameters of a cluster.</p><p>Synthetic 2D mixtures of Gaussians: Each dataset contains n ∈ [100, 500] points on a 2D plane, each sampled from one of four Gaussians.</p><p>CIFAR-100: Each dataset contains n ∈ [100, 500] images sampled from four random classes in the CIFAR-100 dataset. Each image is represented by a 512-dim vector obtained from a pretrained VGG network <ref type="bibr" target="#b25">(Simonyan &amp; Zisserman, 2014)</ref>. <ref type="table" target="#tab_8">Table 3</ref>. Meta clustering results. The number inside parenthesis indicates the number of inducing points used in ISABs of encoders. We show average likelihood per data for the synthetic dataset and the adjusted rand index (ARI) for the CIFAR-100 experiment. LL1/data, ARI1 are the evaluation metrics after a single EM update step. The oracle for the synthetic dataset is the log likelihood of the actual parameters used to generate the set, and the CIFAR oracle was computed by running EM until convergence.  We report the performance of the oracle along with the setinput neural networks in <ref type="table" target="#tab_8">Table 3</ref>. We additionally report scores of all models after a single EM update. Overall, the Set Transformer found accurate parameters and even outperformed the oracles after a single EM update. This may be due to the relatively small size of the input sets; some clusters have fewer than 10 points. In this regime, sample statistics can differ substantially from population statistics, which limits the performance of the oracle while the Set Transformer can adapt accordingly. Notably, the Set Transformer with only 16 inducing points showed the best performance, even outperforming the full Set Transformer. We believe this is due to the knowledge transfer and regularization via inducing points, helping the network to learn global structures. Our results also imply that the improvement from using the PMA is more significant than that of the SAB, supporting our claim of the importance of attention-based decoders. We provide detailed genera-tive processes, network architectures, and training schemes along with additional experiments with various numbers of inducing points in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Synthetic</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Set Anomaly Detection</head><p>We evaluate our methods on the task of meta-anomaly detection within a set using the CelebA dataset. The dataset consists of 202,599 images with the total of 40 attributes. We randomly sample 1,000 sets of images. For every set, we select two attributes at random and construct the set by selecting seven images containing both attributes and one image with neither. The goal of this task is to find the image that does not belong to the set. We give a detailed description of the experimental setup in the supplementary material. We report the area under receiver operating characteristic curve (AUROC) and area under precision-recall curve (AUPR) in <ref type="table" target="#tab_4">Table 5</ref>. Set Transformers outperformed all other methods by a significant margin.  <ref type="figure">Figure 5</ref>. Sampled datasets. Each row is a dataset, consisting of 7 normal images and 1 anomaly (red box). In each subsampled dataset, a normal image has two attributes (rightmost column) which anomalies do not. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Point Cloud Classification</head><p>We evaluated Set Transformers on a classification task using the ModelNet40 <ref type="bibr" target="#b2">(Chang et al., 2015</ref>) dataset 1 , which contains three-dimensional objects in 40 different categories. Each object is represented as a point cloud, which we treat as a set of n vectors in R 3 . We performed experiments with input sets of size n ∈ {100, 1000, 5000}. Because of the large set sizes, MABs are prohibitively time-consuming due to their O(n ) time complexity. <ref type="table" target="#tab_3">Table 4</ref> shows classification accuracies. We point out that <ref type="bibr" target="#b35">Zaheer et al. (2017)</ref> used significantly more engineering for the 5000 point experiment. For this experiment only, they augmented data (scaling, rotation) and used a different optimizer (Adamax) and learning rate schedule. Set Transformers were superior when given small sets, but were outperformed by ISAB (16) + Pooling on larger sets. First note that classification is harder when given fewer points. We think Set Transformers were outperformed in the problems with large sets because such sets already had sufficient information for classification, diminishing the need to model complex interactions among points. We point out that PMA outperformed simple pooling in all other experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we introduced the Set Transformer, an attention-based set-input neural network architecture. Our proposed method uses attention mechanisms for both encoding and aggregating features, and we have empirically validated that both of them are necessary for modelling complicated interactions among elements of a set. We also proposed an inducing point method for self-attention, which makes our approach scalable to large sets. We also showed useful theoretical properties of our model, including the fact that it is a universal approximator for permutation invariant functions. An interesting future work would be to apply Set Transformers to meta-learning problems. In particular, using Set Transformers to meta-learn posterior inference in Bayesian models seems like a promising line of research. Another exciting extension of our work would be to model the uncertainty in set functions by injecting noise variables into Set Transformers in a principled way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Proofs</head><p>Lemma 1. The mean operator mean({x 1 , . . . ,</p><formula xml:id="formula_20">x n }) = 1 n n i=1</formula><p>x i is a special case of dot-product attention with softmax.</p><p>Proof. Let</p><formula xml:id="formula_21">s = 0 ∈ R d and X ∈ R n×d . Att(s, X, X; softmax) = softmax sX √ d X = 1 n n i=1 x i</formula><p>Lemma 2. The decoder of a Set Transformer, given enough nodes, can express any element-wise function of the form n</p><formula xml:id="formula_22">n i=1 z p i 1 p .</formula><p>Proof. We first note that we can view the decoder as the composition of functions</p><formula xml:id="formula_23">Decoder(Z) = rFF(H)<label>(1)</label></formula><p>where</p><formula xml:id="formula_24">H = rFF(MAB(Z, rFF(Z)))<label>(2)</label></formula><p>We focus on H in (2). Since feed-forward networks are universal function approximators at the limit of infinite nodes, let the feed-forward layers in front and back of the MAB encode the element-wise functions z → z p and z → z 1 p , respectively. We let h = d, so the number of heads is the same as the dimensionality of the inputs, and each head is one-dimensional. Let the projection matrices in multi-head attention (W Q j , W K j , W V j ) represent projections onto the jth dimension and the output matrix (W O ) the identity matrix. Since the mean operator is a special case of dot-product attention, by simple composition, we see that an MAB can express any dimension-wise function of the form</p><formula xml:id="formula_25">M p (z 1 , • • • , z n ) = 1 n n i=1 z p i 1 p .<label>(3)</label></formula><p>Lemma 3. A PMA, given enough nodes, can express sum pooling (</p><formula xml:id="formula_26">n i=1 z i ).</formula><p>Proof. We prove this by construction.</p><p>Set the seed s to a zero vector and let ω(</p><formula xml:id="formula_27">•) = 1 + f (•),</formula><p>where f is any activation function such that f (0) = 0. The identiy, sigmoid, or relu functions are suitable choices for f . The output of the multihead attention is then simply a sum of the values, which is Z in this case.</p><p>We additionally have the following universality theorem for pooling architectures:</p><p>Theorem 1. Models of the form rFF(sum(rFF(•))) are universal function approximators in the space of permutation invariant functions.</p><p>Proof. See Appendix A of ?.</p><p>arXiv:1810.00825v3 [cs.</p><p>LG] 26 May 2019</p><p>By Lemma 3, we know that decoder(Z) can express any function of the form rFF(sum(Z)). Using this fact along with Theorem 1, we can prove the universality of Set Transformers:</p><p>Proposition 1. The Set Transformer is a universal function approximator in the space of permutation invariant functions.</p><p>Proof. By setting the matrix W O to a zero matrix in every SAB and ISAB, we can ignore all pairwise interaction terms in the encoder. Therefore, the encoder(X) can express any instance-wise feed-forward network (Z = rFF(X)). Directly invoking Theorem 1 concludes this proof.</p><p>While this proof required us to ignore the pairwise interaction terms inside the SABs and ISABs to prove that Set Transformers are universal function approximators, our experiments indicated that self-attention in the encoder was crucial for good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Experiment Details</head><p>In all implementations, we omit the feed-forward layer in the beginning of the decoder (rFF(Z)) because the end of the previous block contains a feed-forward layer. All MABs (inside SAB, ISAB and PMA) use fully-connected layers with ReLU activations for rFF layers.</p><p>In the architecture descriptions, FC <ref type="formula">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Max Regression</head><p>Given a set of real numbers {x 1 , . . . , x n }, the goal of this task is to return the maximum value in the set</p><formula xml:id="formula_28">max(x 1 , • • • , x n ).</formula><p>We construct training data as follows. We first sample a dataset size n uniformly from the set of integers {1,  We show the detailed architectures used for the experiments in <ref type="table" target="#tab_0">Table 1</ref>. We trained all networks using the Adam optimizer (?) with a constant learning rate of 10 −3 and a batch size of 128 for 20,000 batches, after which loss converged for all architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Counting Unique Characters</head><p>The task generation procedure is as follows. We first sample a set size n uniformly from the set of integers {6, . . . , 10}. We then sample the number of characters c uniformly from {1, . . . , n}. We sample c characters from the training set of characters, and randomly sample instances of each character so that the total number of instances sums to n and each set of characters has at least one instance in the resulting set.</p><p>We show the detailed architectures used for the experiments in <ref type="table" target="#tab_8">Table 3</ref>. For both architectures, the resulting 1-dimensional output is passed through a softplus activation to produce the Poisson parameter γ. The role of softplus is to ensure that γ is always positive.  <ref type="formula" target="#formula_23">1</ref>0.6037 ± 0.0072 SAB + PMA <ref type="formula" target="#formula_1">2</ref>0.5806 ± 0.0075 SAB + PMA <ref type="formula" target="#formula_5">4</ref>0.5945 ± 0.0072 SAB + PMA <ref type="formula" target="#formula_10">8</ref>0.6001 ± 0.0078 The loss function we optimize, as previously mentioned, is the log likelihood log p(x|γ) = x log(γ) − γ − log(x!). We chose this loss function over mean squared error or mean absolute error because it seemed like the more logical choice when trying to make a real number match a target integer. Early experiments showed that directly optimizing for mean absolute error had roughly the same result as optimizing γ in this way and measuring |γ − x|. We train using the Adam optimizer with a constant learning rate of 10 −4 for 200,000 batches each with batch size 32.</p><p>2.3. Solving maximum likelihood problems for mixture of Gaussians</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">DETAILS FOR 2D SYNTHETIC MIXTURES OF GAUSSIANS EXPERIMENT</head><p>We generated the datasets according to the following generative process.</p><p>1. Generate the number of data points, n ∼ Unif(100, 500).</p><p>2. Generate k centers.</p><formula xml:id="formula_29">µ j,d ∼ Unif(−4, 4), j = 1, . . . , 4, d = 1, 2.<label>(4)</label></formula><p>3. Generate cluster labels.</p><formula xml:id="formula_30">π ∼ Dir([1, 1] ), z i ∼ Categorical(π), i = 1, . . . , n.<label>(5)</label></formula><p>4. Generate data from spherical Gaussian. <ref type="table" target="#tab_3">Table 4</ref> summarizes the architectures used for the experiments. For all architectures, at each training step, we generate 10 random datasets according to the above generative process, and updated the parameters via Adam optimizer with initial learning rate 10 −3 . We trained all the algorithms for 50k steps, and decayed the learning rate to 10 −4 after 35k steps. <ref type="table" target="#tab_4">Table 5</ref> summarizes the detailed results with various number of inducing points in the ISAB. <ref type="figure">Figure ?</ref>? shows the actual clustering results based on the predicted parameters.  <ref type="table" target="#tab_4">Table 5</ref>. Average log-likelihood/data (LL0/data) and average log-likelihood/data after single EM iteration (LL1/data) the clustering experiment. The number inside parenthesis indicates the number of inducing points used in the SABs of encoder. For all PMAs, four seed vectors were used.</p><formula xml:id="formula_31">x i ∼ N (µ zi , (0.3) 2 I).<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Architecture</head><p>LL0/data LL1/data Oracle -1.4726 rFF + Pooling -2.0006 ± 0.0123 -1.6186 ± 0.0042 rFFp-mean + Pooling -1.7606 ± 0.0213 -1.5191 ± 0.0026 rFFp-max + Pooling -1.7692 ± 0.0130 -1.5103 ± 0.0035 rFF+Dotprod -1.8549 ± 0.0128 -1.5621 ± 0.0046 SAB + Pooling -1.6772 ± 0.0066 -1.5070 ± 0.0115 ISAB (16) + Pooling -1.6955 ± 0.0730 -1.4742 ± 0.0158 ISAB (32) + Pooling -1.6353 ± 0.0182 -1.4681 ± 0.0038 ISAB (64) + Pooling -1.6349 ± 0.0429 -1.4664 ± 0.0080 rFF + PMA -1.6680 ± 0.0040 -1.5409 ± 0.0037 SAB + PMA -1.5145 ± 0.0046 -1.4619 ± 0.0048 ISAB (16) + PMA -1.5009 ± 0.0068 -1.4530 ± 0.0037 ISAB (32) + PMA -1.4963 ± 0.0064 -1.4524 ± 0.0044 ISAB (64) + PMA -1.5042 ± 0.0158 -1.4535 ± 0.0053</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">2D SYNTHETIC MIXTURES OF GAUSSIANS EXPERIMENT ON LARGE-SCALE DATA</head><p>To show the scalability of the set transformer, we conducted additional experiments on large-scale 2D synthetic clustering dataset. We generated the synthetic data as before, except that we sample the number of data points n Unif(1000, 5000) and set k = 6. We report the clustering accuracy of a subset of comparing methods in <ref type="table">Table 6</ref>. The set transformer with only 32 inducing points works extremely well, demonstrating its scalability and efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">DETAILS FOR CIFAR-100 AMORTIZED CLUTERING EXPERIMENT</head><p>We pretrained VGG net (?) with CIFAR-100, and obtained the test accuracy 68.54%. Then, we extracted feature vectors of 50k training images of CIFAR-100 from the 512-dimensional hidden layers of the VGG net (the layer just before the last layer). Given these feature vectors, the generative process of datasets is as follows.</p><p>1. Generate the number of data points, n ∼ Unif(100, 500).</p><p>2. Uniformly sample four classes among 100 classes.</p><p>3. Uniformly sample n data points among four sampled classes. <ref type="table">Table 6</ref>. Average log-likelihood/data (LL0/data) and average log-likelihood/data after single EM iteration (LL1/data) the clustering experiment on large-scale data. The number inside parenthesis indicates the number of inducing points used in the SABs of encoder. For all PMAs, six seed vectors were used. Architecture LL0/data LL1/data Oracle -1.8202 rFF + Pooling -2.5195 ± 0.0105 -2.0709 ± 0.0062 rFFp-mean + Pooling -2.3126 ± 0.0154 -1.9749 ± 0.0062 rFF + PMA (6) -2.0515 ± 0.0067 -1.9424 ± 0.0047 SAB (32) + PMA (6) -1.8928 ± 0.0076 -1.8549 ± 0.0024  <ref type="table" target="#tab_10">Table 7</ref> summarizes the architectures used for the experiments. For all architectures, at each training step, we generate 10 random datasets according to the above generative process, and updated the parameters via Adam optimizer with initial learning rate 10 −4 . We trained all the algorithms for 50k steps, and decayed the learning rate to 10 −5 after 35k steps. <ref type="table">Table 8</ref> summarizes the detailed results with various number of inducing points in the ISAB. <ref type="table">Table 9</ref> describes the architecture for meta set anomaly experiments. We trained all models via Adam optimizer with learning rate 10 −4 and exponential decay of learning rate for 1,000 iterations. 1,000 datasets subsampled from CelebA dataset (see <ref type="figure">Figure ??</ref>) are used to train and test all the methods. We split 800 training datasets and 200 test datasets for the subsampled datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Set Anomaly Detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Point Cloud Classification</head><p>We used the ModelNet40 dataset for our point cloud classification experiments. This dataset consists of a three-dimensional representation of 9,843 training and 2,468 test data which each belong to one of 40 object classes. As input to our architectures, we produce point clouds with n = 100, 1000, 5000 points each (each point is represented by (x, y, z) coordinates). For generalization, we randomly rotate and scale each set during training.</p><p>We show results our architectures in <ref type="table" target="#tab_0">Table 10</ref> and additional experiments which used n = 100, 5000 points in <ref type="table">Table ?</ref>?. We trained using the Adam optimizer with an initial learning rate of 10 −3 which we decayed by a factor of 0.3 every 20,000 steps. For the experiment with 5,000 points ( <ref type="table">Table ??</ref>), we increased the dimension of the attention blocks (ISAB 16 (512, 4) instead of ISAB 16 (128, 4)) and also decayed the weights by a factor of 10 −7 . We also only used one ISAB block in the encoder because using two lead to overfitting in this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Additional Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Runtime of SAB and ISAB</head><p>We measured the runtime of SAB and ISAB on a simple benchmark <ref type="figure" target="#fig_0">(Figure 1</ref>). We used a single GPU (Tesla P40) for this experiment. The input data was a constant (zero) tensor of n three-dimensional vectors. We report the number of seconds it  <ref type="figure" target="#fig_0">Figure 1</ref>. Runtime of a single SAB/ISAB block on dummy data. x axis is the size of the input set and y axis is time (seconds). Note that the x-axis is log-scale.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Diagrams of our attention-based set operations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>the rest of the paper. Unless otherwise specified, we use a scaled softmax ω j (•) = softmax(•/ √ d), which our experiments were worked robustly in most settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Counting unique characters: this is a randomly sampled set of 20 images from the Omniglot dataset. There are 14 different characters inside this set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Clustering results for 10 test datasets, along with centers and covariance matrices. rFF+Pooling (top-left), SAB+Pooling (top-right), rFF+PMA (bottom-left), Set Transformer (bottom-right). Best viewed magnified in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>• • • , 10}. We then sample real numbers x i independently from the interval [0, 100]. Given the network's prediction p, we use the actual maximum value max(x 1 , • • • , x n ) to compute the mean absolute error |p − max(x 1 , • • • , x n )|. We don't explicitly consider splits of train and test data, since we sample a new set {x 1 , . . . , x n } at each time step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Mean absolute errors on the max regression task.</figDesc><table><row><cell>Architecture</cell><cell>MAE</cell></row><row><cell>rFF + Pooling (mean) rFF + Pooling (sum) rFF + Pooling (max) SAB + PMA (ours)</cell><cell>2.133 ± 0.190 1.902 ± 0.137 0.1355 ± 0.0074 0.2085 ± 0.0127</cell></row><row><cell cols="2">ments five times and report performance metrics evaluated on corresponding test datasets. Along with baselines, we compared various architectures arising from the combina-tion of the choices of having attention in encoders and de-coders. Unless specified otherwise, "simple pooling" means average pooling.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Accuracy on the unique character counting task.</figDesc><table><row><cell>Architecture</cell><cell>Accuracy</cell></row><row><cell cols="2">rFF + Pooling rFFp-mean + Pooling 0.4617 ± 0.0076 0.4382 ± 0.0072 rFFp-max + Pooling 0.4359 ± 0.0077 rFF + Dotprod 0.4471 ± 0.0076 rFF + PMA (ours) 0.4572 ± 0.0076 SAB + Pooling (ours) 0.5659 ± 0.0077 SAB + PMA (ours) 0.6037 ± 0.0075</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Test accuracy for the point cloud classification task using 100, 1000, 5000 points.</figDesc><table><row><cell>Architecture</cell><cell>100 pts</cell><cell>1000 pts</cell><cell>5000 pts</cell></row><row><cell>rFF + Pooling (Zaheer et al., 2017) rFFp-max + Pooling (Zaheer et al., 2017) rFF + Pooling rFF + PMA (ours) ISAB (16) + Pooling (ours) ISAB (16) + PMA (ours)</cell><cell cols="3">-0.82 ± 0.02 0.7951 ± 0.0166 0.8551 ± 0.0142 0.8933 ± 0.0156 0.83 ± 0.01 -0.87 ± 0.01 0.90 ± 0.003 0.8076 ± 0.0160 0.8534 ± 0.0152 0.8628 ± 0.0136 0.8273 ± 0.0159 0.8915 ± 0.0144 0.9040 ± 0.0173 0.8454 ± 0.0144 0.8662 ± 0.0149 0.8779 ± 0.0122</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Meta set anomaly results. Each architecture is evaluated using average of test AUROC and test AUPR.</figDesc><table><row><cell>Architecture</cell><cell>Test AUROC</cell><cell>Test AUPR</cell></row><row><cell cols="3">Random guess rFF + Pooling rFFp-mean + Pooling 0.5687 ± 0.0061 0.4125 ± 0.0127 0.5 0.125 0.5643 ± 0.0139 0.4126 ± 0.0108 rFFp-max + Pooling 0.5717 ± 0.0117 0.4135 ± 0.0162 rFF + Dotprod 0.5671 ± 0.0139 0.4155 ± 0.0115 SAB + Pooling (ours) 0.5757 ± 0.0143 0.4189 ± 0.0167 rFF + PMA (ours) 0.5756 ± 0.0130 0.4227 ± 0.0127 SAB + PMA (ours) 0.5941 ± 0.0170 0.4386 ± 0.0089</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>d, f ) denotes the fully-connected layer with d units and activation function f . SAB(d, h) denotes the SAB with d units and h heads. ISAB m (d, h) denotes the ISAB with d units, h heads and m inducing points. PMA k (d, h) denotes the PMA with d units, h heads and k vectors. All MABs used in SAB and PMA uses FC layers with ReLU activations for FF layers.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 .</head><label>1</label><figDesc>Detailed architectures used in the max regression experiments.</figDesc><table><row><cell>Encoder</cell><cell></cell><cell>Decoder</cell><cell></cell></row><row><cell>FF</cell><cell>SAB</cell><cell>Pooling</cell><cell>PMA</cell></row><row><cell cols="4">FC(64, ReLU) SAB(64, 4) mean, sum, max PMA1(64, 4)</cell></row><row><cell cols="2">FC(64, ReLU) SAB(64, 4) FC(64, ReLU) FC(64, −)</cell><cell>FC(64, ReLU) FC(1, −)</cell><cell>FC(1, −)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 .</head><label>2</label><figDesc>Detailed results for the unique character counting experiment.</figDesc><table><row><cell>Architecture</cell><cell>Accuracy</cell></row><row><cell cols="2">rFF + Pooling rFF + PMA rFFp-mean + Pooling 0.4617 ± 0.0076 0.4366 ± 0.0071 0.4617 ± 0.0073 rFFp-max + Pooling 0.4359 ± 0.0077 rFF + Dotprod 0.4471 ± 0.0076 SAB + Pooling 0.5659 ± 0.0067 SAB + Dotprod 0.5888 ± 0.0072 SAB + PMA</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 .</head><label>3</label><figDesc>Detailed architectures used in the unique character counting experiments.</figDesc><table><row><cell>Encoder</cell><cell></cell><cell>Decoder</cell><cell></cell></row><row><cell>rFF</cell><cell>SAB</cell><cell>Pooling</cell><cell>PMA</cell></row><row><cell cols="2">Conv(64, 3, 2, BN, ReLU) Conv(64, 3, 2, BN, ReLU)</cell><cell>mean</cell><cell>PMA1(8, 8)</cell></row><row><cell cols="4">Conv(64, 3, 2, BN, ReLU) Conv(64, 3, 2, BN, ReLU) FC(64, ReLU) FC(1, softplus)</cell></row><row><cell cols="3">Conv(64, 3, 2, BN, ReLU) Conv(64, 3, 2, BN, ReLU) FC(1, softplus)</cell><cell></cell></row><row><cell cols="2">Conv(64, 3, 2, BN, ReLU) Conv(64, 3, 2, BN, ReLU)</cell><cell></cell><cell></cell></row><row><cell>FC(64, ReLU)</cell><cell>SAB(64, 4)</cell><cell></cell><cell></cell></row><row><cell>FC(64, ReLU)</cell><cell>SAB(64, 4)</cell><cell></cell><cell></cell></row><row><cell>FC(64, ReLU)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>FC(64, −)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 .</head><label>4</label><figDesc>Detailed architectures used in 2D synthetic experiments.</figDesc><table><row><cell></cell><cell>Encoder</cell><cell></cell><cell cols="2">Decoder</cell></row><row><cell>rFF</cell><cell>SAB</cell><cell>ISAB</cell><cell>Pooling</cell><cell>PMA</cell></row><row><cell cols="3">FC(128, ReLU) SAB(128, 4) ISABm(128, 4)</cell><cell>mean</cell><cell>PMA4(128, 4)</cell></row><row><cell cols="3">FC(128, ReLU) SAB(128, 4) ISABm(128, 4)</cell><cell>FC(128, ReLU)</cell><cell>SAB(128, 4)</cell></row><row><cell>FC(128, ReLU) FC(128, ReLU)</cell><cell></cell><cell></cell><cell>FC(128, ReLU) FC(128, ReLU)</cell><cell>FC(4 • (1 + 2 • 2), −)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>FC(4 • (1 + 2 • 2), −)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 .</head><label>7</label><figDesc>Detailed architectures used in CIFAR-100 meta clustering experiments.</figDesc><table><row><cell></cell><cell>Encoder</cell><cell></cell><cell cols="2">Decoder</cell></row><row><cell>rFF</cell><cell>SAB</cell><cell>ISAB</cell><cell>rFF</cell><cell>PMA</cell></row><row><cell cols="3">FC(256, ReLU) SAB(256, 4) ISABm(256, 4)</cell><cell>mean</cell><cell>PMA4(128, 4)</cell></row><row><cell cols="3">FC(256, ReLU) SAB(256, 4) ISABm(256, 4)</cell><cell>FC(256, ReLU)</cell><cell>SAB(256, 4)</cell></row><row><cell cols="3">FC(256, ReLU) SAB(256, 4) ISABm(256, 4)</cell><cell>FC(256, ReLU)</cell><cell>SAB(256, 4)</cell></row><row><cell>FC(256, ReLU) FC(256, ReLU)</cell><cell></cell><cell></cell><cell>FC(256, ReLU)) FC(256, ReLU)</cell><cell>FC(4 • (1 + 2 • 512), −)</cell></row><row><cell>FC(256, −)</cell><cell></cell><cell></cell><cell>FC(256, ReLU) FC(4 • (1 + 2 • 512), −)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 .</head><label>10</label><figDesc>Detailed architectures used in the point cloud classification experiments.</figDesc><table><row><cell>Encoder</cell><cell></cell><cell cols="2">Decoder</cell></row><row><cell>rFF</cell><cell>ISAB</cell><cell>Pooling</cell><cell>PMA</cell></row><row><cell cols="2">FC(256, ReLU) ISAB(256, 4)</cell><cell>max</cell><cell>Dropout(0.5)</cell></row><row><cell cols="2">FC(256, ReLU) ISAB(256, 4)</cell><cell>Dropout(0.5)</cell><cell>PMA1(256, 4)</cell></row><row><cell>FC(256, ReLU)</cell><cell></cell><cell cols="2">FC(256, ReLU) Dropout(0.5)</cell></row><row><cell>FC(256, −)</cell><cell></cell><cell>Dropout(0.5) FC(40, −)</cell><cell>FC(40, −)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The point-cloud dataset used in this experiment was obtained directly from the authors of<ref type="bibr" target="#b35">Zaheer et al. (2017)</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>took to process 10,000 sets of each size. The maximum set size we report for SAB is 2,000 because the computation graph of bigger sets could not fit on our GPU. The specific attention blocks used are ISAB 4 (64, 8) and SAB(64, 8).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<title level="m">Layer normalization. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bloem-Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.06082</idno>
		<title level="m">Probabilistic symmetry and invariant neural networks. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shapenet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<title level="m">An information-rich 3D model repository. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Point-Net: Deep learning on point sets for 3D classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Q</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaichun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Solving the multiple instance problem with axis-parallel rectangles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lathrop Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="31" to="71" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards a neural statistician</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Model-agnostic metalearning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spectral grouping using the Nyström method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="225" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Conditional neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Eslami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</title>
		<meeting>the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attention-based deep multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attentive neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations</title>
		<meeting>International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Gradient-based meta-learning with learned layerwise metric and subspace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discovering causal signals in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Attend and interact: higher-order object interactions for video understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Melvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alregib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A framework for multipleinstance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning from distributions via support measure machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dinuzzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distribution to distribution regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Póczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural episodic control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Puigdomenech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A simple neural network module for relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G T</forename><surname>Barret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Evolutionary Principles in Self-Referential Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Technical University of Munich</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">DeepPano: deep panoramic representation for 3-D shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2339" to="2343" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition. arXiv eprints</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sparse Gaussian processes using pseudo-inputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Snelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-view convolutional neural networks for 3D shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning to Learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Order matters: sequence to sequence for sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wagstaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osborne</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09006</idno>
		<title level="m">On the limitations of representing functions on sets</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">3D ShapeNets: a deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Attentional aggregation of deep feature sets for multi-view 3D reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Trigoni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.00758</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
