{"1000": "unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train. unfortunately, the best completely unsupervised english pos tagger ( that does not make use of a tagging dictionary) reaches only accuracy, making its practical usability questionable at best. across eight european languages, our approach results in an average absolute improvement of over a state-of-the-art baseline, and over vanilla hidden markov models induced with the expectation maximization algorithm. this paper proposes a new approach to pos tagging in languages for which no labeled resources are available. the paper proposes a new approach to pos tagging in languages for which no labeled resources are available.", "1001": "this paper presents a novel approach for fv representation of sequences using a recurrent neural network ( rnn) . the rnn is trained to predict the next element of a sequence given the previous elements. given a sequence of vectors s with n vector elements x1 , ... , xn, we convert it to the input sequence x ( x0 , x1, ... , xn1) where x0 xstart. this special element is used to denote the beginning of the input sequence, and we use xstart throughout this paper. the paper explores two different approaches for training the rnn for the image annotation and image search tasks. one type is based on training a regression problem, and the other on training a classification problem. the large vocabulary size makes the regression approach more scalable and achieves better results than the classification approach. in this paper, we propose a new method for training a convolutional neural network (cnn) to predict the next word of a sequence of words. the network is trained for regression with the mean square error ( mse) loss function. the rnn-fv is capable of encoding the sequence properties, and as underlying features, we rely on video encodings that are based on single frames or on fixed length blocks of each video frame. the network can naturally handle unseen words, since it predicts vectors in the word vector space rather than an index of a specific word, and hence also of each gradient. a sentence, being an ordered sequence of words, can be represented as a vector using the rnn-fv scheme. the rnn model consists of three layers : a 200d fullyconnected layer units with leaky-relu activation ( 0.1) , a 200-units long short-term memory ( lstm) layer, and a 500d linear fully connected layer. the early stopping point is chosen at the epoch with highest recognition accuracy on the validation set. this paper introduces a novel fv representation for sequences that is derived from rnns. the proposed representation is sensitive to the element ordering in the sequence and provides a richer model than the additive bag model typically used for conventional fvs. the rnn-fv representation surpasses the state-of-theart results for video action recognition on two challenging datasets. when used for representing sentences, the rnnfv representation achieves state-of-the-art or competitive results on image annotation and image search tasks. since the length of the sentences in these tasks is usually short and, therefore, the ordering is less crucial, we believe that using the rnn-fv representation for tasks that use longer text will provide an even larger gap between the conventional fv and the rnn-fv .", "1002": "the rate of publications of scientific papers is increasing and it is almost impossible for re- searchers to keep up with relevant research. thus, the talk must be coherent as viewed by its authors, and is much more comprehensive than the abstract. thus, the talk can be considered as a sum- mary of the paper, as viewed by its authors. to do so, the speaker must describe their paper coherently and concisely ( since there is a time limit), provid- ing a good basis for generating summaries. based on this idea, in this paper, we propose a new method, named talksumm ( acronym for talk- based summarization), to automatically generate extractive content-based summaries for scientific papers based on video talks. our approach uti- lizes the transcripts of video content of conference talks, and treat them as spoken summaries of pa- pers. then, using unsupervised alignment- rithms, we map the transcripts to correspond- ing papers, and create extractive summaries. to our knowl- edge, this is the first approach to automatically cre- ate extractive summaries for scientific papers by utilizing the videos of conference talks. this paper proposes a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza-tion, based on conference talks given by authors.", "1003": "emotion detection from text has become a popular task due to the key role of emotions in human-machine interaction. current approaches represent text as a sparse bag-of-words vector. in this work, we propose a new approach that utilizes pre-trained, dense word embedding representations. we introduce an ensemble approach combining both sparse and dense representations. for example, cbow representation for glove source showed a improvement in f1-score relative to word2vec. also, the class method we 2url/ 3url/ 4url 5url/ proposed outperformed the other embedded document representation methods.", "1004": "in this paper we show that, in addition to text based turn features, dialogue features can significantly improve detection of emotions in social media customer service dialogues and help predict emotional techniques used by customer service agents. we defined a dialogue to be a sequence of turns between a specific customer and an agent, where the customer initiates the first turn. consecutive posts of the same party ( customer or agent) uninterrupted by the other party are considered as a single turn ( even if there are several tweets). given the nature of customer support services, we assume the last turn in the dialogue is an agent turn. thus, we expect an even number of turns in the dialogue. we extracted this data from december until june specifically, for each customer that posted a tweet to the customer support accounts, we searched for the previous, if any , turn to which it replied. given this method we traced back previous turns and reconstructed entire dialogues. this analysis reflects our ultimate goal: to enable a computer system to discern the emotions expressed by human customers , and to develop computerized tools that mimic the emotional technique used by a human customer service agent in a particular situation. the goal of this paper is to predict the emotions of a customer or an agent turn in social media. the paper proposes two models for this task. the first model is based on an svm approach. the second model is based on a sequence classification method (svmhmm) approach. the svm model is based on a kth order hidden markov model (hmm) model. the svm-hmm model is based on a kth order hidden markov model (hmm) model. the svm-hmm model generates models that are isomorphic to a kth order hidden markov model (hmm) model. in this paper , we have proposed two different models ( svm dialogue and svm-hmm dialogue models ) for support service classification tasks. in the svm dialogue model , we have proposed two different models ( svm-hmm dialogue and svm-hmm dialogue models ) for these tasks. in the svm-hmm dialogue model , we have proposed two different models ( svm-hmm dialogue and svm-hmm dialogue models ) for these tasks. we have studied the impact of dialogue features and dialogue history on the quality of the classification and showed improvement in performance for both models and both classification tasks.", "1005": "few-shot learning ( fsl) is a topic of rapidly growing interest. typically, in fsl a model is trained on a dataset consisting of many small tasks ( meta-tasks) and learns to adapt to novel tasks that it will encounter during test time. this is also referred to as meta-learning. another topic closely related to meta-learning with a lot of interest in the community is neural architecture search ( nas) , automatically finding optimal architecture instead of engineering it manually. in this work, we propose to employ tools inspired by the differentiable neural architecture search ( d-nas ) literature in order to optimize the architecture for fsl without overfitting. additionally, to make the architecture task adaptive, we propose the concept of metadapt controllers. these modules are added to the model and predict optimal network connections for a given novel task. using the proposed approach we observe state-of-theart results on two popular few-shot benchmarks: miniimagenet and fc100. this paper proposes a new method for few-shot architecture search called metadapt. in this method, the architecture of the block is built from feature maps v xi that are linked by mixtures of operations. each feature map xi in the block is connected to all previous maps by setting it to be: xi ji o ( j, i) o ( x) oo exp ( ( i, j) o ) oo exp ( ( i, j) o) is a set of the search space operations, o ( x) is an operation applied to x, and ( i, j) o is an optimised coefficient for operation o at edge ( i, j) o is an optimised coefficient for operation o at edge ( i, j) o is an optimised coefficient for operation o at edge ( i, j) o is an optimised coefficient for operation o at edge ( i, j) o is an optimised coefficient for operation o at edge ( i, j) o is an optimised coefficient for operation o at edge ( i, j) o is an optimised coefficient for operation o at edge ( i, j) o is an optimised coefficient for operation o at edge ( i, j) in this paper , we propose an adaptive network architecture for few-shot tasks . in particular , the proposed approach is designed to search the network architecture of the last block of the training set for a given few-shot task , and then adaptively search the network architecture of the next block of the training set for a given few-shot task . in this paper , we propose an adaptive network architecture for few-shot tasks , and then adaptively search the network architecture of the next block of the training set for a given few-shot task .", "1006": "the goal of this work is to reliably detect egregious conversations between a human and a virtual agent. we consider customer inputs throughout a whole conversation, and detect cues such as rephrasing, the presence of heightened emotions, and queries about whether the intent is to speak to an actual human. in addition, we analyze the worst agent responses, looking repetitions ( e.g., from loops that might be due to flow problems), and the presence of not trained responses. if detected in real time, a human agent can be pulled in to salvage the conversation. as an aid to the improvement, analysis of egregious conversations can often point to problems in training data or system logic that can be repaired. the goal of this work is to give developers of automated agents tools to detect and then solve problems cre- ated by exceptionally bad conversations. in this context, the goal of this work is to give developers of automated agents tools to detect and then solve problems cre- ated by exceptionally bad conversations.", "1007": "this paper presents an analysis into the inner workings of convolutional neural networks ( cnns) for processing text. cnns used for computer vision can be interpreted by projecting filters into image space, but for discrete sequence inputs cnns remain a mystery. we aim to understand the method by which the networks process and classify text. we examine common hypotheses to this problem: that filters, accompanied by global max-pooling, serve as ngram detectors. we show that filters may capture several different semantic classes of ngrams by using different activation patterns, and that global max-pooling induces behavior which separates important ngrams from the rest. finally, we show practical use cases derived from our findings in the form of model interpretability ( explaining a trained model by deriving a concrete identity for each filter, bridging the gap between visualization tools in vision tasks and nlp) and prediction interpretability ( explaining predictions) . this paper proposes a new approach to the analysis of cnns based on the concept of slot activations. the slot activations of a cnn are the activations of the words in the ngram.", "1008": "a summary generated by editnet may include sentences that were either extracted, abstracted or of both types. moreover, per considered sentence, editnet may decide not to take either of these decisions and completely reject the sentence. the paper proposes a novel alternative summarization approach that instead of solely applying extraction or abstraction, mixes both together. moreover, editnet implements a novel sentence decision, allowing to correct initial sentence selection decisions which are predicted to negatively effect summarization quality. on average, and of editnet s decisions were to abstract ( a) or reject ( r) , respectively. moreover, on average, per summary, editnet keeps only of the original ( extracted) sentences, while the rest ( 67) are abstracted ones. this demonstrates that, editnet has a high capability of utilizing abstraction, while being able to maintain or reject the original extracted text whenever it is estimated to provide the best benefit for summary s quality.", "1009": "this paper presents dimsim, a learned ndimensional encoding for chinese along with a phonetic similarity algorithm, which uses the encoding to generate and rank phonetically similar words. dimsim demonstrates a 7.5x improvement on mean reciprocal rank over the state-of-the-art algorithms. this paper proposes a new learning model for chinese word encodings based on annotators and word pairs. the model is based on a set of chinese word encodings and a set of chinese word pairs. the model aims to minimize the sum of the absolute differences between the euclidean distances of component pairs and the average distances obtained from the annotated training data across all pairs for initials ( or finals) . we also incorporate a penalty function, p, for pairs deviating from the manually annotated distance so that more phonetically similar pairs are penalized more highly. for each word pair, we use equation to calculate the distance with the average value of labels across the annotators. equation inverts the labels so that the output can be used as a distance metric ( phonetically similar initials or finals are closer together, and scales the result to more accurately measure phonetic similarities. we also ask two native chinese speakers to annotate the quality of the generated candidates. since downstream applications will only consider a limited number of candidates in practice, we evaluate precision via a manual annotation task on the top-k candidates generated by each approach. dimsim improves recall by factors of 1.5, 1.5, and 1.2, and improves mrr by factors of 7.5 , 1.4, and 1.2, respectively. phonetic transcription is a widely observed phenomenon in chinese social media and informal language. in this paper, we propose an accurate phonetic similarity algorithm called dimsim. dimsim generates phonetically similar candidate words based on learned encodings that capture the pronunciation characteristics of pinyin initial, final, and tone components. using a real world dataset, we demonstrate that dimsim effectively improves mrr by 7.5x, recall by 1.5x and precision by 1.4x over existing approaches.", "1010": "relation detection is a core component of many nlp applications including knowledge base question answering ( kbqa). although general relation detection1 methods are well studied in the nlp community, such studies usually do not take the end task of kbqa into consideration. as a result, there is a significant gap between general relation detection studies and kb-specific relation detection. first, in most general relation detection tasks, the number of target relations is limited, normally smaller than in contrast, in kbqa even a small kb, like freebase2m ( bordes et al., 2015), contains more than 6,000 relation types. second, relation detection for kbqa often becomes a zero-shot learning task, since some test instances may have unseen relations in the training data. third, for some kbqa tasks like webquestions, we need to predict a chain of relations instead of a single relation. this increases the number of target relation types and the sizes of candidate relation pools, further increasing the difficulty of kb relation detection. this paper improves kb relation detection to cope with the problems mentioned above. first, in order to deal with the unseen relations, we propose to break the relation names into word sequences for question-relation matching. this paper proposes a hierarchical residual bilstm ( hr-bilstm) model for the relation detection task. the hr-bilstm model can be viewed as entity linking on a kb subgraph. for each question q, after generating a score srel ( r; q) for each relation using hr-bilstm, we use the top l best scoring relations ( rlq) to re-rank the original entity candidates. the embeddings of relation names are randomly initialized , since existing pretrained relation embeddings ( e.g. transe) usually support limited sets of relation names. finally, the system outputs the entity , relation ( or core-chain) pair ( e, r) max e2el0 k0 ( q) , where is a hyperparameter to be tuned. compared to previous approaches, the main difference is that we have an additional entity reranking step after the initial entity linking. for example, on simplequestions the best reported linker could only get top-1 accuracy on identifying topic entities. for cnns we double the size for fair comparison. kb relation detection is a key step in kbqa and is significantly different from general relation extraction tasks. we propose a novel kb relation detection model, hr-bilstm, that performs hierarchical matching between questions and kb relations. our model outperforms the previous methods on kb relation detection tasks and allows our kbqa system to achieve state-of-the-arts. for future work, we will investigate the integration of our hr-bilstm into end-to-end systems.", "1011": "in this paper, we propose a human-in-the-loop ( huml) dictionary expansion approach that employs identifying a lightweight neural language model coupled with tight huml supervision to assist the user in building and maintaining a domain-specific dictionary from an input text corpus. the approach is based on the explore/exploit paradigm to effectively discover new instances ( explore) from the text corpus as well as predict new unseen terms not currently in the corpus using the accepted dictionary entries ( exploit) this paper proposes an interactive dictionary expansion tool using a lightweight neural language model. our algorithm is iterative and purely statistical, hence does not require any feature extraction beyond tokenization. it incorporates human feedback to improve performance and control semantic drift at every iteration cycle. the experiments showed high importance of tight huml integration on discovery efficiency.", "1012": "this paper presents a novel approach for textual grounding which is based on a deep net based model. the model is based on a set of image concepts, such as semantic segmentations, detections, and word priors, which are subsumed in the set c. the energy function is based on a set of image concepts, such as semantic segmentations, detections, and word priors, which are subsumed in the set c. the search over a large number of bounding boxes allows us to retrieve an accurate bounding-box prediction for a given phrase and an image. the search for this box can be solved via an efficient branch and bound 31st conference neural information processing systems ( nips 2017 ) textual grounding is an important but challenging task for human-computer interaction, robotics and knowledge mining. the energy function is based on a set of image concepts, such as semantic segmentations, detections, and word priors, which are subsumed in the set c. the search over a large number of bounding boxes allows us to retrieve an accurate bounding-box prediction for a given phrase and an image. in this paper, we propose a new method for finding a lower bound on the energy of a given space. the lower bound is obtained by a linear combination of word priors and accumulated segmentation masks. the method is based on the idea of finding a lower bound on the energy of a given space.", "1013": "perceptual features ( pfs) have been used with great success in tasks such as transfer learning, style transfer, and superresolution. however, the efficacy of pfs as key source of information for learning generative models is not well studied. we investigate here the use of pfs in the context of learning implicit generative models through moment matching ( mm) this paper proposes a new approach to training implicit generative models by using pretrained feature extractors. the idea is to train a generator g that maps from a prior uniform distribution to the latent code learned by a pretrained ae, and then uses the frozen pretrained decoder to map back to image space. the idea is to train a generator g that maps from a prior uniform distribution to the latent code learned by a pretrained ae, and then use the frozen pretrained decoder to map back to image space. the objective of this paper is to show that if a discriminator can distinguish perfectly between real and fake early on, the generator can not learn properly and the min/max game becomes unbalanced, having no good discriminator gradients for the generator to learn from, producing degenerate models. in this appendix, we present a comparison between the simple moving average ( ma) and adam moving average ( ama) for the case where vgg19 imagenet classifier is used as a feature extractor. indeed, the discriminator, being pretrained on imagenet, can quickly learn to distinguish between real and fake images. this limits the reliability of the gradient information from the discriminator, which in turn renders the training of a proper generator extremely challenging or even impossible. this is a well - known issue with gan training where the training of the generator and discriminator must strike a balance. if a discriminator can distinguish perfectly between real and fake early on, the generator can not learn properly and the min/max game becomes unbalanced, having no good discriminator gradients for the generator to learn from, producing degenerate models. figure shows some examples of images generated by the unsuccessfully trained models.", "1014": "we pose the problem of demand-aware recommendation via joint low-rank tensor completion and product category inter- purchase duration vector estimation. given a set of m users, n items, and l slots, we construct a third-order binary tensor p. given this observation, we follow and include a label-dependent loss trading the relative cost of positive and unlabeled samples, a problem usually referred to as positive-unlabeled ( pu) learning to address these issues. to this end, we use a nonnegative vector d rr to quantify the underlying inter-purchase duration times of the r item categories. it is understood that the inter-purchase durations for nondurable good categories are large, while for durable good categories are small, or even zero. to overcome this limitation, we develop an efficient alternating minimization algorithm and show that its time complexity is only approximately proportional to the number of nonzero elements in the purchase tensor p since p is usually very sparse , our algorithm is extremely efficient and can solve problems with millions of users and millions of items in a single thread. in this paper , we propose a demand-aware recommender for one -sided sampling ( daross ) , where each user can make at least one purchase and each item should be purchased at least once to be included in p, n and m are smaller than p0. since each user should make at least one purchase and each item should be purchased at least once to be included in p, n and m are smaller than p0. to this end, we first construct a low-rank matrix x wht, where w rm10 and h rn10 are random gaussian matrices with entries drawn from n ( 1 , 0.5) , and then normalize x to the range of 0, which is a significant improvement over the naive approach with at least o ( mnl) complexity. since our problem has only two blocks d, x and each subproblem is convex, our optimization algorithm is guaranteed to converge to a stationary point indeed, it converges very fast in practice. as a concrete example, our experiment shows that it takes only iterations to optimize a problem with million users, million items, and more than million purchase records. in this paper, we examine the problem of demand-aware recommendation in settings when inter-purchase duration within item categories affects users inter-purchase intention in combination with intrinsic properties of the items themselves. we formulate as norm minimization problem that seeks to jointly learn the form utility tensor and a vector of duration vectors in noiseless settings; it is robust to noise scalable as analyzed theoretically. on two real-world datasets, tmall and amazon review, we show that our algorithm outperforms six state-of-theart recommendation algorithms on the tasks of category, item, and purchase time predictions.", "1015": "we present a personality-based neural response generation model that generates responses conditioned on a target personality. the model learns high level features based on the target personality, and uses them to update its hidden state. our model achieves performance improvements in both perplexity and bleu scores over a baseline sequence-to-sequence model, and is validated by human judges.", "1016": "we introduce a stereo correspondence system implemented fully on event-based digital hardware, using a fully graph-based non von-neumann computation model, where no frames, arrays, or any other such data-structures are used. this is the first time that an end-to-end stereo pipeline from image acquisition and rectification , multi-scale spatiotemporal stereo correspondence, winner-take-all, to disparity regularization is implemented fully on event-based hardware. using a cluster of truenorth neurosynaptic processors, we demonstrate their ability to process bilateral event- based inputs streamed live by dynamic vision sensors ( dvs), at up to 2,000 disparity maps per second, producing high fidelity disparities which are in turn used to reconstruct, at low power, the depth of events produced from rapidly changing scenes. experiments on real-world sequences demonstrate the ability of the system to take full advantage of the asynchronous and sparse nature of dvs sensors for low power depth reconstruction, in environments where conventional frame-based cameras connected to synchronous processors would be inefficient for rapidly moving objects. the winner-take-all ( wta) system is a feed-forward neural network that takes as input d thermometer code representations of the hadamard products for d distinct candidate disparity levels, and finds the disparity with the largest value, at every tick. for designing a scalable and compact wta system, numbers can be efficiently coded using base4 representation where each digit is encoded using a 3-bits thermometer code. for a set of qt-coded inputs, the wta system is realized by a cascade of ( b1) feed-forward pruning networks where each of the pruning networks process only 3-bits of the qt codes and prune the inputs not equal to the bitwise maximum of the qt codes from all inputs. now starting from the most significant bits, all the inputs smaller than the maximum will survive at the output of the last cascade network. while it takes a few more bits than a binary code, it allows designing a feed-forward wta network comprising only four cascaded subnetworks, compared to eight for a binary representation, requiring fewer hardware resources as well as half the latency. latency is further improved with larger bases, but the growth in thermometer code length for each digit results in consuming more hardware resources. this paper presents the first example of a fully end-to-end low-power, high throughput fully event-based neuromorphic stereo system capable of running on live input event streams, using a fully graph-based computation model, where no frames, arrays or other such data-structures are used. the implemented neuromorphic stereo disparity system achieves these advantages, while consuming less power per pixel per disparity map compared to the stateof-the-art the homogeneous computational substrate provides the first example of a fully end-to-end low-power, high throughput fully event-based neuromorphic stereo system capable of running on live input event streams, using a fully graph-based computation model, where no frames, arrays or other such data-structures are used.", "1017": "given a collection of distributions , two causal graphs are called interventionally equivalent if they are associated with the same family of interventional distributions, where the elements of the family are indistinguishable using the invariances obtained from a direct application of the calculus rules. we introduce a graphical representation that can be used to determine if two causal graphs are interventionally equivalent. we provide a formal graphical characterization of this equivalence. finally, we extend the fci algorithm, which was originally designed to operate based on cis, to combine observational and interventional datasets, including new orientation rules particular to this setting. in order to characterize causal graphs that are i-markov equivalent, we draw some insight from the markov equivalence of causal graphs with latents. ancestral graphs, and more specifically mags, were proposed as a representation to encode the d-separation statements of a causal graph among the measured variables while not explicitly encoding the latent nodes. the proposed rule is a mixture of rules and as we could be conditioning in w on a subset of the symmetrical difference set i4j. for instance, consider the causal graph d c cd a b, c cd b and suppose we have the interventional distributions pa, b and pc, b. this generalization will soon play a significant role in the characterization and learning of the interventional equivalence class. since b a , c in da, c, then pa, b ( ba) pb, c. this generalization will soon play a significant role in the characterization and learning of the interventional equivalence class. the fci algorithm learns the causal structure underlying a phenomenon of interest from a combination of observational and experimental data. we pursue this endeavor by noting that a generalization of pearl s do-calculus leads to new tests that can be evaluated against data. these tests, in turn, translate into constraints over the structure itself. we then define an interventional equivalence class based on such criteria ( def. 1) , and then derive a graphical characterization for the equivalence of two causal graphs ( thm. finally, we develop an algorithm to learn an interventional equivalence class from data, which includes new orientation rules. we investigate the problem of learning the causal structure underlying a phenomenon of interest from a combination of observational and experimental data. we pursue this endeavor by noting that a generalization of pearl s do-calculus ( thm. 1) leads to new tests that can be evaluated against data.", "1018": "neural program induction ( npi) is a pragmatic approach toward modularizing the reasoning process by translating a complex natural language query into a multistep executable program. while npi has been commonly trained with the gold sketch or its program sketch, practically only natural language queries and the corresponding answers can be provided for training. the resulting combinatorial explosion in program space, along with extremely sparse rewards, makes npi for kbqa ambitious and challenging. we present complex imperative program induction from terminal rewards ( cipitr) , an advanced neural programmer that mitigates sparsity with auxiliary rewards, and uses high-level constraints, kb schema, and inferred answer type. cipitr solves complex kbqa considerably more accurately than key-value memory networks and neural symbolic machines ( nsm) . for moderately complex queries requiring 2to 5-step programs, cipitr scores at least higher f1 than the competing systems. on one of the hardest class of programs ( comparative reasoning) with steps, cipitr outperforms nsm by a factor of and kvmnet by a factor of further. cipitr is a reinforcement learning model that takes as input the natural language question, the kb, and the prepopulated variable memory tables to generate a program ( i.e., a sequence of operators invoked with past instantiated variables as their arguments and generating new variables in memory ) . the interpreter executes the generated program with the help of the kb and scratch memory and outputs the system answer. in the current version of cipitr, the preprocessor consults an oracle to link entities, relations, and type linking which acts as input to the program induction. this is to isolate the programming performance of cipitr from the effect of imperfect linkage. additionally, whereas the relatively simple nsm architecture could explore a large beam size ( 50100) , the complex architecture of cipitr entailed by the cpi problem could only afford to operate with a smaller beam size ( 20) , which further exacerbates the sparsity of the reward space. for example, for integer answers, only a single point in the integer space returns a positive reward, without any notion of partial reward. a problem as complex as ours requires not only generic constraints for producing semantically correct programs, but also of prior knowledge, if the model permits. cipitr is an advanced npi model for program induction in absence of gold programs. the model is trained using the adam optimizer and tuned all hyperparameters on the validation set. some parameters are selectively turned on/ off after few training iterations, which is itself a hyperparameter. for the train and valid splits, a rule-based query type classifier with accuracy was used. also, the nsm model uses a key-variable memory and decodes the program as a sequence of operators and memory variables. nsm uses a key-variable memory and decodes the program as a sequence of operators and memory variables. on the other hand, training the kvmnet model on the balanced data helps showcase the real performance of the model, where cipitr outperforms kvmnet significantly on most of the complex queries. the hardest types are quantitative and quantitative count, which translate to an average of lined programs.", "1019": "the vast amounts of textual data end users need to consume motivates the need for automatic summarization an automatic summarizer gets as an input one or more documents and possibly also a limit on summary length. the summarizer then needs to produce a summary that captures the most salient ( general and informative) content parts within input documents. the summarizer may also be required to satisfy a specific user information need, expressed by one or more queries. therefore, the summarizer will need to produce a focused summary which includes the most relevant information to that need. overall, dual-ces provides a significantly better summarization quality compared to other alternative unsupervised summarizers; and in many cases, it even outperforms that of state-of-the art supervised summarizers. in this paper, the ce-method is used to produce a 250-word ( lmax 250) focused summary. here, the target measure qfoc ( q, d) guides the optimization towards the production of a focused summary, while still keeping high saliency as much as possible. to achieve that, we use an additional focusdriven predictor which bias summary production towards higher focus. moreover , using the pseudo-reference summary sl we introduce an additional auxiliary saliency-based predictor, whose goal is to enhance the saliency of produced focused summary.", "1020": "this paper presents a tts system that can synthesize speech with close to natural quality while running times faster than real-time on a standard cpu. the modular setup of the system allows for simple adaptation to new voices with a small amount of data. we first demonstrate the ability of the system to produce high quality speech when trained on large, high quality datasets. following that, we demonstrate its adaptability by mimicking unseen voices using to minutes long datasets with lower recording quality. large scale mean opinion score quality and similarity tests are presented, showing that the system can adapt to unseen voices with quality gap of and similarity gap of compared to natural speech for male voices and quality gap of and similarity of for female voices. the goal of this paper is to show that it is possible to build a tts system that is able to produce high quality speech while operating at faster than real-time rate without an expensive gpu support. the system is built around three nn models for generating the prosody, acoustic features and the final speech signal. we tested this system using two proprietary tts voice datasets and demonstrated that our system produces high quality speech that is comparable to larger and much slower tacotron2 wavenet systems. the task of creating a high-quality tts system out of a smaller set of audio data is even more challenging. we demonstrated that when we reduce the size of the training data, there is some graceful degradation to the quality, but we are still able to maintain good similarity to the original speaker. for future work, we plan to allow voice modifications by adding control over voice parameters such as pitch , breathiness and vocal tract.", "1021": "feature selection is an important problem in statistics and machine learning for interpretable predictive modeling and scientific discoveries. code is available at url. in this paper we introduce empirical non convex sic ( sic) as a generalization of convex sic. sic can be seen as a sparse gradient regularized mmd 3, and relates to the sobolev discrepancy of 5, feature selection with mmd was introduced in and is based on backward elimination of features by recomputing mmd on the ablated vectors. sic has the advantage of fitting one critic that has interpretable feature scores. in this paper , we propose a novel approach to training neural networks for classification tasks. the approach is based on the idea of using a neural network as a generator of a predictive model. the neural network is trained randomly sampling an index j1 , , p for each sample x in the training set, and minimizing the cross-entropy loss between the output of the neural network and xj ( xj) using mini-batch sgd. the output of the generator is a nbins-dimensional softmax over bins tessellating the range of the distribution of xj, such that the bins are uniform quantiles of the inverse cdf of the distribution of xj estimated over the training set. in all simulations we used a number of bins nbins generators are trained randomly sampling an index j1 , , p for each sample x in the training set, and minimizing the cross-entropy loss between the output of the neural network and xj ( xj) using mini-batch sgd. in particular, we used the adam optimizer with the default pytorch parameters and learning rate which is every epochs , and batch size of in order to recover the correct conditional independence. is a standard three-layer relu dropout network with no biases, i.e. when using this network, the inputs x and y are first concatenated then given as input to the network."}