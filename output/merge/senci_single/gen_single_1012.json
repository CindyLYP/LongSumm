{"1012": "grounding of textual phrases, i.e., finding bounding boxes in images which relate to textual phrases, is an important problem for human-computer interaction, robotics and mining of knowledge bases, three applications that are of increasing importance when considering autonomous systems , augmented and virtual reality environments. for example, we may want to guide bottle on your left phrase such as autonomous system by using the plate in the top shelf. while those phrases pose significant challenges for present day textual grounding algorithms, as interpretation of those phrases requires an understanding of objects and their spatial-image relationships and provide interpretability. more specifically, deep net models are designed to extract features from given bounding boxes and textual data, which are then compared to measure their fitness. to obtain suitable bounding boxes, many of the textual grounding frameworks, such as 38, 15, make use of region proposals. this paper proposes an energy minimization approach for bounding box proposals. the approach is based on a set of image concepts like semantic segmentations, energy detections or image priors. all those concepts come in the form of score maps which we combine linearly searching for the bounding box containing the highest accumulated score over the combined score map. moreover, linear combination of score maps reveals importance of score maps for specific queries as well as similarity between queries such as skier , snowboarder. hence the framework that we discuss in the following is easy to interpret and extend to other settings. the search over a large number of bounding boxes allows us to retrieve an accurate bounding-box prediction for a given phrase and an image. importantly, by leveraging branch-and-bound techniques, we are able to find the global minimizer very effectively. in this paper, we propose a new approach to find the bounding box with lowest energy. the approach is based on a set of word priors and k2 geometric cues. for the top k1 words in the training set we construct word prior maps like the ones shown in fig. for the top k1 words in the training set we obtain probability maps for a set of class categories, i.e., a subset of the nouns of interest. to obtain the prior for a particular word, we search a given training set for each occurrence of the word. with the corresponding subset of image-text pairs and respective bounding box annotations at hand, we compute the average number of times a pixel is covered by a bounding box. to facilitate this operation, we scale each image to a predetermined size. the k2 geometric cues provide the aspect ratio and the area of the hypothesized bounding box y. note that the word priors and geometry features contain no information about the image specifics. to encode measurements dedicated to the image at hand, we take advantage of semantic segmentation and object detection techniques. in this paper, we show how to compute a lower bound e ( x, yj, w) on the energy for an output space, and to illustrate the conditions which guarantee convergence to the global minimum of the energy function. for the latter, we note that bounds on score maps for bounding box intervals can be computed by considering either the largest or the smallest possible bounding box in the bounding box hypothesis, y depending on whether the weight in wt is positive or negative and whether the feature mask contains only positive or negative values. intuitively , if the weight is positive and the feature mask contains only positive values, we obtain the smallest lower bound e ( x, y, w) by considering the content within the smallest possible bounding box. note that score maps do not necessarily contain only positive or negative numbers. however we can split the given score maps into two separate score maps ( i.e., one with only positive values, and another with only negative values) while applying the same weight. it is important to note that computation of the bound e ( x, yj, w) has to be extremely effective for the algorithm to run at a reasonable speed. however, computing the feature mask content for a bounding box is trivially possible using integral images. this paper proposes a novel approach for object detection and segmentation. we demonstrate a mechanism for grounding of textual phrases which provides interpretability, is easy to extend, and permits globally optimal inference. in contrast to existing approaches which are generally based on a small set of bounding box proposals, we efficiently search over all possible bounding boxes. we think interpretability, i.e., linking of word and image concepts, is an important concept, particularly for textual grounding, which deserves more attention. this paper presents a novel approach for textual grounding which is based on a deep net based model. the model is based on a set of image concepts, such as semantic segmentations, detections, and word priors. the search for this box can be solved via an efficient branch and bound 31st conference neural information processing systems ( nips 2017 ) textual grounding is an important but challenging task for human-computer interaction, robotics and knowledge mining. while those phrases pose significant challenges for present day textual grounding algorithms, as interpretation of those phrases requires an understanding of objects and images. based on those image concepts, which are represented as score maps, we formulate grounding as a search over all possible bounding boxes. the search for this box can be solved via an efficient branch and bound 31st conference neural information processing systems ( nips 2017 ) in this paper, we propose a novel approach for unsupervised learning of the parameters of a feature space. the method is based on the idea of learning a lower bound e ( x, yj, w) on the energy of the feature space. the lower bound e ( x, yj, w) is computed using a linear combination of word priors and accumulated segmentation masks.", "1000": "###", "1001": "###", "1002": "###", "1003": "###", "1004": "###", "1005": "###", "1006": "###", "1007": "###", "1008": "###", "1009": "###", "1010": "###", "1011": "###", "1013": "###", "1014": "###", "1015": "###", "1016": "###", "1017": "###", "1018": "###", "1019": "###", "1020": "###", "1021": "###"}