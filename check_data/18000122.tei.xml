<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/cindy/tmp/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Comparison of Word Embeddings for the Biomedical Natural Language Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-02-09">9 Feb 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanshan</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijia</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveed</forename><surname>Afzal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Majid</forename><surname>Rastegar-Mojarad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feichen</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Sijia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afzal</forename><surname>Naveed</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojarad</forename><surname>Majid</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Liwei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Feichen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Liu.Hongfang}@mayo.edu</roleName><forename type="first">Kingsbury</forename><surname>Paul1</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Health Sciences Research</orgName>
								<orgName type="institution">Mayo Clinic Rochester</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Comparison of Word Embeddings for the Biomedical Natural Language Processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-02-09">9 Feb 2018</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1802.00400v2[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-01-31T12:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Background Neural word embeddings have been widely used in biomedical Natural Language Processing (NLP) applications as they provide vector representations of words capturing the semantic properties of words and the linguistic relationship between words. Many biomedical applications use different textual resources (e.g., Wikipedia and biomedical articles) to train word embeddings and apply these word embeddings to downstream biomedical applications. However, there has been little work on evaluating the word embeddings trained from these resources. Methods In this study, we provide an empirical evaluation of word embeddings trained from four different resources, namely clinical notes, biomedical publications, Wikipedia, and news. For the former two resources, we trained word embeddings utilizing clinical notes available at Mayo Clinic and articles from the PubMed Central (PMC), respectively. For the latter two resources, we used publicly available pre-trained word embeddings, GloVe and Google News. We performed the evaluation qualitatively and quantitatively. In qualitative evaluation, we manually inspected five most similar medical words to a given set of target medical words, and then analyzed word embeddings through the visualization of those word embeddings. In quantitative evaluation, we conducted both intrinsic and extrinsic evaluation. Intrinsic evaluation directly tested semantic relationships between medical words using four published datasets for measuring semantic similarity between medical terms, i.e., Pedersen, Hliaoutakis, MayoSRS, and UMNSRS. In extrinsic evaluation, we applied word embeddings to downstream biomedical NLP applications, including clinical information extraction (IE), biomedical information retrieval (IR), and relation extraction (RE), using data from shared tasks. Results Qualitative evaluation shows that the word embeddings trained from EHR and PubMed can find more relevant similar medical terms than these from GloVe and Google News. In the intrinsic quantitative evaluation, the semantic similarity captured by the word embeddings trained from EHR are closer to human experts&apos; judgments on all four tested datasets. In the extrinsic quantitative evaluation, the word embeddings trained from EHR has the best F1 score of 0.900 for the clinical IE task; no word embeddings improve the performance in terms of inference average precision and mean average precision for the biomedical IR task; and the word embeddings trained on Google News has the best overall F1 score of 0.790 for the RE task. Conclusion Based on the evaluation results, we can draw the following conclusions. First, the word embeddings trained on EHR and PubMed can capture the semantics of medical terms better than those trained on GloVe and Google News and find more relevant similar medical terms, and are closer to human experts' judgments, compared to these trained on GloVe and Google News. Second, there does not exist a consistent global ranking of word embedding quality for downstream biomedical NLP applications. However, adding word embeddings as extra features will improve results on most downstream tasks. Finally, the word embeddings trained on biomedical domain corpora do not necessarily have better performance than those trained on other general domain corpora for any downstream biomedical NLP tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Neural word embeddings have been widely used in Natural Language Processing (NLP) applications as they provide vector representations of words capturing the semantic properties of words and the linguistic relationship between words. There has been an increasing number of studies applying word embeddings in common NLP tasks, such as information extraction (IE) <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, information retrieval (IR) <ref type="bibr" target="#b6">[7]</ref>, sentiment analysis <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, question answering <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, and text summarization <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. Recently in the biomedical domain word embeddings have been remarkably utilized in applications like biomedical named entity recognition (NER) <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, medical synonym extraction <ref type="bibr" target="#b15">[16]</ref>, relation extraction (RE) including chemical-disease relation <ref type="bibr" target="#b16">[17]</ref>, drugdrug interaction <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> and protein-protein interaction <ref type="bibr" target="#b19">[20]</ref>, biomedical IR <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> and medical abbreviation disambiguation <ref type="bibr" target="#b22">[23]</ref>. Many biomedical applications use task corpora to train word embeddings or use external data resources such as Wikipedia <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref> to train word embeddings based on an implicit assumption that the external resources contain the knowledge that could be used to enhance domain tasks <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. A number of pre-trained word embeddings are publicly available, such as Google News embeddings and GloVe embeddings <ref type="bibr" target="#b1">2</ref> . These embeddings could capture semantics of general English words from a large corpus. However, one question remains unanswered:</p><p>Do we need to train word embeddings for a specific NLP task since there are a number of public pre-trained word embeddings? This question becomes more significant for biomedical applications, and particularly more important for the clinical domain. The reason is that few electrical health records (EHRs) data are publicly available due to Health Insurance Portability and Accountability Act (HIPAA) rule while a big volume of biomedical literature data is available online. However, there has been little work on evaluating the word embeddings trained from these textual resources for biomedical applications, to the best of our knowledge.</p><p>In this study, we provide an empirical evaluation of word embeddings trained from four different resources, namely clinical notes, biomedical publications, Wikipedia, and news. For the former two resources, we utilized clinical notes from the EHR system at Mayo Clinic and biomedical publications from the PubMed Central (PMC) <ref type="bibr" target="#b2">3</ref> to train word embeddings separately. For the latter two resources, we used publicly available pre-trained word embeddings, GloVe and Google News. We performed the evaluation qualitatively and quantitatively. In qualitative evaluation, we manually inspected five most similar medical words to a given set of target medical words, and then analyzed word embeddings through the visualization of those word embeddings. In quantitative evaluation, we conducted both intrinsic and extrinsic evaluation. Intrinsic evaluation directly tested semantic relationships between medical words using four published datasets for measuring semantic similarity between medical terms, i.e., Pedersen <ref type="bibr" target="#b27">[28]</ref>, Hliaoutakis <ref type="bibr" target="#b28">[29]</ref>, MayoSRS <ref type="bibr" target="#b29">[30]</ref>, and UMNSRS <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. In extrinsic evaluation, we applied word embeddings to downstream NLP applications in the biomedical domain including clinical IE, biomedical IR, and RE, and measured the performance of word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Due to the successful usage of word embeddings in a variety of NLP applications, there exists recent work on evaluation of word embeddings in representing word semantics. Most of the previous work focuses on evaluating word embeddings generated by different approaches. Baroni et al <ref type="bibr" target="#b32">[33]</ref> presented the first systematic evaluation of word embeddings generated by count models (using DISSECT 4 on a corpus of 2.8 billion tokens constructed by concatenating ukWaC <ref type="bibr" target="#b4">5</ref> the English GloVe <ref type="bibr" target="#b5">6</ref> and the British National Corpus 7 ), CBOW <ref type="bibr" target="#b0">[1]</ref> (using word2vec <ref type="bibr" target="#b7">8</ref> on the same corpus as DISSECT), Distributional Memory model <ref type="bibr" target="#b8">9</ref> (on the same corpus as DISSECT), and Collobert and Weston model <ref type="bibr" target="#b9">10</ref> (on the GloVe), and tested them on fourteen benchmarks in five categories: semantic relatedness (a dataset of semantic benchmarks constructed by asking human subjects to rate the degree of semantic similarity or relatedness between two words on a numerical scale, such as Rubenstein and Goodenough's dataset <ref type="bibr" target="#b33">[34]</ref> and WordSim353 <ref type="bibr" target="#b34">[35]</ref>), synonym detection (a dataset containing 80 multiple-choice questions that pair a target term with 4 synonym candidates, such as TOEFL dataset <ref type="bibr" target="#b35">[36]</ref>), concept categorization (given a set of nominal concepts, the task is to group them into natural categories, such as Almuhareb-Poesio dataset <ref type="bibr" target="#b36">[37]</ref>), selectional preferences (a dataset containing verb-noun pairs that were rated by subjects for the typicality of the noun as a subject or object of the verb, such as Ulrike Pado's dataset <ref type="bibr" target="#b37">[38]</ref>), and analogy (a dataset containing semantic and syntactic analogy questions, such as Mikolov's dataset <ref type="bibr" target="#b0">[1]</ref>). They found that the word2vec model, CBOW, performed the best for almost all the tasks. Schnabel et al <ref type="bibr" target="#b38">[39]</ref> trained the CBOW model of word2vec <ref type="bibr" target="#b0">[1]</ref>, C&amp;W embeddings <ref type="bibr" target="#b39">[40]</ref>, Hellinger PCA <ref type="bibr" target="#b40">[41]</ref>, GloVe <ref type="bibr" target="#b41">[42]</ref>, TSCCA <ref type="bibr" target="#b42">[43]</ref> and Sparse Random Projections <ref type="bibr" target="#b43">[44]</ref> on a 2008 GloVe dump, and <ref type="bibr" target="#b2">3</ref> http://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/ http://clic.cimec.unitn.it/composes/ <ref type="bibr" target="#b4">5</ref> http://wacky.sslmit.unibo.it/ <ref type="bibr" target="#b5">6</ref> http://en.GloVe.org/ <ref type="bibr" target="#b6">7</ref> http://www.natcorp.ox.ac.uk/ <ref type="bibr" target="#b7">8</ref> https://code.google.com/p/word2vec/ <ref type="bibr" target="#b8">9</ref> http://clic.cimec.unitn.it/dm/ <ref type="bibr" target="#b9">10</ref> http://ronan.collobert.com/senna/ tested on the same fourteen datasets. They also found the CBOW outperformed other embeddings on 10 datasets. In addition to this intrinsic evaluation, they conducted extrinsic evaluation by using the embeddings as input features to two downstream tasks, namely noun phrase chunking and sentiment classification, and found the results of CBOW were also among the best. Ghannay et al <ref type="bibr" target="#b44">[45]</ref> conducted a similar intrinsic evaluation, they additionally evaluated the skip-gram models of word2vec <ref type="bibr" target="#b0">[1]</ref>, CSLM word embeddings <ref type="bibr" target="#b45">[46]</ref>, dependency-based word embeddings <ref type="bibr" target="#b2">[3]</ref>, and combined word embeddings on NLP tasks (i.e., Part-Of-Speech Tagging, chunking, named entity recognition, mention detection) and linguistic tasks using Mikolov's dataset <ref type="bibr" target="#b0">[1]</ref> and the WordSim353 dataset <ref type="bibr" target="#b34">[35]</ref>. They trained these word embeddings on the Gigaword corpus composed of 4 billion words and found that the dependency-based word embeddings gave the best performance on the NLP tasks and combination of the embeddings yielded significant improvement. In Nayak et al's study <ref type="bibr" target="#b46">[47]</ref>, they recommended that the evaluation should test both syntactic and semantic properties of the word embeddings and that the tasks should be closer to real-word applications. However, none of these studies evaluate word embeddings in the biomedical domain and none of these datasets focus on biomedical data.</p><p>As most of the aforementioned studies evaluate word embeddings in the general (i.e., non-medical) NLP domain, only one recent paper by Pakhomov et al <ref type="bibr" target="#b31">[32]</ref> is about evaluating word embeddings in the biomedical domain, to the best of our knowledge. They trained the CBOW model on two biomedical corpora, namely clinical notes and biomedical publications, and one general English corpora, namely GloVe. The word embeddings were evaluated on subsets of UMNSRS dataset, which consisted of pairs of medical terms with the similarity of each pair assessed by medical experts, and on a document retrieval task and a word sense disambiguation task. They found that the semantics captured by the embeddings computed from biomedical publications were on par with that from clinical notes. Inspired by this work, we would like to conduct a complementary study to extend their evaluation of word embeddings by 1) utilizing four datasets to evaluate word embeddings on capturing medical term semantics; 2) conducting a qualitative evaluation; and 3) examining word embeddings on more biomedical application.</p><p>In this work, we provide a comparison of the quality of word embeddings trained separately from different resources. Specifically, our contributions are: 1) We performed qualitative evaluation where we manually inspected five most similar medical words to a given set of target medical words and plotted a visualization of selected medical words from those word embeddings.</p><p>2) We performed quantitative evaluation, including extrinsic and intrinsic evaluation. In the intrinsic evaluation, we used four published datasets for measuring semantic similarity between medical terms.</p><p>3) In extrinsic evaluation, we evaluated word embeddings by applying them to three publicly shared biomedical tasks, including biomedical IR, NER, and RE, and one institutional clinical NLP task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. WORD EMBEDDINGS</head><p>Since it has been shown that the word2vec outperforms other approaches in generating good embeddings in general NLP tasks <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b38">[39]</ref>, the skip-gram model of word2vec is utilized as the approach for generating word embeddings in this paper. Since no evidence shows the CBOW outperforms the skip-gram model or vice versa, we arbitrarily chose the skip-gram model of word2vec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Brief Introduction</head><p>Word embeddings can be represented as a mapping V → R D : w → θ which maps a word w from a vocabulary V to a real-valued vector θ in an embedding space with a dimension of D. The skip-gram model is an architecture proposed by Mikolov et al <ref type="bibr" target="#b0">[1]</ref>, which trains embeddings using the negative-sampling procedure. It constructed with the focus word as the single input vector, and the target contextual words are at the output layer. Negative-sampling updates a sample of output words per iteration, and the target output words should be kept in the sample and gets updated while a few non-target words are added as negative samples. Mathematically, given a target word w and its contextual word h, the goal is to maximize the log-likelihood on the training data, i.e., max J = log P (h|w),</p><p>where P (h|w) is the conditional probability in the neural probabilistic language model that is usually defined as: <ref type="bibr">w,h)</ref> w∈V e score(w,h) ,</p><formula xml:id="formula_0">P (h|w) = σ(score(w, h)) = e score(</formula><p>where σ() is a softmax function that normalize real vector into a probability vector. Accordingly, the log-likelihood function can be written as:</p><formula xml:id="formula_1">J = score(w, h) − log( w∈V e score(w,h) ).</formula><p>Negative-sample is adopted here to avoid expensive computation over |V | words, i.e.,</p><formula xml:id="formula_2">J = w,h∈D log Q θ (D = 1|w, h) + w,h∈D log Q θ (D = 0|w, h),</formula><p>where D is the observed data, D is the unobserved data, θ is the embedding vector, and Q θ (D = 1|w, h) is the probability of w and h being observed. The word embeddings can be computed by maximizing the log-likelihood function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Parameter Settings</head><p>We tested dimensions of 20, 60 and 100 for word embeddings trained on EHR and PubMed and chose 100 for EHR and 60 for PubMed according to their performance in our intrinsic evaluation. Similarly, we chose the dimension of 100 for GloVe, and that of 300 for Google News since only 300 dimension was publicly available for Google News. The whole results of using different dimensions for word embeddings are provided in Appendix A.</p><p>For training word embeddings on the EHR and PubMed, we set the window size to 5 words, the minimum word frequency to 7 (i.e., the words occurred less than 7 times in the corpus were ignored), and the negative sampling to 5. These parameters were selected based on previous studies <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b18">[19]</ref>.</p><p>IV. DATA</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Text Corpora</head><p>We compared word embeddings computed from four different kinds of corpora.  <ref type="bibr" target="#b10">11</ref> and GloVe embeddings <ref type="bibr" target="#b11">12</ref> , were also considered in the evaluation. The Google News embeddings have embeddings for 3 million words from Google News, trained using the wor2vec <ref type="bibr" target="#b0">[1]</ref>. The GloVe embeddings have embeddings for 400k words from a snapshot of Wikipedia in 2014 and Gigaword Fifth Edition <ref type="bibr" target="#b12">13</ref> , trained using the GloVe model <ref type="bibr" target="#b41">[42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Pre-processing</head><p>The PubMed was pre-processed minimally by removing punctuations (one exception is that we replaced '-' by ' ' if two words were connected by '-' and we treated them as one word), lowercasing, and replacing all digits with "7". We conducted additional pre-processing on the EHR since the narratives written by physicians are more sparse than research articles. Specifically, the section of "Family history" in the corpus was removed if it was semi-structured <ref type="bibr" target="#b47">[48]</ref>. See an example of the "Family history" section in <ref type="table" target="#tab_1">Table I</ref>  The section of "Vital Signs" was totally removed since it did not contain contextual information for training word embeddings. See an example of the "Vital Signs" section in <ref type="table" target="#tab_1">Table II</ref>. Note that these pre-processing strategies are specific for the clinical notes at Mayo Clinic. Moreover, we replace all text contractions with their respective complete text. For example, "can't" is replaced with "can not". For clinical corpus, we removed all the clinical notes metadata and note sections headers, dates, phone numbers, weight and height information and punctuations from clinical corpus. For PubMed articles, we removed all the websites url, email addresses, twitter handler and punctuations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. QUALITATIVE EVALUATION</head><p>The first experiment is qualitative evaluation by manually inspecting the five most similar words to a given target word. We used the commonly employed cosine similarity to calculate the most similar words. Suppose w 1 and w 2 are two words, the similarity between w 1 and w 2 is defined as</p><formula xml:id="formula_3">similarity(w 1 , w 2 ) = θ 1 • θ 2 θ 1 θ 2 ,<label>(1)</label></formula><p>where θ 1 and θ 2 are vector representations for w 1 and w 2 in the embedding space, respectively. If the target word is a medical phrase s 1 consisting of multiple words, i.e., s 1 = w 1 , w 2 , ..., w n , the similarity function becomes</p><formula xml:id="formula_4">similarity(s 1 , w 2 ) = Θ 1θ2 Θ 1 θ 2<label>(2)</label></formula><p>where Θ 1 = 1 n n i θ i is the representation for s 1 in the embedding space. This is different from Pakhomov et al's study <ref type="bibr" target="#b31">[32]</ref> where only single word terms were considered. <ref type="table" target="#tab_1">Table III</ref> lists eight target words in three medical categories, i.e., disorder, symptom and drug, and their five most similar words induced by different word embeddings.</p><p>For the first target word describing an disorder, diabetes, EHR and PubMed find its synonym, mellitus, in the most similar words while GloVe and Google News fail to find it. EHR finds two terms related to co-morbidities of diabetes, cholesterolemia and dyslipidemia, and a most common modifier term, uncontrolled. PubMed finds terms relevant to co-existing conditions for diabetes, such as cardiovascular (very possibly from cardiovascular disease), nonalcoholic (very possibly from nonalcoholic fatty liver disease), obesity, and polycystic (very possibly from polycystic ovary syndrome which is a hyperandrogenic disorder that is associated with a high-risk of development of Type 2 diabetes). Most of these terms are from medical research topics and thus occur in the PubMed articles.</p><p>GloVe finds two related terms, hypertension and obesity, while other three terms, i.e., arthritis, cancer and alzheimer, are less relevant disease names. Google News finds two morphological terms, diabetics and diabetic, relevant to the target words, one synonym, diabetes mellitus, and one related disease name, heart disease. We can draw similar conclusions for the second and third disorder words. It is obvious shown from these target words that EHR and PubMed can capture the semantics of medical terms better than GloVe and Google News and find more relevant similar medical terms. However, EHR and PubMed find similar medical terms from different perspectives due to their different focuses. EHR contains clinical narratives and thus it is closer to clinical language. Yet, it contains terms with different morphologies and even typos, such as melitis, caner and thraot as listed in <ref type="table" target="#tab_1">Table III</ref>. Differently, PubMed contains more medical terminology used in medical articles, and finds similar words mostly from a medical research perspective.</p><p>In order to visualize the semantics of medical terms captured by different word embeddings, we extracted 377 medical terms from the UMNSRS dataset <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref> and plotted the word embeddings for these medical terms using t-SNE <ref type="bibr" target="#b48">[49]</ref>. Example clusters of medical terms in the word embeddings are shown in <ref type="figure" target="#fig_1">Figure 1</ref>.  We tested word embeddings with quantitative evaluation to show the qualitative differences between them. We utilized extrinsic and intrinsic evaluation, where the former used four published datasets for measuring semantic similarity between medical terms and the latter used downstream biomedical tasks to evaluate word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Intrinsic Evaluation</head><p>We tested word embeddings on four published biomedical datasets commonly used to measure semantic similarity between medical terms. The first is Pedersen's dataset <ref type="bibr" target="#b27">[28]</ref>  For each pair of medical terms in the testing datasets, we used Equations 1 and 2 to calculate the semantic similarity for each pair in the embeddings space. Since some medical terms might not exist in the vocabulary of word embeddings, we used fastText <ref type="bibr" target="#b49">[50]</ref> to compute word vectors for these out-of-vocabulary medical terms.</p><p>Pearson correlation coefficient was employed to calculate the correlation between similarity scores from human judgments and those from word embeddings.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Extrinsic Evaluation</head><p>Extrinsic evaluations are used to measure the contribution of word embeddings to specific biomedical tasks. In this evaluation, we applied word embeddings to three prevalent shared tasks: clinical IE, biomedical IR, and RE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Clinical Information Extraction:</head><p>We evaluated word embeddings on two clinical IE tasks. The first experiment is a shared task while the second is an institutional task. We would like to examine whether our local institutional word embeddings are better than external pre-trained word embeddings.</p><p>In the first experiment, we evaluated the word embeddings on an institutional information extraction task at Mayo Clinic. In this task, a set of 1000 radiology reports was examined to detect whether a hand and figure/wrist fracture could be identified. Reports were drawn from a cohort of residents of Olmsted County, aged 18 or older, who experienced fractures in 2009-2011. Each report was annotated by a medical expert with multiple years of experience abstracting fractures by assigning "1" if a hand and figure/wrist fracture was found, or "0" otherwise.</p><p>In our experiment, word embeddings were employed as features for machine learning models and evaluated by precision, recall and F1 scores <ref type="bibr" target="#b51">[52]</ref>. </p><formula xml:id="formula_5">x = 1 M M i x i ,</formula><p>where x i is the embedding vector for word w i from the word embedding matrix. Then x was utilized as input to the machine learning models. A prevalent machine learning model, Support Vector Machine (SVM), was tested in this experiment. We performed 10-fold cross validation on the dataset and reported means of precision, recall and F1 scores from the cross validation. As comparison, the baseline method used term frequency features as input.  we can observe that using word embeddings trained on EHR has the best performance with a F1 score of 0.900.</p><p>This result is interesting since the EHR corpus used to train the word embeddings is from a different institution.</p><p>The reason might be that the smoking dataset has similar sublanguage characteristics as our EHR corpus. This result indicates that effective word embeddings can be shared across institutions for clinical NLP tasks. Another interesting observation is that the performance of word embeddings trained on Google News is close to that on EHR corpus with a comparable F1 score and a better recall. The performance difference is not statistically significant (p&lt;0.01). This implies that word embeddings trained on a public dataset may not be definitely inferior to these trained on a medical specific dataset for a medical IE task. The likely cause is that the terminology used in smoking status extraction task also appears frequently in news, such as medications and advice for smokers. In order to make comparison as fair as possible, we first implemented an IR system as a baseline system following <ref type="bibr" target="#b21">[22]</ref> and then employed the simplest query expansion using word embeddings. That is, we expanded each query term with five most similar terms from word embeddings. Indri <ref type="bibr" target="#b54">[55]</ref> was utilized as our indexing and retrieval tool.</p><p>The preprocessing included stopword removal and Porter stemming. The stopword list was based on the PubMed stopwords <ref type="bibr" target="#b13">14</ref> . The article-id, title, abstract and body fields of each document were indexed. Language models with two-stage smoothing <ref type="bibr" target="#b55">[56]</ref> was used to obtain all the retrieval results. Official metrics, Inferred Normalized</p><p>Discounted Cumulated Gain (infNDCG) <ref type="bibr" target="#b56">[57]</ref>, Inferred Average Precision (infAP) <ref type="bibr" target="#b56">[57]</ref>, Precision at 10 (P@10) and</p><p>Mean Average Precision (MAP), were utilized to measure the performance. <ref type="table" target="#tab_1">Table VII</ref> shows the results on the TREC 2016 CDS track. It is interesting that query expansion using word embeddings almost does not improve retrieval performance and even worsen the performance when infAP and MAP were used as metrics. By comparing the retrieval performance of different word embeddings, we observe that EHR and PubMed perform slight better than GloVe and Google News without statistical significance (p&lt;0.01). This result implies that applying different word embeddings trained from different resources has almost no significant difference for biomedical IR tasks. We also note that this may also be due to the query expansion method used in our evaluation. 3) Relation Extraction: Drug-drug interaction (DDI) extraction is a specific RE task in the biomedical domain.</p><p>DDI is an unexpected change in a drug's effect on the human body when the drug and a second drug are coprescribed and taken together. Automatic extracting DDI information from literature is a challenging and important research topic since the volume of the published literature grows rapidly and greatly. In this experiment, we evaluate word embeddings on DDIExtraction 2013 challenge corpus <ref type="bibr" target="#b57">[58]</ref>. The dataset for DDIExtraction 2013 was composed of sentences describing DDIs from the DrugBank database and MedLine abstracts. In this dataset, drug entities and DDIs were annotated at the sentence level and each sentence could contain two or more drugs. An RE system should be able to automatically extract DDI drug pairs from a sentence. We leveraged the baseline system introduced in <ref type="bibr" target="#b18">[19]</ref> and evaluated word embeddings by concatenating to the baseline features. We utilized Random Forest [59] as the classifier since it had the best performance in <ref type="bibr" target="#b18">[19]</ref>. F1 score was used as the evaluation metric. <ref type="table" target="#tab_1">Table VIII</ref> shows the results on the DDIExtraction 2013 challenge. We can see that the overall performance of word embeddings trained on Google News is the best. The reason is that the semantics of general English terms in the context of drug mentions are more important for determining the drug interactions. For example, in the sentence "Acarbose may interact with metformin", the term "interact" is crucial to classify the relation. Since these crucial terms are generally not medical terminology, word embeddings trained on Google News where the corpus represents general English are able to capture the semantics of these terms. However, the superiority of Google News to other corpora is minor for this task. Another interesting observation is that word embeddings trained from</p><p>PubMed have the best performance for the DrugBank corpus while these from Google News perform the best for the MedLine corpus. Though MedLine abstracts are from PubMed articles, this result shows that word embeddings trained from the same corpus are not necessarily superior to other embeddings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION AND DISCUSSION</head><p>In this study, we provided an empirical evaluation of word embeddings trained from four different resources, namely clinical notes, biomedical publications, Wikipedia, and news. We performed the evaluation qualitatively and quantitatively. In qualitative evaluation, we selected a set of medical words and evaluated the five most similar medical words. We then analyzed word embeddings through the visualization of those word embeddings.</p><p>We conducted extrinsic and intrinsic evaluation for quantitative evaluation. Intrinsic evaluation directly tested semantic relationships between medical words using four published datasets for measuring semantic similarity between medical terms while extrinsic evaluation evaluated word embeddings in three downstream biomedical NLP applications, i.e., clinical IE, biomedical IR, and RE.</p><p>Based on the evaluation results, we can draw the following conclusions. First, the word embeddings trained on EHR and PubMed can capture the semantics of medical terms better than those trained on GloVe and Google News and find more relevant similar medical terms. However, EHR finds similar terms vis a vis clinical language while PubMed contains more medical terminology used in medical articles, and finds similar words mostly from a medical research perspective. Second, the medical semantic similarity captured by the word embeddings trained on EHR and PubMed are closer to human experts' judgments, compared to these trained on GloVe and Google News.</p><p>Third, there does not exist a consistent global ranking of word embedding quality for downstream biomedical NLP applications. However, adding word embeddings as extra features will improve results on most downstream tasks.</p><p>Finally, word embeddings trained from biomedical domain corpora do not necessarily have better performance than those trained on other general domain corpora. That is, there might be no significant difference when word embeddings trained from an out-domain corpus were employed for a biomedical NLP application. However, the performance of word embeddings trained from a local corpus is better for local NLP tasks.</p><p>In a biomedical NLP application, our experiment implicitly show that applying word embeddings trained from corpora in a general domain, such as Wikipedia and news, is not significantly inferior to applying those obtained from biomedical or clinical domain, which is usually difficult to access due to privacy. This result is consistent with but more general than the conclusion drawn in <ref type="bibr" target="#b31">[32]</ref>. Thus, lack of access to a domain-specific corpus is not necessarily a barrier to the use of word embeddings in practical implementations.</p><p>As a future direction, we would like to evaluate word embeddings on more downstream biomedical NLP applications, such as medial named entity recognition and clinical note summarization. We will investigate whether different word embeddings represent language characteristics differently for a corpus, such as term frequency and medical concepts. We also want to assess word embeddings across health care institutions using different EHR systems and investigate how sublanguage characteristics affect the portability of word embeddings. Moreover, we want to apply clustering methods on word embeddings and compare the word-level and concept-level difference between clusters of medical terms.</p></div>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>TheFig. 1 :</head><label>1</label><figDesc>dyspnea example in the symptom category demonstrates the advantage of EHR and PubMed. EHR finds palpitations, a common cause of dyspnea, and orthopnea, exertional, and doe (dyspnea on exertion) are synonyms or specific conditions for dyspnea. PubMed finds related symptoms, sweats and orthopnea, a synonym breathlessness, a relevant disorder hypotension, and a term relevant to the symptom rhonchi. Wikipedia finds synonyms shortness and breathlessness, and less relevant symptoms cyanosis and photophobia. Google News finds less relevant symptoms pruritus and rhinorrhea and less relevant disease nasopharyngitis. Similar observations can be found for sore throat and low blood pressure as well. The drug category further differentials the word embeddings. In opioid, EHR finds opiate, benzodiazepine, sedative, polypharmacy, which are very relevant medications. PubMed finds nmda receptor, affective motivational, Example clusters in different word embeddings. naloxone precipitated, hyperlocomotion, which are related to the mechanism of action of opioid. GloVe finds analgesic and less relevant anti-inflammatory, and Google News finds opioid-related phrases and relevant term antipsychotics. In aspirin, EHR also finds very clinically relevant used terms and PubMed finds relevant terms in research articles while GloVe and Google News only find medication names.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 1adepicts a cluster of symptoms in word embeddings trained on EHR, such as "heartburn", "vomiting" and "nausea". As shown inFigure 1b, a cluster of an antibiotic medications can be obviously observed from PubMed embeddings, such as "bacitracin", "cefoxitin", and "chloramphenicol".Figures 1c and 1dillustrate clusters of symptoms in word embeddings trained from GloVe and Google News, respectively. Since we did not employ any clustering method, these clusters were intuitively observed from the visualization. The visualization of the whole 377 medical terms can be found in Appendix B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>that consists of 30 medical term pairs that were scored by physician experts according to their relatedness. The second is Hliaoutakis's dataset<ref type="bibr" target="#b28">[29]</ref> consisting of 34 medical term pairs with similarity scores obtained by human judgments. The third one is MayoSRS dataset, developed by Pakhomov et al<ref type="bibr" target="#b29">[30]</ref>, which consists of 101 clinical term pairs whose relatedness was determined by nine medical coders and three physicians from the Mayo Clinic. The relatedness of each term pair was assessed based on a four point scale: (4.0) practically synonymous, (3.0) related, (2.0) marginally related and (1.0) unrelated. We evaluated word embeddings on the mean score of the physicians and medical coders. The fourth is UMNSRS similarity dataset, also developed by Pakhomov et al<ref type="bibr" target="#b30">[31]</ref>, which consists of 566 medical term pairs whose semantic similarity was determined independently by eight medical residents from the University of Minnesota Medical School. The similarity and relatedness of each term pair was annotated based on a continuous scale by having the resident touch a bar on a touch sensitive computer screen to indicate the degree of similarity or relatedness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>For a clinical document d = {w 1 , w 2 , .., w M } where w i , i = 1, 2, ..., M is the ith word and M is the total number of words in this document, the feature vector x of document d is defined by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 :Fig. 3 :</head><label>23</label><figDesc>Visualization of word embeddings trained on EHR. Visualization of word embeddings trained on PuBMed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 :Fig. 5 :</head><label>45</label><figDesc>Visualization of word embeddings trained on GloVe. Visualization of word embeddings trained on Google News.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The first corpus, denoted as EHR, was from the Electronic Health Record system at Mayo Clinic. It contains textual clinical notes for a cohort of 113k patients receiving their primary care at Mayo Clinic, spanning a period of 15 years from 1998 to 2013. The vocabulary size |V | of this corpus is 103k. The second corpus, denoted as PubMed, is from a snapshot of the Open Access Subset of PMC in 2016. PMC is an online digital database of freely available full-text biomedical literature.The PubMed contains 1.25 million biomedical articles and 2 million distinct words (i.e., |V |). As comparisons, two additional public pre-trained word embeddings from two general English resources, i.e., Google News embeddings</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>An example of the "Family history" section.</figDesc><table><row><cell>MOTHER</cell></row><row><cell>Stroke/TIA</cell></row><row><cell>BROTHERS</cell></row><row><cell>brothers alive 1 brother deceased</cell></row><row><cell>SISTERS</cell></row><row><cell>2 sisters alive</cell></row><row><cell>DAUGHTERS</cell></row><row><cell>1 daughter alive</cell></row><row><cell>Heart disease</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II :</head><label>II</label><figDesc>An example of the "Family history" section.</figDesc><table><row><cell>Height: 149.1 cm. Weight: 44.5 kg. BSA(G): 1.3573 M2. BMI: 20.02 KG/M2.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III :</head><label>III</label><figDesc>Selected medical words and their five most similar words induced by different word embeddings.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">VI. QUANTITATIVE EVALUATION</cell><cell></cell><cell></cell></row><row><cell>Semantic</cell><cell>Target Word</cell><cell>EHR</cell><cell>PubMed</cell><cell>GloVe</cell><cell>Google News</cell></row><row><cell>Category</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>diabetes</cell><cell>mellitus,</cell><cell>cardiovascular,</cell><cell>hypertension,</cell><cell>diabetics,</cell></row><row><cell>Disorder</cell><cell></cell><cell>uncontrolled,</cell><cell>nonalcoholic,</cell><cell>obesity,</cell><cell>hypertension,</cell></row><row><cell></cell><cell></cell><cell>cholesterolemia,</cell><cell>obesity,</cell><cell>arthritis,</cell><cell>diabetic,</cell></row><row><cell></cell><cell></cell><cell>dyslipidemia,</cell><cell>mellitus,</cell><cell>cancer,</cell><cell>diabetes mellitus,</cell></row><row><cell></cell><cell></cell><cell>melitis</cell><cell>polycystic</cell><cell>alzheimer</cell><cell>heart disease</cell></row><row><cell></cell><cell>peptic ulcer disease</cell><cell>scleroderma,</cell><cell>gastritis,</cell><cell>ulcers,</cell><cell>ichen planus,</cell></row><row><cell></cell><cell></cell><cell>duodenal,</cell><cell>alcoholism,</cell><cell>arthritis,</cell><cell>Candida infection,</cell></row><row><cell></cell><cell></cell><cell>crohn,</cell><cell>rheumatic,</cell><cell>diseases,</cell><cell>vaginal yeast infections,</cell></row><row><cell></cell><cell></cell><cell>gastroduodenal,</cell><cell>ischaemic,</cell><cell>diabetes,</cell><cell>oral thrush,</cell></row><row><cell></cell><cell></cell><cell>diverticular</cell><cell>nephropathy</cell><cell>stomach</cell><cell>dermopathy</cell></row><row><cell></cell><cell>colon cancer</cell><cell>breast,</cell><cell>breast,</cell><cell>breast,</cell><cell>breast,</cell></row><row><cell></cell><cell></cell><cell>ovarian,</cell><cell>mcf,</cell><cell>prostate,</cell><cell>prostate,</cell></row><row><cell></cell><cell></cell><cell>prostate,</cell><cell>cancers,</cell><cell>cancers,</cell><cell>tumor,</cell></row><row><cell></cell><cell></cell><cell>postmenopausally,</cell><cell>tumor suppressing,</cell><cell>tumor,</cell><cell>pre cancerous lesion,</cell></row><row><cell></cell><cell></cell><cell>caner</cell><cell>downregulation</cell><cell>liver</cell><cell>cancerous polyp</cell></row><row><cell></cell><cell>dyspnea</cell><cell>palpitations,</cell><cell>sweats,</cell><cell>shortness,</cell><cell>dyspnoea,</cell></row><row><cell>Symptom</cell><cell></cell><cell>orthopnea,</cell><cell>orthopnea,</cell><cell>breathlessness,</cell><cell>pruritus,</cell></row><row><cell></cell><cell></cell><cell>exertional,</cell><cell>breathlessness,</cell><cell>cyanosis,</cell><cell>nasopharyngitis,</cell></row><row><cell></cell><cell></cell><cell>doe,</cell><cell>hypotension,</cell><cell>photophobia,</cell><cell>symptom severity,</cell></row><row><cell></cell><cell></cell><cell>dyspnoea</cell><cell>rhonchi</cell><cell>faintness</cell><cell>rhinorrhea</cell></row><row><cell></cell><cell>sore throat</cell><cell>scratchy,</cell><cell>runny,</cell><cell>shoulder,</cell><cell>soreness,</cell></row><row><cell></cell><cell></cell><cell>thoat,</cell><cell>rhinorrhea,</cell><cell>stomach,</cell><cell>bruised,</cell></row><row><cell></cell><cell></cell><cell>cough,</cell><cell>myalgia,</cell><cell>nose,</cell><cell>inflammed,</cell></row><row><cell></cell><cell></cell><cell>runny,</cell><cell>swab fecal,</cell><cell>chest,</cell><cell>contusion,</cell></row><row><cell></cell><cell></cell><cell>thraot</cell><cell>nose</cell><cell>neck</cell><cell>sore triceps</cell></row><row><cell></cell><cell>low blood pressure</cell><cell>readings,</cell><cell>dose,</cell><cell>because,</cell><cell>splattering tombstones,</cell></row><row><cell></cell><cell></cell><cell>pressue,</cell><cell>cardio ankle,</cell><cell>result,</cell><cell>Zapping nerves helps,</cell></row><row><cell></cell><cell></cell><cell>presssure,</cell><cell>ncbav,</cell><cell>high,</cell><cell>pressue,</cell></row><row><cell></cell><cell></cell><cell>bptru,</cell><cell>preload,</cell><cell>enough,</cell><cell>Marblehead Swampscott VNA,</cell></row><row><cell></cell><cell></cell><cell>systolically</cell><cell>gr</cell><cell>higher</cell><cell>pill Norvasc</cell></row><row><cell>Drug</cell><cell>opioid</cell><cell>opiate, benzodiazepine,</cell><cell>opioids, nmda receptor,</cell><cell>analgesic, opiate,</cell><cell>opioids, opioid analgesics,</cell></row><row><cell></cell><cell></cell><cell>opioids,</cell><cell>affective motivational,</cell><cell>opioids,</cell><cell>opioid painkillers,</cell></row><row><cell></cell><cell></cell><cell>sedative,</cell><cell>naloxone precipitated,</cell><cell>anti-inflammatory,</cell><cell>antipsychotics,</cell></row><row><cell></cell><cell></cell><cell>polypharmacy</cell><cell>hyperlocomotion</cell><cell>analgesics</cell><cell>tricyclic antidepressants</cell></row><row><cell></cell><cell>aspirin</cell><cell>ecotrin,</cell><cell>chads,</cell><cell>ibuprofen,</cell><cell>dose aspirin,</cell></row><row><cell></cell><cell></cell><cell>uncoated,</cell><cell>vasc,</cell><cell>tamoxifen,</cell><cell>ibuprofen,</cell></row><row><cell></cell><cell></cell><cell>nonenteric,</cell><cell>newer,</cell><cell>pills,</cell><cell>statins,</cell></row><row><cell></cell><cell></cell><cell>effient,</cell><cell>cha,</cell><cell>statins,</cell><cell>statin,</cell></row><row><cell></cell><cell></cell><cell>onk</cell><cell>angina</cell><cell>medication</cell><cell>calcium supplements</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV :</head><label>IV</label><figDesc>Pearson correlation coefficient for four datasets.</figDesc><table><row><cell>Dataset</cell><cell>EHR</cell><cell cols="3">PubMed GloVe Google News</cell></row><row><cell>Pedersen's</cell><cell>0.632</cell><cell>0.569</cell><cell>0.403</cell><cell>0.357</cell></row><row><cell cols="2">Hliaoutakis's 0.482</cell><cell>0.311</cell><cell>0.247</cell><cell>0.243</cell></row><row><cell>MayoSRS</cell><cell>0.412</cell><cell>0.300</cell><cell>0.082</cell><cell>0.084</cell></row><row><cell>UMNSRS</cell><cell>0.440</cell><cell>0.404</cell><cell>0.177</cell><cell>0.154</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table V</head><label>V</label><figDesc>Since this task is a medical task with specific medical terminologies, word embeddings trained on Google News have the worst performance. However, the word embeddings trained on GloVe are close to those trained on EHR with 0.02 difference on F1 score without statistically significance (p&lt;0.01). This experiment shows that word embeddings trained on local corpus have the best performance for a local task but those trained on external Wikipedia corpus also have comparable performance.</figDesc><table /><note>reports the means of precision, recall, and F1 score from the cross validation. The word embeddings trained from EHR are superior to other word embeddings on all metrics (precision: 0.974, recall: 0.972, F1 score: 0.972). The fracture dataset in this experiment is curated from the same EHR system as the EHR corpus used to train word embeddings, and thus they have identical sublanguage characteristics embedded in word embeddings. The word embeddings trained on PubMed also have comparable results (precision: 0.946, recall: 0.943, F1 score: 0.942).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE V :</head><label>V</label><figDesc>Results on the institutional fracture extraction task.We secondly tested word embeddings on the i2b2 (Informatics for Integrating Biology to the Bedside) 2006 smoking status extraction shared task<ref type="bibr" target="#b50">[51]</ref>. Participants of this task were asked to develop automatic NLP systems to determine the smoking status of patients from their discharge records in Partners HealthCare. For each discharge record, an automatic system should be able to categorize it into five pre-determined smoking status categories: past smoker, current smoker, smoker, non-smoker, and unknown, where a past and current smoker are distinguished based on temporal expressions in the patient's medical records. The dataset contains a total of 389 documents, including 35 documents of current smoker, 66 of non-smoker, 36 of past smoker, and 252 of unknown.The experimental results are shown inTable VI. First, it is obviously shown that word embedding features perform better than term frequency features due to the semantics embedded in word embeddings. FromTable VI,</figDesc><table><row><cell>Metric</cell><cell>baseline</cell><cell>EHR</cell><cell cols="3">PubMed GloVe Google News</cell></row><row><cell>Precision</cell><cell>0.612</cell><cell>0.974</cell><cell>0.946</cell><cell>0.951</cell><cell>0.809</cell></row><row><cell>Recall</cell><cell>0.612</cell><cell>0.972</cell><cell>0.943</cell><cell>0.950</cell><cell>0.856</cell></row><row><cell>F1 score</cell><cell>0.609</cell><cell>0.972</cell><cell>0.942</cell><cell>0.950</cell><cell>0.823</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VI :</head><label>VI</label><figDesc>Results on the i2b2 2006 smoking status extraction task. We utilized Text REtreival Conference 2016 Clinical Decision Support (TREC 2016 CDS) track as the experimental data sets for evaluating word embeddings for biomedical IR. TREC CDS track focuses on biomedical literature retrieval that helps physicians find the precise literature information and make the best clinical decision at the point of care<ref type="bibr" target="#b52">[53]</ref>. EHRs from MIMIC-III data set<ref type="bibr" target="#b53">[54]</ref> were utilized to generate the query topics. Those topics are categorized into three most common types, namely Diagnosis, Test and Treatment, according to physicians' information needs, and 10 topics are provided for each type. Each topic is comprised of a note field (admission note), a description field (jargons and clinical abbreviations are removed) and a summary field (simplified version of the description). The participants are required to use only one of these three fields in their submissions and at least one submission must utilize the note field. Submitted systems should</figDesc><table><row><cell>Metric</cell><cell>baseline</cell><cell>EHR</cell><cell cols="3">PubMed GloVe Google News</cell></row><row><cell>Precision</cell><cell>0.692</cell><cell>0.919</cell><cell>0.878</cell><cell>0.893</cell><cell>0.910</cell></row><row><cell>Recall</cell><cell>0.486</cell><cell>0.903</cell><cell>0.871</cell><cell>0.889</cell><cell>0.905</cell></row><row><cell>F1 score</cell><cell>0.539</cell><cell>0.900</cell><cell>0.867</cell><cell>0.884</cell><cell>0.897</cell></row><row><cell cols="2">2) Biomedical Information Retrieval:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>retrieve relevant biomedical articles from a given PMC article collection for each given query topic to answer three corresponding clinical questions: What is the patient's diagnosis? What tests should the patient receive? How should the patient be treated?. Each IR system can retrieve up to 1000 documents per query.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VII :</head><label>VII</label><figDesc>Results on the TREC 2016 CDS track.</figDesc><table><row><cell>Metric</cell><cell>baseline</cell><cell>EHR</cell><cell cols="3">PubMed GloVe Google News</cell></row><row><cell>infNDCG</cell><cell>0.249</cell><cell>0.250</cell><cell>0.249</cell><cell>0.249</cell><cell>0.238</cell></row><row><cell>infAP</cell><cell>0.058</cell><cell>0.056</cell><cell>0.055</cell><cell>0.051</cell><cell>0.052</cell></row><row><cell>P@10</cell><cell>0.247</cell><cell>0.243</cell><cell>0.248</cell><cell>0.233</cell><cell>0.243</cell></row><row><cell>MAP</cell><cell>0.067</cell><cell>0.063</cell><cell>0.065</cell><cell>0.063</cell><cell>0.059</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE VIII :</head><label>VIII</label><figDesc>F1 scores on the DDIExtraction 2013 challenge.</figDesc><table><row><cell>Category</cell><cell>baseline</cell><cell>EHR</cell><cell cols="3">PubMed GloVe Google News</cell></row><row><cell>DrugBank (5265 pairs)</cell><cell>0.590</cell><cell>0.708</cell><cell>0.715</cell><cell>0.714</cell><cell>0.705</cell></row><row><cell>MedLine (451 pairs)</cell><cell>0.690</cell><cell>0.696</cell><cell>0.690</cell><cell>0.699</cell><cell>0.708</cell></row><row><cell>Total (5716 pairs)</cell><cell>0.760</cell><cell>0.789</cell><cell>0.788</cell><cell>0.787</cell><cell>0.790</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE IX :</head><label>IX</label><figDesc>Pearson correlation coefficient for four datasets.</figDesc><table><row><cell>Dataset</cell><cell>EHR</cell><cell>EHR</cell><cell>EHR</cell><cell>PubMed</cell><cell>PubMed</cell><cell>PubMed</cell><cell>GloVe</cell><cell>GloVe</cell><cell>Google News</cell></row><row><cell></cell><cell>(d=20)</cell><cell>(d=60)</cell><cell>(d=100)</cell><cell>(d=20)</cell><cell>(d=60)</cell><cell>(d=100)</cell><cell>(d=50)</cell><cell>(d=100)</cell><cell>(d=300)</cell></row><row><cell>Pedersen's</cell><cell>0.390</cell><cell>0.542</cell><cell>0.632</cell><cell>0.304</cell><cell>0.569</cell><cell>0.363</cell><cell>0.334</cell><cell>0.403</cell><cell>0.357</cell></row><row><cell cols="2">Hliaoutakis's 0.333</cell><cell>0.417</cell><cell>0.482</cell><cell>0.117</cell><cell>0.311</cell><cell>0.164</cell><cell>0.159</cell><cell>0.247</cell><cell>0.243</cell></row><row><cell>MayoSRS</cell><cell>0.192</cell><cell>0.296</cell><cell>0.412</cell><cell>0.177</cell><cell>0.300</cell><cell>0.154</cell><cell>0.001</cell><cell>0.082</cell><cell>0.084</cell></row><row><cell>UMNSRS</cell><cell>0.310</cell><cell>0.375</cell><cell>0.440</cell><cell>0.295</cell><cell>0.404</cell><cell>0.396</cell><cell>0.190</cell><cell>0.177</cell><cell>0.154</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit 2 https://nlp.stanford.edu/projects/glove/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing<ref type="bibr" target="#b11">12</ref> http://nlp.stanford.edu/data/glove.6B.zip<ref type="bibr" target="#b12">13</ref> https://catalog.ldc.upenn.edu/LDC2011T07</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">http://www.ncbi.nlm.nih.gov/books/NBK3827/table/pubmedhelp.T.stopwords/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">hlt-Naacl</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Learning for biomedical information extraction: Methodological review of recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jagannatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.07993</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dependency-based word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Clinical information extraction applications: A literature review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rastegar-Mojarad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Employing word representations and regularization for domain adaptation of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="68" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Word embedding based generalized language model for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="795" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning sentiment-specific word embedding for twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1555" to="1565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning word vectors for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="142" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploring models and data for image question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2953" to="2961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Question answering over freebase with multi-column convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extractive summarization by maximizing semantic volume</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="1961" to="1966" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00685</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evaluating word representation features in biomedical named entity recognition tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMed research international</title>
		<imprint>
			<biblScope unit="volume">2014</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Effects of semantic features on machine learning-based drug name recognition systems: word embeddings vs. manually constructed dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="848" to="865" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mining and ranking biomedical synonym candidates from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Jagannatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Workshop on Health Text Mining and Information Analysis (Louhi)</title>
		<meeting>the Sixth International Workshop on Health Text Mining and Information Analysis (Louhi)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="142" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A crd-wel system for chemical-disease relations extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The fifth BioCreative challenge evaluation workshop</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Drug-drug interaction extraction via convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational and mathematical methods in medicine</title>
		<imprint>
			<biblScope unit="volume">2016</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dependency embeddings and amr embeddings for drug-drug interaction extraction from biomedical texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rastegar-Mojarad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics</title>
		<meeting>the 8th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A general protein-protein interaction extraction architecture based on word representation and feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Data Mining and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="276" to="291" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cbnu at trec 2016 clinical decision support track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text REtrieval Conference (TREC 2016)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An ensemble model of clinical information extraction and information retrieval for clinical decision support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rastegar-Mojarad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Elayavilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Clinical abbreviation disambiguation using neural word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Workshop on Biomedical Natural Language Processing</title>
		<meeting>the 2015 Workshop on Biomedical Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="171" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semi-supervised information retrieval system for clinical decision support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gurulingappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Toldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schepers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Megaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Knowledge discovery from biomedical ontologies in cross domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">160005</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Predicate oriented pattern analysis for biomedical knowledge discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intelligent Information Management</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">03</biblScope>
			<biblScope unit="page" from="66" to="85" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bmqgen: Biomedical query generator for knowledge discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on</title>
		<imprint>
			<publisher>BIBM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1092" to="1097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Measures of semantic similarity and relatedness in the biomedical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Chute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="288" to="299" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semantic similarity measures in mesh ontology and their application to information retrieval on medline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hliaoutakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Master&apos;s thesis</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards a framework for developing semantic relatedness reference standards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Melton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Chute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="265" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semantic similarity and relatedness between clinical terms: an experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Melton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA annual symposium proceedings</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">572</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Corpus domain effects on distributional semantic modeling of medical terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcewan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Melton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3635" to="3644" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Contextual correlates of synonymy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rubenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Goodenough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="627" to="633" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Placing search in context: The concept revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wolfman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th international conference on World Wide Web</title>
		<meeting>the 10th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="406" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A solution to plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">211</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Attributes in lexical acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Almuhareb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of Essex</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dependency-based construction of semantic space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="199" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Evaluation methods for unsupervised word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="298" to="307" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Word emdeddings through hellinger pca</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lebret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5542</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing</title>
		<meeting>the 2014 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Two step cca: A new spectral method for estimating vector models of words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rodu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.6403</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Very sparse random projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Church</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Word embedding evaluation and combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghannay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Esteve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Camelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cslm-a modular open-source continuous space language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1198" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Evaluating word embeddings using a representative suite of practical tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Systematic analysis of free-text family history in electronic health record</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rastegar-Mojarad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMIA Summits on Translational Science Proceedings</title>
		<imprint>
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page">104</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Identifying patient smoking status from medical discharge records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ö</forename><surname>Uzuner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kohane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="24" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">A distant supervision paradigm for clinical information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Overview of the trec 2016 clinical decision support track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mimic-iii, a freely accessible critical care database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">H</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Indri: A language model-based search engine for complex queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Two-stage language models for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 25th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A simple and efficient sampling method for estimating ap and ndcg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="603" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Segura Bedmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herrero Zazo</surname></persName>
		</author>
		<title level="m">Semeval-2013 task 9: Extraction of drug-drug interactions from biomedical texts</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
